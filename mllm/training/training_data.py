import torch
from dataclasses import dataclass



@dataclass
class TensorTrajectory:
    input_ids:      torch.LongTensor # (Nt,)
    action_mask:    torch.BoolTensor # (Nt,)
    timesteps:      torch.IntTensor # (Nt,)
    state_ends_idx:     torch.BoolTensor # (Ns,)
    rewards:        torch.FloatTensor # (Ns,)
    """
    Entries:
        input_ids:
            Shape (Nt,) where `Nt` is is the number of tokens.
            All of the tokens of both the user and the assistant, flattened.
        action_mask:
            Shape (Nt,)
            Set to true on the tokens of the assistant (tokens generated by the model).
        timesteps:
            Shape (Nt,)
            Therefore, max(timesteps) = Ns - 1.
        state_ends_idx:
            Shape (Ns,) where `Ns` is the number of states.
            Indices of the tokens at which state descriptions end.
        rewards:
            Shape (Ns,).
            rewards[t] := R_t(s_t, a_t)
    Example:
        position:       "0  1  2  3  4  5  6  7  8  9  10 11 12 13 14"
        input_ids:      "U  U  U  a  a  a  U  a  U  a  a  a  U  U  U" (U := User, A := Assistant)
        action_mask:    "x  x  x  ✓  ✓  ✓  x  ✓  x  ✓  ✓  ✓  x  x  x"
        timestep:       "0  0  0  0  0  0  1  1  1  1  1  1  2  2  2"
        state_ends_dx:  [2, 6, 14]
        rewards:        [r0, r1, r2]
    """

def is_not_element(key: slice):
    # TODO
    pass



NestedLongTensors = torch.LongTensor
NestedFloatTensors = torch.FloatTensor
NestedBoolTensors = torch.BoolTensor
NestedIntTensors = torch.IntTensor

@dataclass
class TrajectoryBatch:
    """
    Tensorized batch of trajectories.
    """
    batch_input_ids:      NestedLongTensors
    batch_action_mask:    NestedBoolTensors
    batch_timesteps:      NestedIntTensors
    batch_state_ends_idx: NestedBoolTensors
    batch_rewards:        NestedFloatTensors

    def __getitem__(self, key) -> TrajectoryBatch:
        if isinstance(key, slice):
            ret = TrajectoryBatch(
                batch_input_ids = self.batch_input_ids.__getitem__(key),
                batch_action_mask = self.batch_action_mask.__getitem__(key),
                batch_timesteps = self.batch_timesteps.__getitem__(key),
                batch_state_ends_idx = self.batch_state_ends_idx.__getitem__(key),
                batch_rewards = self.batch_state_ends_idx.__getitem__(key)
            )
            return ret

    def __len__(self):
        return self.batch_input_ids

    def get_padded_input_ids(self, padding: float):
        """
        TOWRITE
        """
        padded_batch_input_ids = torch.nested.to_padded_tensor(self.batch_input_ids, padding=padding)
        return padded_batch_input_ids

timestep = int


@dataclass
class TrainingBatch:
    batch_input_ids:      NestedLongTensors
    batch_action_mask:    NestedBoolTensors
    batch_credits:        NestedFloatTensors

    def __getitem__(self, key) -> TrainingBatch:
        if isinstance(key, slice):
            ret = TrainingBatch(
                batch_input_ids = self.batch_input_ids.__getitem__(key),
                batch_action_mask = self.batch_action_mask.__getitem__(key),
                batch_credits = self.batch_credits.__getitem__(key),
            )
            return ret

    def __len__(self):
        return self.batch_input_ids.__len__()

    def get_padded_tensors(self, padding: torch.FloatType):
        """
        TOWRITE
        Always pad to the right.
        """
        padded_batch_input_ids = torch.nested.to_padded_tensor(self.batch_input_ids, padding=padding)
        padded_batch_action_mask = torch.nested.to_padded_tensor(self.batch_action_mask, padding=padding)
        padded_batch_credits = torch.nested.to_padded_tensor(self.batch_credits, padding=padding)

        @dataclass
        class PaddedTensorTrainingBatch:
            batch_input_ids:      torch.LongTensor
            batch_action_mask:    torch.BoolTensor
            batch_credits:        torch.FloatTensor

        return PaddedTensorTrainingBatch(padded_batch_input_ids, padded_batch_action_mask, padded_batch_credits)

timestep = int
