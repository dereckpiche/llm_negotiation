/home/mila/d/dereck.piche/llm_negotiation/src/run.py:14: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../conf", config_name="config")
[2025-01-08 17:08:39,478][root][INFO] - Loading VLLM model.
WARNING 01-08 17:08:39 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:08:39 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:08:40 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:08:41 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:08:41,285][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:08:42,608][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:08:42,995][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 17:08:44,290][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 17:08:45,628][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 17:08:45,629][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:08:45 model_runner.py:926] Loading model weights took 14.9927 GB
INFO 01-08 17:09:00 gpu_executor.py:122] # GPU blocks: 19859, # CPU blocks: 2048
INFO 01-08 17:09:01 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:09:01 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:09:20 model_runner.py:1335] Graph capturing finished in 19 secs.
[2025-01-08 17:09:20,590][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:21,971][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:01<00:20,  1.38s/it, est. speed input: 365.77 toks/s, output: 42.01 toks/s]
[2025-01-08 17:09:22,142][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:01<00:05,  2.37it/s, est. speed input: 976.47 toks/s, output: 119.88 toks/s]
[2025-01-08 17:09:22,265][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:01<00:02,  4.24it/s, est. speed input: 1508.52 toks/s, output: 201.33 toks/s]
[2025-01-08 17:09:22,491][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:01<00:01,  5.43it/s, est. speed input: 1859.76 toks/s, output: 272.52 toks/s]
[2025-01-08 17:09:22,668][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:02<00:01,  6.76it/s, est. speed input: 2188.36 toks/s, output: 347.63 toks/s]
[2025-01-08 17:09:22,867][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:02<00:00,  7.63it/s, est. speed input: 2439.94 toks/s, output: 419.02 toks/s]
[2025-01-08 17:09:23,339][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:02<00:00,  6.02it/s, est. speed input: 2388.66 toks/s, output: 447.89 toks/s]
[2025-01-08 17:09:23,815][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:03<00:00,  5.28it/s, est. speed input: 2349.16 toks/s, output: 488.13 toks/s]
[2025-01-08 17:09:23,816][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.96it/s, est. speed input: 2505.58 toks/s, output: 546.39 toks/s]
[2025-01-08 17:09:23,820][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:24,292][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  2.12it/s, est. speed input: 1275.40 toks/s, output: 61.44 toks/s]
[2025-01-08 17:09:24,319][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  4.00it/s, est. speed input: 2671.34 toks/s, output: 120.15 toks/s]
[2025-01-08 17:09:24,334][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:25,493][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:01<00:15,  1.16s/it, est. speed input: 603.51 toks/s, output: 32.81 toks/s]
[2025-01-08 17:09:25,678][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:01<00:07,  1.71it/s, est. speed input: 1040.72 toks/s, output: 65.51 toks/s]
[2025-01-08 17:09:26,078][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:01<00:05,  2.00it/s, est. speed input: 1202.89 toks/s, output: 94.07 toks/s]
[2025-01-08 17:09:26,187][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:01<00:01,  5.17it/s, est. speed input: 2263.82 toks/s, output: 220.23 toks/s]
[2025-01-08 17:09:26,392][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:02<00:00,  6.32it/s, est. speed input: 2717.71 toks/s, output: 286.25 toks/s]
[2025-01-08 17:09:26,523][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:02<00:00,  7.98it/s, est. speed input: 3193.62 toks/s, output: 363.68 toks/s]
[2025-01-08 17:09:26,734][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:02<00:00,  8.43it/s, est. speed input: 3495.95 toks/s, output: 427.61 toks/s]
[2025-01-08 17:09:27,089][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  7.26it/s, est. speed input: 3552.24 toks/s, output: 476.24 toks/s]
[2025-01-08 17:09:27,090][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.08it/s, est. speed input: 3552.24 toks/s, output: 476.24 toks/s]
[2025-01-08 17:09:27,105][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:28,496][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:01<00:16,  1.39s/it, est. speed input: 484.84 toks/s, output: 40.28 toks/s]
[2025-01-08 17:09:28,944][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:01<00:09,  1.20it/s, est. speed input: 726.80 toks/s, output: 76.70 toks/s]
[2025-01-08 17:09:29,052][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:01<00:03,  2.89it/s, est. speed input: 1379.74 toks/s, output: 163.92 toks/s]
[2025-01-08 17:09:29,202][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:02<00:02,  3.51it/s, est. speed input: 1588.26 toks/s, output: 200.86 toks/s]
[2025-01-08 17:09:29,304][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:02<00:01,  4.36it/s, est. speed input: 1821.87 toks/s, output: 241.03 toks/s]
[2025-01-08 17:09:29,421][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:02<00:01,  5.13it/s, est. speed input: 2031.65 toks/s, output: 279.38 toks/s]
[2025-01-08 17:09:29,538][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:02<00:00,  9.39it/s, est. speed input: 2799.77 toks/s, output: 416.53 toks/s]
[2025-01-08 17:09:29,810][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:02<00:00,  8.55it/s, est. speed input: 3078.17 toks/s, output: 478.09 toks/s]
[2025-01-08 17:09:30,429][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  3.91it/s, est. speed input: 2727.59 toks/s, output: 446.82 toks/s]
[2025-01-08 17:09:30,433][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:30,971][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.86it/s, est. speed input: 1589.69 toks/s, output: 53.98 toks/s]
[2025-01-08 17:09:31,431][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:00<00:00,  2.03it/s, est. speed input: 1556.27 toks/s, output: 93.19 toks/s]
[2025-01-08 17:09:32,447][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.37it/s, est. speed input: 1024.59 toks/s, output: 116.71 toks/s]
[2025-01-08 17:09:32,447][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.49it/s, est. speed input: 1024.59 toks/s, output: 116.71 toks/s]
[2025-01-08 17:09:32,454][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:33,054][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:00<00:01,  1.67it/s, est. speed input: 1618.98 toks/s, output: 48.35 toks/s]
[2025-01-08 17:09:33,261][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:00<00:00,  2.71it/s, est. speed input: 2083.20 toks/s, output: 90.41 toks/s]
[2025-01-08 17:09:33,643][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.67it/s, est. speed input: 2122.41 toks/s, output: 122.72 toks/s]
[2025-01-08 17:09:33,657][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.32it/s, est. speed input: 2651.20 toks/s, output: 182.84 toks/s]
[2025-01-08 17:09:33,675][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:35,013][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:14,  1.34s/it, est. speed input: 755.89 toks/s, output: 28.41 toks/s]
[2025-01-08 17:09:35,521][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:01<00:08,  1.18it/s, est. speed input: 1123.16 toks/s, output: 58.51 toks/s]
[2025-01-08 17:09:35,631][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:01<00:01,  3.74it/s, est. speed input: 2678.67 toks/s, output: 172.31 toks/s]
[2025-01-08 17:09:35,931][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:02<00:01,  4.55it/s, est. speed input: 3270.89 toks/s, output: 232.30 toks/s]
[2025-01-08 17:09:36,638][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:02<00:00,  3.72it/s, est. speed input: 3202.36 toks/s, output: 266.38 toks/s]
[2025-01-08 17:09:36,957][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:03<00:00,  3.58it/s, est. speed input: 3232.55 toks/s, output: 291.37 toks/s]
[2025-01-08 17:09:37,392][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  3.18it/s, est. speed input: 3143.35 toks/s, output: 311.05 toks/s]
[2025-01-08 17:09:37,392][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.23it/s, est. speed input: 3435.05 toks/s, output: 364.84 toks/s]
[2025-01-08 17:09:37,410][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:39,061][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:18,  1.65s/it, est. speed input: 574.42 toks/s, output: 39.99 toks/s]
[2025-01-08 17:09:39,170][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:01<00:07,  1.34it/s, est. speed input: 1012.21 toks/s, output: 79.00 toks/s]
[2025-01-08 17:09:39,573][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:05,  1.70it/s, est. speed input: 1197.95 toks/s, output: 110.04 toks/s]
[2025-01-08 17:09:39,737][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:02<00:01,  4.25it/s, est. speed input: 2193.23 toks/s, output: 236.81 toks/s]
[2025-01-08 17:09:40,047][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:02<00:01,  3.95it/s, est. speed input: 2281.77 toks/s, output: 258.67 toks/s]
[2025-01-08 17:09:40,224][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:02<00:00,  4.28it/s, est. speed input: 2457.00 toks/s, output: 293.26 toks/s]
[2025-01-08 17:09:40,425][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  4.45it/s, est. speed input: 2612.13 toks/s, output: 325.77 toks/s]
[2025-01-08 17:09:40,555][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:03<00:00,  5.04it/s, est. speed input: 2787.46 toks/s, output: 365.13 toks/s]
[2025-01-08 17:09:41,002][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  3.72it/s, est. speed input: 2694.30 toks/s, output: 375.31 toks/s]
[2025-01-08 17:09:41,003][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.34it/s, est. speed input: 2972.51 toks/s, output: 430.97 toks/s]
[2025-01-08 17:09:41,010][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:41,863][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:00<00:02,  1.17it/s, est. speed input: 1572.23 toks/s, output: 45.76 toks/s]
[2025-01-08 17:09:42,221][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.78it/s, est. speed input: 1963.61 toks/s, output: 85.09 toks/s]
[2025-01-08 17:09:43,222][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.31it/s, est. speed input: 1577.40 toks/s, output: 109.89 toks/s]
[2025-01-08 17:09:43,473][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.78it/s, est. speed input: 1888.37 toks/s, output: 163.22 toks/s]
[2025-01-08 17:09:43,474][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.62it/s, est. speed input: 1888.37 toks/s, output: 163.22 toks/s]
[2025-01-08 17:09:43,481][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:44,374][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:00<00:02,  1.12it/s, est. speed input: 934.92 toks/s, output: 52.62 toks/s]
[2025-01-08 17:09:45,013][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.34it/s, est. speed input: 1114.82 toks/s, output: 90.73 toks/s]
[2025-01-08 17:09:45,408][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  1.71it/s, est. speed input: 1311.24 toks/s, output: 135.43 toks/s]
[2025-01-08 17:09:45,672][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.18it/s, est. speed input: 1645.96 toks/s, output: 183.90 toks/s]
[2025-01-08 17:09:45,672][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.83it/s, est. speed input: 1645.96 toks/s, output: 183.90 toks/s]
[2025-01-08 17:09:45,695][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:47,630][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.93s/it, est. speed input: 729.98 toks/s, output: 30.50 toks/s]
[2025-01-08 17:09:47,841][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:05,  1.72it/s, est. speed input: 1914.41 toks/s, output: 89.48 toks/s]
[2025-01-08 17:09:48,243][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:02<00:01,  3.93it/s, est. speed input: 3900.53 toks/s, output: 203.33 toks/s]
[2025-01-08 17:09:48,427][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:02<00:00,  4.16it/s, est. speed input: 3907.02 toks/s, output: 229.89 toks/s]
[2025-01-08 17:09:48,531][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:02<00:00,  5.78it/s, est. speed input: 4825.62 toks/s, output: 302.61 toks/s]
[2025-01-08 17:09:49,219][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  4.33it/s, est. speed input: 4713.01 toks/s, output: 326.65 toks/s]
[2025-01-08 17:09:49,219][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.41it/s, est. speed input: 4713.01 toks/s, output: 326.65 toks/s]
[2025-01-08 17:09:49,289][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:50,170][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 1241.73 toks/s, output: 69.24 toks/s]
[2025-01-08 17:09:50,170][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 1241.73 toks/s, output: 69.24 toks/s]
[2025-01-08 17:09:50,182][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:51,092][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:00<00:03,  1.10it/s, est. speed input: 1823.77 toks/s, output: 31.88 toks/s]
[2025-01-08 17:09:51,592][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.50it/s, est. speed input: 2403.96 toks/s, output: 65.28 toks/s]
[2025-01-08 17:09:52,081][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:01<00:00,  2.48it/s, est. speed input: 3348.42 toks/s, output: 134.80 toks/s]
[2025-01-08 17:09:52,320][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.84it/s, est. speed input: 3687.54 toks/s, output: 174.93 toks/s]
[2025-01-08 17:09:52,320][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.34it/s, est. speed input: 3687.54 toks/s, output: 174.93 toks/s]
[2025-01-08 17:09:52,356][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:54,132][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 668.47 toks/s, output: 72.08 toks/s]
[2025-01-08 17:09:54,132][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 668.47 toks/s, output: 72.08 toks/s]
[2025-01-08 17:09:54,134][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:09:55,676][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.54s/it, est. speed input: 604.17 toks/s, output: 72.68 toks/s]
[2025-01-08 17:09:55,676][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.54s/it, est. speed input: 604.17 toks/s, output: 72.68 toks/s]
[2025-01-08 17:09:55,964][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:09:56,017][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:09:57,701][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 17:09:59,290][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 17:10:00,858][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 17:10:01,351][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.16s/it]
[2025-01-08 17:10:01,351][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.33s/it]
[2025-01-08 17:10:13,484][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:10:13,994][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:10:14,046][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:10:15,972][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.93s/it]
[2025-01-08 17:10:17,633][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 17:10:19,246][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 17:10:19,740][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:10:19,740][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 17:10:33,995][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:10:34,317][root][INFO] - Loading VLLM model.
WARNING 01-08 17:10:34 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:10:34 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:10:34 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:10:35 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:10:35,709][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:10:37,018][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 17:10:37,403][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 17:10:38,700][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 17:10:40,027][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
[2025-01-08 17:10:40,027][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 17:10:40 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:10:54 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:10:54 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:10:54 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:11:15 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:11:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:15,412][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:19,829][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:06,  4.42s/it, est. speed input: 114.34 toks/s, output: 13.13 toks/s]
[2025-01-08 17:11:20,216][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:16,  1.29s/it, est. speed input: 315.38 toks/s, output: 38.72 toks/s]
[2025-01-08 17:11:20,484][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:05<00:11,  1.07it/s, est. speed input: 398.28 toks/s, output: 51.86 toks/s]
[2025-01-08 17:11:20,679][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:05<00:07,  1.45it/s, est. speed input: 479.42 toks/s, output: 65.70 toks/s]
[2025-01-08 17:11:21,060][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:05<00:04,  2.23it/s, est. speed input: 625.91 toks/s, output: 93.13 toks/s]
[2025-01-08 17:11:21,201][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:02,  2.71it/s, est. speed input: 697.95 toks/s, output: 108.32 toks/s]
[2025-01-08 17:11:21,422][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:06<00:01,  4.68it/s, est. speed input: 924.37 toks/s, output: 156.75 toks/s]
[2025-01-08 17:11:21,871][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:06<00:00,  4.60it/s, est. speed input: 1016.42 toks/s, output: 183.62 toks/s]
[2025-01-08 17:11:21,986][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  6.03it/s, est. speed input: 1152.33 toks/s, output: 221.64 toks/s]
[2025-01-08 17:11:22,103][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.39it/s, est. speed input: 1207.60 toks/s, output: 239.28 toks/s]
WARNING 01-08 17:11:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:22,286][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:23,142][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 703.69 toks/s, output: 33.90 toks/s]
[2025-01-08 17:11:23,727][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.44it/s, est. speed input: 883.73 toks/s, output: 64.56 toks/s]
[2025-01-08 17:11:23,727][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.39it/s, est. speed input: 883.73 toks/s, output: 64.56 toks/s]
WARNING 01-08 17:11:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:23,924][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:27,405][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:45,  3.48s/it, est. speed input: 200.82 toks/s, output: 14.94 toks/s]
[2025-01-08 17:11:28,687][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:04<00:26,  2.19s/it, est. speed input: 293.56 toks/s, output: 29.82 toks/s]
[2025-01-08 17:11:29,278][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:05<00:16,  1.46s/it, est. speed input: 391.72 toks/s, output: 46.70 toks/s]
[2025-01-08 17:11:29,431][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:05<00:06,  1.48it/s, est. speed input: 634.70 toks/s, output: 86.08 toks/s]
[2025-01-08 17:11:29,566][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:05<00:01,  3.03it/s, est. speed input: 991.25 toks/s, output: 145.71 toks/s]
[2025-01-08 17:11:29,947][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:06<00:01,  3.54it/s, est. speed input: 1160.67 toks/s, output: 180.33 toks/s]
[2025-01-08 17:11:30,551][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:06<00:01,  2.89it/s, est. speed input: 1160.38 toks/s, output: 188.34 toks/s]
[2025-01-08 17:11:30,789][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:06<00:00,  3.11it/s, est. speed input: 1221.91 toks/s, output: 207.15 toks/s]
[2025-01-08 17:11:31,083][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:07<00:00,  3.17it/s, est. speed input: 1269.34 toks/s, output: 225.18 toks/s]
[2025-01-08 17:11:31,252][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  3.60it/s, est. speed input: 1335.55 toks/s, output: 247.29 toks/s]
[2025-01-08 17:11:31,252][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.91it/s, est. speed input: 1335.55 toks/s, output: 247.29 toks/s]
WARNING 01-08 17:11:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:31,457][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:34,682][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.22s/it, est. speed input: 204.67 toks/s, output: 17.99 toks/s]
[2025-01-08 17:11:35,527][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:04<00:21,  1.82s/it, est. speed input: 320.47 toks/s, output: 34.65 toks/s]
[2025-01-08 17:11:35,935][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:04<00:08,  1.24it/s, est. speed input: 588.55 toks/s, output: 71.70 toks/s]
[2025-01-08 17:11:36,230][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:05,  1.54it/s, est. speed input: 695.92 toks/s, output: 89.48 toks/s]
[2025-01-08 17:11:36,419][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.57it/s, est. speed input: 949.47 toks/s, output: 130.40 toks/s]
[2025-01-08 17:11:36,813][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  4.49it/s, est. speed input: 1397.87 toks/s, output: 209.33 toks/s]
[2025-01-08 17:11:37,972][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  3.51it/s, est. speed input: 1478.91 toks/s, output: 243.13 toks/s]
[2025-01-08 17:11:37,973][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.15it/s, est. speed input: 1478.91 toks/s, output: 243.13 toks/s]
WARNING 01-08 17:11:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:38,187][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:39,177][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 515.13 toks/s, output: 36.36 toks/s]
[2025-01-08 17:11:39,863][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.23it/s, est. speed input: 721.25 toks/s, output: 67.41 toks/s]
[2025-01-08 17:11:39,863][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.19it/s, est. speed input: 721.25 toks/s, output: 67.41 toks/s]
WARNING 01-08 17:11:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:40,062][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:41,069][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 706.34 toks/s, output: 28.81 toks/s]
[2025-01-08 17:11:41,363][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.70it/s, est. speed input: 1258.46 toks/s, output: 56.89 toks/s]
[2025-01-08 17:11:42,372][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.28it/s, est. speed input: 1061.75 toks/s, output: 77.51 toks/s]
[2025-01-08 17:11:42,372][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.30it/s, est. speed input: 1061.75 toks/s, output: 77.51 toks/s]
WARNING 01-08 17:11:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:42,602][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:46,045][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:41,  3.44s/it, est. speed input: 297.70 toks/s, output: 15.10 toks/s]
[2025-01-08 17:11:46,478][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:18,  1.67s/it, est. speed input: 546.37 toks/s, output: 30.18 toks/s]
[2025-01-08 17:11:47,588][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:14,  1.42s/it, est. speed input: 642.57 toks/s, output: 43.52 toks/s]
[2025-01-08 17:11:47,979][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:05<00:09,  1.01s/it, est. speed input: 815.17 toks/s, output: 61.37 toks/s]
[2025-01-08 17:11:48,118][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:05<00:03,  1.95it/s, est. speed input: 1189.37 toks/s, output: 102.06 toks/s]
[2025-01-08 17:11:48,293][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:05<00:01,  3.04it/s, est. speed input: 1534.39 toks/s, output: 141.79 toks/s]
[2025-01-08 17:11:48,502][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:05<00:01,  3.33it/s, est. speed input: 1668.92 toks/s, output: 159.50 toks/s]
[2025-01-08 17:11:48,902][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:06<00:00,  3.07it/s, est. speed input: 1735.04 toks/s, output: 173.50 toks/s]
[2025-01-08 17:11:49,025][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  3.68it/s, est. speed input: 1879.45 toks/s, output: 194.78 toks/s]
[2025-01-08 17:11:49,796][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:07<00:00,  2.44it/s, est. speed input: 1837.29 toks/s, output: 201.69 toks/s]
[2025-01-08 17:11:49,797][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.81it/s, est. speed input: 1988.59 toks/s, output: 229.48 toks/s]
WARNING 01-08 17:11:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:50,007][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:52,440][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:29,  2.43s/it, est. speed input: 393.79 toks/s, output: 12.74 toks/s]
[2025-01-08 17:11:54,320][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:23,  2.11s/it, est. speed input: 415.10 toks/s, output: 27.60 toks/s]
[2025-01-08 17:11:54,729][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:13,  1.33s/it, est. speed input: 579.21 toks/s, output: 46.59 toks/s]
[2025-01-08 17:11:54,848][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:07,  1.17it/s, est. speed input: 743.25 toks/s, output: 67.14 toks/s]
[2025-01-08 17:11:54,991][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.68it/s, est. speed input: 896.95 toks/s, output: 87.29 toks/s]
[2025-01-08 17:11:55,423][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:05<00:03,  1.85it/s, est. speed input: 972.78 toks/s, output: 103.59 toks/s]
[2025-01-08 17:11:55,633][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:05<00:02,  2.31it/s, est. speed input: 1095.39 toks/s, output: 123.55 toks/s]
[2025-01-08 17:11:55,821][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:05<00:01,  3.71it/s, est. speed input: 1362.93 toks/s, output: 167.53 toks/s]
[2025-01-08 17:11:56,325][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:06<00:00,  3.04it/s, est. speed input: 1397.44 toks/s, output: 180.28 toks/s]
[2025-01-08 17:11:56,750][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  3.57it/s, est. speed input: 1575.12 toks/s, output: 221.41 toks/s]
[2025-01-08 17:11:56,954][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  3.81it/s, est. speed input: 1663.32 toks/s, output: 243.72 toks/s]
[2025-01-08 17:11:56,954][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.87it/s, est. speed input: 1663.32 toks/s, output: 243.72 toks/s]
WARNING 01-08 17:11:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:11:57,171][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:11:59,983][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:02<00:05,  2.81s/it, est. speed input: 478.14 toks/s, output: 39.49 toks/s]
[2025-01-08 17:12:00,259][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:03<00:01,  1.32s/it, est. speed input: 812.08 toks/s, output: 76.77 toks/s]
[2025-01-08 17:12:00,682][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.10it/s, est. speed input: 1013.30 toks/s, output: 110.53 toks/s]
[2025-01-08 17:12:00,682][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.17s/it, est. speed input: 1013.30 toks/s, output: 110.53 toks/s]
WARNING 01-08 17:12:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:00,886][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:01,924][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.04s/it, est. speed input: 790.12 toks/s, output: 27.94 toks/s]
[2025-01-08 17:12:02,898][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:00,  1.00it/s, est. speed input: 930.30 toks/s, output: 55.19 toks/s]
[2025-01-08 17:12:03,705][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.10it/s, est. speed input: 950.07 toks/s, output: 85.50 toks/s]
[2025-01-08 17:12:03,706][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.06it/s, est. speed input: 950.07 toks/s, output: 85.50 toks/s]
WARNING 01-08 17:12:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:03,919][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:07,846][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:47,  3.93s/it, est. speed input: 344.07 toks/s, output: 13.24 toks/s]
[2025-01-08 17:12:08,050][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:19,  1.74s/it, est. speed input: 707.94 toks/s, output: 26.63 toks/s]
[2025-01-08 17:12:08,307][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:10,  1.06s/it, est. speed input: 994.14 toks/s, output: 40.11 toks/s]
[2025-01-08 17:12:08,551][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.35it/s, est. speed input: 1281.32 toks/s, output: 53.98 toks/s]
[2025-01-08 17:12:09,100][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:05<00:05,  1.49it/s, est. speed input: 1430.37 toks/s, output: 66.21 toks/s]
[2025-01-08 17:12:09,378][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:05<00:03,  1.86it/s, est. speed input: 1626.13 toks/s, output: 81.71 toks/s]
[2025-01-08 17:12:09,944][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:06<00:03,  1.83it/s, est. speed input: 1725.01 toks/s, output: 94.62 toks/s]
[2025-01-08 17:12:10,121][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:06<00:02,  2.33it/s, est. speed input: 1937.40 toks/s, output: 113.04 toks/s]
[2025-01-08 17:12:10,303][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:06<00:00,  3.73it/s, est. speed input: 2350.21 toks/s, output: 152.58 toks/s]
[2025-01-08 17:12:10,427][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  4.32it/s, est. speed input: 2402.58 toks/s, output: 171.96 toks/s]
[2025-01-08 17:12:10,703][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  4.11it/s, est. speed input: 2526.07 toks/s, output: 188.54 toks/s]
[2025-01-08 17:12:11,382][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  2.75it/s, est. speed input: 2495.23 toks/s, output: 198.21 toks/s]
[2025-01-08 17:12:11,382][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.74it/s, est. speed input: 2495.23 toks/s, output: 198.21 toks/s]
WARNING 01-08 17:12:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:11,642][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:13,630][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.99s/it, est. speed input: 537.97 toks/s, output: 50.32 toks/s]
[2025-01-08 17:12:13,630][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.99s/it, est. speed input: 537.97 toks/s, output: 50.32 toks/s]
WARNING 01-08 17:12:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:13,829][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:16,049][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.22s/it, est. speed input: 759.31 toks/s, output: 27.49 toks/s]
[2025-01-08 17:12:17,689][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:03<00:03,  1.88s/it, est. speed input: 841.47 toks/s, output: 52.33 toks/s]
[2025-01-08 17:12:18,200][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.16it/s, est. speed input: 1476.28 toks/s, output: 117.84 toks/s]
[2025-01-08 17:12:18,200][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.09s/it, est. speed input: 1476.28 toks/s, output: 117.84 toks/s]
WARNING 01-08 17:12:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:18,435][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:19,959][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.52s/it, est. speed input: 788.49 toks/s, output: 47.27 toks/s]
[2025-01-08 17:12:19,959][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.52s/it, est. speed input: 788.49 toks/s, output: 47.27 toks/s]
WARNING 01-08 17:12:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:12:20,148][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:12:22,255][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.11s/it, est. speed input: 408.69 toks/s, output: 51.74 toks/s]
[2025-01-08 17:12:22,255][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.11s/it, est. speed input: 408.69 toks/s, output: 51.74 toks/s]
[2025-01-08 17:12:27,965][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:12:28,019][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:12:29,689][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 17:12:31,281][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.62s/it]
[2025-01-08 17:12:32,813][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.58s/it]
[2025-01-08 17:12:33,311][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.15s/it]
[2025-01-08 17:12:33,311][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.32s/it]
[2025-01-08 17:12:45,232][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:12:45,771][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:12:45,823][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:12:47,746][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 17:12:49,332][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 17:12:50,878][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 17:12:51,380][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 17:12:51,380][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 17:13:06,366][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:13:06,718][root][INFO] - Loading VLLM model.
WARNING 01-08 17:13:06 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:13:06 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:13:07 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:13:07 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:13:07,655][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:13:08,978][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:13:09,372][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 17:13:10,677][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 17:13:12,022][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:13:12,022][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:13:12 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:13:26 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:13:26 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:13:26 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:13:47 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:13:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:13:47,664][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:13:51,716][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:00,  4.05s/it, est. speed input: 124.63 toks/s, output: 14.31 toks/s]
[2025-01-08 17:13:51,970][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:25,  1.82s/it, est. speed input: 234.59 toks/s, output: 28.57 toks/s]
[2025-01-08 17:13:52,180][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.08s/it, est. speed input: 335.46 toks/s, output: 42.96 toks/s]
[2025-01-08 17:13:52,378][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:05,  1.90it/s, est. speed input: 535.67 toks/s, output: 72.98 toks/s]
[2025-01-08 17:13:52,588][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:04<00:03,  2.96it/s, est. speed input: 717.96 toks/s, output: 103.18 toks/s]
[2025-01-08 17:13:52,729][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:02,  3.45it/s, est. speed input: 797.74 toks/s, output: 117.88 toks/s]
[2025-01-08 17:13:52,835][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:05<00:01,  4.12it/s, est. speed input: 878.96 toks/s, output: 133.44 toks/s]
[2025-01-08 17:13:53,066][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  4.17it/s, est. speed input: 934.92 toks/s, output: 146.63 toks/s]
[2025-01-08 17:13:53,280][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:01,  4.30it/s, est. speed input: 989.12 toks/s, output: 160.79 toks/s]
[2025-01-08 17:13:53,437][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  4.74it/s, est. speed input: 1049.86 toks/s, output: 176.88 toks/s]
[2025-01-08 17:13:53,539][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:05<00:00,  7.17it/s, est. speed input: 1203.54 toks/s, output: 215.17 toks/s]
[2025-01-08 17:13:54,854][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.93it/s, est. speed input: 1123.88 toks/s, output: 224.50 toks/s]
[2025-01-08 17:13:54,854][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.23it/s, est. speed input: 1123.88 toks/s, output: 224.50 toks/s]
WARNING 01-08 17:13:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:13:55,050][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:13:55,915][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 696.37 toks/s, output: 33.55 toks/s]
[2025-01-08 17:13:55,949][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1443.47 toks/s, output: 66.77 toks/s]
WARNING 01-08 17:13:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:13:56,158][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:13:58,877][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.72s/it, est. speed input: 257.13 toks/s, output: 15.82 toks/s]
[2025-01-08 17:13:59,450][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:17,  1.46s/it, est. speed input: 424.75 toks/s, output: 31.29 toks/s]
[2025-01-08 17:13:59,611][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.68it/s, est. speed input: 809.89 toks/s, output: 66.91 toks/s]
[2025-01-08 17:13:59,784][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:03<00:02,  2.82it/s, est. speed input: 1156.71 toks/s, output: 102.05 toks/s]
[2025-01-08 17:13:59,972][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  3.20it/s, est. speed input: 1283.12 toks/s, output: 117.48 toks/s]
[2025-01-08 17:14:00,283][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.21it/s, est. speed input: 1355.72 toks/s, output: 130.43 toks/s]
[2025-01-08 17:14:00,453][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.67it/s, est. speed input: 1465.05 toks/s, output: 147.88 toks/s]
[2025-01-08 17:14:00,701][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:01,  3.76it/s, est. speed input: 1538.73 toks/s, output: 163.56 toks/s]
[2025-01-08 17:14:00,810][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  4.53it/s, est. speed input: 1653.24 toks/s, output: 184.05 toks/s]
[2025-01-08 17:14:01,028][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  4.54it/s, est. speed input: 1722.63 toks/s, output: 201.26 toks/s]
[2025-01-08 17:14:01,267][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  4.43it/s, est. speed input: 1778.99 toks/s, output: 218.68 toks/s]
[2025-01-08 17:14:01,820][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.10it/s, est. speed input: 1728.69 toks/s, output: 227.35 toks/s]
[2025-01-08 17:14:01,820][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.47it/s, est. speed input: 1728.69 toks/s, output: 227.35 toks/s]
WARNING 01-08 17:14:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:02,029][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:05,153][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:40,  3.12s/it, est. speed input: 214.88 toks/s, output: 17.61 toks/s]
[2025-01-08 17:14:05,491][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:17,  1.49s/it, est. speed input: 383.37 toks/s, output: 34.67 toks/s]
[2025-01-08 17:14:05,852][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:10,  1.03it/s, est. speed input: 520.39 toks/s, output: 51.28 toks/s]
[2025-01-08 17:14:06,384][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:05,  1.75it/s, est. speed input: 767.01 toks/s, output: 84.28 toks/s]
[2025-01-08 17:14:06,724][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:04,  1.98it/s, est. speed input: 852.59 toks/s, output: 100.77 toks/s]
[2025-01-08 17:14:06,938][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.38it/s, est. speed input: 957.07 toks/s, output: 119.58 toks/s]
[2025-01-08 17:14:07,084][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:05<00:01,  3.81it/s, est. speed input: 1210.21 toks/s, output: 162.43 toks/s]
[2025-01-08 17:14:07,197][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:00,  4.42it/s, est. speed input: 1319.71 toks/s, output: 183.06 toks/s]
[2025-01-08 17:14:07,306][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  5.11it/s, est. speed input: 1420.47 toks/s, output: 203.93 toks/s]
[2025-01-08 17:14:07,544][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  7.44it/s, est. speed input: 1749.87 toks/s, output: 268.58 toks/s]
[2025-01-08 17:14:07,544][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.54it/s, est. speed input: 1749.87 toks/s, output: 268.58 toks/s]
WARNING 01-08 17:14:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:07,779][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:09,626][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.85s/it, est. speed input: 378.55 toks/s, output: 44.95 toks/s]
[2025-01-08 17:14:09,710][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.04it/s, est. speed input: 626.18 toks/s, output: 88.57 toks/s]
WARNING 01-08 17:14:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:09,905][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:10,774][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 825.43 toks/s, output: 33.38 toks/s]
[2025-01-08 17:14:12,451][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.34s/it, est. speed input: 598.33 toks/s, output: 62.07 toks/s]
[2025-01-08 17:14:12,451][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.27s/it, est. speed input: 598.33 toks/s, output: 62.07 toks/s]
WARNING 01-08 17:14:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:12,689][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:16,575][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:50,  3.89s/it, est. speed input: 268.65 toks/s, output: 15.44 toks/s]
[2025-01-08 17:14:16,782][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:04<00:20,  1.72s/it, est. speed input: 509.68 toks/s, output: 30.79 toks/s]
[2025-01-08 17:14:16,911][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:04<00:06,  1.46it/s, est. speed input: 993.37 toks/s, output: 62.29 toks/s]
[2025-01-08 17:14:17,031][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:04,  1.97it/s, est. speed input: 1207.80 toks/s, output: 77.62 toks/s]
[2025-01-08 17:14:17,231][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.41it/s, est. speed input: 1378.22 toks/s, output: 92.03 toks/s]
[2025-01-08 17:14:17,530][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.64it/s, est. speed input: 1509.26 toks/s, output: 105.34 toks/s]
[2025-01-08 17:14:17,980][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:05<00:01,  3.25it/s, est. speed input: 1792.83 toks/s, output: 135.15 toks/s]
[2025-01-08 17:14:18,138][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  4.63it/s, est. speed input: 2152.04 toks/s, output: 173.43 toks/s]
[2025-01-08 17:14:18,877][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  3.68it/s, est. speed input: 2248.39 toks/s, output: 197.33 toks/s]
[2025-01-08 17:14:19,012][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  4.10it/s, est. speed input: 2366.40 toks/s, output: 219.20 toks/s]
[2025-01-08 17:14:19,012][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.21it/s, est. speed input: 2366.40 toks/s, output: 219.20 toks/s]
WARNING 01-08 17:14:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:19,234][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:21,848][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:36,  2.61s/it, est. speed input: 372.59 toks/s, output: 11.09 toks/s]
[2025-01-08 17:14:23,026][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:23,  1.77s/it, est. speed input: 480.47 toks/s, output: 24.00 toks/s]
[2025-01-08 17:14:23,367][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:04<00:13,  1.12s/it, est. speed input: 634.60 toks/s, output: 39.44 toks/s]
[2025-01-08 17:14:23,654][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:05,  1.77it/s, est. speed input: 983.17 toks/s, output: 71.94 toks/s]
[2025-01-08 17:14:24,306][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:05<00:05,  1.69it/s, est. speed input: 1026.51 toks/s, output: 83.00 toks/s]
[2025-01-08 17:14:24,449][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:05<00:03,  2.17it/s, est. speed input: 1170.23 toks/s, output: 101.43 toks/s]
[2025-01-08 17:14:24,652][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:05<00:01,  4.13it/s, est. speed input: 1624.62 toks/s, output: 159.66 toks/s]
[2025-01-08 17:14:24,918][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:05<00:00,  4.89it/s, est. speed input: 1852.67 toks/s, output: 195.63 toks/s]
[2025-01-08 17:14:25,019][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:05<00:00,  5.43it/s, est. speed input: 1994.31 toks/s, output: 215.19 toks/s]
[2025-01-08 17:14:25,332][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  5.75it/s, est. speed input: 2175.55 toks/s, output: 251.57 toks/s]
[2025-01-08 17:14:25,332][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.46it/s, est. speed input: 2175.55 toks/s, output: 251.57 toks/s]
WARNING 01-08 17:14:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:25,550][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:27,230][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 632.32 toks/s, output: 48.82 toks/s]
[2025-01-08 17:14:27,231][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 632.32 toks/s, output: 48.82 toks/s]
WARNING 01-08 17:14:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:27,423][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:28,180][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1092.05 toks/s, output: 38.34 toks/s]
[2025-01-08 17:14:28,180][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1092.05 toks/s, output: 38.34 toks/s]
WARNING 01-08 17:14:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:28,427][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:33,236][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:04<01:07,  4.81s/it, est. speed input: 288.62 toks/s, output: 13.52 toks/s]
[2025-01-08 17:14:33,658][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:05<00:16,  1.40s/it, est. speed input: 821.85 toks/s, output: 39.96 toks/s]
[2025-01-08 17:14:33,929][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:05<00:11,  1.01s/it, est. speed input: 1049.47 toks/s, output: 53.44 toks/s]
[2025-01-08 17:14:34,568][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:06<00:06,  1.50it/s, est. speed input: 1408.17 toks/s, output: 79.14 toks/s]
[2025-01-08 17:14:34,713][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:06<00:04,  1.88it/s, est. speed input: 1611.32 toks/s, output: 94.97 toks/s]
[2025-01-08 17:14:34,824][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:06<00:02,  2.40it/s, est. speed input: 1815.50 toks/s, output: 111.30 toks/s]
[2025-01-08 17:14:35,030][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:06<00:01,  3.58it/s, est. speed input: 2181.01 toks/s, output: 144.33 toks/s]
[2025-01-08 17:14:35,171][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:06<00:00,  4.06it/s, est. speed input: 2345.22 toks/s, output: 160.43 toks/s]
[2025-01-08 17:14:35,707][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:07<00:00,  4.71it/s, est. speed input: 2685.70 toks/s, output: 205.91 toks/s]
[2025-01-08 17:14:36,062][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  4.17it/s, est. speed input: 2763.27 toks/s, output: 219.76 toks/s]
[2025-01-08 17:14:36,063][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  1.96it/s, est. speed input: 2763.27 toks/s, output: 219.76 toks/s]
WARNING 01-08 17:14:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:36,356][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:38,318][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.96s/it, est. speed input: 551.99 toks/s, output: 50.46 toks/s]
[2025-01-08 17:14:38,318][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.96s/it, est. speed input: 551.99 toks/s, output: 50.46 toks/s]
WARNING 01-08 17:14:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:38,509][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:40,211][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.70s/it, est. speed input: 833.17 toks/s, output: 47.59 toks/s]
[2025-01-08 17:14:40,212][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.70s/it, est. speed input: 833.17 toks/s, output: 47.59 toks/s]
WARNING 01-08 17:14:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:40,411][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:44,099][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.69s/it, est. speed input: 345.96 toks/s, output: 54.23 toks/s]
[2025-01-08 17:14:44,100][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.69s/it, est. speed input: 345.96 toks/s, output: 54.23 toks/s]
WARNING 01-08 17:14:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:14:44,290][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:14:47,129][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.84s/it, est. speed input: 539.28 toks/s, output: 52.13 toks/s]
[2025-01-08 17:14:47,129][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.84s/it, est. speed input: 539.28 toks/s, output: 52.13 toks/s]
[2025-01-08 17:14:53,867][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:14:53,920][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:14:55,584][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.66s/it]
[2025-01-08 17:14:57,212][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 17:14:58,805][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 17:14:59,309][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:14:59,310][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 17:15:10,773][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:15:11,240][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:15:11,292][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:15:13,167][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 17:15:14,727][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 17:15:16,240][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 17:15:16,750][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:15:16,750][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:15:31,805][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:15:32,119][root][INFO] - Loading VLLM model.
WARNING 01-08 17:15:32 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:15:32 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:15:32 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:15:32 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:15:33,180][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:15:34,493][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 17:15:34,884][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:15:36,191][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 17:15:37,538][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:15:37,538][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:15:37 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:15:51 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:15:52 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:15:52 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:16:12 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:16:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:13,131][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:17,200][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:01,  4.07s/it, est. speed input: 124.11 toks/s, output: 14.25 toks/s]
[2025-01-08 17:16:17,587][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:15,  1.20s/it, est. speed input: 339.97 toks/s, output: 41.74 toks/s]
[2025-01-08 17:16:17,822][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:10,  1.16it/s, est. speed input: 430.63 toks/s, output: 55.85 toks/s]
[2025-01-08 17:16:18,349][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:05<00:05,  1.77it/s, est. speed input: 580.73 toks/s, output: 82.80 toks/s]
[2025-01-08 17:16:18,728][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:05<00:04,  1.93it/s, est. speed input: 631.56 toks/s, output: 96.12 toks/s]
[2025-01-08 17:16:18,841][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:03,  2.46it/s, est. speed input: 707.53 toks/s, output: 113.49 toks/s]
[2025-01-08 17:16:18,946][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.97it/s, est. speed input: 868.51 toks/s, output: 150.14 toks/s]
[2025-01-08 17:16:19,286][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:06<00:00,  4.54it/s, est. speed input: 984.57 toks/s, output: 181.97 toks/s]
[2025-01-08 17:16:19,720][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:06<00:00,  4.56it/s, est. speed input: 1072.98 toks/s, output: 212.62 toks/s]
[2025-01-08 17:16:20,014][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  4.27it/s, est. speed input: 1100.59 toks/s, output: 227.82 toks/s]
[2025-01-08 17:16:20,564][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  3.28it/s, est. speed input: 1087.01 toks/s, output: 237.85 toks/s]
[2025-01-08 17:16:20,565][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.15it/s, est. speed input: 1087.01 toks/s, output: 237.85 toks/s]
WARNING 01-08 17:16:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:20,759][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:21,735][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 689.76 toks/s, output: 29.72 toks/s]
[2025-01-08 17:16:21,736][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.07it/s, est. speed input: 2069.41 toks/s, output: 89.13 toks/s]
WARNING 01-08 17:16:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:21,943][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:24,041][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.10s/it, est. speed input: 333.26 toks/s, output: 13.83 toks/s]
[2025-01-08 17:16:24,824][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:14,  1.32s/it, est. speed input: 485.27 toks/s, output: 28.46 toks/s]
[2025-01-08 17:16:25,166][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:08,  1.14it/s, est. speed input: 650.70 toks/s, output: 45.30 toks/s]
[2025-01-08 17:16:25,372][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.64it/s, est. speed input: 815.52 toks/s, output: 63.29 toks/s]
[2025-01-08 17:16:25,479][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  4.01it/s, est. speed input: 1384.04 toks/s, output: 123.33 toks/s]
[2025-01-08 17:16:26,129][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.60it/s, est. speed input: 1503.10 toks/s, output: 152.67 toks/s]
[2025-01-08 17:16:26,429][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  4.29it/s, est. speed input: 1714.28 toks/s, output: 191.51 toks/s]
[2025-01-08 17:16:26,697][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  4.99it/s, est. speed input: 1911.55 toks/s, output: 233.29 toks/s]
[2025-01-08 17:16:26,698][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.73it/s, est. speed input: 1911.55 toks/s, output: 233.29 toks/s]
WARNING 01-08 17:16:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:26,913][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:30,493][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:39,  3.58s/it, est. speed input: 179.92 toks/s, output: 21.51 toks/s]
[2025-01-08 17:16:30,837][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:16,  1.68s/it, est. speed input: 332.38 toks/s, output: 42.06 toks/s]
[2025-01-08 17:16:31,004][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:03,  1.94it/s, est. speed input: 829.27 toks/s, output: 107.33 toks/s]
[2025-01-08 17:16:31,275][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.76it/s, est. speed input: 1089.02 toks/s, output: 146.96 toks/s]
[2025-01-08 17:16:31,569][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  2.89it/s, est. speed input: 1169.84 toks/s, output: 163.04 toks/s]
[2025-01-08 17:16:31,806][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  3.13it/s, est. speed input: 1257.14 toks/s, output: 181.49 toks/s]
[2025-01-08 17:16:32,105][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  3.18it/s, est. speed input: 1320.27 toks/s, output: 198.79 toks/s]
[2025-01-08 17:16:32,765][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  2.46it/s, est. speed input: 1290.20 toks/s, output: 207.14 toks/s]
[2025-01-08 17:16:32,916][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.97it/s, est. speed input: 1382.83 toks/s, output: 233.39 toks/s]
[2025-01-08 17:16:32,917][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.00it/s, est. speed input: 1382.83 toks/s, output: 233.39 toks/s]
WARNING 01-08 17:16:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:33,136][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:34,970][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it, est. speed input: 381.23 toks/s, output: 33.81 toks/s]
[2025-01-08 17:16:36,259][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.44it/s, est. speed input: 926.54 toks/s, output: 106.97 toks/s]
[2025-01-08 17:16:36,259][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.28it/s, est. speed input: 926.54 toks/s, output: 106.97 toks/s]
WARNING 01-08 17:16:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:36,462][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:37,584][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.12s/it, est. speed input: 634.10 toks/s, output: 25.86 toks/s]
[2025-01-08 17:16:38,299][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.13it/s, est. speed input: 816.42 toks/s, output: 51.20 toks/s]
[2025-01-08 17:16:38,428][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  1.86it/s, est. speed input: 1197.51 toks/s, output: 84.48 toks/s]
[2025-01-08 17:16:39,015][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.79it/s, est. speed input: 1202.16 toks/s, output: 106.97 toks/s]
[2025-01-08 17:16:39,015][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.57it/s, est. speed input: 1202.16 toks/s, output: 106.97 toks/s]
WARNING 01-08 17:16:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:39,239][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:42,397][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:34,  3.16s/it, est. speed input: 317.23 toks/s, output: 15.83 toks/s]
[2025-01-08 17:16:42,840][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:15,  1.56s/it, est. speed input: 566.27 toks/s, output: 31.66 toks/s]
[2025-01-08 17:16:43,156][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:05,  1.47it/s, est. speed input: 1058.56 toks/s, output: 64.85 toks/s]
[2025-01-08 17:16:43,288][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.56it/s, est. speed input: 1542.34 toks/s, output: 101.01 toks/s]
[2025-01-08 17:16:43,887][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  2.83it/s, est. speed input: 1811.72 toks/s, output: 128.22 toks/s]
[2025-01-08 17:16:44,152][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:01,  2.99it/s, est. speed input: 1934.30 toks/s, output: 145.33 toks/s]
[2025-01-08 17:16:44,926][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.37it/s, est. speed input: 2240.83 toks/s, output: 197.13 toks/s]
[2025-01-08 17:16:44,926][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.11it/s, est. speed input: 2240.83 toks/s, output: 197.13 toks/s]
WARNING 01-08 17:16:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:45,139][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:48,603][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:38,  3.46s/it, est. speed input: 240.72 toks/s, output: 19.05 toks/s]
[2025-01-08 17:16:49,094][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:04,  1.61it/s, est. speed input: 1059.32 toks/s, output: 88.74 toks/s]
[2025-01-08 17:16:49,566][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:03,  1.71it/s, est. speed input: 1145.13 toks/s, output: 102.32 toks/s]
[2025-01-08 17:16:49,884][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:02,  1.93it/s, est. speed input: 1263.71 toks/s, output: 119.69 toks/s]
[2025-01-08 17:16:50,114][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  2.26it/s, est. speed input: 1388.58 toks/s, output: 139.30 toks/s]
[2025-01-08 17:16:50,582][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  2.83it/s, est. speed input: 1602.26 toks/s, output: 177.82 toks/s]
[2025-01-08 17:16:51,425][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:06<00:00,  2.14it/s, est. speed input: 1540.28 toks/s, output: 184.84 toks/s]
[2025-01-08 17:16:51,527][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.66it/s, est. speed input: 1676.46 toks/s, output: 213.20 toks/s]
[2025-01-08 17:16:51,527][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.88it/s, est. speed input: 1676.46 toks/s, output: 213.20 toks/s]
WARNING 01-08 17:16:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:51,728][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:53,817][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.09s/it, est. speed input: 495.76 toks/s, output: 31.61 toks/s]
[2025-01-08 17:16:54,425][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.30it/s, est. speed input: 1183.84 toks/s, output: 86.04 toks/s]
[2025-01-08 17:16:54,730][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.65it/s, est. speed input: 1442.63 toks/s, output: 116.30 toks/s]
[2025-01-08 17:16:54,730][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.33it/s, est. speed input: 1442.63 toks/s, output: 116.30 toks/s]
WARNING 01-08 17:16:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:54,955][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:16:56,310][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.35s/it, est. speed input: 935.37 toks/s, output: 21.41 toks/s]
[2025-01-08 17:16:57,094][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.56it/s, est. speed input: 1446.48 toks/s, output: 58.92 toks/s]
[2025-01-08 17:16:57,332][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.99it/s, est. speed input: 1696.12 toks/s, output: 87.08 toks/s]
[2025-01-08 17:16:57,787][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.06it/s, est. speed input: 1744.46 toks/s, output: 111.23 toks/s]
[2025-01-08 17:16:57,787][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.77it/s, est. speed input: 1744.46 toks/s, output: 111.23 toks/s]
WARNING 01-08 17:16:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:16:58,010][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:17:02,215][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:04<00:42,  4.20s/it, est. speed input: 340.12 toks/s, output: 17.60 toks/s]
[2025-01-08 17:17:02,367][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:04<00:16,  1.82s/it, est. speed input: 644.33 toks/s, output: 35.12 toks/s]
[2025-01-08 17:17:02,508][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:04<00:05,  1.38it/s, est. speed input: 1259.26 toks/s, output: 70.49 toks/s]
[2025-01-08 17:17:02,856][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.65it/s, est. speed input: 1476.83 toks/s, output: 85.44 toks/s]
[2025-01-08 17:17:03,056][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:05<00:02,  2.07it/s, est. speed input: 1708.78 toks/s, output: 102.86 toks/s]
[2025-01-08 17:17:03,240][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:00,  3.33it/s, est. speed input: 2180.18 toks/s, output: 141.71 toks/s]
[2025-01-08 17:17:03,895][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:05<00:00,  2.57it/s, est. speed input: 2182.79 toks/s, output: 150.56 toks/s]
[2025-01-08 17:17:04,134][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:06<00:00,  2.86it/s, est. speed input: 2338.27 toks/s, output: 170.48 toks/s]
[2025-01-08 17:17:04,135][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.80it/s, est. speed input: 2591.12 toks/s, output: 196.28 toks/s]
WARNING 01-08 17:17:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:17:04,423][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:17:06,915][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:02<00:09,  2.49s/it, est. speed input: 559.12 toks/s, output: 26.89 toks/s]
[2025-01-08 17:17:07,071][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.12s/it, est. speed input: 1086.52 toks/s, output: 53.25 toks/s]
[2025-01-08 17:17:07,400][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.32it/s, est. speed input: 1414.19 toks/s, output: 77.61 toks/s]
[2025-01-08 17:17:07,859][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:03<00:00,  1.56it/s, est. speed input: 1625.14 toks/s, output: 100.70 toks/s]
[2025-01-08 17:17:07,911][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.43it/s, est. speed input: 2040.89 toks/s, output: 133.04 toks/s]
WARNING 01-08 17:17:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:17:08,137][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:17:09,064][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.08it/s, est. speed input: 1808.35 toks/s, output: 35.58 toks/s]
[2025-01-08 17:17:09,065][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.08it/s, est. speed input: 1808.35 toks/s, output: 35.58 toks/s]
[2025-01-08 17:17:14,975][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:17:15,028][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:17:16,694][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.67s/it]
[2025-01-08 17:17:18,309][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 17:17:19,866][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 17:17:20,374][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 17:17:20,375][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 17:17:32,125][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:17:32,669][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:17:32,721][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:17:34,706][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.98s/it]
[2025-01-08 17:17:36,365][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.79s/it]
[2025-01-08 17:17:37,969][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 17:17:38,487][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 17:17:38,487][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.44s/it]
[2025-01-08 17:17:53,162][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:17:53,470][root][INFO] - Loading VLLM model.
WARNING 01-08 17:17:53 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:17:53 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:17:54 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:17:54 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:17:54,502][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:17:55,876][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 17:17:56,275][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 17:17:57,583][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
[2025-01-08 17:17:58,919][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:17:58,920][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 17:17:59 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:18:12 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:18:13 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:18:13 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:18:34 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:18:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:35,138][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:39,167][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:00,  4.03s/it, est. speed input: 125.33 toks/s, output: 14.64 toks/s]
[2025-01-08 17:18:39,528][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:26,  1.87s/it, est. speed input: 230.06 toks/s, output: 29.16 toks/s]
[2025-01-08 17:18:39,669][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.08s/it, est. speed input: 334.37 toks/s, output: 44.36 toks/s]
[2025-01-08 17:18:39,865][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:05,  1.91it/s, est. speed input: 534.13 toks/s, output: 74.88 toks/s]
[2025-01-08 17:18:40,231][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:02,  3.29it/s, est. speed input: 793.28 toks/s, output: 118.79 toks/s]
[2025-01-08 17:18:40,364][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:05<00:01,  3.72it/s, est. speed input: 869.66 toks/s, output: 134.32 toks/s]
[2025-01-08 17:18:40,486][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:00,  5.23it/s, est. speed input: 1038.74 toks/s, output: 168.67 toks/s]
[2025-01-08 17:18:40,810][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  5.52it/s, est. speed input: 1157.33 toks/s, output: 198.50 toks/s]
[2025-01-08 17:18:40,960][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  6.84it/s, est. speed input: 1300.97 toks/s, output: 235.29 toks/s]
[2025-01-08 17:18:41,943][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.35it/s, est. speed input: 1187.34 toks/s, output: 228.36 toks/s]
WARNING 01-08 17:18:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:42,164][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:43,142][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 744.31 toks/s, output: 29.65 toks/s]
[2025-01-08 17:18:43,143][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.07it/s, est. speed input: 2092.87 toks/s, output: 88.91 toks/s]
WARNING 01-08 17:18:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:43,355][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:46,296][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.94s/it, est. speed input: 237.74 toks/s, output: 18.37 toks/s]
[2025-01-08 17:18:46,557][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:15,  1.36s/it, est. speed input: 436.63 toks/s, output: 36.23 toks/s]
[2025-01-08 17:18:46,744][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:08,  1.21it/s, est. speed input: 618.86 toks/s, output: 54.30 toks/s]
[2025-01-08 17:18:46,862][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:04,  1.83it/s, est. speed input: 797.37 toks/s, output: 73.01 toks/s]
[2025-01-08 17:18:47,004][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.50it/s, est. speed input: 958.07 toks/s, output: 91.28 toks/s]
[2025-01-08 17:18:48,394][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  3.20it/s, est. speed input: 1387.47 toks/s, output: 157.21 toks/s]
[2025-01-08 17:18:48,751][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:05<00:00,  3.12it/s, est. speed input: 1425.11 toks/s, output: 176.26 toks/s]
[2025-01-08 17:18:49,044][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.18it/s, est. speed input: 1474.49 toks/s, output: 197.93 toks/s]
[2025-01-08 17:18:49,464][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.96it/s, est. speed input: 1487.70 toks/s, output: 217.09 toks/s]
[2025-01-08 17:18:49,464][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.13it/s, est. speed input: 1487.70 toks/s, output: 217.09 toks/s]
WARNING 01-08 17:18:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:49,695][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:53,472][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:41,  3.78s/it, est. speed input: 174.74 toks/s, output: 21.44 toks/s]
[2025-01-08 17:18:53,651][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:09,  1.05s/it, est. speed input: 507.33 toks/s, output: 63.19 toks/s]
[2025-01-08 17:18:53,833][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.73it/s, est. speed input: 1123.72 toks/s, output: 148.38 toks/s]
[2025-01-08 17:18:54,058][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  3.53it/s, est. speed input: 1378.59 toks/s, output: 188.17 toks/s]
[2025-01-08 17:18:54,545][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  3.69it/s, est. speed input: 1530.04 toks/s, output: 218.96 toks/s]
[2025-01-08 17:18:54,730][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.92it/s, est. speed input: 1610.37 toks/s, output: 238.93 toks/s]
[2025-01-08 17:18:54,730][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.38it/s, est. speed input: 1610.37 toks/s, output: 238.93 toks/s]
WARNING 01-08 17:18:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:54,952][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:57,171][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.22s/it, est. speed input: 315.06 toks/s, output: 35.61 toks/s]
[2025-01-08 17:18:57,766][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.26s/it, est. speed input: 497.01 toks/s, output: 66.84 toks/s]
[2025-01-08 17:18:58,542][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.40it/s, est. speed input: 850.06 toks/s, output: 125.93 toks/s]
[2025-01-08 17:18:58,542][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.11it/s, est. speed input: 850.06 toks/s, output: 125.93 toks/s]
WARNING 01-08 17:18:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:18:58,764][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:18:59,880][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.12s/it, est. speed input: 755.85 toks/s, output: 26.00 toks/s]
[2025-01-08 17:19:00,652][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.09it/s, est. speed input: 849.33 toks/s, output: 51.39 toks/s]
[2025-01-08 17:19:01,219][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.32it/s, est. speed input: 972.26 toks/s, output: 79.83 toks/s]
[2025-01-08 17:19:01,370][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.94it/s, est. speed input: 1169.03 toks/s, output: 116.67 toks/s]
[2025-01-08 17:19:01,370][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.54it/s, est. speed input: 1169.03 toks/s, output: 116.67 toks/s]
WARNING 01-08 17:19:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:01,588][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:05,522][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:43,  3.93s/it, est. speed input: 266.88 toks/s, output: 18.55 toks/s]
[2025-01-08 17:19:05,712][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:17,  1.73s/it, est. speed input: 509.65 toks/s, output: 36.85 toks/s]
[2025-01-08 17:19:06,130][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:10,  1.13s/it, est. speed input: 693.37 toks/s, output: 53.95 toks/s]
[2025-01-08 17:19:06,424][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.23it/s, est. speed input: 1301.55 toks/s, output: 111.25 toks/s]
[2025-01-08 17:19:06,695][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:05<00:02,  2.47it/s, est. speed input: 1454.15 toks/s, output: 127.87 toks/s]
[2025-01-08 17:19:06,880][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  2.86it/s, est. speed input: 1600.83 toks/s, output: 146.65 toks/s]
[2025-01-08 17:19:07,145][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:05<00:00,  3.06it/s, est. speed input: 1710.64 toks/s, output: 163.94 toks/s]
[2025-01-08 17:19:07,370][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  3.35it/s, est. speed input: 1826.14 toks/s, output: 182.82 toks/s]
[2025-01-08 17:19:07,663][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:06<00:00,  3.37it/s, est. speed input: 1921.21 toks/s, output: 200.65 toks/s]
[2025-01-08 17:19:08,305][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.52it/s, est. speed input: 1909.60 toks/s, output: 211.27 toks/s]
[2025-01-08 17:19:08,305][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.79it/s, est. speed input: 1909.60 toks/s, output: 211.27 toks/s]
WARNING 01-08 17:19:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:08,520][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:11,904][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:37,  3.38s/it, est. speed input: 244.35 toks/s, output: 19.20 toks/s]
[2025-01-08 17:19:12,031][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:14,  1.47s/it, est. speed input: 473.98 toks/s, output: 38.17 toks/s]
[2025-01-08 17:19:12,386][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:08,  1.04it/s, est. speed input: 654.42 toks/s, output: 55.61 toks/s]
[2025-01-08 17:19:12,840][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.32it/s, est. speed input: 792.86 toks/s, output: 72.23 toks/s]
[2025-01-08 17:19:12,940][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  3.30it/s, est. speed input: 1341.23 toks/s, output: 137.56 toks/s]
[2025-01-08 17:19:13,768][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:05<00:01,  2.90it/s, est. speed input: 1448.72 toks/s, output: 161.77 toks/s]
[2025-01-08 17:19:14,009][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  3.10it/s, est. speed input: 1551.58 toks/s, output: 182.17 toks/s]
[2025-01-08 17:19:14,065][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.16it/s, est. speed input: 1856.71 toks/s, output: 235.90 toks/s]
WARNING 01-08 17:19:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:14,294][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:16,884][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:07,  2.59s/it, est. speed input: 420.14 toks/s, output: 33.60 toks/s]
[2025-01-08 17:19:17,049][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.36it/s, est. speed input: 1171.48 toks/s, output: 97.99 toks/s]
[2025-01-08 17:19:17,118][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.42it/s, est. speed input: 1633.03 toks/s, output: 131.04 toks/s]
WARNING 01-08 17:19:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:17,325][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:18,654][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.33s/it, est. speed input: 721.16 toks/s, output: 21.83 toks/s]
[2025-01-08 17:19:19,677][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.15s/it, est. speed input: 826.79 toks/s, output: 44.66 toks/s]
[2025-01-08 17:19:20,003][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.47it/s, est. speed input: 1747.87 toks/s, output: 132.96 toks/s]
[2025-01-08 17:19:20,003][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.87it/s, est. speed input: 1747.87 toks/s, output: 132.96 toks/s]
WARNING 01-08 17:19:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:20,236][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:24,634][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:04<00:43,  4.40s/it, est. speed input: 325.88 toks/s, output: 17.97 toks/s]
[2025-01-08 17:19:24,750][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:04<00:09,  1.18s/it, est. speed input: 940.65 toks/s, output: 53.39 toks/s]
[2025-01-08 17:19:25,027][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.55it/s, est. speed input: 1512.06 toks/s, output: 88.92 toks/s]
[2025-01-08 17:19:25,203][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:04<00:02,  1.92it/s, est. speed input: 1746.51 toks/s, output: 105.90 toks/s]
[2025-01-08 17:19:25,345][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:05<00:01,  2.41it/s, est. speed input: 1971.49 toks/s, output: 123.71 toks/s]
[2025-01-08 17:19:25,545][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:01,  2.82it/s, est. speed input: 2203.93 toks/s, output: 140.70 toks/s]
[2025-01-08 17:19:25,865][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:05<00:00,  3.74it/s, est. speed input: 2598.08 toks/s, output: 177.14 toks/s]
[2025-01-08 17:19:27,014][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  2.08it/s, est. speed input: 2381.89 toks/s, output: 176.60 toks/s]
[2025-01-08 17:19:27,014][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.62it/s, est. speed input: 2381.89 toks/s, output: 176.60 toks/s]
WARNING 01-08 17:19:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:27,314][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:28,086][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1323.85 toks/s, output: 37.56 toks/s]
[2025-01-08 17:19:28,087][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 1323.85 toks/s, output: 37.56 toks/s]
WARNING 01-08 17:19:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:28,296][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:29,984][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.69s/it, est. speed input: 1051.86 toks/s, output: 17.18 toks/s]
[2025-01-08 17:19:31,361][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:03<00:04,  1.51s/it, est. speed input: 1154.49 toks/s, output: 39.15 toks/s]
[2025-01-08 17:19:31,710][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:03<00:01,  1.02it/s, est. speed input: 1462.84 toks/s, output: 66.79 toks/s]
[2025-01-08 17:19:31,836][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  2.18it/s, est. speed input: 2223.51 toks/s, output: 128.80 toks/s]
[2025-01-08 17:19:31,837][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.41it/s, est. speed input: 2223.51 toks/s, output: 128.80 toks/s]
WARNING 01-08 17:19:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:19:32,068][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:19:34,901][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.83s/it, est. speed input: 500.82 toks/s, output: 52.23 toks/s]
[2025-01-08 17:19:34,902][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.83s/it, est. speed input: 500.82 toks/s, output: 52.23 toks/s]
[2025-01-08 17:19:41,269][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:19:41,322][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:19:43,033][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.71s/it]
[2025-01-08 17:19:44,641][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 17:19:46,219][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 17:19:46,735][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:19:46,735][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 17:19:58,273][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:19:58,892][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:19:58,944][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:20:00,861][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 17:20:02,540][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:20:04,169][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 17:20:04,674][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 17:20:04,674][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 17:20:19,819][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:20:20,122][root][INFO] - Loading VLLM model.
WARNING 01-08 17:20:20 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:20:20 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:20:21 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:20:21 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:20:21,436][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:20:22,757][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:20:23,147][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 17:20:24,455][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 17:20:25,802][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:20:25,803][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:20:26 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:20:39 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:20:40 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:20:40 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:21:01 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:21:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:01,843][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:05,857][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:00,  4.01s/it, est. speed input: 125.81 toks/s, output: 14.45 toks/s]
[2025-01-08 17:21:06,104][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.13s/it, est. speed input: 355.54 toks/s, output: 42.71 toks/s]
[2025-01-08 17:21:06,238][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:09,  1.27it/s, est. speed input: 459.59 toks/s, output: 57.11 toks/s]
[2025-01-08 17:21:06,398][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:04,  2.30it/s, est. speed input: 665.20 toks/s, output: 87.16 toks/s]
[2025-01-08 17:21:07,129][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:03,  2.46it/s, est. speed input: 764.19 toks/s, output: 108.57 toks/s]
[2025-01-08 17:21:07,236][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.64it/s, est. speed input: 936.37 toks/s, output: 144.81 toks/s]
[2025-01-08 17:21:07,645][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:01,  3.99it/s, est. speed input: 1044.51 toks/s, output: 174.43 toks/s]
[2025-01-08 17:21:07,942][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:06<00:00,  3.85it/s, est. speed input: 1076.29 toks/s, output: 188.21 toks/s]
[2025-01-08 17:21:08,434][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:06<00:00,  3.22it/s, est. speed input: 1072.70 toks/s, output: 198.61 toks/s]
[2025-01-08 17:21:08,638][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  3.50it/s, est. speed input: 1114.73 toks/s, output: 217.94 toks/s]
[2025-01-08 17:21:08,922][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  3.51it/s, est. speed input: 1141.36 toks/s, output: 235.90 toks/s]
[2025-01-08 17:21:08,922][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.26it/s, est. speed input: 1141.36 toks/s, output: 235.90 toks/s]
WARNING 01-08 17:21:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:09,123][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:10,091][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.03it/s, est. speed input: 622.21 toks/s, output: 29.97 toks/s]
[2025-01-08 17:21:11,610][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.23it/s, est. speed input: 780.63 toks/s, output: 71.59 toks/s]
[2025-01-08 17:21:11,610][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.21it/s, est. speed input: 780.63 toks/s, output: 71.59 toks/s]
WARNING 01-08 17:21:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:11,821][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:13,990][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.17s/it, est. speed input: 322.24 toks/s, output: 14.29 toks/s]
[2025-01-08 17:21:14,936][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:15,  1.45s/it, est. speed input: 448.79 toks/s, output: 29.21 toks/s]
[2025-01-08 17:21:15,123][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:08,  1.15it/s, est. speed input: 635.11 toks/s, output: 47.55 toks/s]
[2025-01-08 17:21:15,447][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.52it/s, est. speed input: 771.13 toks/s, output: 64.54 toks/s]
[2025-01-08 17:21:15,560][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.17it/s, est. speed input: 934.68 toks/s, output: 84.24 toks/s]
[2025-01-08 17:21:15,908][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:02,  2.37it/s, est. speed input: 1026.22 toks/s, output: 100.08 toks/s]
[2025-01-08 17:21:16,659][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:03,  1.89it/s, est. speed input: 1011.34 toks/s, output: 109.96 toks/s]
[2025-01-08 17:21:16,957][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:05<00:01,  2.89it/s, est. speed input: 1224.94 toks/s, output: 154.41 toks/s]
[2025-01-08 17:21:17,123][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:05<00:00,  4.19it/s, est. speed input: 1450.25 toks/s, output: 203.14 toks/s]
[2025-01-08 17:21:17,306][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  4.42it/s, est. speed input: 1529.15 toks/s, output: 224.41 toks/s]
[2025-01-08 17:21:18,077][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.79it/s, est. speed input: 1452.45 toks/s, output: 228.73 toks/s]
[2025-01-08 17:21:18,078][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.08it/s, est. speed input: 1452.45 toks/s, output: 228.73 toks/s]
WARNING 01-08 17:21:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:18,309][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:20,887][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:23,  2.58s/it, est. speed input: 256.11 toks/s, output: 22.51 toks/s]
[2025-01-08 17:21:21,451][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:03<00:11,  1.39s/it, est. speed input: 416.99 toks/s, output: 43.29 toks/s]
[2025-01-08 17:21:21,665][root][ERROR] - Processed prompts:  30%|###       | 3/10 [00:03<00:05,  1.17it/s, est. speed input: 595.71 toks/s, output: 66.16 toks/s]
[2025-01-08 17:21:21,837][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:03<00:02,  2.38it/s, est. speed input: 940.45 toks/s, output: 113.98 toks/s]
[2025-01-08 17:21:21,950][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:03<00:01,  3.02it/s, est. speed input: 1103.57 toks/s, output: 137.36 toks/s]
[2025-01-08 17:21:22,079][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:00,  3.67it/s, est. speed input: 1241.59 toks/s, output: 160.24 toks/s]
[2025-01-08 17:21:22,212][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  5.59it/s, est. speed input: 1567.80 toks/s, output: 210.61 toks/s]
[2025-01-08 17:21:22,247][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:03<00:00,  2.54it/s, est. speed input: 1729.00 toks/s, output: 237.49 toks/s]
WARNING 01-08 17:21:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:22,468][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:23,840][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.37s/it, est. speed input: 371.71 toks/s, output: 21.14 toks/s]
[2025-01-08 17:21:23,976][root][ERROR] - Processed prompts:  33%|###3      | 2/6 [00:01<00:02,  1.55it/s, est. speed input: 891.35 toks/s, output: 42.44 toks/s]
[2025-01-08 17:21:24,449][root][ERROR] - Processed prompts:  50%|#####     | 3/6 [00:01<00:01,  1.77it/s, est. speed input: 1031.26 toks/s, output: 61.08 toks/s]
[2025-01-08 17:21:24,786][root][ERROR] - Processed prompts:  67%|######6   | 4/6 [00:02<00:00,  2.10it/s, est. speed input: 1254.17 toks/s, output: 84.13 toks/s]
[2025-01-08 17:21:24,969][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:02<00:00,  2.70it/s, est. speed input: 1543.60 toks/s, output: 111.54 toks/s]
[2025-01-08 17:21:25,187][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  3.14it/s, est. speed input: 1676.76 toks/s, output: 138.26 toks/s]
[2025-01-08 17:21:25,188][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.21it/s, est. speed input: 1676.76 toks/s, output: 138.26 toks/s]
WARNING 01-08 17:21:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:25,396][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:28,171][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:02<00:16,  2.78s/it, est. speed input: 279.23 toks/s, output: 28.10 toks/s]
[2025-01-08 17:21:28,899][root][ERROR] - Processed prompts:  29%|##8       | 2/7 [00:03<00:07,  1.57s/it, est. speed input: 416.82 toks/s, output: 53.10 toks/s]
[2025-01-08 17:21:29,575][root][ERROR] - Processed prompts:  57%|#####7    | 4/7 [00:04<00:02,  1.25it/s, est. speed input: 712.43 toks/s, output: 103.86 toks/s]
[2025-01-08 17:21:30,316][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:04<00:01,  1.28it/s, est. speed input: 756.67 toks/s, output: 123.98 toks/s]
[2025-01-08 17:21:30,728][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.96it/s, est. speed input: 1035.11 toks/s, output: 185.68 toks/s]
[2025-01-08 17:21:30,728][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.31it/s, est. speed input: 1035.11 toks/s, output: 185.68 toks/s]
WARNING 01-08 17:21:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:30,946][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:33,832][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:23,  2.89s/it, est. speed input: 360.04 toks/s, output: 20.45 toks/s]
[2025-01-08 17:21:34,131][root][ERROR] - Processed prompts:  22%|##2       | 2/9 [00:03<00:09,  1.36s/it, est. speed input: 580.51 toks/s, output: 40.50 toks/s]
[2025-01-08 17:21:34,316][root][ERROR] - Processed prompts:  33%|###3      | 3/9 [00:03<00:04,  1.21it/s, est. speed input: 860.20 toks/s, output: 61.12 toks/s]
[2025-01-08 17:21:34,513][root][ERROR] - Processed prompts:  44%|####4     | 4/9 [00:03<00:02,  1.73it/s, est. speed input: 1127.52 toks/s, output: 81.58 toks/s]
[2025-01-08 17:21:34,812][root][ERROR] - Processed prompts:  56%|#####5    | 5/9 [00:03<00:01,  2.10it/s, est. speed input: 1300.17 toks/s, output: 100.63 toks/s]
[2025-01-08 17:21:35,341][root][ERROR] - Processed prompts:  67%|######6   | 6/9 [00:04<00:01,  2.02it/s, est. speed input: 1397.44 toks/s, output: 116.28 toks/s]
[2025-01-08 17:21:35,912][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:04<00:00,  2.55it/s, est. speed input: 1674.00 toks/s, output: 158.50 toks/s]
[2025-01-08 17:21:36,706][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  2.01it/s, est. speed input: 1639.92 toks/s, output: 171.37 toks/s]
[2025-01-08 17:21:36,706][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  1.56it/s, est. speed input: 1639.92 toks/s, output: 171.37 toks/s]
WARNING 01-08 17:21:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:36,916][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:38,752][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:14,  1.84s/it, est. speed input: 387.37 toks/s, output: 15.80 toks/s]
[2025-01-08 17:21:39,828][root][ERROR] - Processed prompts:  22%|##2       | 2/9 [00:02<00:09,  1.39s/it, est. speed input: 520.26 toks/s, output: 33.65 toks/s]
[2025-01-08 17:21:40,248][root][ERROR] - Processed prompts:  33%|###3      | 3/9 [00:03<00:05,  1.06it/s, est. speed input: 703.65 toks/s, output: 54.93 toks/s]
[2025-01-08 17:21:40,395][root][ERROR] - Processed prompts:  44%|####4     | 4/9 [00:03<00:03,  1.59it/s, est. speed input: 928.92 toks/s, output: 78.78 toks/s]
[2025-01-08 17:21:40,579][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:03<00:00,  3.66it/s, est. speed input: 1587.82 toks/s, output: 152.34 toks/s]
[2025-01-08 17:21:40,726][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:03<00:00,  4.10it/s, est. speed input: 1811.29 toks/s, output: 174.80 toks/s]
[2025-01-08 17:21:40,794][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.32it/s, est. speed input: 1999.65 toks/s, output: 200.63 toks/s]
WARNING 01-08 17:21:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:41,030][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:42,862][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.83s/it, est. speed input: 757.79 toks/s, output: 15.83 toks/s]
[2025-01-08 17:21:43,573][root][ERROR] - Processed prompts:  29%|##8       | 2/7 [00:02<00:05,  1.17s/it, est. speed input: 995.48 toks/s, output: 34.22 toks/s]
[2025-01-08 17:21:43,711][root][ERROR] - Processed prompts:  43%|####2     | 3/7 [00:02<00:02,  1.43it/s, est. speed input: 1396.49 toks/s, output: 56.34 toks/s]
[2025-01-08 17:21:44,425][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:03<00:01,  1.98it/s, est. speed input: 1733.14 toks/s, output: 93.08 toks/s]
[2025-01-08 17:21:44,903][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:03<00:00,  2.01it/s, est. speed input: 1795.77 toks/s, output: 113.88 toks/s]
[2025-01-08 17:21:45,545][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:04<00:00,  1.85it/s, est. speed input: 1830.82 toks/s, output: 133.78 toks/s]
[2025-01-08 17:21:45,546][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:04<00:00,  1.55it/s, est. speed input: 1830.82 toks/s, output: 133.78 toks/s]
WARNING 01-08 17:21:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:45,770][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:48,198][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:02<00:14,  2.43s/it, est. speed input: 390.95 toks/s, output: 24.31 toks/s]
[2025-01-08 17:21:48,568][root][ERROR] - Processed prompts:  43%|####2     | 3/7 [00:02<00:03,  1.30it/s, est. speed input: 971.12 toks/s, output: 69.34 toks/s]
[2025-01-08 17:21:49,757][root][ERROR] - Processed prompts:  57%|#####7    | 4/7 [00:03<00:02,  1.10it/s, est. speed input: 984.94 toks/s, output: 81.03 toks/s]
[2025-01-08 17:21:50,034][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:04<00:00,  1.89it/s, est. speed input: 1355.96 toks/s, output: 140.03 toks/s]
[2025-01-08 17:21:50,979][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.57it/s, est. speed input: 1303.37 toks/s, output: 153.01 toks/s]
[2025-01-08 17:21:50,980][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.34it/s, est. speed input: 1303.37 toks/s, output: 153.01 toks/s]
WARNING 01-08 17:21:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:51,197][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:54,406][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:03<00:25,  3.21s/it, est. speed input: 428.83 toks/s, output: 19.32 toks/s]
[2025-01-08 17:21:54,711][root][ERROR] - Processed prompts:  22%|##2       | 2/9 [00:03<00:10,  1.50s/it, est. speed input: 569.25 toks/s, output: 38.42 toks/s]
[2025-01-08 17:21:54,872][root][ERROR] - Processed prompts:  33%|###3      | 3/9 [00:03<00:05,  1.12it/s, est. speed input: 919.25 toks/s, output: 58.24 toks/s]
[2025-01-08 17:21:55,023][root][ERROR] - Processed prompts:  44%|####4     | 4/9 [00:03<00:02,  1.67it/s, est. speed input: 1184.68 toks/s, output: 78.16 toks/s]
[2025-01-08 17:21:55,188][root][ERROR] - Processed prompts:  56%|#####5    | 5/9 [00:03<00:01,  2.26it/s, est. speed input: 1508.55 toks/s, output: 97.98 toks/s]
[2025-01-08 17:21:55,455][root][ERROR] - Processed prompts:  67%|######6   | 6/9 [00:04<00:01,  2.62it/s, est. speed input: 1743.02 toks/s, output: 116.26 toks/s]
[2025-01-08 17:21:55,619][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:04<00:00,  3.22it/s, est. speed input: 2019.03 toks/s, output: 137.27 toks/s]
[2025-01-08 17:21:56,959][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:05<00:00,  1.57it/s, est. speed input: 1809.98 toks/s, output: 137.47 toks/s]
[2025-01-08 17:21:57,213][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:06<00:00,  1.93it/s, est. speed input: 1985.58 toks/s, output: 164.90 toks/s]
[2025-01-08 17:21:57,213][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:06<00:00,  1.50it/s, est. speed input: 1985.58 toks/s, output: 164.90 toks/s]
WARNING 01-08 17:21:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:21:57,458][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:21:58,561][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 1131.42 toks/s, output: 26.29 toks/s]
[2025-01-08 17:22:00,588][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.04s/it, est. speed input: 1067.63 toks/s, output: 66.15 toks/s]
[2025-01-08 17:22:00,588][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.04s/it, est. speed input: 1067.63 toks/s, output: 66.15 toks/s]
WARNING 01-08 17:22:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:22:00,822][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:22:03,106][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:02<00:13,  2.28s/it, est. speed input: 648.49 toks/s, output: 15.33 toks/s]
[2025-01-08 17:22:04,161][root][ERROR] - Processed prompts:  29%|##8       | 2/7 [00:03<00:07,  1.56s/it, est. speed input: 967.55 toks/s, output: 33.55 toks/s]
[2025-01-08 17:22:04,411][root][ERROR] - Processed prompts:  57%|#####7    | 4/7 [00:03<00:01,  1.51it/s, est. speed input: 1802.89 toks/s, output: 78.30 toks/s]
[2025-01-08 17:22:04,555][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:03<00:01,  2.00it/s, est. speed input: 2102.92 toks/s, output: 100.74 toks/s]
[2025-01-08 17:22:04,775][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:03<00:00,  2.41it/s, est. speed input: 2360.24 toks/s, output: 122.19 toks/s]
[2025-01-08 17:22:04,843][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:04<00:00,  1.74it/s, est. speed input: 2740.77 toks/s, output: 147.72 toks/s]
WARNING 01-08 17:22:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:22:05,111][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:22:06,762][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 881.03 toks/s, output: 47.26 toks/s]
[2025-01-08 17:22:06,762][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 881.03 toks/s, output: 47.26 toks/s]
WARNING 01-08 17:22:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:22:06,967][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:22:08,736][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.77s/it, est. speed input: 855.18 toks/s, output: 39.00 toks/s]
[2025-01-08 17:22:09,109][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.06it/s, est. speed input: 1432.98 toks/s, output: 74.71 toks/s]
[2025-01-08 17:22:09,109][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.07s/it, est. speed input: 1432.98 toks/s, output: 74.71 toks/s]
WARNING 01-08 17:22:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:22:09,332][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:22:11,090][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.76s/it, est. speed input: 444.80 toks/s, output: 49.49 toks/s]
[2025-01-08 17:22:11,090][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.76s/it, est. speed input: 444.80 toks/s, output: 49.49 toks/s]
[2025-01-08 17:22:16,741][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:22:16,794][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:22:18,469][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 17:22:20,087][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 17:22:21,666][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 17:22:22,217][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 17:22:22,217][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:22:33,987][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:22:34,541][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:22:34,594][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:22:36,552][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.96s/it]
[2025-01-08 17:22:38,130][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 17:22:39,715][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 17:22:40,209][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 17:22:40,210][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 17:22:55,132][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:22:55,424][root][INFO] - Loading VLLM model.
WARNING 01-08 17:22:55 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:22:55 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:22:56 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:22:56 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:22:56,981][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:22:58,362][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 17:22:58,766][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 17:23:00,128][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 17:23:01,539][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 17:23:01,539][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 17:23:01 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:23:15 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:23:16 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:23:16 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:23:37 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:23:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:37,615][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:41,297][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:55,  3.68s/it, est. speed input: 137.18 toks/s, output: 15.76 toks/s]
[2025-01-08 17:23:41,684][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.10s/it, est. speed input: 372.37 toks/s, output: 45.72 toks/s]
[2025-01-08 17:23:41,852][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:09,  1.29it/s, est. speed input: 476.85 toks/s, output: 61.38 toks/s]
[2025-01-08 17:23:42,125][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:04<00:03,  2.73it/s, est. speed input: 783.98 toks/s, output: 110.22 toks/s]
[2025-01-08 17:23:42,293][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.10it/s, est. speed input: 863.69 toks/s, output: 125.28 toks/s]
[2025-01-08 17:23:42,655][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.73it/s, est. speed input: 1002.03 toks/s, output: 154.97 toks/s]
[2025-01-08 17:23:42,773][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  5.17it/s, est. speed input: 1174.89 toks/s, output: 193.10 toks/s]
[2025-01-08 17:23:42,876][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:05<00:00,  6.87it/s, est. speed input: 1343.97 toks/s, output: 231.72 toks/s]
[2025-01-08 17:23:43,334][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  5.79it/s, est. speed input: 1413.01 toks/s, output: 259.69 toks/s]
[2025-01-08 17:23:43,334][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.80it/s, est. speed input: 1413.01 toks/s, output: 259.69 toks/s]
WARNING 01-08 17:23:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:43,536][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:44,493][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.04it/s, est. speed input: 629.11 toks/s, output: 29.26 toks/s]
[2025-01-08 17:23:44,646][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  3.28it/s, est. speed input: 1750.59 toks/s, output: 84.73 toks/s]
[2025-01-08 17:23:44,646][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.70it/s, est. speed input: 1750.59 toks/s, output: 84.73 toks/s]
WARNING 01-08 17:23:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:44,859][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:47,972][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:37,  3.11s/it, est. speed input: 224.60 toks/s, output: 18.96 toks/s]
[2025-01-08 17:23:48,332][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:16,  1.49s/it, est. speed input: 402.64 toks/s, output: 37.15 toks/s]
[2025-01-08 17:23:48,582][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:09,  1.08it/s, est. speed input: 563.39 toks/s, output: 55.61 toks/s]
[2025-01-08 17:23:48,696][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.30it/s, est. speed input: 910.86 toks/s, output: 95.91 toks/s]
[2025-01-08 17:23:48,884][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:02,  2.75it/s, est. speed input: 1042.11 toks/s, output: 113.55 toks/s]
[2025-01-08 17:23:49,155][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:00,  4.71it/s, est. speed input: 1464.53 toks/s, output: 171.34 toks/s]
[2025-01-08 17:23:49,519][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  4.95it/s, est. speed input: 1650.14 toks/s, output: 206.02 toks/s]
[2025-01-08 17:23:49,958][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  4.81it/s, est. speed input: 1782.13 toks/s, output: 240.44 toks/s]
[2025-01-08 17:23:49,959][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.55it/s, est. speed input: 1782.13 toks/s, output: 240.44 toks/s]
WARNING 01-08 17:23:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:50,201][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:52,834][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:26,  2.63s/it, est. speed input: 250.67 toks/s, output: 20.51 toks/s]
[2025-01-08 17:23:53,362][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:12,  1.39s/it, est. speed input: 423.94 toks/s, output: 39.86 toks/s]
[2025-01-08 17:23:53,616][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:06,  1.14it/s, est. speed input: 590.67 toks/s, output: 60.62 toks/s]
[2025-01-08 17:23:53,830][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:03<00:04,  1.63it/s, est. speed input: 741.63 toks/s, output: 81.58 toks/s]
[2025-01-08 17:23:54,149][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:03<00:01,  2.68it/s, est. speed input: 1011.72 toks/s, output: 124.12 toks/s]
[2025-01-08 17:23:54,583][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:04<00:00,  3.27it/s, est. speed input: 1219.51 toks/s, output: 163.62 toks/s]
[2025-01-08 17:23:54,881][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:04<00:00,  3.29it/s, est. speed input: 1290.46 toks/s, output: 182.49 toks/s]
[2025-01-08 17:23:54,992][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  3.92it/s, est. speed input: 1405.15 toks/s, output: 208.13 toks/s]
[2025-01-08 17:23:55,076][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.26it/s, est. speed input: 1524.27 toks/s, output: 234.90 toks/s]
WARNING 01-08 17:23:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:55,294][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:56,447][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.15s/it, est. speed input: 442.48 toks/s, output: 21.69 toks/s]
[2025-01-08 17:23:57,168][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:01<00:01,  1.77it/s, est. speed input: 1103.44 toks/s, output: 61.39 toks/s]
[2025-01-08 17:23:57,480][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  2.09it/s, est. speed input: 1345.87 toks/s, output: 88.32 toks/s]
[2025-01-08 17:23:57,731][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.48it/s, est. speed input: 1493.95 toks/s, output: 117.38 toks/s]
[2025-01-08 17:23:57,731][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.05it/s, est. speed input: 1493.95 toks/s, output: 117.38 toks/s]
WARNING 01-08 17:23:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:23:57,935][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:23:59,036][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.10s/it, est. speed input: 644.77 toks/s, output: 26.34 toks/s]
[2025-01-08 17:24:00,062][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.06s/it, est. speed input: 645.01 toks/s, output: 51.71 toks/s]
[2025-01-08 17:24:00,630][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.20it/s, est. speed input: 775.46 toks/s, output: 82.37 toks/s]
[2025-01-08 17:24:00,898][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.64it/s, est. speed input: 963.77 toks/s, output: 118.11 toks/s]
[2025-01-08 17:24:00,898][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.35it/s, est. speed input: 963.77 toks/s, output: 118.11 toks/s]
WARNING 01-08 17:24:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:01,118][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:03,550][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.43s/it, est. speed input: 236.04 toks/s, output: 11.93 toks/s]
[2025-01-08 17:24:04,720][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:16,  1.69s/it, est. speed input: 447.55 toks/s, output: 26.38 toks/s]
[2025-01-08 17:24:04,899][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:09,  1.00s/it, est. speed input: 707.15 toks/s, output: 44.16 toks/s]
[2025-01-08 17:24:05,271][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.33it/s, est. speed input: 899.59 toks/s, output: 60.68 toks/s]
[2025-01-08 17:24:05,380][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.62it/s, est. speed input: 1369.35 toks/s, output: 100.66 toks/s]
[2025-01-08 17:24:05,823][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.51it/s, est. speed input: 1472.55 toks/s, output: 113.93 toks/s]
[2025-01-08 17:24:06,723][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  2.89it/s, est. speed input: 1816.97 toks/s, output: 161.46 toks/s]
[2025-01-08 17:24:07,182][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:06<00:00,  2.71it/s, est. speed input: 1853.49 toks/s, output: 178.27 toks/s]
[2025-01-08 17:24:07,587][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.65it/s, est. speed input: 1901.49 toks/s, output: 198.02 toks/s]
[2025-01-08 17:24:07,587][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.85it/s, est. speed input: 1901.49 toks/s, output: 198.02 toks/s]
WARNING 01-08 17:24:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:07,811][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:11,707][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:42,  3.90s/it, est. speed input: 215.08 toks/s, output: 20.53 toks/s]
[2025-01-08 17:24:12,039][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:10,  1.13s/it, est. speed input: 596.76 toks/s, output: 60.08 toks/s]
[2025-01-08 17:24:12,238][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.23it/s, est. speed input: 755.59 toks/s, output: 79.51 toks/s]
[2025-01-08 17:24:12,373][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:04,  1.70it/s, est. speed input: 925.89 toks/s, output: 99.73 toks/s]
[2025-01-08 17:24:12,584][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.15it/s, est. speed input: 1051.29 toks/s, output: 118.58 toks/s]
[2025-01-08 17:24:12,859][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  3.24it/s, est. speed input: 1337.48 toks/s, output: 158.49 toks/s]
[2025-01-08 17:24:13,027][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  4.60it/s, est. speed input: 1631.92 toks/s, output: 202.84 toks/s]
[2025-01-08 17:24:13,284][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  4.42it/s, est. speed input: 1714.21 toks/s, output: 219.80 toks/s]
[2025-01-08 17:24:13,790][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.40it/s, est. speed input: 1722.18 toks/s, output: 230.47 toks/s]
[2025-01-08 17:24:13,790][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.01it/s, est. speed input: 1722.18 toks/s, output: 230.47 toks/s]
WARNING 01-08 17:24:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:14,027][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:16,091][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.06s/it, est. speed input: 500.85 toks/s, output: 30.52 toks/s]
[2025-01-08 17:24:16,214][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:01,  1.08it/s, est. speed input: 1006.21 toks/s, output: 60.34 toks/s]
[2025-01-08 17:24:16,520][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.27it/s, est. speed input: 1802.09 toks/s, output: 115.91 toks/s]
[2025-01-08 17:24:16,520][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.60it/s, est. speed input: 1802.09 toks/s, output: 115.91 toks/s]
WARNING 01-08 17:24:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:16,738][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:18,107][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.37s/it, est. speed input: 697.62 toks/s, output: 27.03 toks/s]
[2025-01-08 17:24:18,328][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.44it/s, est. speed input: 1119.89 toks/s, output: 53.48 toks/s]
[2025-01-08 17:24:19,612][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.04it/s, est. speed input: 938.26 toks/s, output: 70.65 toks/s]
[2025-01-08 17:24:19,967][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.38it/s, est. speed input: 1136.79 toks/s, output: 105.93 toks/s]
[2025-01-08 17:24:19,967][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.24it/s, est. speed input: 1136.79 toks/s, output: 105.93 toks/s]
WARNING 01-08 17:24:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:20,195][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:24,440][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:04<00:46,  4.24s/it, est. speed input: 334.36 toks/s, output: 15.55 toks/s]
[2025-01-08 17:24:24,596][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:10,  1.16s/it, est. speed input: 972.71 toks/s, output: 46.59 toks/s]
[2025-01-08 17:24:24,741][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.24it/s, est. speed input: 1251.47 toks/s, output: 61.83 toks/s]
[2025-01-08 17:24:24,849][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.31it/s, est. speed input: 1863.56 toks/s, output: 94.11 toks/s]
[2025-01-08 17:24:25,548][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  2.51it/s, est. speed input: 2183.94 toks/s, output: 119.38 toks/s]
[2025-01-08 17:24:25,737][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  3.51it/s, est. speed input: 2625.10 toks/s, output: 156.64 toks/s]
[2025-01-08 17:24:26,031][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  3.48it/s, est. speed input: 2734.62 toks/s, output: 171.70 toks/s]
[2025-01-08 17:24:27,147][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.09it/s, est. speed input: 2501.12 toks/s, output: 172.92 toks/s]
[2025-01-08 17:24:27,147][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.73it/s, est. speed input: 2501.12 toks/s, output: 172.92 toks/s]
WARNING 01-08 17:24:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:27,422][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:28,864][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 575.13 toks/s, output: 48.56 toks/s]
[2025-01-08 17:24:28,864][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.44s/it, est. speed input: 575.13 toks/s, output: 48.56 toks/s]
WARNING 01-08 17:24:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:29,075][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:30,446][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.37s/it, est. speed input: 502.12 toks/s, output: 21.16 toks/s]
[2025-01-08 17:24:31,367][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.11s/it, est. speed input: 901.07 toks/s, output: 44.94 toks/s]
[2025-01-08 17:24:31,514][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.50it/s, est. speed input: 1431.75 toks/s, output: 75.85 toks/s]
[2025-01-08 17:24:31,920][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.77it/s, est. speed input: 1760.34 toks/s, output: 102.29 toks/s]
[2025-01-08 17:24:31,921][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.41it/s, est. speed input: 1760.34 toks/s, output: 102.29 toks/s]
WARNING 01-08 17:24:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:32,140][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:33,697][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 688.69 toks/s, output: 48.18 toks/s]
[2025-01-08 17:24:33,698][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.56s/it, est. speed input: 688.69 toks/s, output: 48.18 toks/s]
WARNING 01-08 17:24:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:33,917][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:35,163][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 1364.55 toks/s, output: 41.74 toks/s]
[2025-01-08 17:24:35,163][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 1364.55 toks/s, output: 41.74 toks/s]
WARNING 01-08 17:24:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:35,384][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:36,310][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.08it/s, est. speed input: 1273.34 toks/s, output: 39.96 toks/s]
[2025-01-08 17:24:36,311][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.08it/s, est. speed input: 1273.34 toks/s, output: 39.96 toks/s]
WARNING 01-08 17:24:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:24:36,530][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:24:37,287][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1059.68 toks/s, output: 38.32 toks/s]
[2025-01-08 17:24:37,287][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1059.68 toks/s, output: 38.32 toks/s]
[2025-01-08 17:24:43,120][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:24:43,173][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:24:44,933][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 17:24:46,602][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 17:24:48,240][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 17:24:48,769][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:24:48,769][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 17:25:00,246][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:25:00,762][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:25:00,814][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:25:02,799][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.98s/it]
[2025-01-08 17:25:04,475][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.80s/it]
[2025-01-08 17:25:06,091][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.72s/it]
[2025-01-08 17:25:06,596][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 17:25:06,597][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.45s/it]
[2025-01-08 17:25:21,112][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:25:21,467][root][INFO] - Loading VLLM model.
WARNING 01-08 17:25:21 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:25:21 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:25:22 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:25:22 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:25:22,348][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:25:23,719][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 17:25:24,124][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 17:25:25,484][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 17:25:26,893][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 17:25:26,893][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 17:25:27 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:25:40 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:25:41 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:25:41 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:26:02 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:26:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:02,657][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:06,795][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:02,  4.14s/it, est. speed input: 122.05 toks/s, output: 14.02 toks/s]
[2025-01-08 17:26:07,182][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:15,  1.22s/it, est. speed input: 334.84 toks/s, output: 41.11 toks/s]
[2025-01-08 17:26:07,449][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:10,  1.13it/s, est. speed input: 421.49 toks/s, output: 54.88 toks/s]
[2025-01-08 17:26:07,624][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.06it/s, est. speed input: 813.41 toks/s, output: 116.98 toks/s]
[2025-01-08 17:26:08,143][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.27it/s, est. speed input: 920.48 toks/s, output: 141.26 toks/s]
[2025-01-08 17:26:08,263][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:01,  3.69it/s, est. speed input: 990.97 toks/s, output: 157.52 toks/s]
[2025-01-08 17:26:08,414][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  4.93it/s, est. speed input: 1140.26 toks/s, output: 192.45 toks/s]
[2025-01-08 17:26:08,607][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  5.97it/s, est. speed input: 1273.08 toks/s, output: 227.73 toks/s]
[2025-01-08 17:26:08,741][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.63it/s, est. speed input: 1328.07 toks/s, output: 244.57 toks/s]
WARNING 01-08 17:26:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:08,945][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:09,910][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.04it/s, est. speed input: 623.85 toks/s, output: 30.05 toks/s]
[2025-01-08 17:26:09,946][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  3.00it/s, est. speed input: 1931.14 toks/s, output: 89.91 toks/s]
WARNING 01-08 17:26:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:10,159][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:13,237][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:36,  3.08s/it, est. speed input: 227.14 toks/s, output: 18.85 toks/s]
[2025-01-08 17:26:13,629][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:16,  1.50s/it, est. speed input: 402.91 toks/s, output: 36.89 toks/s]
[2025-01-08 17:26:13,863][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.08it/s, est. speed input: 943.59 toks/s, output: 94.76 toks/s]
[2025-01-08 17:26:13,970][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:02,  2.59it/s, est. speed input: 1100.43 toks/s, output: 113.61 toks/s]
[2025-01-08 17:26:14,173][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  5.33it/s, est. speed input: 1741.31 toks/s, output: 193.31 toks/s]
[2025-01-08 17:26:14,458][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  5.75it/s, est. speed input: 1951.42 toks/s, output: 227.76 toks/s]
[2025-01-08 17:26:14,912][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.74it/s, est. speed input: 1911.92 toks/s, output: 233.97 toks/s]
WARNING 01-08 17:26:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:15,155][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:18,690][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:38,  3.54s/it, est. speed input: 189.25 toks/s, output: 21.78 toks/s]
[2025-01-08 17:26:18,928][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:09,  1.00s/it, est. speed input: 523.47 toks/s, output: 63.61 toks/s]
[2025-01-08 17:26:19,039][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:03,  1.94it/s, est. speed input: 851.76 toks/s, output: 107.11 toks/s]
[2025-01-08 17:26:19,486][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.55it/s, est. speed input: 1090.79 toks/s, output: 142.93 toks/s]
[2025-01-08 17:26:19,674][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  4.24it/s, est. speed input: 1488.89 toks/s, output: 211.34 toks/s]
[2025-01-08 17:26:20,072][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  4.46it/s, est. speed input: 1653.03 toks/s, output: 247.71 toks/s]
[2025-01-08 17:26:20,072][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.44it/s, est. speed input: 1653.03 toks/s, output: 247.71 toks/s]
WARNING 01-08 17:26:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:20,285][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:21,389][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.10s/it, est. speed input: 734.65 toks/s, output: 26.27 toks/s]
[2025-01-08 17:26:22,133][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.12it/s, est. speed input: 817.03 toks/s, output: 51.94 toks/s]
[2025-01-08 17:26:22,427][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.62it/s, est. speed input: 1031.56 toks/s, output: 83.59 toks/s]
[2025-01-08 17:26:23,128][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.54it/s, est. speed input: 956.46 toks/s, output: 106.94 toks/s]
[2025-01-08 17:26:23,128][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.41it/s, est. speed input: 956.46 toks/s, output: 106.94 toks/s]
WARNING 01-08 17:26:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:23,332][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:24,437][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.11s/it, est. speed input: 643.29 toks/s, output: 26.24 toks/s]
[2025-01-08 17:26:25,593][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.40it/s, est. speed input: 1001.40 toks/s, output: 66.79 toks/s]
[2025-01-08 17:26:25,627][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.74it/s, est. speed input: 1281.08 toks/s, output: 106.76 toks/s]
WARNING 01-08 17:26:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:25,848][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:29,311][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:38,  3.46s/it, est. speed input: 303.57 toks/s, output: 17.04 toks/s]
[2025-01-08 17:26:29,974][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:18,  1.82s/it, est. speed input: 522.83 toks/s, output: 33.69 toks/s]
[2025-01-08 17:26:30,121][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:05,  1.38it/s, est. speed input: 997.95 toks/s, output: 71.85 toks/s]
[2025-01-08 17:26:30,447][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:04,  1.67it/s, est. speed input: 1161.19 toks/s, output: 87.85 toks/s]
[2025-01-08 17:26:30,606][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.15it/s, est. speed input: 1341.75 toks/s, output: 106.57 toks/s]
[2025-01-08 17:26:30,742][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  4.41it/s, est. speed input: 1953.27 toks/s, output: 168.58 toks/s]
[2025-01-08 17:26:31,592][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  3.37it/s, est. speed input: 2030.49 toks/s, output: 196.03 toks/s]
[2025-01-08 17:26:32,150][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.87it/s, est. speed input: 2022.03 toks/s, output: 207.88 toks/s]
[2025-01-08 17:26:32,150][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.90it/s, est. speed input: 2022.03 toks/s, output: 207.88 toks/s]
WARNING 01-08 17:26:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:32,376][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:34,759][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.38s/it, est. speed input: 359.73 toks/s, output: 12.59 toks/s]
[2025-01-08 17:26:36,175][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:19,  1.81s/it, est. speed input: 449.65 toks/s, output: 27.12 toks/s]
[2025-01-08 17:26:36,866][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:13,  1.30s/it, est. speed input: 577.60 toks/s, output: 44.11 toks/s]
[2025-01-08 17:26:36,984][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.67it/s, est. speed input: 920.22 toks/s, output: 85.73 toks/s]
[2025-01-08 17:26:37,120][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:03,  2.15it/s, est. speed input: 1079.92 toks/s, output: 105.21 toks/s]
[2025-01-08 17:26:37,251][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:02,  2.72it/s, est. speed input: 1222.69 toks/s, output: 124.73 toks/s]
[2025-01-08 17:26:37,398][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:05<00:01,  3.30it/s, est. speed input: 1357.42 toks/s, output: 143.99 toks/s]
[2025-01-08 17:26:37,532][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  5.12it/s, est. speed input: 1660.65 toks/s, output: 186.58 toks/s]
[2025-01-08 17:26:37,833][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:05<00:00,  4.52it/s, est. speed input: 1734.46 toks/s, output: 201.21 toks/s]
[2025-01-08 17:26:38,157][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  5.08it/s, est. speed input: 1952.28 toks/s, output: 240.62 toks/s]
[2025-01-08 17:26:38,158][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.25it/s, est. speed input: 1952.28 toks/s, output: 240.62 toks/s]
WARNING 01-08 17:26:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:38,394][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:39,507][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 1000.96 toks/s, output: 26.06 toks/s]
[2025-01-08 17:26:40,021][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.31it/s, est. speed input: 1434.68 toks/s, output: 52.86 toks/s]
[2025-01-08 17:26:40,916][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.22it/s, est. speed input: 1344.28 toks/s, output: 77.72 toks/s]
[2025-01-08 17:26:40,916][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.19it/s, est. speed input: 1344.28 toks/s, output: 77.72 toks/s]
WARNING 01-08 17:26:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:41,131][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:42,311][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.18s/it, est. speed input: 695.17 toks/s, output: 24.58 toks/s]
[2025-01-08 17:26:42,908][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.19it/s, est. speed input: 1003.26 toks/s, output: 49.52 toks/s]
[2025-01-08 17:26:43,312][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.56it/s, est. speed input: 1196.54 toks/s, output: 77.51 toks/s]
[2025-01-08 17:26:43,547][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.08it/s, est. speed input: 1431.58 toks/s, output: 109.26 toks/s]
[2025-01-08 17:26:43,548][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.66it/s, est. speed input: 1431.58 toks/s, output: 109.26 toks/s]
WARNING 01-08 17:26:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:43,771][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:48,585][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:04<00:52,  4.81s/it, est. speed input: 304.51 toks/s, output: 18.28 toks/s]
[2025-01-08 17:26:49,099][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:05<00:22,  2.28s/it, est. speed input: 546.90 toks/s, output: 36.03 toks/s]
[2025-01-08 17:26:49,508][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:05<00:07,  1.02it/s, est. speed input: 882.05 toks/s, output: 72.69 toks/s]
[2025-01-08 17:26:49,674][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:05<00:05,  1.37it/s, est. speed input: 1109.42 toks/s, output: 91.65 toks/s]
[2025-01-08 17:26:49,863][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:06<00:03,  1.78it/s, est. speed input: 1214.80 toks/s, output: 110.32 toks/s]
[2025-01-08 17:26:50,463][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:06<00:02,  1.74it/s, est. speed input: 1322.88 toks/s, output: 123.58 toks/s]
[2025-01-08 17:26:50,681][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:06<00:00,  3.44it/s, est. speed input: 1909.72 toks/s, output: 189.58 toks/s]
[2025-01-08 17:26:50,847][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:07<00:00,  3.79it/s, est. speed input: 2068.52 toks/s, output: 209.73 toks/s]
[2025-01-08 17:26:50,864][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:07<00:00,  1.69it/s, est. speed input: 2263.49 toks/s, output: 233.89 toks/s]
WARNING 01-08 17:26:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:51,140][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:52,088][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1020.12 toks/s, output: 31.65 toks/s]
[2025-01-08 17:26:52,596][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.45it/s, est. speed input: 1425.40 toks/s, output: 61.85 toks/s]
[2025-01-08 17:26:52,596][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.37it/s, est. speed input: 1425.40 toks/s, output: 61.85 toks/s]
WARNING 01-08 17:26:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:52,819][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:54,470][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.65s/it, est. speed input: 943.01 toks/s, output: 17.56 toks/s]
[2025-01-08 17:26:54,737][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.19it/s, est. speed input: 1655.85 toks/s, output: 36.50 toks/s]
[2025-01-08 17:26:55,433][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.29it/s, est. speed input: 1756.97 toks/s, output: 55.47 toks/s]
[2025-01-08 17:26:55,654][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.80it/s, est. speed input: 2138.93 toks/s, output: 81.85 toks/s]
[2025-01-08 17:26:56,043][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  2.02it/s, est. speed input: 2327.21 toks/s, output: 106.08 toks/s]
[2025-01-08 17:26:56,043][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.55it/s, est. speed input: 2327.21 toks/s, output: 106.08 toks/s]
WARNING 01-08 17:26:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:56,292][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:26:57,236][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1098.11 toks/s, output: 30.74 toks/s]
[2025-01-08 17:26:57,963][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.23it/s, est. speed input: 1337.84 toks/s, output: 60.46 toks/s]
[2025-01-08 17:26:57,963][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.20it/s, est. speed input: 1337.84 toks/s, output: 60.46 toks/s]
WARNING 01-08 17:26:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:26:58,199][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:27:00,246][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:02<00:02,  2.05s/it, est. speed input: 445.61 toks/s, output: 43.49 toks/s]
[2025-01-08 17:27:00,500][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.01it/s, est. speed input: 942.41 toks/s, output: 83.89 toks/s]
[2025-01-08 17:27:00,500][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.15s/it, est. speed input: 942.41 toks/s, output: 83.89 toks/s]
[2025-01-08 17:27:06,535][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:27:06,587][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:27:08,339][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 17:27:10,013][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 17:27:11,677][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 17:27:12,212][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 17:27:12,213][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 17:27:23,842][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:27:24,407][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:27:24,460][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:27:26,441][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.98s/it]
[2025-01-08 17:27:28,088][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:27:29,732][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.72s/it]
[2025-01-08 17:27:30,247][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 17:27:30,247][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.45s/it]
[2025-01-08 17:27:44,708][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:27:45,027][root][INFO] - Loading VLLM model.
WARNING 01-08 17:27:45 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:27:45 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:27:45 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:27:45 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:27:45,985][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:27:47,400][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.41s/it]
[2025-01-08 17:27:47,825][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.20it/s]
[2025-01-08 17:27:49,233][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.10s/it]
[2025-01-08 17:27:50,693][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.24s/it]
[2025-01-08 17:27:50,693][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
INFO 01-08 17:27:50 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:28:04 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:28:05 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:28:05 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:28:26 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:28:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:26,946][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:31,000][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:00,  4.05s/it, est. speed input: 124.57 toks/s, output: 14.31 toks/s]
[2025-01-08 17:28:31,177][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.12s/it, est. speed input: 358.08 toks/s, output: 42.54 toks/s]
[2025-01-08 17:28:31,478][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:10,  1.20it/s, est. speed input: 445.69 toks/s, output: 55.60 toks/s]
[2025-01-08 17:28:31,627][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.28it/s, est. speed input: 863.17 toks/s, output: 117.51 toks/s]
[2025-01-08 17:28:32,195][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.35it/s, est. speed input: 962.18 toks/s, output: 139.28 toks/s]
[2025-01-08 17:28:32,427][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  4.15it/s, est. speed input: 1105.66 toks/s, output: 172.42 toks/s]
[2025-01-08 17:28:33,410][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  4.11it/s, est. speed input: 1250.02 toks/s, output: 224.01 toks/s]
[2025-01-08 17:28:33,410][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.48it/s, est. speed input: 1250.02 toks/s, output: 224.01 toks/s]
WARNING 01-08 17:28:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:33,616][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:34,735][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.12s/it, est. speed input: 542.32 toks/s, output: 25.91 toks/s]
[2025-01-08 17:28:34,959][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.68it/s, est. speed input: 1386.30 toks/s, output: 75.94 toks/s]
[2025-01-08 17:28:36,045][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.61it/s, est. speed input: 1056.23 toks/s, output: 85.62 toks/s]
[2025-01-08 17:28:36,045][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.65it/s, est. speed input: 1056.23 toks/s, output: 85.62 toks/s]
WARNING 01-08 17:28:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:36,258][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:38,945][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:29,  2.69s/it, est. speed input: 260.20 toks/s, output: 18.61 toks/s]
[2025-01-08 17:28:39,723][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:15,  1.56s/it, est. speed input: 403.56 toks/s, output: 36.08 toks/s]
[2025-01-08 17:28:39,900][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:08,  1.07it/s, est. speed input: 575.87 toks/s, output: 56.57 toks/s]
[2025-01-08 17:28:40,037][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:03,  2.26it/s, est. speed input: 924.88 toks/s, output: 99.24 toks/s]
[2025-01-08 17:28:40,167][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:02,  2.84it/s, est. speed input: 1072.98 toks/s, output: 119.22 toks/s]
[2025-01-08 17:28:40,557][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  4.36it/s, est. speed input: 1463.52 toks/s, output: 176.57 toks/s]
[2025-01-08 17:28:40,755][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  4.48it/s, est. speed input: 1554.38 toks/s, output: 195.24 toks/s]
[2025-01-08 17:28:40,921][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.76it/s, est. speed input: 1649.07 toks/s, output: 215.76 toks/s]
[2025-01-08 17:28:41,325][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.88it/s, est. speed input: 1655.60 toks/s, output: 228.56 toks/s]
[2025-01-08 17:28:41,325][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.37it/s, est. speed input: 1655.60 toks/s, output: 228.56 toks/s]
WARNING 01-08 17:28:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:41,573][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:44,721][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:34,  3.15s/it, est. speed input: 204.57 toks/s, output: 20.65 toks/s]
[2025-01-08 17:28:44,843][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:07,  1.16it/s, est. speed input: 602.08 toks/s, output: 61.46 toks/s]
[2025-01-08 17:28:44,957][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:04,  1.66it/s, est. speed input: 778.16 toks/s, output: 80.98 toks/s]
[2025-01-08 17:28:45,304][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:03,  1.93it/s, est. speed input: 890.61 toks/s, output: 96.48 toks/s]
[2025-01-08 17:28:45,538][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:02,  2.34it/s, est. speed input: 1007.91 toks/s, output: 114.76 toks/s]
[2025-01-08 17:28:45,815][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.46it/s, est. speed input: 1263.04 toks/s, output: 155.82 toks/s]
[2025-01-08 17:28:46,181][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  3.24it/s, est. speed input: 1305.71 toks/s, output: 170.35 toks/s]
[2025-01-08 17:28:46,460][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.21it/s, est. speed input: 1514.93 toks/s, output: 214.87 toks/s]
[2025-01-08 17:28:47,414][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.48it/s, est. speed input: 1386.82 toks/s, output: 213.30 toks/s]
[2025-01-08 17:28:47,415][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.05it/s, est. speed input: 1386.82 toks/s, output: 213.30 toks/s]
WARNING 01-08 17:28:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:47,628][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:48,725][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.10s/it, est. speed input: 465.03 toks/s, output: 26.44 toks/s]
[2025-01-08 17:28:49,490][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.11it/s, est. speed input: 649.23 toks/s, output: 52.09 toks/s]
[2025-01-08 17:28:49,674][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.74it/s, est. speed input: 932.69 toks/s, output: 85.54 toks/s]
[2025-01-08 17:28:49,674][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.96it/s, est. speed input: 1274.22 toks/s, output: 123.66 toks/s]
WARNING 01-08 17:28:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:49,880][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:51,010][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.13s/it, est. speed input: 634.14 toks/s, output: 25.68 toks/s]
[2025-01-08 17:28:51,286][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.59it/s, est. speed input: 1021.58 toks/s, output: 51.22 toks/s]
[2025-01-08 17:28:52,494][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.12it/s, est. speed input: 847.94 toks/s, output: 69.26 toks/s]
[2025-01-08 17:28:52,847][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.47it/s, est. speed input: 1046.86 toks/s, output: 104.82 toks/s]
[2025-01-08 17:28:52,848][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.35it/s, est. speed input: 1046.86 toks/s, output: 104.82 toks/s]
WARNING 01-08 17:28:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:53,070][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:28:56,845][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:41,  3.77s/it, est. speed input: 283.49 toks/s, output: 18.02 toks/s]
[2025-01-08 17:28:57,414][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:18,  1.89s/it, est. speed input: 491.48 toks/s, output: 35.45 toks/s]
[2025-01-08 17:28:57,564][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:09,  1.10s/it, est. speed input: 713.19 toks/s, output: 54.52 toks/s]
[2025-01-08 17:28:57,808][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.36it/s, est. speed input: 1355.15 toks/s, output: 112.30 toks/s]
[2025-01-08 17:28:58,005][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.71it/s, est. speed input: 1523.51 toks/s, output: 129.69 toks/s]
[2025-01-08 17:28:58,328][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  2.80it/s, est. speed input: 1624.57 toks/s, output: 144.94 toks/s]
[2025-01-08 17:28:58,452][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  4.29it/s, est. speed input: 1992.29 toks/s, output: 188.23 toks/s]
[2025-01-08 17:28:59,772][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:06<00:00,  2.06it/s, est. speed input: 1758.06 toks/s, output: 181.00 toks/s]
[2025-01-08 17:28:59,772][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.79it/s, est. speed input: 1919.41 toks/s, output: 210.83 toks/s]
WARNING 01-08 17:28:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:28:59,995][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:02,966][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:29,  2.97s/it, est. speed input: 265.57 toks/s, output: 19.19 toks/s]
[2025-01-08 17:29:03,366][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:07,  1.09it/s, est. speed input: 746.14 toks/s, output: 55.18 toks/s]
[2025-01-08 17:29:03,555][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:03<00:04,  1.50it/s, est. speed input: 1001.97 toks/s, output: 74.16 toks/s]
[2025-01-08 17:29:04,000][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.69it/s, est. speed input: 1096.25 toks/s, output: 89.65 toks/s]
[2025-01-08 17:29:04,114][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:04<00:01,  3.01it/s, est. speed input: 1472.86 toks/s, output: 134.49 toks/s]
[2025-01-08 17:29:04,441][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:04<00:00,  3.02it/s, est. speed input: 1562.87 toks/s, output: 150.46 toks/s]
[2025-01-08 17:29:04,583][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:04<00:00,  3.57it/s, est. speed input: 1714.20 toks/s, output: 172.42 toks/s]
[2025-01-08 17:29:04,967][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  3.23it/s, est. speed input: 1777.45 toks/s, output: 187.84 toks/s]
[2025-01-08 17:29:05,085][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  3.92it/s, est. speed input: 1905.69 toks/s, output: 212.94 toks/s]
[2025-01-08 17:29:05,086][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  2.16it/s, est. speed input: 1905.69 toks/s, output: 212.94 toks/s]
WARNING 01-08 17:29:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:05,324][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:07,477][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:02<00:08,  2.15s/it, est. speed input: 491.12 toks/s, output: 26.95 toks/s]
[2025-01-08 17:29:07,699][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.02s/it, est. speed input: 998.93 toks/s, output: 53.06 toks/s]
[2025-01-08 17:29:07,882][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  2.29it/s, est. speed input: 1747.41 toks/s, output: 106.33 toks/s]
[2025-01-08 17:29:08,423][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  2.13it/s, est. speed input: 1873.87 toks/s, output: 123.27 toks/s]
[2025-01-08 17:29:08,424][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.61it/s, est. speed input: 1873.87 toks/s, output: 123.27 toks/s]
WARNING 01-08 17:29:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:08,631][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:10,266][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.63s/it, est. speed input: 519.35 toks/s, output: 26.92 toks/s]
[2025-01-08 17:29:10,593][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.16it/s, est. speed input: 853.62 toks/s, output: 52.52 toks/s]
[2025-01-08 17:29:11,032][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.49it/s, est. speed input: 1103.51 toks/s, output: 76.65 toks/s]
[2025-01-08 17:29:11,527][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.66it/s, est. speed input: 1210.00 toks/s, output: 100.86 toks/s]
[2025-01-08 17:29:11,930][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.89it/s, est. speed input: 1320.39 toks/s, output: 128.55 toks/s]
[2025-01-08 17:29:11,930][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.52it/s, est. speed input: 1320.39 toks/s, output: 128.55 toks/s]
WARNING 01-08 17:29:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:12,154][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:16,003][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:03<00:38,  3.85s/it, est. speed input: 371.73 toks/s, output: 16.88 toks/s]
[2025-01-08 17:29:16,155][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:04<00:15,  1.67s/it, est. speed input: 712.99 toks/s, output: 33.74 toks/s]
[2025-01-08 17:29:16,328][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:04<00:07,  1.01it/s, est. speed input: 1028.34 toks/s, output: 50.54 toks/s]
[2025-01-08 17:29:16,894][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.70it/s, est. speed input: 1335.27 toks/s, output: 81.44 toks/s]
[2025-01-08 17:29:17,120][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:04<00:02,  2.06it/s, est. speed input: 1581.03 toks/s, output: 99.08 toks/s]
[2025-01-08 17:29:17,355][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:05<00:01,  2.43it/s, est. speed input: 1786.64 toks/s, output: 116.90 toks/s]
[2025-01-08 17:29:17,932][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:01,  2.17it/s, est. speed input: 1854.86 toks/s, output: 129.81 toks/s]
[2025-01-08 17:29:18,178][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:06<00:00,  2.52it/s, est. speed input: 2021.16 toks/s, output: 150.07 toks/s]
[2025-01-08 17:29:18,563][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:06<00:00,  2.54it/s, est. speed input: 2129.53 toks/s, output: 168.35 toks/s]
[2025-01-08 17:29:18,986][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  2.49it/s, est. speed input: 2215.31 toks/s, output: 187.21 toks/s]
[2025-01-08 17:29:18,986][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.61it/s, est. speed input: 2215.31 toks/s, output: 187.21 toks/s]
WARNING 01-08 17:29:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:19,247][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:21,647][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.40s/it, est. speed input: 504.24 toks/s, output: 51.67 toks/s]
[2025-01-08 17:29:21,647][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.40s/it, est. speed input: 504.24 toks/s, output: 51.67 toks/s]
WARNING 01-08 17:29:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:21,862][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:23,745][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:09,  1.88s/it, est. speed input: 924.62 toks/s, output: 15.40 toks/s]
[2025-01-08 17:29:25,075][root][ERROR] - Processed prompts:  33%|###3      | 2/6 [00:03<00:06,  1.56s/it, est. speed input: 978.61 toks/s, output: 35.79 toks/s]
[2025-01-08 17:29:25,253][root][ERROR] - Processed prompts:  50%|#####     | 3/6 [00:03<00:02,  1.08it/s, est. speed input: 1338.55 toks/s, output: 61.63 toks/s]
[2025-01-08 17:29:25,444][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:03<00:00,  2.19it/s, est. speed input: 2213.83 toks/s, output: 114.47 toks/s]
[2025-01-08 17:29:25,883][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:04<00:00,  2.21it/s, est. speed input: 2318.72 toks/s, output: 134.29 toks/s]
[2025-01-08 17:29:25,884][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:04<00:00,  1.49it/s, est. speed input: 2318.72 toks/s, output: 134.29 toks/s]
WARNING 01-08 17:29:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:26,152][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:28,129][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.98s/it, est. speed input: 691.04 toks/s, output: 49.58 toks/s]
[2025-01-08 17:29:28,130][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.98s/it, est. speed input: 691.04 toks/s, output: 49.58 toks/s]
WARNING 01-08 17:29:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:29:28,338][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:29:30,120][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 452.53 toks/s, output: 50.53 toks/s]
[2025-01-08 17:29:30,120][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.78s/it, est. speed input: 452.53 toks/s, output: 50.53 toks/s]
[2025-01-08 17:29:36,297][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:29:36,350][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:29:38,081][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 17:29:39,757][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 17:29:41,383][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 17:29:41,913][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:29:41,914][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 17:29:53,405][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:29:53,960][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:29:54,014][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:29:56,020][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:02<00:06,  2.01s/it]
[2025-01-08 17:29:57,649][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:33:27,661][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [03:33<01:36, 96.87s/it]
[2025-01-08 17:33:28,166][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [03:34<00:00, 58.82s/it]
[2025-01-08 17:33:28,166][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [03:34<00:00, 53.54s/it]
[2025-01-08 17:33:42,812][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:33:43,102][root][INFO] - Loading VLLM model.
WARNING 01-08 17:33:43 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:33:43 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:33:43 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:33:43 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:33:44,121][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:33:45,439][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:33:45,826][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:33:47,125][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 17:33:48,464][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 17:33:48,465][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:33:48 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:34:02 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:34:03 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:34:03 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:34:24 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:34:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:24,334][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:28,202][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:58,  3.87s/it, est. speed input: 130.59 toks/s, output: 13.19 toks/s]
[2025-01-08 17:34:28,454][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:24,  1.74s/it, est. speed input: 245.16 toks/s, output: 26.46 toks/s]
[2025-01-08 17:34:28,691][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:08,  1.38it/s, est. speed input: 463.70 toks/s, output: 53.49 toks/s]
[2025-01-08 17:34:28,821][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:05,  1.85it/s, est. speed input: 562.80 toks/s, output: 67.31 toks/s]
[2025-01-08 17:34:28,976][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:04,  2.37it/s, est. speed input: 652.85 toks/s, output: 81.01 toks/s]
[2025-01-08 17:34:29,148][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.77it/s, est. speed input: 839.34 toks/s, output: 110.73 toks/s]
[2025-01-08 17:34:29,253][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:04<00:01,  5.55it/s, est. speed input: 1026.66 toks/s, output: 142.11 toks/s]
[2025-01-08 17:34:29,491][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  6.34it/s, est. speed input: 1175.25 toks/s, output: 171.83 toks/s]
[2025-01-08 17:34:30,003][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:05<00:00,  5.23it/s, est. speed input: 1247.33 toks/s, output: 194.42 toks/s]
[2025-01-08 17:34:30,758][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  3.96it/s, est. speed input: 1257.98 toks/s, output: 216.25 toks/s]
[2025-01-08 17:34:30,758][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.49it/s, est. speed input: 1257.98 toks/s, output: 216.25 toks/s]
WARNING 01-08 17:34:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:30,963][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:31,814][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.18it/s, est. speed input: 716.40 toks/s, output: 34.11 toks/s]
[2025-01-08 17:34:31,814][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.35it/s, est. speed input: 1423.87 toks/s, output: 68.19 toks/s]
WARNING 01-08 17:34:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:32,030][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:35,207][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 220.08 toks/s, output: 17.63 toks/s]
[2025-01-08 17:34:35,678][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.37it/s, est. speed input: 766.53 toks/s, output: 66.34 toks/s]
[2025-01-08 17:34:35,826][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:03<00:05,  1.76it/s, est. speed input: 920.88 toks/s, output: 83.79 toks/s]
[2025-01-08 17:34:35,936][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  2.94it/s, est. speed input: 1252.72 toks/s, output: 121.87 toks/s]
[2025-01-08 17:34:36,248][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.72it/s, est. speed input: 1491.60 toks/s, output: 156.49 toks/s]
[2025-01-08 17:34:36,510][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  4.55it/s, est. speed input: 1716.35 toks/s, output: 191.75 toks/s]
[2025-01-08 17:34:36,621][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  6.09it/s, est. speed input: 1979.68 toks/s, output: 233.76 toks/s]
[2025-01-08 17:34:37,408][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.60it/s, est. speed input: 1819.77 toks/s, output: 228.73 toks/s]
WARNING 01-08 17:34:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:37,654][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:40,567][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:34,  2.91s/it, est. speed input: 233.05 toks/s, output: 18.53 toks/s]
[2025-01-08 17:34:40,928][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:15,  1.41s/it, est. speed input: 413.58 toks/s, output: 36.35 toks/s]
[2025-01-08 17:34:41,079][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.74it/s, est. speed input: 786.31 toks/s, output: 74.75 toks/s]
[2025-01-08 17:34:41,399][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:02,  2.64it/s, est. speed input: 1066.93 toks/s, output: 108.94 toks/s]
[2025-01-08 17:34:41,529][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  3.17it/s, est. speed input: 1196.87 toks/s, output: 127.74 toks/s]
[2025-01-08 17:34:41,746][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:04<00:01,  3.45it/s, est. speed input: 1293.13 toks/s, output: 144.41 toks/s]
[2025-01-08 17:34:42,062][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.37it/s, est. speed input: 1360.29 toks/s, output: 159.01 toks/s]
[2025-01-08 17:34:42,314][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  5.50it/s, est. speed input: 1746.12 toks/s, output: 225.72 toks/s]
[2025-01-08 17:34:42,365][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.76it/s, est. speed input: 1868.88 toks/s, output: 250.03 toks/s]
WARNING 01-08 17:34:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:42,583][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:43,590][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 839.69 toks/s, output: 28.82 toks/s]
[2025-01-08 17:34:45,147][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.33s/it, est. speed input: 602.28 toks/s, output: 55.78 toks/s]
[2025-01-08 17:34:45,282][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.27it/s, est. speed input: 831.28 toks/s, output: 98.21 toks/s]
[2025-01-08 17:34:45,282][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.11it/s, est. speed input: 831.28 toks/s, output: 98.21 toks/s]
WARNING 01-08 17:34:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:45,487][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:46,453][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.04it/s, est. speed input: 743.55 toks/s, output: 30.03 toks/s]
[2025-01-08 17:34:47,738][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.38it/s, est. speed input: 939.80 toks/s, output: 72.84 toks/s]
[2025-01-08 17:34:47,739][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.33it/s, est. speed input: 939.80 toks/s, output: 72.84 toks/s]
WARNING 01-08 17:34:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:47,965][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:51,521][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:42,  3.56s/it, est. speed input: 295.35 toks/s, output: 16.03 toks/s]
[2025-01-08 17:34:52,033][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:07,  1.23it/s, est. speed input: 1032.34 toks/s, output: 60.97 toks/s]
[2025-01-08 17:34:52,561][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:02,  2.13it/s, est. speed input: 1609.41 toks/s, output: 107.06 toks/s]
[2025-01-08 17:34:52,886][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  2.73it/s, est. speed input: 1930.66 toks/s, output: 141.45 toks/s]
[2025-01-08 17:34:53,592][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:01,  2.31it/s, est. speed input: 1880.99 toks/s, output: 148.59 toks/s]
[2025-01-08 17:34:53,775][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:05<00:00,  2.65it/s, est. speed input: 2017.28 toks/s, output: 169.56 toks/s]
[2025-01-08 17:34:53,959][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.01it/s, est. speed input: 2134.82 toks/s, output: 190.89 toks/s]
[2025-01-08 17:34:54,651][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.36it/s, est. speed input: 2067.91 toks/s, output: 201.05 toks/s]
[2025-01-08 17:34:54,651][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.94it/s, est. speed input: 2067.91 toks/s, output: 201.05 toks/s]
WARNING 01-08 17:34:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:34:54,910][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:34:57,701][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:30,  2.79s/it, est. speed input: 291.99 toks/s, output: 16.84 toks/s]
[2025-01-08 17:34:58,359][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:15,  1.54s/it, est. speed input: 478.64 toks/s, output: 33.34 toks/s]
[2025-01-08 17:34:58,538][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:08,  1.09it/s, est. speed input: 701.81 toks/s, output: 52.10 toks/s]
[2025-01-08 17:34:59,381][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.02it/s, est. speed input: 1118.99 toks/s, output: 100.42 toks/s]
[2025-01-08 17:34:59,541][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  2.98it/s, est. speed input: 1448.69 toks/s, output: 144.24 toks/s]
[2025-01-08 17:34:59,890][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:01,  2.96it/s, est. speed input: 1528.13 toks/s, output: 160.04 toks/s]
[2025-01-08 17:35:00,076][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  4.09it/s, est. speed input: 1802.02 toks/s, output: 206.35 toks/s]
[2025-01-08 17:35:00,735][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.00it/s, est. speed input: 1762.27 toks/s, output: 213.57 toks/s]
[2025-01-08 17:35:00,735][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.06it/s, est. speed input: 1762.27 toks/s, output: 213.57 toks/s]
WARNING 01-08 17:35:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:35:00,985][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:35:02,295][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.31s/it, est. speed input: 979.84 toks/s, output: 22.13 toks/s]
[2025-01-08 17:35:02,762][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.23it/s, est. speed input: 1368.86 toks/s, output: 45.59 toks/s]
[2025-01-08 17:35:03,001][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.81it/s, est. speed input: 1748.58 toks/s, output: 72.42 toks/s]
[2025-01-08 17:35:05,279][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.23s/it, est. speed input: 1075.88 toks/s, output: 80.57 toks/s]
[2025-01-08 17:35:05,279][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.07s/it, est. speed input: 1075.88 toks/s, output: 80.57 toks/s]
WARNING 01-08 17:35:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:35:05,487][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:35:06,631][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.14s/it, est. speed input: 723.37 toks/s, output: 25.37 toks/s]
[2025-01-08 17:35:07,682][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.09s/it, est. speed input: 743.97 toks/s, output: 50.57 toks/s]
[2025-01-08 17:35:07,811][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.54it/s, est. speed input: 1060.71 toks/s, output: 86.06 toks/s]
[2025-01-08 17:35:09,157][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.08it/s, est. speed input: 909.60 toks/s, output: 100.55 toks/s]
[2025-01-08 17:35:09,157][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.09it/s, est. speed input: 909.60 toks/s, output: 100.55 toks/s]
WARNING 01-08 17:35:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:35:09,386][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:35:13,223][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:42,  3.84s/it, est. speed input: 355.01 toks/s, output: 14.34 toks/s]
[2025-01-08 17:35:13,532][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:09,  1.11s/it, est. speed input: 1002.47 toks/s, output: 42.94 toks/s]
[2025-01-08 17:35:14,282][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:07,  1.02it/s, est. speed input: 1140.34 toks/s, output: 54.94 toks/s]
[2025-01-08 17:35:14,504][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:05<00:05,  1.37it/s, est. speed input: 1360.78 toks/s, output: 71.91 toks/s]
[2025-01-08 17:35:14,629][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  3.05it/s, est. speed input: 2146.08 toks/s, output: 128.56 toks/s]
[2025-01-08 17:35:14,795][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  4.17it/s, est. speed input: 2635.82 toks/s, output: 164.73 toks/s]
[2025-01-08 17:35:15,033][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  5.03it/s, est. speed input: 3058.96 toks/s, output: 201.88 toks/s]
[2025-01-08 17:35:15,034][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.12it/s, est. speed input: 3058.96 toks/s, output: 201.88 toks/s]
WARNING 01-08 17:35:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:35:15,319][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:35:17,488][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.17s/it, est. speed input: 663.13 toks/s, output: 27.67 toks/s]
[2025-01-08 17:35:17,766][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.50it/s, est. speed input: 1841.06 toks/s, output: 80.10 toks/s]
[2025-01-08 17:35:18,240][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.67it/s, est. speed input: 2079.87 toks/s, output: 102.37 toks/s]
[2025-01-08 17:35:18,240][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.37it/s, est. speed input: 2079.87 toks/s, output: 102.37 toks/s]
[2025-01-08 17:35:23,896][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:35:23,952][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:35:25,619][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 17:35:27,193][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.61s/it]
[2025-01-08 17:35:28,739][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.58s/it]
[2025-01-08 17:35:29,253][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.16s/it]
[2025-01-08 17:35:29,253][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.33s/it]
[2025-01-08 17:35:41,468][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:35:41,941][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:35:41,993][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:35:43,893][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 17:35:45,456][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 17:35:46,991][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 17:35:47,486][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:35:47,486][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 17:36:03,056][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:36:03,374][root][INFO] - Loading VLLM model.
WARNING 01-08 17:36:03 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:36:03 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:36:04 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:36:04 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:36:04,518][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:36:05,882][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 17:36:06,286][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 17:36:07,641][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 17:36:09,049][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 17:36:09,049][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 17:36:09 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:36:23 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:36:23 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:36:23 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:36:44 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:36:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:36:45,300][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:36:48,705][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:51,  3.41s/it, est. speed input: 148.31 toks/s, output: 14.98 toks/s]
[2025-01-08 17:36:48,886][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:21,  1.51s/it, est. speed input: 281.65 toks/s, output: 29.84 toks/s]
[2025-01-08 17:36:49,202][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:12,  1.04it/s, est. speed input: 388.28 toks/s, output: 44.08 toks/s]
[2025-01-08 17:36:49,463][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:05,  2.03it/s, est. speed input: 606.55 toks/s, output: 74.71 toks/s]
[2025-01-08 17:36:49,572][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:04<00:01,  5.64it/s, est. speed input: 1182.22 toks/s, output: 160.13 toks/s]
[2025-01-08 17:36:49,988][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:04<00:00,  5.38it/s, est. speed input: 1292.76 toks/s, output: 184.53 toks/s]
[2025-01-08 17:36:50,354][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:05<00:00,  5.40it/s, est. speed input: 1398.78 toks/s, output: 214.07 toks/s]
[2025-01-08 17:36:50,458][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  6.82it/s, est. speed input: 1566.61 toks/s, output: 254.96 toks/s]
[2025-01-08 17:36:50,458][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.10it/s, est. speed input: 1566.61 toks/s, output: 254.96 toks/s]
WARNING 01-08 17:36:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:36:50,658][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:36:51,529][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 744.46 toks/s, output: 33.32 toks/s]
[2025-01-08 17:36:51,529][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1477.90 toks/s, output: 66.60 toks/s]
WARNING 01-08 17:36:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:36:51,743][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:36:54,179][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:31,  2.44s/it, est. speed input: 287.03 toks/s, output: 14.37 toks/s]
[2025-01-08 17:36:54,381][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:13,  1.12s/it, est. speed input: 530.00 toks/s, output: 28.81 toks/s]
[2025-01-08 17:36:55,099][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:10,  1.07it/s, est. speed input: 624.97 toks/s, output: 41.43 toks/s]
[2025-01-08 17:36:55,441][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.42it/s, est. speed input: 756.14 toks/s, output: 57.60 toks/s]
[2025-01-08 17:36:55,810][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.34it/s, est. speed input: 1031.32 toks/s, output: 92.21 toks/s]
[2025-01-08 17:36:56,073][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.33it/s, est. speed input: 1291.66 toks/s, output: 129.81 toks/s]
[2025-01-08 17:36:56,442][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:01,  3.91it/s, est. speed input: 1487.77 toks/s, output: 165.17 toks/s]
[2025-01-08 17:36:56,722][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  3.83it/s, est. speed input: 1544.51 toks/s, output: 181.19 toks/s]
[2025-01-08 17:36:56,861][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  4.30it/s, est. speed input: 1639.11 toks/s, output: 202.25 toks/s]
[2025-01-08 17:36:57,016][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  5.87it/s, est. speed input: 1856.09 toks/s, output: 248.84 toks/s]
[2025-01-08 17:36:57,016][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.66it/s, est. speed input: 1856.09 toks/s, output: 248.84 toks/s]
WARNING 01-08 17:36:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:36:57,231][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:36:59,929][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:32,  2.70s/it, est. speed input: 243.58 toks/s, output: 17.80 toks/s]
[2025-01-08 17:37:00,223][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:14,  1.28s/it, est. speed input: 432.19 toks/s, output: 35.10 toks/s]
[2025-01-08 17:37:00,348][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:07,  1.33it/s, est. speed input: 629.21 toks/s, output: 53.26 toks/s]
[2025-01-08 17:37:00,465][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:04,  1.99it/s, est. speed input: 825.85 toks/s, output: 71.42 toks/s]
[2025-01-08 17:37:00,635][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.61it/s, est. speed input: 991.86 toks/s, output: 88.73 toks/s]
[2025-01-08 17:37:00,790][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  4.39it/s, est. speed input: 1315.16 toks/s, output: 126.43 toks/s]
[2025-01-08 17:37:01,040][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:03<00:00,  5.42it/s, est. speed input: 1575.22 toks/s, output: 161.72 toks/s]
[2025-01-08 17:37:01,255][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  5.22it/s, est. speed input: 1656.52 toks/s, output: 177.46 toks/s]
[2025-01-08 17:37:01,412][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  5.46it/s, est. speed input: 1761.04 toks/s, output: 196.12 toks/s]
[2025-01-08 17:37:01,520][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  7.72it/s, est. speed input: 2021.82 toks/s, output: 242.96 toks/s]
[2025-01-08 17:37:01,520][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  3.03it/s, est. speed input: 2021.82 toks/s, output: 242.96 toks/s]
WARNING 01-08 17:37:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:01,725][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:02,732][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 844.06 toks/s, output: 28.80 toks/s]
[2025-01-08 17:37:04,053][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.19s/it, est. speed input: 665.31 toks/s, output: 55.84 toks/s]
[2025-01-08 17:37:04,205][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.40it/s, est. speed input: 906.54 toks/s, output: 96.78 toks/s]
[2025-01-08 17:37:04,205][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.21it/s, est. speed input: 906.54 toks/s, output: 96.78 toks/s]
WARNING 01-08 17:37:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:04,430][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:05,289][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 881.02 toks/s, output: 33.75 toks/s]
[2025-01-08 17:37:06,041][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.26it/s, est. speed input: 890.16 toks/s, output: 63.94 toks/s]
[2025-01-08 17:37:06,041][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.24it/s, est. speed input: 890.16 toks/s, output: 63.94 toks/s]
WARNING 01-08 17:37:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:06,271][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:09,034][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.76s/it, est. speed input: 309.09 toks/s, output: 10.50 toks/s]
[2025-01-08 17:37:09,411][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:16,  1.36s/it, est. speed input: 593.08 toks/s, output: 21.98 toks/s]
[2025-01-08 17:37:10,045][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.42it/s, est. speed input: 1038.14 toks/s, output: 45.04 toks/s]
[2025-01-08 17:37:10,225][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:03<00:04,  1.84it/s, est. speed input: 1257.70 toks/s, output: 59.70 toks/s]
[2025-01-08 17:37:10,637][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.60it/s, est. speed input: 1639.36 toks/s, output: 88.42 toks/s]
[2025-01-08 17:37:10,889][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.56it/s, est. speed input: 2008.10 toks/s, output: 121.49 toks/s]
[2025-01-08 17:37:11,052][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:01,  3.93it/s, est. speed input: 2165.78 toks/s, output: 137.86 toks/s]
[2025-01-08 17:37:11,668][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:01,  2.92it/s, est. speed input: 2114.66 toks/s, output: 145.45 toks/s]
[2025-01-08 17:37:11,811][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.44it/s, est. speed input: 2260.95 toks/s, output: 165.71 toks/s]
[2025-01-08 17:37:12,105][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  3.43it/s, est. speed input: 2338.06 toks/s, output: 182.90 toks/s]
[2025-01-08 17:37:12,849][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.40it/s, est. speed input: 2242.96 toks/s, output: 191.55 toks/s]
[2025-01-08 17:37:12,849][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.13it/s, est. speed input: 2242.96 toks/s, output: 191.55 toks/s]
WARNING 01-08 17:37:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:13,076][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:16,025][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.95s/it, est. speed input: 268.27 toks/s, output: 16.62 toks/s]
[2025-01-08 17:37:16,355][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:15,  1.41s/it, est. speed input: 469.49 toks/s, output: 32.95 toks/s]
[2025-01-08 17:37:16,505][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.75it/s, est. speed input: 913.78 toks/s, output: 67.67 toks/s]
[2025-01-08 17:37:16,676][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.23it/s, est. speed input: 1092.23 toks/s, output: 83.91 toks/s]
[2025-01-08 17:37:16,938][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  3.34it/s, est. speed input: 1447.52 toks/s, output: 117.30 toks/s]
[2025-01-08 17:37:17,060][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:03<00:01,  3.92it/s, est. speed input: 1619.51 toks/s, output: 135.04 toks/s]
[2025-01-08 17:37:17,175][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:00,  4.59it/s, est. speed input: 1781.21 toks/s, output: 153.23 toks/s]
[2025-01-08 17:37:17,617][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  4.56it/s, est. speed input: 1983.43 toks/s, output: 183.03 toks/s]
[2025-01-08 17:37:17,819][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  4.65it/s, est. speed input: 2079.10 toks/s, output: 201.16 toks/s]
[2025-01-08 17:37:17,887][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.70it/s, est. speed input: 2225.04 toks/s, output: 224.73 toks/s]
WARNING 01-08 17:37:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:18,091][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:19,946][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:03,  1.85s/it, est. speed input: 651.85 toks/s, output: 35.05 toks/s]
[2025-01-08 17:37:20,149][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:00,  1.13it/s, est. speed input: 1151.07 toks/s, output: 68.54 toks/s]
[2025-01-08 17:37:22,244][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.44s/it, est. speed input: 831.20 toks/s, output: 82.13 toks/s]
[2025-01-08 17:37:22,244][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.38s/it, est. speed input: 831.20 toks/s, output: 82.13 toks/s]
WARNING 01-08 17:37:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:22,452][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:24,009][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.56s/it, est. speed input: 531.64 toks/s, output: 42.38 toks/s]
[2025-01-08 17:37:25,625][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.59s/it, est. speed input: 522.78 toks/s, output: 71.85 toks/s]
[2025-01-08 17:37:25,626][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.59s/it, est. speed input: 522.78 toks/s, output: 71.85 toks/s]
WARNING 01-08 17:37:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:25,880][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:29,191][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:43,  3.31s/it, est. speed input: 404.15 toks/s, output: 8.76 toks/s]
[2025-01-08 17:37:29,596][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:11,  1.01s/it, est. speed input: 1028.99 toks/s, output: 26.64 toks/s]
[2025-01-08 17:37:31,043][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:05<00:11,  1.16s/it, est. speed input: 1023.01 toks/s, output: 35.83 toks/s]
[2025-01-08 17:37:31,196][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:05<00:07,  1.21it/s, est. speed input: 1260.97 toks/s, output: 51.92 toks/s]
[2025-01-08 17:37:31,365][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:05<00:03,  2.14it/s, est. speed input: 1732.37 toks/s, output: 84.95 toks/s]
[2025-01-08 17:37:31,648][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:05<00:01,  3.00it/s, est. speed input: 2119.27 toks/s, output: 116.84 toks/s]
[2025-01-08 17:37:31,759][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  5.14it/s, est. speed input: 2857.42 toks/s, output: 171.30 toks/s]
[2025-01-08 17:37:33,258][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  2.74it/s, est. speed input: 2682.22 toks/s, output: 181.35 toks/s]
[2025-01-08 17:37:33,258][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.90it/s, est. speed input: 2682.22 toks/s, output: 181.35 toks/s]
WARNING 01-08 17:37:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:33,543][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:34,844][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.30s/it, est. speed input: 665.71 toks/s, output: 39.20 toks/s]
[2025-01-08 17:37:35,181][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.36it/s, est. speed input: 1070.22 toks/s, output: 74.48 toks/s]
[2025-01-08 17:37:35,182][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.22it/s, est. speed input: 1070.22 toks/s, output: 74.48 toks/s]
WARNING 01-08 17:37:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:35,387][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:37,186][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:03,  1.80s/it, est. speed input: 860.72 toks/s, output: 30.03 toks/s]
[2025-01-08 17:37:37,646][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.01s/it, est. speed input: 1473.46 toks/s, output: 58.88 toks/s]
[2025-01-08 17:37:37,748][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.68it/s, est. speed input: 2048.90 toks/s, output: 92.34 toks/s]
[2025-01-08 17:37:37,749][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.27it/s, est. speed input: 2048.90 toks/s, output: 92.34 toks/s]
WARNING 01-08 17:37:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:37:37,971][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:37:39,013][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.04s/it, est. speed input: 1575.89 toks/s, output: 27.85 toks/s]
[2025-01-08 17:37:40,130][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.09s/it, est. speed input: 1436.83 toks/s, output: 57.45 toks/s]
[2025-01-08 17:37:40,130][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.08s/it, est. speed input: 1436.83 toks/s, output: 57.45 toks/s]
[2025-01-08 17:37:45,899][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:37:45,953][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:37:47,631][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 17:37:49,226][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 17:37:50,792][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 17:37:51,302][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 17:37:51,303][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 17:38:03,172][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:38:03,724][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:38:03,776][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:38:05,597][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 17:38:07,175][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 17:38:08,729][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 17:38:09,220][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:38:09,220][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:38:24,278][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:38:24,599][root][INFO] - Loading VLLM model.
WARNING 01-08 17:38:25 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:38:25 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:38:25 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:38:25 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:38:26,080][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:38:27,395][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 17:38:27,781][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:38:29,128][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
[2025-01-08 17:38:30,533][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
[2025-01-08 17:38:30,533][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.11s/it]
INFO 01-08 17:38:30 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:38:44 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:38:45 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:38:45 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:39:06 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:39:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:06,294][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:10,080][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:56,  3.79s/it, est. speed input: 133.38 toks/s, output: 13.47 toks/s]
[2025-01-08 17:39:10,261][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:23,  1.67s/it, est. speed input: 254.61 toks/s, output: 26.97 toks/s]
[2025-01-08 17:39:10,541][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:13,  1.03s/it, est. speed input: 356.70 toks/s, output: 40.26 toks/s]
[2025-01-08 17:39:10,762][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:03,  2.51it/s, est. speed input: 678.17 toks/s, output: 83.48 toks/s]
[2025-01-08 17:39:10,937][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:04<00:03,  2.90it/s, est. speed input: 761.33 toks/s, output: 96.92 toks/s]
[2025-01-08 17:39:11,230][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:04<00:01,  3.79it/s, est. speed input: 920.71 toks/s, output: 124.79 toks/s]
[2025-01-08 17:39:11,359][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  4.28it/s, est. speed input: 997.08 toks/s, output: 139.99 toks/s]
[2025-01-08 17:39:11,686][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  5.80it/s, est. speed input: 1217.66 toks/s, output: 187.15 toks/s]
[2025-01-08 17:39:11,900][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:05<00:00,  5.55it/s, est. speed input: 1261.19 toks/s, output: 201.22 toks/s]
[2025-01-08 17:39:12,229][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  4.72it/s, est. speed input: 1276.31 toks/s, output: 213.14 toks/s]
[2025-01-08 17:39:12,330][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  5.37it/s, est. speed input: 1338.71 toks/s, output: 233.28 toks/s]
[2025-01-08 17:39:12,330][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.65it/s, est. speed input: 1338.71 toks/s, output: 233.28 toks/s]
WARNING 01-08 17:39:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:12,542][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:13,410][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 737.94 toks/s, output: 33.44 toks/s]
[2025-01-08 17:39:13,510][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.40it/s, est. speed input: 1356.76 toks/s, output: 66.13 toks/s]
[2025-01-08 17:39:13,510][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.07it/s, est. speed input: 1356.76 toks/s, output: 66.13 toks/s]
WARNING 01-08 17:39:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:13,725][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:16,718][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:38,  2.99s/it, est. speed input: 233.58 toks/s, output: 16.71 toks/s]
[2025-01-08 17:39:16,955][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:16,  1.37s/it, est. speed input: 432.96 toks/s, output: 33.14 toks/s]
[2025-01-08 17:39:17,611][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.39it/s, est. speed input: 719.65 toks/s, output: 62.80 toks/s]
[2025-01-08 17:39:17,867][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.28it/s, est. speed input: 1012.75 toks/s, output: 99.00 toks/s]
[2025-01-08 17:39:17,999][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.46it/s, est. speed input: 1308.57 toks/s, output: 138.30 toks/s]
[2025-01-08 17:39:18,313][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.40it/s, est. speed input: 1371.24 toks/s, output: 151.71 toks/s]
[2025-01-08 17:39:18,596][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  4.26it/s, est. speed input: 1578.69 toks/s, output: 189.10 toks/s]
[2025-01-08 17:39:19,388][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  2.81it/s, est. speed input: 1481.33 toks/s, output: 190.55 toks/s]
[2025-01-08 17:39:19,535][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  3.26it/s, est. speed input: 1564.19 toks/s, output: 214.31 toks/s]
[2025-01-08 17:39:20,105][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.68it/s, est. speed input: 1533.99 toks/s, output: 226.51 toks/s]
[2025-01-08 17:39:20,105][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.19it/s, est. speed input: 1533.99 toks/s, output: 226.51 toks/s]
WARNING 01-08 17:39:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:20,336][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:23,214][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:31,  2.88s/it, est. speed input: 230.10 toks/s, output: 19.81 toks/s]
[2025-01-08 17:39:23,524][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:13,  1.37s/it, est. speed input: 410.63 toks/s, output: 38.90 toks/s]
[2025-01-08 17:39:23,752][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:04,  1.72it/s, est. speed input: 788.27 toks/s, output: 78.18 toks/s]
[2025-01-08 17:39:23,934][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:02,  2.86it/s, est. speed input: 1110.71 toks/s, output: 118.13 toks/s]
[2025-01-08 17:39:24,127][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:03<00:01,  3.22it/s, est. speed input: 1239.93 toks/s, output: 135.86 toks/s]
[2025-01-08 17:39:24,303][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  4.60it/s, est. speed input: 1532.51 toks/s, output: 178.23 toks/s]
[2025-01-08 17:39:24,466][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  7.14it/s, est. speed input: 1959.07 toks/s, output: 246.31 toks/s]
[2025-01-08 17:39:24,466][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.91it/s, est. speed input: 1959.07 toks/s, output: 246.31 toks/s]
WARNING 01-08 17:39:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:24,671][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:25,809][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.14s/it, est. speed input: 740.35 toks/s, output: 25.50 toks/s]
[2025-01-08 17:39:26,087][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.58it/s, est. speed input: 1248.02 toks/s, output: 50.85 toks/s]
[2025-01-08 17:39:26,417][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.02it/s, est. speed input: 1412.83 toks/s, output: 76.20 toks/s]
[2025-01-08 17:39:26,850][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.13it/s, est. speed input: 1365.86 toks/s, output: 100.97 toks/s]
[2025-01-08 17:39:26,850][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.84it/s, est. speed input: 1365.86 toks/s, output: 100.97 toks/s]
WARNING 01-08 17:39:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:27,067][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:28,125][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.06s/it, est. speed input: 713.51 toks/s, output: 25.52 toks/s]
[2025-01-08 17:39:29,190][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.06s/it, est. speed input: 661.33 toks/s, output: 50.87 toks/s]
[2025-01-08 17:39:29,347][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.24it/s, est. speed input: 1252.04 toks/s, output: 124.11 toks/s]
[2025-01-08 17:39:29,348][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.75it/s, est. speed input: 1252.04 toks/s, output: 124.11 toks/s]
WARNING 01-08 17:39:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:29,581][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:33,226][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:40,  3.65s/it, est. speed input: 283.12 toks/s, output: 17.56 toks/s]
[2025-01-08 17:39:33,382][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:09,  1.00s/it, est. speed input: 818.78 toks/s, output: 52.62 toks/s]
[2025-01-08 17:39:33,553][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:05,  1.40it/s, est. speed input: 1044.23 toks/s, output: 69.23 toks/s]
[2025-01-08 17:39:33,662][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:03,  1.94it/s, est. speed input: 1275.51 toks/s, output: 86.73 toks/s]
[2025-01-08 17:39:33,847][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.45it/s, est. speed input: 1474.29 toks/s, output: 103.13 toks/s]
[2025-01-08 17:39:33,988][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:00,  4.05it/s, est. speed input: 1909.39 toks/s, output: 140.45 toks/s]
[2025-01-08 17:39:35,444][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:05<00:01,  1.80it/s, est. speed input: 1629.08 toks/s, output: 132.52 toks/s]
[2025-01-08 17:39:35,587][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:06<00:00,  2.25it/s, est. speed input: 1773.10 toks/s, output: 156.85 toks/s]
[2025-01-08 17:39:36,179][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.63it/s, est. speed input: 1951.13 toks/s, output: 198.23 toks/s]
[2025-01-08 17:39:36,179][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.82it/s, est. speed input: 1951.13 toks/s, output: 198.23 toks/s]
WARNING 01-08 17:39:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:36,437][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:38,747][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:27,  2.31s/it, est. speed input: 394.83 toks/s, output: 12.55 toks/s]
[2025-01-08 17:39:40,062][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:18,  1.72s/it, est. speed input: 486.93 toks/s, output: 27.04 toks/s]
[2025-01-08 17:39:40,331][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:06,  1.37it/s, est. speed input: 870.37 toks/s, output: 63.18 toks/s]
[2025-01-08 17:39:40,463][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:02,  2.98it/s, est. speed input: 1473.01 toks/s, output: 120.72 toks/s]
[2025-01-08 17:39:40,697][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.87it/s, est. speed input: 1775.96 toks/s, output: 156.33 toks/s]
[2025-01-08 17:39:41,171][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  3.98it/s, est. speed input: 1961.29 toks/s, output: 186.52 toks/s]
[2025-01-08 17:39:41,410][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  4.02it/s, est. speed input: 2039.24 toks/s, output: 203.52 toks/s]
[2025-01-08 17:39:41,830][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  3.50it/s, est. speed input: 2042.20 toks/s, output: 216.20 toks/s]
[2025-01-08 17:39:41,831][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.41it/s, est. speed input: 2042.20 toks/s, output: 216.20 toks/s]
WARNING 01-08 17:39:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:42,038][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:44,050][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:02<00:04,  2.01s/it, est. speed input: 517.10 toks/s, output: 36.30 toks/s]
[2025-01-08 17:39:44,325][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:00,  1.01it/s, est. speed input: 955.82 toks/s, output: 70.43 toks/s]
[2025-01-08 17:39:44,881][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.26it/s, est. speed input: 1205.47 toks/s, output: 99.19 toks/s]
[2025-01-08 17:39:44,882][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.06it/s, est. speed input: 1205.47 toks/s, output: 99.19 toks/s]
WARNING 01-08 17:39:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:45,083][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:46,092][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 854.38 toks/s, output: 28.74 toks/s]
[2025-01-08 17:39:47,189][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.06s/it, est. speed input: 797.08 toks/s, output: 56.05 toks/s]
[2025-01-08 17:39:47,256][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.38it/s, est. speed input: 1158.36 toks/s, output: 97.10 toks/s]
WARNING 01-08 17:39:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:47,486][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:51,784][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:04<00:51,  4.30s/it, est. speed input: 318.84 toks/s, output: 14.66 toks/s]
[2025-01-08 17:39:51,919][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:20,  1.85s/it, est. speed input: 616.85 toks/s, output: 29.33 toks/s]
[2025-01-08 17:39:52,144][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:11,  1.11s/it, est. speed input: 885.73 toks/s, output: 43.80 toks/s]
[2025-01-08 17:39:52,296][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.37it/s, est. speed input: 1185.10 toks/s, output: 58.84 toks/s]
[2025-01-08 17:39:52,528][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:05<00:04,  1.82it/s, est. speed input: 1412.48 toks/s, output: 73.39 toks/s]
[2025-01-08 17:39:52,827][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:05<00:02,  2.88it/s, est. speed input: 1868.01 toks/s, output: 104.49 toks/s]
[2025-01-08 17:39:53,192][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  4.35it/s, est. speed input: 2537.58 toks/s, output: 153.35 toks/s]
[2025-01-08 17:39:54,244][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  2.54it/s, est. speed input: 2378.10 toks/s, output: 154.05 toks/s]
[2025-01-08 17:39:54,446][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  2.85it/s, est. speed input: 2434.32 toks/s, output: 175.02 toks/s]
[2025-01-08 17:39:54,836][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  2.78it/s, est. speed input: 2500.51 toks/s, output: 192.93 toks/s]
[2025-01-08 17:39:54,837][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.77it/s, est. speed input: 2500.51 toks/s, output: 192.93 toks/s]
WARNING 01-08 17:39:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:55,160][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:56,870][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.71s/it, est. speed input: 600.71 toks/s, output: 49.13 toks/s]
[2025-01-08 17:39:56,870][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.71s/it, est. speed input: 600.71 toks/s, output: 49.13 toks/s]
WARNING 01-08 17:39:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:39:57,076][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:39:59,048][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:03,  1.97s/it, est. speed input: 703.47 toks/s, output: 32.46 toks/s]
[2025-01-08 17:39:59,231][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:00,  1.09it/s, est. speed input: 1345.46 toks/s, output: 64.03 toks/s]
[2025-01-08 17:40:00,381][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.02s/it, est. speed input: 1374.61 toks/s, output: 84.72 toks/s]
[2025-01-08 17:40:00,381][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.10s/it, est. speed input: 1374.61 toks/s, output: 84.72 toks/s]
WARNING 01-08 17:40:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:40:00,601][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:40:02,531][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.93s/it, est. speed input: 688.01 toks/s, output: 49.22 toks/s]
[2025-01-08 17:40:02,532][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.93s/it, est. speed input: 688.01 toks/s, output: 49.22 toks/s]
[2025-01-08 17:40:08,307][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:40:08,360][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:40:10,017][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.66s/it]
[2025-01-08 17:40:11,643][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 17:40:13,219][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 17:40:13,744][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:40:13,745][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 17:40:24,989][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:40:25,497][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:40:25,550][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:40:27,442][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.89s/it]
[2025-01-08 17:40:29,070][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 17:40:30,699][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 17:40:31,203][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:40:31,203][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 17:40:46,042][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:40:46,324][root][INFO] - Loading VLLM model.
WARNING 01-08 17:40:46 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:40:46 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:40:47 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:40:47 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:40:47,320][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:40:48,694][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 17:40:49,099][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 17:40:50,458][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 17:40:51,864][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 17:40:51,865][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 17:40:52 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:41:05 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:41:06 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:41:06 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:41:27 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:41:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:27,980][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:31,609][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:54,  3.63s/it, est. speed input: 139.17 toks/s, output: 14.06 toks/s]
[2025-01-08 17:41:31,790][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:22,  1.60s/it, est. speed input: 265.13 toks/s, output: 28.09 toks/s]
[2025-01-08 17:41:32,105][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:13,  1.01s/it, est. speed input: 367.25 toks/s, output: 41.69 toks/s]
[2025-01-08 17:41:32,367][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:05,  1.95it/s, est. speed input: 575.65 toks/s, output: 70.90 toks/s]
[2025-01-08 17:41:32,479][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:04<00:01,  4.68it/s, est. speed input: 1010.36 toks/s, output: 135.60 toks/s]
[2025-01-08 17:41:32,873][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:04<00:01,  4.80it/s, est. speed input: 1135.46 toks/s, output: 160.86 toks/s]
[2025-01-08 17:41:33,239][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  4.98it/s, est. speed input: 1248.46 toks/s, output: 189.03 toks/s]
[2025-01-08 17:41:33,351][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  6.37it/s, est. speed input: 1410.32 toks/s, output: 227.33 toks/s]
[2025-01-08 17:41:33,652][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.82it/s, est. speed input: 1424.57 toks/s, output: 238.90 toks/s]
WARNING 01-08 17:41:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:33,860][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:34,836][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 656.63 toks/s, output: 29.71 toks/s]
[2025-01-08 17:41:34,853][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.02it/s, est. speed input: 1948.38 toks/s, output: 88.56 toks/s]
WARNING 01-08 17:41:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:35,074][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:37,501][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:29,  2.43s/it, est. speed input: 288.06 toks/s, output: 15.25 toks/s]
[2025-01-08 17:41:38,217][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:08,  1.12it/s, est. speed input: 667.28 toks/s, output: 42.96 toks/s]
[2025-01-08 17:41:38,364][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.57it/s, est. speed input: 849.83 toks/s, output: 60.79 toks/s]
[2025-01-08 17:41:38,476][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:02,  2.88it/s, est. speed input: 1232.84 toks/s, output: 99.06 toks/s]
[2025-01-08 17:41:38,606][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  3.44it/s, est. speed input: 1385.40 toks/s, output: 116.37 toks/s]
[2025-01-08 17:41:38,799][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:03<00:01,  3.79it/s, est. speed input: 1501.09 toks/s, output: 132.34 toks/s]
[2025-01-08 17:41:39,206][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.29it/s, est. speed input: 1522.55 toks/s, output: 143.52 toks/s]
[2025-01-08 17:41:39,314][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  4.03it/s, est. speed input: 1648.56 toks/s, output: 164.62 toks/s]
[2025-01-08 17:41:39,790][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  3.18it/s, est. speed input: 1630.42 toks/s, output: 175.36 toks/s]
[2025-01-08 17:41:40,139][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.08it/s, est. speed input: 1656.03 toks/s, output: 192.49 toks/s]
[2025-01-08 17:41:40,961][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.12it/s, est. speed input: 1543.58 toks/s, output: 199.08 toks/s]
[2025-01-08 17:41:40,961][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.21it/s, est. speed input: 1543.58 toks/s, output: 199.08 toks/s]
WARNING 01-08 17:41:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:41,207][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:44,229][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:03<00:30,  3.02s/it, est. speed input: 214.10 toks/s, output: 21.84 toks/s]
[2025-01-08 17:41:44,435][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:12,  1.37s/it, est. speed input: 417.58 toks/s, output: 43.06 toks/s]
[2025-01-08 17:41:44,784][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:03<00:04,  1.62it/s, est. speed input: 749.74 toks/s, output: 83.58 toks/s]
[2025-01-08 17:41:44,966][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:03<00:02,  2.07it/s, est. speed input: 893.91 toks/s, output: 104.29 toks/s]
[2025-01-08 17:41:45,085][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  3.51it/s, est. speed input: 1204.11 toks/s, output: 151.35 toks/s]
[2025-01-08 17:41:45,192][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  5.21it/s, est. speed input: 1503.76 toks/s, output: 198.76 toks/s]
[2025-01-08 17:41:45,700][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  4.66it/s, est. speed input: 1641.00 toks/s, output: 229.47 toks/s]
[2025-01-08 17:41:45,700][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.45it/s, est. speed input: 1641.00 toks/s, output: 229.47 toks/s]
WARNING 01-08 17:41:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:45,921][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:47,126][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.20s/it, est. speed input: 423.42 toks/s, output: 22.42 toks/s]
[2025-01-08 17:41:48,802][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.47it/s, est. speed input: 1023.90 toks/s, output: 70.48 toks/s]
[2025-01-08 17:41:49,288][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.60it/s, est. speed input: 1083.53 toks/s, output: 103.96 toks/s]
[2025-01-08 17:41:49,289][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.48it/s, est. speed input: 1083.53 toks/s, output: 103.96 toks/s]
WARNING 01-08 17:41:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:49,497][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:50,850][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.35s/it, est. speed input: 554.57 toks/s, output: 30.32 toks/s]
[2025-01-08 17:41:50,965][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.54it/s, est. speed input: 1387.82 toks/s, output: 89.93 toks/s]
[2025-01-08 17:41:51,720][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.80it/s, est. speed input: 1263.12 toks/s, output: 100.80 toks/s]
WARNING 01-08 17:41:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:51,953][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:41:54,435][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:27,  2.48s/it, est. speed input: 232.04 toks/s, output: 12.49 toks/s]
[2025-01-08 17:41:54,657][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:02<00:11,  1.15s/it, est. speed input: 586.98 toks/s, output: 25.52 toks/s]
[2025-01-08 17:41:55,135][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:07,  1.18it/s, est. speed input: 830.39 toks/s, output: 38.66 toks/s]
[2025-01-08 17:41:55,392][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:04,  1.63it/s, est. speed input: 1070.42 toks/s, output: 54.09 toks/s]
[2025-01-08 17:41:55,528][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:03,  2.27it/s, est. speed input: 1343.20 toks/s, output: 71.05 toks/s]
[2025-01-08 17:41:55,660][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:02,  2.98it/s, est. speed input: 1576.27 toks/s, output: 88.21 toks/s]
[2025-01-08 17:41:56,008][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.91it/s, est. speed input: 1956.74 toks/s, output: 120.60 toks/s]
[2025-01-08 17:41:56,193][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  5.30it/s, est. speed input: 2378.51 toks/s, output: 159.20 toks/s]
[2025-01-08 17:41:56,469][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.80it/s, est. speed input: 2478.48 toks/s, output: 174.27 toks/s]
[2025-01-08 17:41:56,926][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  3.71it/s, est. speed input: 2460.46 toks/s, output: 186.22 toks/s]
[2025-01-08 17:41:56,926][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.41it/s, est. speed input: 2460.46 toks/s, output: 186.22 toks/s]
WARNING 01-08 17:41:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:41:57,150][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:00,087][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:32,  2.94s/it, est. speed input: 255.37 toks/s, output: 17.71 toks/s]
[2025-01-08 17:42:00,527][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:14,  1.47s/it, est. speed input: 458.76 toks/s, output: 34.95 toks/s]
[2025-01-08 17:42:00,812][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:05,  1.57it/s, est. speed input: 887.21 toks/s, output: 71.27 toks/s]
[2025-01-08 17:42:01,378][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:04,  1.63it/s, est. speed input: 964.52 toks/s, output: 84.67 toks/s]
[2025-01-08 17:42:01,593][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.28it/s, est. speed input: 1490.61 toks/s, output: 149.24 toks/s]
[2025-01-08 17:42:01,702][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  3.80it/s, est. speed input: 1659.53 toks/s, output: 170.04 toks/s]
[2025-01-08 17:42:01,854][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  5.20it/s, est. speed input: 1967.01 toks/s, output: 213.90 toks/s]
[2025-01-08 17:42:02,325][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.97it/s, est. speed input: 1948.37 toks/s, output: 222.82 toks/s]
[2025-01-08 17:42:02,325][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.32it/s, est. speed input: 1948.37 toks/s, output: 222.82 toks/s]
WARNING 01-08 17:42:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:02,567][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:03,866][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.30s/it, est. speed input: 964.73 toks/s, output: 22.33 toks/s]
[2025-01-08 17:42:04,554][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.06it/s, est. speed input: 1181.21 toks/s, output: 46.32 toks/s]
[2025-01-08 17:42:06,591][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:04<00:01,  1.44s/it, est. speed input: 861.37 toks/s, output: 66.11 toks/s]
[2025-01-08 17:42:07,031][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.05s/it, est. speed input: 1022.25 toks/s, output: 104.40 toks/s]
[2025-01-08 17:42:07,031][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.12s/it, est. speed input: 1022.25 toks/s, output: 104.40 toks/s]
WARNING 01-08 17:42:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:07,249][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:08,260][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 832.42 toks/s, output: 28.70 toks/s]
[2025-01-08 17:42:08,554][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.70it/s, est. speed input: 1312.52 toks/s, output: 56.73 toks/s]
[2025-01-08 17:42:09,308][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.50it/s, est. speed input: 1209.43 toks/s, output: 79.66 toks/s]
[2025-01-08 17:42:09,308][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.46it/s, est. speed input: 1209.43 toks/s, output: 79.66 toks/s]
WARNING 01-08 17:42:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:09,548][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:12,649][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:37,  3.10s/it, est. speed input: 390.22 toks/s, output: 9.35 toks/s]
[2025-01-08 17:42:12,938][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:09,  1.10it/s, est. speed input: 1146.16 toks/s, output: 28.32 toks/s]
[2025-01-08 17:42:13,636][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:07,  1.19it/s, est. speed input: 1288.41 toks/s, output: 38.41 toks/s]
[2025-01-08 17:42:13,954][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:05,  1.50it/s, est. speed input: 1513.54 toks/s, output: 51.98 toks/s]
[2025-01-08 17:42:14,230][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:03,  1.85it/s, est. speed input: 1720.79 toks/s, output: 66.42 toks/s]
[2025-01-08 17:42:14,404][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.83it/s, est. speed input: 2538.55 toks/s, output: 117.19 toks/s]
[2025-01-08 17:42:14,870][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  3.27it/s, est. speed input: 2588.43 toks/s, output: 127.58 toks/s]
[2025-01-08 17:42:15,202][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.97it/s, est. speed input: 2957.85 toks/s, output: 162.19 toks/s]
[2025-01-08 17:42:15,811][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  3.04it/s, est. speed input: 2903.26 toks/s, output: 172.59 toks/s]
[2025-01-08 17:42:15,812][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.08it/s, est. speed input: 2903.26 toks/s, output: 172.59 toks/s]
WARNING 01-08 17:42:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:16,080][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:17,362][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.28s/it, est. speed input: 592.80 toks/s, output: 39.00 toks/s]
[2025-01-08 17:42:17,615][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.48it/s, est. speed input: 1108.70 toks/s, output: 74.91 toks/s]
[2025-01-08 17:42:17,616][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.30it/s, est. speed input: 1108.70 toks/s, output: 74.91 toks/s]
WARNING 01-08 17:42:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:17,829][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:19,296][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.47s/it, est. speed input: 600.41 toks/s, output: 21.13 toks/s]
[2025-01-08 17:42:19,768][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.13it/s, est. speed input: 1256.74 toks/s, output: 43.83 toks/s]
[2025-01-08 17:42:20,338][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.35it/s, est. speed input: 1586.90 toks/s, output: 67.75 toks/s]
[2025-01-08 17:42:21,540][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.08it/s, est. speed input: 1495.62 toks/s, output: 87.85 toks/s]
[2025-01-08 17:42:21,540][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.08it/s, est. speed input: 1495.62 toks/s, output: 87.85 toks/s]
WARNING 01-08 17:42:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:21,766][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:24,075][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.31s/it, est. speed input: 411.47 toks/s, output: 51.97 toks/s]
[2025-01-08 17:42:24,076][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.31s/it, est. speed input: 411.47 toks/s, output: 51.97 toks/s]
WARNING 01-08 17:42:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:24,312][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:25,853][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.54s/it, est. speed input: 981.61 toks/s, output: 36.33 toks/s]
[2025-01-08 17:42:27,225][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.44s/it, est. speed input: 1087.46 toks/s, output: 66.25 toks/s]
[2025-01-08 17:42:27,225][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.46s/it, est. speed input: 1087.46 toks/s, output: 66.25 toks/s]
WARNING 01-08 17:42:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:42:27,452][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:42:28,466][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1600.39 toks/s, output: 28.60 toks/s]
[2025-01-08 17:42:28,501][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.91it/s, est. speed input: 2678.87 toks/s, output: 57.22 toks/s]
[2025-01-08 17:42:34,472][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:42:34,526][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:42:36,251][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 17:42:37,914][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 17:42:39,551][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.66s/it]
[2025-01-08 17:42:40,077][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:42:40,077][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 17:42:51,320][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:42:51,836][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:42:51,891][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:42:53,840][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.95s/it]
[2025-01-08 17:42:55,470][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 17:42:57,065][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 17:42:57,583][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 17:42:57,583][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 17:43:12,675][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:43:12,962][root][INFO] - Loading VLLM model.
WARNING 01-08 17:43:13 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:43:13 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:43:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:43:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:43:14,112][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:43:15,437][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:43:15,822][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:43:17,180][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.04s/it]
[2025-01-08 17:43:18,584][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
[2025-01-08 17:43:18,585][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
INFO 01-08 17:43:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:43:32 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:43:33 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:43:33 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:43:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:43:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:43:54,496][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:43:58,458][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:59,  3.96s/it, est. speed input: 127.49 toks/s, output: 12.87 toks/s]
[2025-01-08 17:43:58,638][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:24,  1.74s/it, est. speed input: 243.84 toks/s, output: 25.83 toks/s]
[2025-01-08 17:43:58,919][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:13,  1.07s/it, est. speed input: 342.54 toks/s, output: 38.66 toks/s]
[2025-01-08 17:43:59,140][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:04,  2.43it/s, est. speed input: 652.44 toks/s, output: 80.32 toks/s]
[2025-01-08 17:43:59,312][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.50it/s, est. speed input: 839.01 toks/s, output: 108.61 toks/s]
[2025-01-08 17:43:59,459][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:04<00:00,  5.61it/s, est. speed input: 1119.36 toks/s, output: 153.55 toks/s]
[2025-01-08 17:43:59,815][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  5.61it/s, est. speed input: 1234.45 toks/s, output: 180.14 toks/s]
[2025-01-08 17:44:00,215][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  5.41it/s, est. speed input: 1324.66 toks/s, output: 207.92 toks/s]
[2025-01-08 17:44:00,282][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.77it/s, est. speed input: 1396.52 toks/s, output: 226.93 toks/s]
WARNING 01-08 17:44:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:00,487][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:01,370][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.13it/s, est. speed input: 710.51 toks/s, output: 32.86 toks/s]
[2025-01-08 17:44:01,771][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.67it/s, est. speed input: 994.69 toks/s, output: 63.87 toks/s]
[2025-01-08 17:44:01,771][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.56it/s, est. speed input: 994.69 toks/s, output: 63.87 toks/s]
WARNING 01-08 17:44:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:01,992][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:04,218][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.23s/it, est. speed input: 314.00 toks/s, output: 13.03 toks/s]
[2025-01-08 17:44:04,589][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:13,  1.13s/it, est. speed input: 538.36 toks/s, output: 26.57 toks/s]
[2025-01-08 17:44:05,046][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:09,  1.21it/s, est. speed input: 686.51 toks/s, output: 40.27 toks/s]
[2025-01-08 17:44:05,295][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.67it/s, est. speed input: 846.35 toks/s, output: 56.00 toks/s]
[2025-01-08 17:44:05,467][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:03<00:02,  3.06it/s, est. speed input: 1206.69 toks/s, output: 91.21 toks/s]
[2025-01-08 17:44:05,655][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  3.47it/s, est. speed input: 1335.77 toks/s, output: 107.01 toks/s]
[2025-01-08 17:44:05,828][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:00,  5.01it/s, est. speed input: 1639.79 toks/s, output: 143.62 toks/s]
[2025-01-08 17:44:06,122][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:00,  4.50it/s, est. speed input: 1692.23 toks/s, output: 156.39 toks/s]
[2025-01-08 17:44:06,424][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  4.12it/s, est. speed input: 1734.71 toks/s, output: 170.33 toks/s]
[2025-01-08 17:44:06,553][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  5.97it/s, est. speed input: 1992.17 toks/s, output: 214.85 toks/s]
[2025-01-08 17:44:07,460][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.95it/s, est. speed input: 1789.54 toks/s, output: 210.30 toks/s]
[2025-01-08 17:44:07,461][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.56it/s, est. speed input: 1789.54 toks/s, output: 210.30 toks/s]
WARNING 01-08 17:44:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:07,705][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:10,701][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  3.00s/it, est. speed input: 214.02 toks/s, output: 18.70 toks/s]
[2025-01-08 17:44:10,831][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:08,  1.21it/s, est. speed input: 629.30 toks/s, output: 55.99 toks/s]
[2025-01-08 17:44:11,146][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:03,  2.08it/s, est. speed input: 946.96 toks/s, output: 89.81 toks/s]
[2025-01-08 17:44:11,280][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:02,  2.58it/s, est. speed input: 1093.57 toks/s, output: 107.71 toks/s]
[2025-01-08 17:44:11,551][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:03<00:00,  5.15it/s, est. speed input: 1713.17 toks/s, output: 184.40 toks/s]
[2025-01-08 17:44:11,789][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  5.83it/s, est. speed input: 1952.10 toks/s, output: 222.61 toks/s]
[2025-01-08 17:44:13,467][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.28it/s, est. speed input: 1507.56 toks/s, output: 192.48 toks/s]
[2025-01-08 17:44:13,468][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.26it/s, est. speed input: 1507.56 toks/s, output: 192.48 toks/s]
WARNING 01-08 17:44:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:13,680][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:14,660][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 823.62 toks/s, output: 29.60 toks/s]
[2025-01-08 17:44:14,972][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.70it/s, est. speed input: 1019.17 toks/s, output: 58.04 toks/s]
[2025-01-08 17:44:16,213][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.13it/s, est. speed input: 795.99 toks/s, output: 76.99 toks/s]
[2025-01-08 17:44:16,213][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.18it/s, est. speed input: 795.99 toks/s, output: 76.99 toks/s]
WARNING 01-08 17:44:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:16,417][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:17,417][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.00it/s, est. speed input: 742.38 toks/s, output: 29.01 toks/s]
[2025-01-08 17:44:18,469][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.54it/s, est. speed input: 1143.18 toks/s, output: 73.09 toks/s]
[2025-01-08 17:44:18,470][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.46it/s, est. speed input: 1143.18 toks/s, output: 73.09 toks/s]
WARNING 01-08 17:44:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:18,691][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:21,246][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.55s/it, est. speed input: 392.34 toks/s, output: 11.35 toks/s]
[2025-01-08 17:44:21,593][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:02<00:07,  1.26it/s, est. speed input: 899.56 toks/s, output: 33.78 toks/s]
[2025-01-08 17:44:22,310][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:06,  1.31it/s, est. speed input: 1007.36 toks/s, output: 44.77 toks/s]
[2025-01-08 17:44:22,521][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:02,  2.85it/s, est. speed input: 1776.57 toks/s, output: 94.52 toks/s]
[2025-01-08 17:44:22,670][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:03<00:01,  3.27it/s, est. speed input: 1972.08 toks/s, output: 110.61 toks/s]
[2025-01-08 17:44:22,993][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.23it/s, est. speed input: 2076.92 toks/s, output: 123.69 toks/s]
[2025-01-08 17:44:23,218][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  4.36it/s, est. speed input: 2448.15 toks/s, output: 160.82 toks/s]
[2025-01-08 17:44:23,770][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.31it/s, est. speed input: 2396.68 toks/s, output: 169.55 toks/s]
[2025-01-08 17:44:23,906][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  3.82it/s, est. speed input: 2536.78 toks/s, output: 192.17 toks/s]
[2025-01-08 17:44:23,906][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.49it/s, est. speed input: 2536.78 toks/s, output: 192.17 toks/s]
WARNING 01-08 17:44:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:24,127][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:26,976][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:34,  2.85s/it, est. speed input: 274.85 toks/s, output: 16.15 toks/s]
[2025-01-08 17:44:27,273][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:14,  1.35s/it, est. speed input: 505.49 toks/s, output: 32.11 toks/s]
[2025-01-08 17:44:27,573][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.68it/s, est. speed input: 926.43 toks/s, output: 64.72 toks/s]
[2025-01-08 17:44:27,739][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:02,  2.82it/s, est. speed input: 1352.14 toks/s, output: 100.22 toks/s]
[2025-01-08 17:44:28,044][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:03<00:00,  4.40it/s, est. speed input: 1865.23 toks/s, output: 151.39 toks/s]
[2025-01-08 17:44:28,197][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  4.70it/s, est. speed input: 1998.83 toks/s, output: 168.08 toks/s]
[2025-01-08 17:44:28,477][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  4.40it/s, est. speed input: 2059.63 toks/s, output: 181.39 toks/s]
[2025-01-08 17:44:28,680][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  4.51it/s, est. speed input: 2153.37 toks/s, output: 198.80 toks/s]
[2025-01-08 17:44:28,950][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  4.28it/s, est. speed input: 2212.81 toks/s, output: 215.04 toks/s]
[2025-01-08 17:44:28,950][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.70it/s, est. speed input: 2212.81 toks/s, output: 215.04 toks/s]
WARNING 01-08 17:44:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:29,182][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:30,307][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.12s/it, est. speed input: 986.82 toks/s, output: 25.78 toks/s]
[2025-01-08 17:44:31,795][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.34s/it, est. speed input: 845.40 toks/s, output: 53.20 toks/s]
[2025-01-08 17:44:32,370][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.01it/s, est. speed input: 1053.26 toks/s, output: 88.76 toks/s]
[2025-01-08 17:44:32,371][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.06s/it, est. speed input: 1053.26 toks/s, output: 88.76 toks/s]
WARNING 01-08 17:44:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:32,585][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:33,898][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.31s/it, est. speed input: 652.75 toks/s, output: 22.09 toks/s]
[2025-01-08 17:44:34,247][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.34it/s, est. speed input: 1037.67 toks/s, output: 44.51 toks/s]
[2025-01-08 17:44:34,568][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:01<00:01,  1.81it/s, est. speed input: 1320.77 toks/s, output: 68.08 toks/s]
[2025-01-08 17:44:35,046][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.91it/s, est. speed input: 1398.27 toks/s, output: 90.21 toks/s]
[2025-01-08 17:44:35,774][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.68it/s, est. speed input: 1414.28 toks/s, output: 110.38 toks/s]
[2025-01-08 17:44:35,774][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.57it/s, est. speed input: 1414.28 toks/s, output: 110.38 toks/s]
WARNING 01-08 17:44:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:36,011][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:38,764][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:27,  2.75s/it, est. speed input: 473.98 toks/s, output: 10.53 toks/s]
[2025-01-08 17:44:39,098][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:11,  1.33s/it, est. speed input: 854.51 toks/s, output: 22.35 toks/s]
[2025-01-08 17:44:39,761][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:08,  1.03s/it, est. speed input: 1069.47 toks/s, output: 35.20 toks/s]
[2025-01-08 17:44:40,191][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.76it/s, est. speed input: 1635.45 toks/s, output: 65.79 toks/s]
[2025-01-08 17:44:40,367][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:04<00:02,  2.20it/s, est. speed input: 1896.76 toks/s, output: 82.88 toks/s]
[2025-01-08 17:44:41,504][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:01,  1.98it/s, est. speed input: 2032.14 toks/s, output: 106.86 toks/s]
[2025-01-08 17:44:41,648][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:05<00:00,  2.39it/s, est. speed input: 2239.22 toks/s, output: 129.67 toks/s]
[2025-01-08 17:44:42,054][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:06<00:00,  2.41it/s, est. speed input: 2332.28 toks/s, output: 148.44 toks/s]
[2025-01-08 17:44:42,631][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  2.18it/s, est. speed input: 2349.82 toks/s, output: 165.72 toks/s]
[2025-01-08 17:44:42,631][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.66it/s, est. speed input: 2349.82 toks/s, output: 165.72 toks/s]
WARNING 01-08 17:44:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:42,912][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:44,713][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:09,  1.80s/it, est. speed input: 498.77 toks/s, output: 16.11 toks/s]
[2025-01-08 17:44:45,206][root][ERROR] - Processed prompts:  67%|######6   | 4/6 [00:02<00:00,  2.11it/s, est. speed input: 2360.69 toks/s, output: 61.06 toks/s]
[2025-01-08 17:44:47,284][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:04<00:00,  1.09it/s, est. speed input: 1578.91 toks/s, output: 70.00 toks/s]
[2025-01-08 17:44:47,861][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:04<00:00,  1.22it/s, est. speed input: 1712.78 toks/s, output: 102.26 toks/s]
[2025-01-08 17:44:47,861][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:04<00:00,  1.21it/s, est. speed input: 1712.78 toks/s, output: 102.26 toks/s]
WARNING 01-08 17:44:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:48,085][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:49,332][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 796.51 toks/s, output: 45.72 toks/s]
[2025-01-08 17:44:49,333][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.25s/it, est. speed input: 796.51 toks/s, output: 45.72 toks/s]
WARNING 01-08 17:44:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:49,539][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:50,600][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.06s/it, est. speed input: 1407.56 toks/s, output: 27.34 toks/s]
[2025-01-08 17:44:51,414][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.09it/s, est. speed input: 1771.45 toks/s, output: 56.54 toks/s]
[2025-01-08 17:44:51,414][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.07it/s, est. speed input: 1771.45 toks/s, output: 56.54 toks/s]
WARNING 01-08 17:44:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:44:51,654][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:44:52,898][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.24s/it, est. speed input: 965.85 toks/s, output: 44.23 toks/s]
[2025-01-08 17:44:52,898][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.24s/it, est. speed input: 965.85 toks/s, output: 44.23 toks/s]
[2025-01-08 17:44:58,855][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:44:58,908][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:45:00,635][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 17:45:02,258][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 17:45:03,825][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 17:45:04,338][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:45:04,339][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:45:15,586][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:45:16,086][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:45:16,139][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:45:18,042][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 17:45:19,651][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 17:45:21,208][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 17:45:21,711][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 17:45:21,711][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 17:45:36,534][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:45:36,862][root][INFO] - Loading VLLM model.
WARNING 01-08 17:45:37 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:45:37 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:45:37 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:45:37 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:45:37,754][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:45:39,069][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 17:45:39,457][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:45:40,759][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 17:45:42,105][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 17:45:42,106][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:45:42 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:45:56 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:45:56 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:45:56 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:46:17 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:46:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:18,169][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:21,950][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:56,  3.78s/it, est. speed input: 133.57 toks/s, output: 13.49 toks/s]
[2025-01-08 17:46:22,131][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:23,  1.66s/it, est. speed input: 254.93 toks/s, output: 27.01 toks/s]
[2025-01-08 17:46:22,411][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:13,  1.03s/it, est. speed input: 357.09 toks/s, output: 40.30 toks/s]
[2025-01-08 17:46:22,633][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:03,  2.51it/s, est. speed input: 678.77 toks/s, output: 83.56 toks/s]
[2025-01-08 17:46:22,776][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:02,  3.68it/s, est. speed input: 876.89 toks/s, output: 113.30 toks/s]
[2025-01-08 17:46:22,949][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:04<00:00,  5.72it/s, est. speed input: 1162.06 toks/s, output: 158.98 toks/s]
[2025-01-08 17:46:23,277][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  5.83it/s, est. speed input: 1285.17 toks/s, output: 185.78 toks/s]
[2025-01-08 17:46:23,718][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  5.37it/s, est. speed input: 1365.04 toks/s, output: 213.36 toks/s]
[2025-01-08 17:46:23,836][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  5.74it/s, est. speed input: 1425.87 toks/s, output: 231.53 toks/s]
[2025-01-08 17:46:23,836][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.82it/s, est. speed input: 1425.87 toks/s, output: 231.53 toks/s]
WARNING 01-08 17:46:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:24,041][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:24,826][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.28it/s, est. speed input: 800.83 toks/s, output: 31.88 toks/s]
[2025-01-08 17:46:24,893][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.35it/s, est. speed input: 1473.81 toks/s, output: 63.41 toks/s]
WARNING 01-08 17:46:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:25,116][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:27,940][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:36,  2.82s/it, est. speed input: 247.54 toks/s, output: 16.29 toks/s]
[2025-01-08 17:46:28,378][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:17,  1.42s/it, est. speed input: 428.62 toks/s, output: 32.19 toks/s]
[2025-01-08 17:46:28,536][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.73it/s, est. speed input: 817.73 toks/s, output: 66.97 toks/s]
[2025-01-08 17:46:28,712][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:03<00:04,  2.20it/s, est. speed input: 971.90 toks/s, output: 83.15 toks/s]
[2025-01-08 17:46:28,902][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  3.50it/s, est. speed input: 1292.49 toks/s, output: 118.07 toks/s]
[2025-01-08 17:46:29,267][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  4.09it/s, est. speed input: 1515.75 toks/s, output: 148.66 toks/s]
[2025-01-08 17:46:29,403][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:00,  4.54it/s, est. speed input: 1630.65 toks/s, output: 166.80 toks/s]
[2025-01-08 17:46:29,700][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  5.20it/s, est. speed input: 1829.80 toks/s, output: 202.00 toks/s]
[2025-01-08 17:46:30,141][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  4.06it/s, est. speed input: 1808.33 toks/s, output: 211.54 toks/s]
[2025-01-08 17:46:31,148][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.34it/s, est. speed input: 1622.46 toks/s, output: 208.90 toks/s]
[2025-01-08 17:46:31,148][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.32it/s, est. speed input: 1622.46 toks/s, output: 208.90 toks/s]
WARNING 01-08 17:46:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:31,368][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:34,448][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:36,  3.08s/it, est. speed input: 213.02 toks/s, output: 19.16 toks/s]
[2025-01-08 17:46:34,855][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:09,  1.05it/s, est. speed input: 560.42 toks/s, output: 54.78 toks/s]
[2025-01-08 17:46:35,147][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:03<00:01,  3.30it/s, est. speed input: 1411.81 toks/s, output: 149.52 toks/s]
[2025-01-08 17:46:35,440][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:01,  3.32it/s, est. speed input: 1472.62 toks/s, output: 162.59 toks/s]
[2025-01-08 17:46:35,591][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  3.68it/s, est. speed input: 1575.81 toks/s, output: 181.40 toks/s]
[2025-01-08 17:46:36,244][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  2.82it/s, est. speed input: 1509.72 toks/s, output: 185.23 toks/s]
[2025-01-08 17:46:36,537][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  2.94it/s, est. speed input: 1549.09 toks/s, output: 204.30 toks/s]
[2025-01-08 17:46:36,571][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.50it/s, est. speed input: 1673.31 toks/s, output: 232.76 toks/s]
WARNING 01-08 17:46:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:36,808][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:37,788][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 520.51 toks/s, output: 29.60 toks/s]
[2025-01-08 17:46:37,991][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.91it/s, est. speed input: 1118.16 toks/s, output: 58.36 toks/s]
[2025-01-08 17:46:38,375][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.18it/s, est. speed input: 1290.35 toks/s, output: 84.28 toks/s]
[2025-01-08 17:46:38,375][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.92it/s, est. speed input: 1290.35 toks/s, output: 84.28 toks/s]
WARNING 01-08 17:46:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:38,592][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:39,615][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.02s/it, est. speed input: 716.49 toks/s, output: 24.44 toks/s]
[2025-01-08 17:46:40,429][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  1.76it/s, est. speed input: 1154.22 toks/s, output: 66.97 toks/s]
[2025-01-08 17:46:40,480][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.12it/s, est. speed input: 1560.13 toks/s, output: 103.30 toks/s]
WARNING 01-08 17:46:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:40,704][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:44,145][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:37,  3.44s/it, est. speed input: 297.93 toks/s, output: 16.86 toks/s]
[2025-01-08 17:46:44,335][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:15,  1.53s/it, est. speed input: 569.56 toks/s, output: 33.60 toks/s]
[2025-01-08 17:46:44,510][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:05,  1.60it/s, est. speed input: 1089.18 toks/s, output: 67.79 toks/s]
[2025-01-08 17:46:44,724][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.63it/s, est. speed input: 1558.55 toks/s, output: 101.75 toks/s]
[2025-01-08 17:46:44,846][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.97it/s, est. speed input: 2019.77 toks/s, output: 138.58 toks/s]
[2025-01-08 17:46:45,640][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  3.28it/s, est. speed input: 2138.04 toks/s, output: 160.05 toks/s]
[2025-01-08 17:46:46,063][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  3.04it/s, est. speed input: 2173.10 toks/s, output: 174.30 toks/s]
[2025-01-08 17:46:47,010][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.13it/s, est. speed input: 2032.20 toks/s, output: 179.83 toks/s]
[2025-01-08 17:46:47,011][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.90it/s, est. speed input: 2032.20 toks/s, output: 179.83 toks/s]
WARNING 01-08 17:46:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:47,234][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:49,269][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.03s/it, est. speed input: 391.75 toks/s, output: 14.25 toks/s]
[2025-01-08 17:46:50,070][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:11,  1.31s/it, est. speed input: 580.28 toks/s, output: 29.98 toks/s]
[2025-01-08 17:46:50,268][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:06,  1.25it/s, est. speed input: 814.53 toks/s, output: 48.79 toks/s]
[2025-01-08 17:46:50,614][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:03<00:01,  2.88it/s, est. speed input: 1453.95 toks/s, output: 104.74 toks/s]
[2025-01-08 17:46:51,183][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  2.50it/s, est. speed input: 1458.34 toks/s, output: 115.49 toks/s]
[2025-01-08 17:46:51,405][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:04<00:00,  3.54it/s, est. speed input: 1772.91 toks/s, output: 161.13 toks/s]
[2025-01-08 17:46:51,644][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  3.66it/s, est. speed input: 1874.28 toks/s, output: 180.96 toks/s]
[2025-01-08 17:46:52,320][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  2.70it/s, est. speed input: 1808.87 toks/s, output: 189.56 toks/s]
[2025-01-08 17:46:52,320][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  2.16it/s, est. speed input: 1808.87 toks/s, output: 189.56 toks/s]
WARNING 01-08 17:46:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:52,537][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:54,823][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:02<00:09,  2.29s/it, est. speed input: 385.93 toks/s, output: 28.88 toks/s]
[2025-01-08 17:46:54,945][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  2.15it/s, est. speed input: 1871.40 toks/s, output: 114.60 toks/s]
[2025-01-08 17:46:54,963][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.06it/s, est. speed input: 2322.15 toks/s, output: 143.87 toks/s]
WARNING 01-08 17:46:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:55,178][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:46:56,472][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.29s/it, est. speed input: 652.89 toks/s, output: 22.41 toks/s]
[2025-01-08 17:46:57,536][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.16s/it, est. speed input: 772.74 toks/s, output: 45.38 toks/s]
[2025-01-08 17:46:57,716][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.41it/s, est. speed input: 1028.51 toks/s, output: 76.45 toks/s]
[2025-01-08 17:46:57,900][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.99it/s, est. speed input: 1254.94 toks/s, output: 106.90 toks/s]
[2025-01-08 17:46:58,154][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.42it/s, est. speed input: 1460.14 toks/s, output: 135.43 toks/s]
[2025-01-08 17:46:58,154][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.68it/s, est. speed input: 1460.14 toks/s, output: 135.43 toks/s]
WARNING 01-08 17:46:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:46:58,410][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:47:01,094][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:26,  2.68s/it, est. speed input: 302.94 toks/s, output: 10.81 toks/s]
[2025-01-08 17:47:01,912][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:14,  1.59s/it, est. speed input: 626.53 toks/s, output: 24.27 toks/s]
[2025-01-08 17:47:02,135][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:03<00:04,  1.51it/s, est. speed input: 1328.14 toks/s, output: 55.31 toks/s]
[2025-01-08 17:47:02,296][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:03<00:03,  1.97it/s, est. speed input: 1627.33 toks/s, output: 71.02 toks/s]
[2025-01-08 17:47:02,447][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:04<00:01,  2.51it/s, est. speed input: 1915.04 toks/s, output: 87.19 toks/s]
[2025-01-08 17:47:03,341][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:04<00:01,  2.38it/s, est. speed input: 2145.38 toks/s, output: 111.13 toks/s]
[2025-01-08 17:47:03,732][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:05<00:00,  3.02it/s, est. speed input: 2544.50 toks/s, output: 150.88 toks/s]
[2025-01-08 17:47:03,851][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  3.53it/s, est. speed input: 2767.55 toks/s, output: 174.05 toks/s]
[2025-01-08 17:47:03,851][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  2.02it/s, est. speed input: 2767.55 toks/s, output: 174.05 toks/s]
WARNING 01-08 17:47:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:47:04,133][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:47:04,898][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 1184.64 toks/s, output: 37.92 toks/s]
[2025-01-08 17:47:04,899][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 1184.64 toks/s, output: 37.92 toks/s]
WARNING 01-08 17:47:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:47:05,112][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:47:07,357][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:02<00:08,  2.25s/it, est. speed input: 671.57 toks/s, output: 24.49 toks/s]
[2025-01-08 17:47:07,647][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.09s/it, est. speed input: 1138.61 toks/s, output: 48.53 toks/s]
[2025-01-08 17:47:07,790][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.51it/s, est. speed input: 1629.70 toks/s, output: 73.92 toks/s]
[2025-01-08 17:47:07,934][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  3.06it/s, est. speed input: 2609.66 toks/s, output: 127.93 toks/s]
[2025-01-08 17:47:07,934][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.77it/s, est. speed input: 2609.66 toks/s, output: 127.93 toks/s]
WARNING 01-08 17:47:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:47:08,170][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:47:08,958][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1416.06 toks/s, output: 36.80 toks/s]
[2025-01-08 17:47:08,958][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1416.06 toks/s, output: 36.80 toks/s]
[2025-01-08 17:47:15,087][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:47:15,140][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:47:16,879][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 17:47:18,519][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 17:47:20,077][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 17:47:20,599][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 17:47:20,600][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:47:31,806][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:47:32,387][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:47:32,439][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:47:34,288][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 17:47:35,859][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 17:47:37,463][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 17:47:37,959][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 17:47:37,959][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 17:47:52,532][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:47:52,889][root][INFO] - Loading VLLM model.
WARNING 01-08 17:47:53 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:47:53 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:47:53 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:47:53 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:47:54,007][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:47:55,343][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.34s/it]
[2025-01-08 17:47:55,737][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.28it/s]
[2025-01-08 17:47:57,046][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 17:47:58,392][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:47:58,393][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 17:47:58 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:48:12 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:48:12 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:48:12 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:48:34 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:48:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:34,587][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:37,317][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.73s/it, est. speed input: 185.01 toks/s, output: 13.92 toks/s]
[2025-01-08 17:48:37,786][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:19,  1.40s/it, est. speed input: 315.80 toks/s, output: 27.83 toks/s]
[2025-01-08 17:48:37,961][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:10,  1.19it/s, est. speed input: 449.06 toks/s, output: 42.98 toks/s]
[2025-01-08 17:48:38,162][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.70it/s, est. speed input: 565.09 toks/s, output: 57.91 toks/s]
[2025-01-08 17:48:38,291][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:03,  3.22it/s, est. speed input: 818.15 toks/s, output: 91.26 toks/s]
[2025-01-08 17:48:38,437][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:03<00:02,  3.77it/s, est. speed input: 918.22 toks/s, output: 106.24 toks/s]
[2025-01-08 17:48:38,545][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:03<00:00,  7.08it/s, est. speed input: 1276.17 toks/s, output: 158.95 toks/s]
[2025-01-08 17:48:38,893][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:04<00:00,  7.68it/s, est. speed input: 1524.85 toks/s, output: 203.47 toks/s]
[2025-01-08 17:48:39,064][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:04<00:00,  8.54it/s, est. speed input: 1692.19 toks/s, output: 239.25 toks/s]
[2025-01-08 17:48:39,181][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  3.48it/s, est. speed input: 1758.90 toks/s, output: 256.43 toks/s]
WARNING 01-08 17:48:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:39,393][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:40,247][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 721.43 toks/s, output: 33.96 toks/s]
[2025-01-08 17:48:40,331][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1305.06 toks/s, output: 67.17 toks/s]
WARNING 01-08 17:48:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:40,548][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:44,113][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:46,  3.56s/it, est. speed input: 196.10 toks/s, output: 18.80 toks/s]
[2025-01-08 17:48:44,214][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:18,  1.53s/it, est. speed input: 381.31 toks/s, output: 37.37 toks/s]
[2025-01-08 17:48:44,405][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.59it/s, est. speed input: 724.89 toks/s, output: 73.89 toks/s]
[2025-01-08 17:48:44,907][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:05,  1.69it/s, est. speed input: 801.85 toks/s, output: 86.72 toks/s]
[2025-01-08 17:48:45,098][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.79it/s, est. speed input: 1075.47 toks/s, output: 125.94 toks/s]
[2025-01-08 17:48:45,202][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.40it/s, est. speed input: 1201.57 toks/s, output: 145.47 toks/s]
[2025-01-08 17:48:45,681][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:01,  3.68it/s, est. speed input: 1361.83 toks/s, output: 176.90 toks/s]
[2025-01-08 17:48:46,376][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.34it/s, est. speed input: 1439.37 toks/s, output: 204.89 toks/s]
[2025-01-08 17:48:46,486][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  3.85it/s, est. speed input: 1530.25 toks/s, output: 229.02 toks/s]
[2025-01-08 17:48:47,057][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  3.01it/s, est. speed input: 1503.56 toks/s, output: 239.68 toks/s]
[2025-01-08 17:48:47,057][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.15it/s, est. speed input: 1503.56 toks/s, output: 239.68 toks/s]
WARNING 01-08 17:48:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:47,279][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:49,335][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.06s/it, est. speed input: 305.92 toks/s, output: 14.10 toks/s]
[2025-01-08 17:48:50,020][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:13,  1.25s/it, est. speed input: 463.66 toks/s, output: 28.82 toks/s]
[2025-01-08 17:48:50,238][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:02<00:07,  1.28it/s, est. speed input: 651.20 toks/s, output: 45.96 toks/s]
[2025-01-08 17:48:50,354][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:02,  2.70it/s, est. speed input: 1064.75 toks/s, output: 83.25 toks/s]
[2025-01-08 17:48:50,510][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  4.17it/s, est. speed input: 1420.48 toks/s, output: 119.15 toks/s]
[2025-01-08 17:48:50,651][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:03<00:00,  5.76it/s, est. speed input: 1748.34 toks/s, output: 156.59 toks/s]
[2025-01-08 17:48:51,218][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:03<00:00,  4.69it/s, est. speed input: 1834.23 toks/s, output: 183.02 toks/s]
[2025-01-08 17:48:51,402][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  4.83it/s, est. speed input: 1921.82 toks/s, output: 201.54 toks/s]
[2025-01-08 17:48:51,704][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  4.38it/s, est. speed input: 1939.92 toks/s, output: 216.73 toks/s]
[2025-01-08 17:48:51,704][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.94it/s, est. speed input: 1939.92 toks/s, output: 216.73 toks/s]
WARNING 01-08 17:48:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:51,956][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:53,165][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.21s/it, est. speed input: 578.54 toks/s, output: 33.11 toks/s]
[2025-01-08 17:48:53,294][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.74it/s, est. speed input: 1180.16 toks/s, output: 65.07 toks/s]
[2025-01-08 17:48:53,728][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.96it/s, est. speed input: 1178.79 toks/s, output: 90.33 toks/s]
[2025-01-08 17:48:53,728][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.69it/s, est. speed input: 1178.79 toks/s, output: 90.33 toks/s]
WARNING 01-08 17:48:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:53,935][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:48:54,906][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.03it/s, est. speed input: 753.64 toks/s, output: 29.90 toks/s]
[2025-01-08 17:48:55,328][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.54it/s, est. speed input: 1043.85 toks/s, output: 58.19 toks/s]
[2025-01-08 17:48:56,750][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.00s/it, est. speed input: 758.70 toks/s, output: 77.47 toks/s]
[2025-01-08 17:48:56,750][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.07it/s, est. speed input: 758.70 toks/s, output: 77.47 toks/s]
WARNING 01-08 17:48:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:48:56,979][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:00,929][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:47,  3.95s/it, est. speed input: 267.13 toks/s, output: 16.96 toks/s]
[2025-01-08 17:49:01,129][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:19,  1.74s/it, est. speed input: 504.90 toks/s, output: 33.74 toks/s]
[2025-01-08 17:49:01,314][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.41it/s, est. speed input: 975.15 toks/s, output: 68.05 toks/s]
[2025-01-08 17:49:01,771][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:05,  1.59it/s, est. speed input: 1104.67 toks/s, output: 81.39 toks/s]
[2025-01-08 17:49:01,989][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:05<00:03,  1.98it/s, est. speed input: 1269.80 toks/s, output: 98.41 toks/s]
[2025-01-08 17:49:02,280][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:05<00:02,  2.28it/s, est. speed input: 1403.66 toks/s, output: 114.52 toks/s]
[2025-01-08 17:49:02,658][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  3.82it/s, est. speed input: 1877.62 toks/s, output: 170.47 toks/s]
[2025-01-08 17:49:03,128][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  3.27it/s, est. speed input: 1926.03 toks/s, output: 182.49 toks/s]
[2025-01-08 17:49:03,514][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  3.08it/s, est. speed input: 1987.37 toks/s, output: 198.48 toks/s]
[2025-01-08 17:49:03,548][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.98it/s, est. speed input: 2150.35 toks/s, output: 224.38 toks/s]
WARNING 01-08 17:49:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:03,775][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:06,044][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:27,  2.27s/it, est. speed input: 327.95 toks/s, output: 12.78 toks/s]
[2025-01-08 17:49:06,570][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:13,  1.24s/it, est. speed input: 557.16 toks/s, output: 26.48 toks/s]
[2025-01-08 17:49:07,165][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:09,  1.06it/s, est. speed input: 702.52 toks/s, output: 40.72 toks/s]
[2025-01-08 17:49:07,343][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.55it/s, est. speed input: 896.14 toks/s, output: 58.30 toks/s]
[2025-01-08 17:49:07,505][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:01,  3.66it/s, est. speed input: 1491.19 toks/s, output: 114.77 toks/s]
[2025-01-08 17:49:07,700][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:03<00:01,  3.92it/s, est. speed input: 1629.13 toks/s, output: 130.47 toks/s]
[2025-01-08 17:49:07,905][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:04<00:00,  4.12it/s, est. speed input: 1740.31 toks/s, output: 146.52 toks/s]
[2025-01-08 17:49:08,122][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  4.24it/s, est. speed input: 1841.40 toks/s, output: 162.90 toks/s]
[2025-01-08 17:49:08,501][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  3.64it/s, est. speed input: 1876.86 toks/s, output: 175.64 toks/s]
[2025-01-08 17:49:08,685][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  4.01it/s, est. speed input: 1984.57 toks/s, output: 195.95 toks/s]
[2025-01-08 17:49:08,685][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.65it/s, est. speed input: 2165.34 toks/s, output: 222.83 toks/s]
WARNING 01-08 17:49:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:08,898][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:10,061][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.16s/it, est. speed input: 1178.96 toks/s, output: 24.96 toks/s]
[2025-01-08 17:49:10,263][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.67it/s, est. speed input: 1750.51 toks/s, output: 50.56 toks/s]
[2025-01-08 17:49:10,568][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.16it/s, est. speed input: 2153.25 toks/s, output: 76.07 toks/s]
[2025-01-08 17:49:10,568][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.80it/s, est. speed input: 2153.25 toks/s, output: 76.07 toks/s]
WARNING 01-08 17:49:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:10,800][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:12,331][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:03,  1.53s/it, est. speed input: 548.75 toks/s, output: 35.93 toks/s]
[2025-01-08 17:49:12,717][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.17it/s, est. speed input: 910.41 toks/s, output: 68.35 toks/s]
[2025-01-08 17:49:12,768][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.52it/s, est. speed input: 1294.00 toks/s, output: 106.73 toks/s]
WARNING 01-08 17:49:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:13,006][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:18,360][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:05<01:04,  5.35s/it, est. speed input: 160.09 toks/s, output: 17.37 toks/s]
[2025-01-08 17:49:18,580][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:05<00:09,  1.07s/it, est. speed input: 919.21 toks/s, output: 68.71 toks/s]
[2025-01-08 17:49:18,724][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:05<00:04,  1.57it/s, est. speed input: 1401.30 toks/s, output: 103.37 toks/s]
[2025-01-08 17:49:18,982][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:05<00:02,  2.26it/s, est. speed input: 1847.91 toks/s, output: 136.23 toks/s]
[2025-01-08 17:49:19,241][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:06<00:01,  2.48it/s, est. speed input: 2007.28 toks/s, output: 150.77 toks/s]
[2025-01-08 17:49:19,515][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  3.32it/s, est. speed input: 2394.44 toks/s, output: 185.75 toks/s]
[2025-01-08 17:49:19,993][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  2.95it/s, est. speed input: 2437.44 toks/s, output: 196.65 toks/s]
[2025-01-08 17:49:20,129][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  3.43it/s, est. speed input: 2592.45 toks/s, output: 217.20 toks/s]
[2025-01-08 17:49:20,129][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.83it/s, est. speed input: 2592.45 toks/s, output: 217.20 toks/s]
WARNING 01-08 17:49:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:20,414][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:21,537][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.12s/it, est. speed input: 835.78 toks/s, output: 44.55 toks/s]
[2025-01-08 17:49:21,537][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.12s/it, est. speed input: 835.78 toks/s, output: 44.55 toks/s]
WARNING 01-08 17:49:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:21,751][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:23,861][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.11s/it, est. speed input: 631.81 toks/s, output: 27.02 toks/s]
[2025-01-08 17:49:24,925][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:03<00:02,  1.49s/it, est. speed input: 973.11 toks/s, output: 52.29 toks/s]
[2025-01-08 17:49:25,091][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:03<00:00,  1.13it/s, est. speed input: 1429.16 toks/s, output: 85.02 toks/s]
[2025-01-08 17:49:25,768][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.24it/s, est. speed input: 1572.68 toks/s, output: 110.02 toks/s]
[2025-01-08 17:49:25,769][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.00s/it, est. speed input: 1572.68 toks/s, output: 110.02 toks/s]
WARNING 01-08 17:49:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:49:26,000][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:49:27,845][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.85s/it, est. speed input: 663.35 toks/s, output: 47.69 toks/s]
[2025-01-08 17:49:27,846][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.85s/it, est. speed input: 663.35 toks/s, output: 47.69 toks/s]
[2025-01-08 17:49:33,990][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:49:34,043][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:49:35,719][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 17:49:37,303][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.62s/it]
[2025-01-08 17:49:38,900][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 17:49:39,417][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:49:39,418][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 17:49:50,408][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:49:50,893][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:49:50,945][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:49:52,824][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 17:49:54,414][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 17:49:55,967][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 17:49:56,495][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 17:49:56,495][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 17:50:11,585][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:50:11,904][root][INFO] - Loading VLLM model.
WARNING 01-08 17:50:12 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:50:12 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:50:12 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:50:12 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:50:12,860][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:50:14,177][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:50:14,568][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:50:15,865][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 17:50:17,201][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 17:50:17,202][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:50:17 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:50:31 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:50:31 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:50:31 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:50:53 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:50:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:50:53,496][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:50:56,834][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:50,  3.34s/it, est. speed input: 151.34 toks/s, output: 11.39 toks/s]
[2025-01-08 17:50:57,051][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:21,  1.50s/it, est. speed input: 284.19 toks/s, output: 23.07 toks/s]
[2025-01-08 17:50:57,296][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:12,  1.08it/s, est. speed input: 398.73 toks/s, output: 35.00 toks/s]
[2025-01-08 17:50:57,397][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.66it/s, est. speed input: 517.85 toks/s, output: 47.94 toks/s]
[2025-01-08 17:50:57,555][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:03,  3.08it/s, est. speed input: 746.51 toks/s, output: 74.40 toks/s]
[2025-01-08 17:50:57,672][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:01,  4.77it/s, est. speed input: 967.64 toks/s, output: 102.27 toks/s]
[2025-01-08 17:50:57,906][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:04<00:01,  5.73it/s, est. speed input: 1145.31 toks/s, output: 128.14 toks/s]
[2025-01-08 17:50:58,108][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:04<00:00,  7.91it/s, est. speed input: 1423.59 toks/s, output: 173.04 toks/s]
[2025-01-08 17:50:58,442][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:04<00:00,  7.22it/s, est. speed input: 1531.66 toks/s, output: 198.36 toks/s]
[2025-01-08 17:50:58,476][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  3.21it/s, est. speed input: 1622.62 toks/s, output: 217.29 toks/s]
WARNING 01-08 17:50:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:50:58,691][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:50:59,551][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 706.62 toks/s, output: 33.76 toks/s]
[2025-01-08 17:51:00,252][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.30it/s, est. speed input: 777.19 toks/s, output: 64.07 toks/s]
[2025-01-08 17:51:00,253][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.28it/s, est. speed input: 777.19 toks/s, output: 64.07 toks/s]
WARNING 01-08 17:51:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:00,487][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:02,617][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.13s/it, est. speed input: 328.21 toks/s, output: 12.21 toks/s]
[2025-01-08 17:51:02,718][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:11,  1.07it/s, est. speed input: 626.49 toks/s, output: 24.65 toks/s]
[2025-01-08 17:51:03,828][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:11,  1.02s/it, est. speed input: 627.65 toks/s, output: 35.32 toks/s]
[2025-01-08 17:51:04,015][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.45it/s, est. speed input: 792.55 toks/s, output: 53.01 toks/s]
[2025-01-08 17:51:04,160][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:03<00:02,  2.76it/s, est. speed input: 1141.72 toks/s, output: 90.65 toks/s]
[2025-01-08 17:51:04,318][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:03<00:01,  4.17it/s, est. speed input: 1459.82 toks/s, output: 127.39 toks/s]
[2025-01-08 17:51:04,683][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  6.33it/s, est. speed input: 1999.01 toks/s, output: 198.04 toks/s]
[2025-01-08 17:51:05,233][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  4.49it/s, est. speed input: 1914.58 toks/s, output: 202.05 toks/s]
[2025-01-08 17:51:05,468][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  4.45it/s, est. speed input: 1964.50 toks/s, output: 221.02 toks/s]
[2025-01-08 17:51:05,469][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  2.81it/s, est. speed input: 1964.50 toks/s, output: 221.02 toks/s]
WARNING 01-08 17:51:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:05,701][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:07,668][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.97s/it, est. speed input: 332.06 toks/s, output: 16.78 toks/s]
[2025-01-08 17:51:08,169][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:09,  1.10s/it, est. speed input: 526.02 toks/s, output: 33.64 toks/s]
[2025-01-08 17:51:08,282][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:02<00:05,  1.53it/s, est. speed input: 749.00 toks/s, output: 53.08 toks/s]
[2025-01-08 17:51:08,442][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:02<00:03,  2.19it/s, est. speed input: 951.56 toks/s, output: 71.88 toks/s]
[2025-01-08 17:51:09,193][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:03<00:02,  2.42it/s, est. speed input: 1124.44 toks/s, output: 100.53 toks/s]
[2025-01-08 17:51:09,389][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:03<00:00,  3.60it/s, est. speed input: 1427.02 toks/s, output: 147.53 toks/s]
[2025-01-08 17:51:09,534][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  5.96it/s, est. speed input: 1890.21 toks/s, output: 224.11 toks/s]
[2025-01-08 17:51:09,535][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  2.87it/s, est. speed input: 1890.21 toks/s, output: 224.11 toks/s]
WARNING 01-08 17:51:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:09,786][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:11,030][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 664.86 toks/s, output: 23.31 toks/s]
[2025-01-08 17:51:11,726][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:01<00:00,  2.36it/s, est. speed input: 1520.35 toks/s, output: 79.37 toks/s]
[2025-01-08 17:51:12,900][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.58it/s, est. speed input: 1171.75 toks/s, output: 93.44 toks/s]
[2025-01-08 17:51:12,900][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.61it/s, est. speed input: 1171.75 toks/s, output: 93.44 toks/s]
WARNING 01-08 17:51:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:13,137][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:14,481][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.34s/it, est. speed input: 477.23 toks/s, output: 36.48 toks/s]
[2025-01-08 17:51:14,715][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.30it/s, est. speed input: 1226.84 toks/s, output: 102.02 toks/s]
[2025-01-08 17:51:14,716][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.90it/s, est. speed input: 1226.84 toks/s, output: 102.02 toks/s]
WARNING 01-08 17:51:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:14,955][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:17,506][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.55s/it, est. speed input: 395.15 toks/s, output: 11.37 toks/s]
[2025-01-08 17:51:18,372][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:06,  1.40it/s, est. speed input: 1040.84 toks/s, output: 42.44 toks/s]
[2025-01-08 17:51:18,515][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:04,  1.80it/s, est. speed input: 1290.04 toks/s, output: 58.43 toks/s]
[2025-01-08 17:51:19,030][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:03,  1.83it/s, est. speed input: 1386.79 toks/s, output: 71.17 toks/s]
[2025-01-08 17:51:19,206][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:04<00:01,  2.94it/s, est. speed input: 1824.88 toks/s, output: 108.91 toks/s]
[2025-01-08 17:51:19,342][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  4.28it/s, est. speed input: 2253.40 toks/s, output: 148.16 toks/s]
[2025-01-08 17:51:19,954][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  3.85it/s, est. speed input: 2411.67 toks/s, output: 175.23 toks/s]
[2025-01-08 17:51:21,171][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.20it/s, est. speed input: 2118.98 toks/s, output: 173.11 toks/s]
[2025-01-08 17:51:21,171][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.09it/s, est. speed input: 2118.98 toks/s, output: 173.11 toks/s]
WARNING 01-08 17:51:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:21,407][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:23,875][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:27,  2.47s/it, est. speed input: 292.58 toks/s, output: 15.80 toks/s]
[2025-01-08 17:51:24,314][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:02<00:12,  1.27s/it, est. speed input: 508.82 toks/s, output: 31.65 toks/s]
[2025-01-08 17:51:24,433][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:06,  1.34it/s, est. speed input: 746.92 toks/s, output: 49.24 toks/s]
[2025-01-08 17:51:24,547][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:03,  2.01it/s, est. speed input: 981.31 toks/s, output: 66.89 toks/s]
[2025-01-08 17:51:24,736][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:02,  2.59it/s, est. speed input: 1158.46 toks/s, output: 83.52 toks/s]
[2025-01-08 17:51:24,893][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:01,  3.25it/s, est. speed input: 1358.23 toks/s, output: 100.99 toks/s]
[2025-01-08 17:51:25,282][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:03<00:01,  2.99it/s, est. speed input: 1446.16 toks/s, output: 114.08 toks/s]
[2025-01-08 17:51:25,446][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  6.98it/s, est. speed input: 2194.05 toks/s, output: 203.28 toks/s]
[2025-01-08 17:51:25,800][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.73it/s, est. speed input: 2201.69 toks/s, output: 214.00 toks/s]
WARNING 01-08 17:51:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:26,028][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:27,399][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.37s/it, est. speed input: 824.60 toks/s, output: 21.16 toks/s]
[2025-01-08 17:51:28,329][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.96it/s, est. speed input: 2053.74 toks/s, output: 74.33 toks/s]
[2025-01-08 17:51:28,329][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.74it/s, est. speed input: 2053.74 toks/s, output: 74.33 toks/s]
WARNING 01-08 17:51:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:28,552][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:30,420][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:07,  1.87s/it, est. speed input: 412.29 toks/s, output: 29.98 toks/s]
[2025-01-08 17:51:30,615][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:02,  1.13it/s, est. speed input: 784.94 toks/s, output: 58.66 toks/s]
[2025-01-08 17:51:31,044][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  2.15it/s, est. speed input: 1283.74 toks/s, output: 111.96 toks/s]
[2025-01-08 17:51:31,432][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.27it/s, est. speed input: 1393.96 toks/s, output: 135.44 toks/s]
[2025-01-08 17:51:31,432][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.74it/s, est. speed input: 1393.96 toks/s, output: 135.44 toks/s]
WARNING 01-08 17:51:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:31,693][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:35,114][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:03<00:34,  3.42s/it, est. speed input: 383.20 toks/s, output: 14.91 toks/s]
[2025-01-08 17:51:35,479][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:14,  1.62s/it, est. speed input: 708.89 toks/s, output: 30.11 toks/s]
[2025-01-08 17:51:35,760][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:04<00:04,  1.44it/s, est. speed input: 1304.81 toks/s, output: 62.22 toks/s]
[2025-01-08 17:51:36,268][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.57it/s, est. speed input: 1470.76 toks/s, output: 75.41 toks/s]
[2025-01-08 17:51:36,768][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:05<00:02,  1.68it/s, est. speed input: 1609.70 toks/s, output: 90.04 toks/s]
[2025-01-08 17:51:37,107][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:01,  2.52it/s, est. speed input: 2024.43 toks/s, output: 129.29 toks/s]
[2025-01-08 17:51:37,435][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:05<00:00,  2.64it/s, est. speed input: 2156.23 toks/s, output: 146.80 toks/s]
[2025-01-08 17:51:37,638][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:05<00:00,  3.01it/s, est. speed input: 2325.94 toks/s, output: 167.70 toks/s]
[2025-01-08 17:51:37,909][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  3.17it/s, est. speed input: 2467.29 toks/s, output: 187.74 toks/s]
[2025-01-08 17:51:37,909][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.77it/s, est. speed input: 2467.29 toks/s, output: 187.74 toks/s]
WARNING 01-08 17:51:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:38,210][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:39,159][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 892.30 toks/s, output: 42.14 toks/s]
[2025-01-08 17:51:39,159][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 892.30 toks/s, output: 42.14 toks/s]
WARNING 01-08 17:51:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:39,383][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:40,978][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.59s/it, est. speed input: 872.13 toks/s, output: 18.18 toks/s]
[2025-01-08 17:51:41,934][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.79it/s, est. speed input: 2144.87 toks/s, output: 65.86 toks/s]
[2025-01-08 17:51:42,070][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.26it/s, est. speed input: 2574.50 toks/s, output: 95.65 toks/s]
[2025-01-08 17:51:42,070][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.86it/s, est. speed input: 2574.50 toks/s, output: 95.65 toks/s]
WARNING 01-08 17:51:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:42,318][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:43,887][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 633.39 toks/s, output: 48.43 toks/s]
[2025-01-08 17:51:43,888][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 633.39 toks/s, output: 48.43 toks/s]
WARNING 01-08 17:51:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:44,103][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:46,059][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.96s/it, est. speed input: 790.11 toks/s, output: 47.56 toks/s]
[2025-01-08 17:51:46,059][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.96s/it, est. speed input: 790.11 toks/s, output: 47.56 toks/s]
WARNING 01-08 17:51:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:51:46,283][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:51:47,121][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1457.88 toks/s, output: 34.60 toks/s]
[2025-01-08 17:51:47,121][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1457.88 toks/s, output: 34.60 toks/s]
[2025-01-08 17:51:53,524][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:51:53,577][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:51:55,413][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 17:51:57,139][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 17:51:58,806][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.72s/it]
[2025-01-08 17:51:59,355][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.26s/it]
[2025-01-08 17:51:59,356][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.44s/it]
[2025-01-08 17:52:10,309][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:52:10,811][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:52:10,863][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:52:12,795][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.93s/it]
[2025-01-08 17:52:14,469][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:52:16,032][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 17:52:16,524][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 17:52:16,525][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 17:52:31,228][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:52:31,629][root][INFO] - Loading VLLM model.
WARNING 01-08 17:52:31 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:52:31 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:52:32 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:52:32 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:52:32,674][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:52:33,988][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 17:52:34,377][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 17:52:35,672][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 17:52:36,998][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
[2025-01-08 17:52:36,998][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 17:52:37 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:52:51 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:52:51 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:52:51 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:53:12 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:53:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:13,081][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:15,113][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:30,  2.03s/it, est. speed input: 248.64 toks/s, output: 6.89 toks/s]
[2025-01-08 17:53:15,978][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:18,  1.35s/it, est. speed input: 348.76 toks/s, output: 17.96 toks/s]
[2025-01-08 17:53:16,189][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:10,  1.21it/s, est. speed input: 487.63 toks/s, output: 30.90 toks/s]
[2025-01-08 17:53:16,390][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:06,  1.72it/s, est. speed input: 610.64 toks/s, output: 44.13 toks/s]
[2025-01-08 17:53:16,520][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:04,  2.39it/s, est. speed input: 734.42 toks/s, output: 58.17 toks/s]
[2025-01-08 17:53:16,661][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:03<00:01,  6.24it/s, est. speed input: 1269.95 toks/s, output: 119.03 toks/s]
[2025-01-08 17:53:16,775][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:03<00:00, 10.45it/s, est. speed input: 1777.67 toks/s, output: 181.96 toks/s]
[2025-01-08 17:53:17,582][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  6.43it/s, est. speed input: 1795.30 toks/s, output: 207.97 toks/s]
[2025-01-08 17:53:17,583][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  3.55it/s, est. speed input: 1795.30 toks/s, output: 207.97 toks/s]
WARNING 01-08 17:53:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:17,797][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:18,665][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 643.07 toks/s, output: 33.42 toks/s]
[2025-01-08 17:53:18,665][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1365.00 toks/s, output: 66.81 toks/s]
WARNING 01-08 17:53:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:18,887][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:21,298][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:31,  2.41s/it, est. speed input: 289.87 toks/s, output: 14.10 toks/s]
[2025-01-08 17:53:22,376][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:19,  1.63s/it, est. speed input: 400.70 toks/s, output: 28.66 toks/s]
[2025-01-08 17:53:22,671][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:11,  1.02s/it, est. speed input: 554.17 toks/s, output: 46.25 toks/s]
[2025-01-08 17:53:22,943][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  3.02it/s, est. speed input: 1206.19 toks/s, output: 120.30 toks/s]
[2025-01-08 17:53:23,358][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:02,  2.87it/s, est. speed input: 1250.57 toks/s, output: 131.72 toks/s]
[2025-01-08 17:53:23,504][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.31it/s, est. speed input: 1362.67 toks/s, output: 150.76 toks/s]
[2025-01-08 17:53:23,707][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:01,  3.59it/s, est. speed input: 1450.06 toks/s, output: 168.45 toks/s]
[2025-01-08 17:53:24,169][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.86it/s, est. speed input: 1587.93 toks/s, output: 202.56 toks/s]
[2025-01-08 17:53:24,798][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.58it/s, est. speed input: 1655.45 toks/s, output: 235.14 toks/s]
[2025-01-08 17:53:24,798][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.37it/s, est. speed input: 1655.45 toks/s, output: 235.14 toks/s]
WARNING 01-08 17:53:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:25,019][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:27,416][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.40s/it, est. speed input: 269.08 toks/s, output: 17.94 toks/s]
[2025-01-08 17:53:27,603][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:02<00:10,  1.10s/it, est. speed input: 493.03 toks/s, output: 35.60 toks/s]
[2025-01-08 17:53:27,802][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:02<00:03,  2.12it/s, est. speed input: 923.01 toks/s, output: 71.14 toks/s]
[2025-01-08 17:53:27,906][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:02<00:01,  4.52it/s, est. speed input: 1558.96 toks/s, output: 129.88 toks/s]
[2025-01-08 17:53:28,318][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  4.64it/s, est. speed input: 1753.73 toks/s, output: 157.03 toks/s]
[2025-01-08 17:53:28,576][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  5.36it/s, est. speed input: 1987.55 toks/s, output: 194.26 toks/s]
[2025-01-08 17:53:28,627][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.33it/s, est. speed input: 2152.23 toks/s, output: 218.13 toks/s]
WARNING 01-08 17:53:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:28,838][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:30,081][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 747.82 toks/s, output: 24.95 toks/s]
[2025-01-08 17:53:30,553][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.27it/s, est. speed input: 949.46 toks/s, output: 50.16 toks/s]
[2025-01-08 17:53:31,048][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.53it/s, est. speed input: 1130.28 toks/s, output: 76.05 toks/s]
[2025-01-08 17:53:32,138][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.21it/s, est. speed input: 968.71 toks/s, output: 95.48 toks/s]
[2025-01-08 17:53:32,138][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.21it/s, est. speed input: 968.71 toks/s, output: 95.48 toks/s]
WARNING 01-08 17:53:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:32,371][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:33,463][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.09s/it, est. speed input: 616.90 toks/s, output: 26.58 toks/s]
[2025-01-08 17:53:33,958][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.15it/s, est. speed input: 1302.12 toks/s, output: 71.88 toks/s]
[2025-01-08 17:53:34,158][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.67it/s, est. speed input: 1525.71 toks/s, output: 101.86 toks/s]
[2025-01-08 17:53:34,159][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.24it/s, est. speed input: 1525.71 toks/s, output: 101.86 toks/s]
WARNING 01-08 17:53:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:34,393][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:38,001][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:39,  3.61s/it, est. speed input: 290.49 toks/s, output: 17.46 toks/s]
[2025-01-08 17:53:38,412][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:17,  1.73s/it, est. speed input: 512.75 toks/s, output: 34.58 toks/s]
[2025-01-08 17:53:38,632][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:03,  1.84it/s, est. speed input: 1230.83 toks/s, output: 88.71 toks/s]
[2025-01-08 17:53:38,779][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.41it/s, est. speed input: 1911.67 toks/s, output: 145.68 toks/s]
[2025-01-08 17:53:39,256][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  3.63it/s, est. speed input: 2177.24 toks/s, output: 176.42 toks/s]
[2025-01-08 17:53:39,367][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.09it/s, est. speed input: 2349.61 toks/s, output: 196.22 toks/s]
[2025-01-08 17:53:39,672][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  3.89it/s, est. speed input: 2426.69 toks/s, output: 210.65 toks/s]
[2025-01-08 17:53:39,672][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.27it/s, est. speed input: 2426.69 toks/s, output: 210.65 toks/s]
WARNING 01-08 17:53:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:39,906][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:42,542][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:28,  2.64s/it, est. speed input: 293.68 toks/s, output: 16.69 toks/s]
[2025-01-08 17:53:42,762][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:02<00:12,  1.21s/it, est. speed input: 542.50 toks/s, output: 33.27 toks/s]
[2025-01-08 17:53:42,929][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:02,  2.60it/s, est. speed input: 1288.76 toks/s, output: 85.34 toks/s]
[2025-01-08 17:53:43,060][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:03<00:01,  3.12it/s, est. speed input: 1488.47 toks/s, output: 101.47 toks/s]
[2025-01-08 17:53:43,198][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:03<00:00,  4.66it/s, est. speed input: 1901.51 toks/s, output: 136.99 toks/s]
[2025-01-08 17:53:43,939][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:04<00:00,  3.66it/s, est. speed input: 1974.51 toks/s, output: 160.20 toks/s]
[2025-01-08 17:53:44,049][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.19it/s, est. speed input: 2113.23 toks/s, output: 182.24 toks/s]
[2025-01-08 17:53:44,487][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  3.51it/s, est. speed input: 2085.81 toks/s, output: 194.30 toks/s]
[2025-01-08 17:53:44,487][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.62it/s, est. speed input: 2085.81 toks/s, output: 194.30 toks/s]
WARNING 01-08 17:53:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:44,702][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:47,473][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:08,  2.77s/it, est. speed input: 373.10 toks/s, output: 34.28 toks/s]
[2025-01-08 17:53:48,024][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:03<00:02,  1.47s/it, est. speed input: 681.76 toks/s, output: 65.32 toks/s]
[2025-01-08 17:53:48,556][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:03<00:01,  1.04s/it, est. speed input: 909.37 toks/s, output: 95.48 toks/s]
[2025-01-08 17:53:48,675][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.48it/s, est. speed input: 1165.61 toks/s, output: 132.39 toks/s]
[2025-01-08 17:53:48,675][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.01it/s, est. speed input: 1165.61 toks/s, output: 132.39 toks/s]
WARNING 01-08 17:53:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:48,888][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:50,026][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.14s/it, est. speed input: 692.60 toks/s, output: 25.49 toks/s]
[2025-01-08 17:53:51,015][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.51it/s, est. speed input: 1156.34 toks/s, output: 66.28 toks/s]
[2025-01-08 17:53:51,049][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.85it/s, est. speed input: 1504.49 toks/s, output: 104.56 toks/s]
WARNING 01-08 17:53:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:51,281][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:55,021][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:41,  3.74s/it, est. speed input: 375.93 toks/s, output: 13.90 toks/s]
[2025-01-08 17:53:55,343][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:17,  1.73s/it, est. speed input: 690.38 toks/s, output: 28.07 toks/s]
[2025-01-08 17:53:55,691][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.33it/s, est. speed input: 1270.69 toks/s, output: 56.91 toks/s]
[2025-01-08 17:53:55,909][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.23it/s, est. speed input: 1846.12 toks/s, output: 88.59 toks/s]
[2025-01-08 17:53:56,035][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:01,  2.72it/s, est. speed input: 2085.34 toks/s, output: 104.55 toks/s]
[2025-01-08 17:53:56,340][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  2.85it/s, est. speed input: 2239.32 toks/s, output: 118.00 toks/s]
[2025-01-08 17:53:56,719][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:05<00:01,  2.79it/s, est. speed input: 2358.68 toks/s, output: 131.31 toks/s]
[2025-01-08 17:53:57,391][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  3.50it/s, est. speed input: 2823.52 toks/s, output: 181.83 toks/s]
[2025-01-08 17:53:57,392][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.96it/s, est. speed input: 2823.52 toks/s, output: 181.83 toks/s]
WARNING 01-08 17:53:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:53:57,705][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:53:59,602][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:09,  1.90s/it, est. speed input: 879.93 toks/s, output: 15.29 toks/s]
[2025-01-08 17:54:00,502][root][ERROR] - Processed prompts:  33%|###3      | 2/6 [00:02<00:05,  1.31s/it, est. speed input: 1129.37 toks/s, output: 34.32 toks/s]
[2025-01-08 17:54:00,836][root][ERROR] - Processed prompts:  50%|#####     | 3/6 [00:03<00:02,  1.16it/s, est. speed input: 1530.42 toks/s, output: 56.85 toks/s]
[2025-01-08 17:54:00,980][root][ERROR] - Processed prompts:  67%|######6   | 4/6 [00:03<00:01,  1.72it/s, est. speed input: 1893.31 toks/s, output: 81.52 toks/s]
[2025-01-08 17:54:01,861][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:04<00:00,  1.45it/s, est. speed input: 1868.18 toks/s, output: 97.20 toks/s]
[2025-01-08 17:54:02,928][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:05<00:00,  1.22it/s, est. speed input: 1806.60 toks/s, output: 115.64 toks/s]
[2025-01-08 17:54:02,928][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:05<00:00,  1.15it/s, est. speed input: 1806.60 toks/s, output: 115.64 toks/s]
WARNING 01-08 17:54:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:54:03,179][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:54:04,098][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 2096.29 toks/s, output: 33.74 toks/s]
[2025-01-08 17:54:04,098][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 2096.29 toks/s, output: 33.74 toks/s]
[2025-01-08 17:54:10,465][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:54:10,520][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:54:12,184][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.66s/it]
[2025-01-08 17:54:13,760][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.61s/it]
[2025-01-08 17:54:15,357][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 17:54:15,875][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:54:15,876][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 17:54:26,667][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:54:27,210][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:54:27,263][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:54:29,117][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 17:54:30,688][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 17:54:32,246][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 17:54:32,747][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 17:54:32,748][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 17:54:47,959][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:54:48,292][root][INFO] - Loading VLLM model.
WARNING 01-08 17:54:48 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:54:48 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:54:49 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:54:49 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:54:49,332][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:54:50,654][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 17:54:51,050][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 17:54:52,358][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 17:54:53,706][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 17:54:53,706][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 17:54:54 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:55:07 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:55:08 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:55:08 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:55:29 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:55:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:30,092][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:32,109][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:30,  2.02s/it, est. speed input: 250.43 toks/s, output: 6.94 toks/s]
[2025-01-08 17:55:32,973][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:18,  1.34s/it, est. speed input: 350.59 toks/s, output: 18.05 toks/s]
[2025-01-08 17:55:33,184][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:10,  1.21it/s, est. speed input: 490.07 toks/s, output: 31.05 toks/s]
[2025-01-08 17:55:33,384][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:06,  1.73it/s, est. speed input: 613.58 toks/s, output: 44.35 toks/s]
[2025-01-08 17:55:33,514][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:04,  2.40it/s, est. speed input: 737.85 toks/s, output: 58.44 toks/s]
[2025-01-08 17:55:33,655][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:03<00:01,  6.26it/s, est. speed input: 1275.73 toks/s, output: 119.57 toks/s]
[2025-01-08 17:55:33,765][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:03<00:00, 11.83it/s, est. speed input: 1924.86 toks/s, output: 199.84 toks/s]
[2025-01-08 17:55:34,450][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  3.67it/s, est. speed input: 1854.40 toks/s, output: 209.31 toks/s]
WARNING 01-08 17:55:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:34,680][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:35,540][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 705.04 toks/s, output: 33.74 toks/s]
[2025-01-08 17:55:35,557][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.28it/s, est. speed input: 1327.21 toks/s, output: 67.27 toks/s]
WARNING 01-08 17:55:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:35,784][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:38,718][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:38,  2.93s/it, est. speed input: 238.27 toks/s, output: 16.70 toks/s]
[2025-01-08 17:55:39,223][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:18,  1.50s/it, est. speed input: 406.59 toks/s, output: 32.86 toks/s]
[2025-01-08 17:55:39,354][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:09,  1.14it/s, est. speed input: 587.51 toks/s, output: 50.71 toks/s]
[2025-01-08 17:55:39,885][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:04,  1.88it/s, est. speed input: 852.44 toks/s, output: 81.71 toks/s]
[2025-01-08 17:55:40,538][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:02,  2.78it/s, est. speed input: 1176.34 toks/s, output: 131.05 toks/s]
[2025-01-08 17:55:40,723][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:01,  3.73it/s, est. speed input: 1415.48 toks/s, output: 173.14 toks/s]
[2025-01-08 17:55:41,162][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.97it/s, est. speed input: 1559.88 toks/s, output: 207.72 toks/s]
[2025-01-08 17:55:42,242][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  2.44it/s, est. speed input: 1407.27 toks/s, output: 203.96 toks/s]
[2025-01-08 17:55:42,242][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.17it/s, est. speed input: 1515.45 toks/s, output: 234.92 toks/s]
WARNING 01-08 17:55:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:42,456][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:44,560][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.10s/it, est. speed input: 296.12 toks/s, output: 18.06 toks/s]
[2025-01-08 17:55:44,708][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:08,  1.05it/s, est. speed input: 558.77 toks/s, output: 35.98 toks/s]
[2025-01-08 17:55:44,877][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:02<00:04,  1.68it/s, est. speed input: 788.20 toks/s, output: 53.70 toks/s]
[2025-01-08 17:55:45,244][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:02<00:01,  3.54it/s, est. speed input: 1379.80 toks/s, output: 106.19 toks/s]
[2025-01-08 17:55:45,392][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:02<00:00,  6.87it/s, est. speed input: 2194.40 toks/s, output: 191.07 toks/s]
[2025-01-08 17:55:45,393][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  3.75it/s, est. speed input: 2411.84 toks/s, output: 215.57 toks/s]
WARNING 01-08 17:55:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:45,600][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:46,860][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.26s/it, est. speed input: 651.65 toks/s, output: 22.22 toks/s]
[2025-01-08 17:55:47,595][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:01<00:00,  2.29it/s, est. speed input: 1677.84 toks/s, output: 76.72 toks/s]
[2025-01-08 17:55:47,696][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.91it/s, est. speed input: 1930.61 toks/s, output: 108.34 toks/s]
[2025-01-08 17:55:47,696][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.39it/s, est. speed input: 1930.61 toks/s, output: 108.34 toks/s]
WARNING 01-08 17:55:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:47,904][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:49,078][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.17s/it, est. speed input: 613.87 toks/s, output: 24.69 toks/s]
[2025-01-08 17:55:49,512][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:01<00:00,  2.15it/s, est. speed input: 1258.17 toks/s, output: 68.38 toks/s]
[2025-01-08 17:55:49,806][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:01<00:00,  2.46it/s, est. speed input: 1402.77 toks/s, output: 93.06 toks/s]
[2025-01-08 17:55:50,441][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.08it/s, est. speed input: 1322.88 toks/s, output: 111.13 toks/s]
[2025-01-08 17:55:50,442][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.97it/s, est. speed input: 1322.88 toks/s, output: 111.13 toks/s]
WARNING 01-08 17:55:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:50,664][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:54,109][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:03<00:34,  3.44s/it, est. speed input: 301.06 toks/s, output: 18.58 toks/s]
[2025-01-08 17:55:54,259][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:13,  1.51s/it, est. speed input: 583.61 toks/s, output: 37.00 toks/s]
[2025-01-08 17:55:54,659][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:08,  1.00s/it, est. speed input: 792.56 toks/s, output: 54.07 toks/s]
[2025-01-08 17:55:55,425][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:03,  1.54it/s, est. speed input: 1108.77 toks/s, output: 86.34 toks/s]
[2025-01-08 17:55:55,982][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:05<00:01,  2.06it/s, est. speed input: 1394.91 toks/s, output: 124.13 toks/s]
[2025-01-08 17:55:56,093][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:05<00:01,  2.54it/s, est. speed input: 1561.46 toks/s, output: 147.56 toks/s]
[2025-01-08 17:55:56,448][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:05<00:00,  3.27it/s, est. speed input: 1857.86 toks/s, output: 191.08 toks/s]
[2025-01-08 17:55:56,702][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  3.40it/s, est. speed input: 1964.22 toks/s, output: 212.03 toks/s]
[2025-01-08 17:55:56,702][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.82it/s, est. speed input: 1964.22 toks/s, output: 212.03 toks/s]
WARNING 01-08 17:55:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:55:56,946][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:55:59,544][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:25,  2.60s/it, est. speed input: 309.51 toks/s, output: 18.48 toks/s]
[2025-01-08 17:55:59,654][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:02<00:01,  2.96it/s, est. speed input: 1753.64 toks/s, output: 111.15 toks/s]
[2025-01-08 17:56:00,017][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  4.08it/s, est. speed input: 2322.68 toks/s, output: 159.90 toks/s]
[2025-01-08 17:56:00,301][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  4.65it/s, est. speed input: 2574.67 toks/s, output: 195.25 toks/s]
[2025-01-08 17:56:00,301][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  3.28it/s, est. speed input: 2574.67 toks/s, output: 195.25 toks/s]
WARNING 01-08 17:56:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:00,520][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:01,943][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.42s/it, est. speed input: 789.40 toks/s, output: 19.68 toks/s]
[2025-01-08 17:56:02,594][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.64it/s, est. speed input: 1615.82 toks/s, output: 55.95 toks/s]
[2025-01-08 17:56:02,741][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  2.22it/s, est. speed input: 1977.60 toks/s, output: 82.87 toks/s]
[2025-01-08 17:56:03,063][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.46it/s, est. speed input: 2221.95 toks/s, output: 106.61 toks/s]
[2025-01-08 17:56:03,063][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.97it/s, est. speed input: 2221.95 toks/s, output: 106.61 toks/s]
WARNING 01-08 17:56:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:03,271][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:04,285][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 824.60 toks/s, output: 28.60 toks/s]
[2025-01-08 17:56:05,702][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.27it/s, est. speed input: 1026.03 toks/s, output: 70.76 toks/s]
[2025-01-08 17:56:05,702][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.23it/s, est. speed input: 1026.03 toks/s, output: 70.76 toks/s]
WARNING 01-08 17:56:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:05,935][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:09,038][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:37,  3.10s/it, est. speed input: 388.36 toks/s, output: 9.02 toks/s]
[2025-01-08 17:56:09,983][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:20,  1.83s/it, est. speed input: 659.12 toks/s, output: 20.75 toks/s]
[2025-01-08 17:56:10,403][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:04<00:11,  1.19s/it, est. speed input: 878.38 toks/s, output: 34.25 toks/s]
[2025-01-08 17:56:10,586][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:07,  1.26it/s, est. speed input: 1141.42 toks/s, output: 49.02 toks/s]
[2025-01-08 17:56:10,818][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.70it/s, est. speed input: 1380.36 toks/s, output: 63.69 toks/s]
[2025-01-08 17:56:11,249][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:05<00:02,  2.50it/s, est. speed input: 1792.45 toks/s, output: 92.77 toks/s]
[2025-01-08 17:56:11,770][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:05<00:01,  2.93it/s, est. speed input: 2144.95 toks/s, output: 122.36 toks/s]
[2025-01-08 17:56:11,938][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:06<00:00,  4.09it/s, est. speed input: 2577.38 toks/s, output: 160.92 toks/s]
[2025-01-08 17:56:12,746][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  2.75it/s, est. speed input: 2508.74 toks/s, output: 167.24 toks/s]
[2025-01-08 17:56:13,204][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  2.59it/s, est. speed input: 2566.59 toks/s, output: 184.22 toks/s]
[2025-01-08 17:56:13,204][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.79it/s, est. speed input: 2566.59 toks/s, output: 184.22 toks/s]
WARNING 01-08 17:56:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:13,474][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:14,752][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.28s/it, est. speed input: 599.64 toks/s, output: 39.92 toks/s]
[2025-01-08 17:56:15,004][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.48it/s, est. speed input: 1017.90 toks/s, output: 76.49 toks/s]
[2025-01-08 17:56:15,004][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.31it/s, est. speed input: 1017.90 toks/s, output: 76.49 toks/s]
WARNING 01-08 17:56:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:15,231][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:17,292][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:06,  2.06s/it, est. speed input: 885.00 toks/s, output: 26.20 toks/s]
[2025-01-08 17:56:17,416][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:01,  1.09it/s, est. speed input: 1472.49 toks/s, output: 52.18 toks/s]
[2025-01-08 17:56:17,824][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.12it/s, est. speed input: 2400.27 toks/s, output: 99.88 toks/s]
[2025-01-08 17:56:17,825][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.54it/s, est. speed input: 2400.27 toks/s, output: 99.88 toks/s]
WARNING 01-08 17:56:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:18,067][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:19,094][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.03s/it, est. speed input: 1467.84 toks/s, output: 27.27 toks/s]
[2025-01-08 17:56:19,094][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.95it/s, est. speed input: 3024.18 toks/s, output: 54.52 toks/s]
WARNING 01-08 17:56:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:56:19,298][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:56:20,359][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.06s/it, est. speed input: 1585.04 toks/s, output: 27.34 toks/s]
[2025-01-08 17:56:20,884][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.34it/s, est. speed input: 2062.28 toks/s, output: 56.13 toks/s]
[2025-01-08 17:56:20,884][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.26it/s, est. speed input: 2062.28 toks/s, output: 56.13 toks/s]
[2025-01-08 17:56:27,284][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:56:27,338][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:56:29,009][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 17:56:30,612][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 17:56:32,167][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 17:56:32,686][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 17:56:32,686][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 17:56:43,482][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:56:43,985][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:56:44,038][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:56:45,952][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 17:56:47,633][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:56:49,243][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 17:56:49,752][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 17:56:49,752][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 17:57:04,909][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:57:05,210][root][INFO] - Loading VLLM model.
WARNING 01-08 17:57:05 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:57:05 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:57:05 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:57:05 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:57:06,187][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:57:07,556][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 17:57:07,961][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 17:57:09,323][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 17:57:10,730][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 17:57:10,731][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 17:57:11 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:57:24 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:57:25 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:57:25 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 17:57:46 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 17:57:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:57:46,687][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:57:48,918][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:33,  2.23s/it, est. speed input: 226.42 toks/s, output: 6.28 toks/s]
[2025-01-08 17:57:49,458][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:17,  1.24s/it, est. speed input: 364.54 toks/s, output: 15.52 toks/s]
[2025-01-08 17:57:49,774][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:03<00:10,  1.23it/s, est. speed input: 490.87 toks/s, output: 26.24 toks/s]
[2025-01-08 17:57:49,975][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:06,  1.74it/s, est. speed input: 614.44 toks/s, output: 38.02 toks/s]
[2025-01-08 17:57:50,158][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:03<00:02,  3.98it/s, est. speed input: 1018.80 toks/s, output: 76.95 toks/s]
[2025-01-08 17:57:50,270][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:03<00:01,  4.56it/s, est. speed input: 1127.84 toks/s, output: 89.61 toks/s]
[2025-01-08 17:57:50,374][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:03<00:00,  7.84it/s, est. speed input: 1507.07 toks/s, output: 133.48 toks/s]
[2025-01-08 17:57:50,656][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:03<00:00, 10.02it/s, est. speed input: 1908.90 toks/s, output: 187.49 toks/s]
[2025-01-08 17:57:52,091][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.96it/s, est. speed input: 1495.36 toks/s, output: 167.12 toks/s]
WARNING 01-08 17:57:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:57:52,328][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:57:53,148][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.22it/s, est. speed input: 680.50 toks/s, output: 32.93 toks/s]
[2025-01-08 17:57:53,182][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.34it/s, est. speed input: 1358.01 toks/s, output: 65.56 toks/s]
WARNING 01-08 17:57:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:57:53,398][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:57:55,629][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.23s/it, est. speed input: 313.31 toks/s, output: 13.00 toks/s]
[2025-01-08 17:57:57,008][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:20,  1.73s/it, est. speed input: 387.31 toks/s, output: 27.43 toks/s]
[2025-01-08 17:57:57,337][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:11,  1.09s/it, est. speed input: 532.38 toks/s, output: 45.44 toks/s]
[2025-01-08 17:57:57,520][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:04,  1.91it/s, est. speed input: 847.85 toks/s, output: 84.42 toks/s]
[2025-01-08 17:57:57,633][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.46it/s, est. speed input: 990.21 toks/s, output: 103.41 toks/s]
[2025-01-08 17:57:57,928][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.68it/s, est. speed input: 1080.16 toks/s, output: 118.99 toks/s]
[2025-01-08 17:57:58,058][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.31it/s, est. speed input: 1200.03 toks/s, output: 138.42 toks/s]
[2025-01-08 17:57:58,276][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.61it/s, est. speed input: 1289.74 toks/s, output: 155.81 toks/s]
[2025-01-08 17:57:58,727][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:01,  3.04it/s, est. speed input: 1311.67 toks/s, output: 167.95 toks/s]
[2025-01-08 17:57:58,857][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  3.71it/s, est. speed input: 1408.54 toks/s, output: 189.78 toks/s]
[2025-01-08 17:57:58,996][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  4.33it/s, est. speed input: 1498.35 toks/s, output: 211.50 toks/s]
[2025-01-08 17:57:59,838][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  2.42it/s, est. speed input: 1411.01 toks/s, output: 213.97 toks/s]
[2025-01-08 17:57:59,939][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  3.12it/s, est. speed input: 1496.03 toks/s, output: 241.24 toks/s]
[2025-01-08 17:57:59,940][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.14it/s, est. speed input: 1496.03 toks/s, output: 241.24 toks/s]
WARNING 01-08 17:58:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:00,159][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:02,524][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.36s/it, est. speed input: 268.52 toks/s, output: 17.34 toks/s]
[2025-01-08 17:58:02,645][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:05,  1.52it/s, est. speed input: 772.56 toks/s, output: 51.50 toks/s]
[2025-01-08 17:58:02,776][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:02<00:01,  3.56it/s, est. speed input: 1465.24 toks/s, output: 102.83 toks/s]
[2025-01-08 17:58:03,320][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:03<00:00,  4.93it/s, est. speed input: 2027.07 toks/s, output: 159.48 toks/s]
[2025-01-08 17:58:05,387][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.31it/s, est. speed input: 1493.65 toks/s, output: 149.79 toks/s]
[2025-01-08 17:58:05,387][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.30it/s, est. speed input: 1493.65 toks/s, output: 149.79 toks/s]
WARNING 01-08 17:58:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:05,596][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:06,895][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.30s/it, est. speed input: 538.16 toks/s, output: 26.95 toks/s]
[2025-01-08 17:58:07,014][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.65it/s, est. speed input: 1165.31 toks/s, output: 53.58 toks/s]
[2025-01-08 17:58:07,326][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.12it/s, est. speed input: 1502.62 toks/s, output: 77.44 toks/s]
[2025-01-08 17:58:07,778][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.16it/s, est. speed input: 1511.67 toks/s, output: 100.35 toks/s]
[2025-01-08 17:58:07,778][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.83it/s, est. speed input: 1511.67 toks/s, output: 100.35 toks/s]
WARNING 01-08 17:58:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:08,007][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:09,075][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.07s/it, est. speed input: 628.16 toks/s, output: 25.28 toks/s]
[2025-01-08 17:58:10,084][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.11it/s, est. speed input: 1404.27 toks/s, output: 82.83 toks/s]
[2025-01-08 17:58:10,084][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.93it/s, est. speed input: 1404.27 toks/s, output: 82.83 toks/s]
WARNING 01-08 17:58:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:10,325][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:12,787][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:27,  2.46s/it, est. speed input: 320.04 toks/s, output: 11.78 toks/s]
[2025-01-08 17:58:13,735][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:15,  1.57s/it, est. speed input: 549.25 toks/s, output: 25.81 toks/s]
[2025-01-08 17:58:13,911][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:05,  1.56it/s, est. speed input: 1115.94 toks/s, output: 59.95 toks/s]
[2025-01-08 17:58:14,400][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:04,  1.68it/s, est. speed input: 1242.63 toks/s, output: 73.12 toks/s]
[2025-01-08 17:58:14,532][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:04<00:02,  2.21it/s, est. speed input: 1455.28 toks/s, output: 91.74 toks/s]
[2025-01-08 17:58:14,828][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:04<00:02,  2.47it/s, est. speed input: 1608.46 toks/s, output: 107.93 toks/s]
[2025-01-08 17:58:14,966][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.09it/s, est. speed input: 1789.89 toks/s, output: 127.54 toks/s]
[2025-01-08 17:58:15,077][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:00,  3.85it/s, est. speed input: 1967.73 toks/s, output: 147.93 toks/s]
[2025-01-08 17:58:15,564][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  3.05it/s, est. speed input: 1997.52 toks/s, output: 159.95 toks/s]
[2025-01-08 17:58:16,040][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  2.68it/s, est. speed input: 2017.01 toks/s, output: 174.79 toks/s]
[2025-01-08 17:58:16,378][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.76it/s, est. speed input: 2085.06 toks/s, output: 194.93 toks/s]
[2025-01-08 17:58:16,379][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.98it/s, est. speed input: 2085.06 toks/s, output: 194.93 toks/s]
WARNING 01-08 17:58:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:16,615][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:19,040][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.43s/it, est. speed input: 314.20 toks/s, output: 16.08 toks/s]
[2025-01-08 17:58:19,253][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:06,  1.41it/s, est. speed input: 866.97 toks/s, output: 48.14 toks/s]
[2025-01-08 17:58:19,362][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:02<00:01,  3.38it/s, est. speed input: 1653.63 toks/s, output: 99.39 toks/s]
[2025-01-08 17:58:19,666][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  4.88it/s, est. speed input: 2266.75 toks/s, output: 143.88 toks/s]
[2025-01-08 17:58:20,336][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  4.08it/s, est. speed input: 2288.60 toks/s, output: 169.82 toks/s]
[2025-01-08 17:58:20,538][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  4.21it/s, est. speed input: 2366.85 toks/s, output: 189.12 toks/s]
[2025-01-08 17:58:20,538][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.06it/s, est. speed input: 2366.85 toks/s, output: 189.12 toks/s]
WARNING 01-08 17:58:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:20,746][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:22,669][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it, est. speed input: 553.39 toks/s, output: 29.13 toks/s]
[2025-01-08 17:58:23,345][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.19s/it, est. speed input: 901.75 toks/s, output: 55.81 toks/s]
[2025-01-08 17:58:24,115][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:03<00:00,  1.00it/s, est. speed input: 1014.50 toks/s, output: 81.94 toks/s]
[2025-01-08 17:58:24,909][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.09it/s, est. speed input: 1125.65 toks/s, output: 109.06 toks/s]
[2025-01-08 17:58:24,910][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.04s/it, est. speed input: 1125.65 toks/s, output: 109.06 toks/s]
WARNING 01-08 17:58:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:25,117][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:26,238][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.12s/it, est. speed input: 694.14 toks/s, output: 24.09 toks/s]
[2025-01-08 17:58:27,378][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.40it/s, est. speed input: 1029.26 toks/s, output: 64.13 toks/s]
[2025-01-08 17:58:28,663][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.10it/s, est. speed input: 966.20 toks/s, output: 87.43 toks/s]
[2025-01-08 17:58:28,663][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:03<00:00,  1.13it/s, est. speed input: 966.20 toks/s, output: 87.43 toks/s]
WARNING 01-08 17:58:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:28,900][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:31,849][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:32,  2.95s/it, est. speed input: 369.91 toks/s, output: 9.83 toks/s]
[2025-01-08 17:58:32,814][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:17,  1.78s/it, est. speed input: 642.62 toks/s, output: 22.49 toks/s]
[2025-01-08 17:58:33,180][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:04<00:10,  1.14s/it, est. speed input: 921.13 toks/s, output: 37.15 toks/s]
[2025-01-08 17:58:33,324][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:05,  1.34it/s, est. speed input: 1195.48 toks/s, output: 53.12 toks/s]
[2025-01-08 17:58:34,104][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:05<00:03,  1.80it/s, est. speed input: 1569.00 toks/s, output: 80.32 toks/s]
[2025-01-08 17:58:34,330][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:05<00:02,  2.15it/s, est. speed input: 1779.62 toks/s, output: 97.98 toks/s]
[2025-01-08 17:58:34,462][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:05<00:00,  4.21it/s, est. speed input: 2527.92 toks/s, output: 159.12 toks/s]
[2025-01-08 17:58:34,627][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:05<00:00,  4.49it/s, est. speed input: 2721.83 toks/s, output: 177.04 toks/s]
[2025-01-08 17:58:35,829][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.25it/s, est. speed input: 2473.42 toks/s, output: 175.21 toks/s]
[2025-01-08 17:58:35,829][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.73it/s, est. speed input: 2473.42 toks/s, output: 175.21 toks/s]
WARNING 01-08 17:58:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:36,124][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:36,890][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 1095.49 toks/s, output: 37.91 toks/s]
[2025-01-08 17:58:36,890][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 1095.49 toks/s, output: 37.91 toks/s]
WARNING 01-08 17:58:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:37,114][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:39,991][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:02<00:11,  2.88s/it, est. speed input: 484.51 toks/s, output: 26.76 toks/s]
[2025-01-08 17:58:40,258][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:03<00:04,  1.34s/it, est. speed input: 967.55 toks/s, output: 52.80 toks/s]
[2025-01-08 17:58:40,589][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:03<00:00,  1.66it/s, est. speed input: 1822.03 toks/s, output: 104.18 toks/s]
[2025-01-08 17:58:42,163][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:05<00:00,  1.11it/s, est. speed input: 1595.82 toks/s, output: 111.30 toks/s]
[2025-01-08 17:58:42,164][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:05<00:00,  1.01s/it, est. speed input: 1595.82 toks/s, output: 111.30 toks/s]
WARNING 01-08 17:58:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 17:58:42,396][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 17:58:43,942][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.55s/it, est. speed input: 902.01 toks/s, output: 35.59 toks/s]
[2025-01-08 17:58:44,282][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.20it/s, est. speed input: 1790.45 toks/s, output: 68.94 toks/s]
[2025-01-08 17:58:44,282][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.06it/s, est. speed input: 1790.45 toks/s, output: 68.94 toks/s]
[2025-01-08 17:58:50,762][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:58:50,816][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:58:52,490][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 17:58:54,118][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 17:58:55,730][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 17:58:56,250][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 17:58:56,251][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 17:59:06,998][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 17:59:07,531][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 17:59:07,584][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:59:09,541][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.96s/it]
[2025-01-08 17:59:11,206][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 17:59:12,818][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 17:59:13,321][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 17:59:13,322][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 17:59:28,553][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 17:59:28,876][root][INFO] - Loading VLLM model.
WARNING 01-08 17:59:29 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 17:59:29 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 17:59:29 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 17:59:29 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 17:59:29,960][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 17:59:31,340][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 17:59:31,743][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 17:59:33,111][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 17:59:34,511][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 17:59:34,511][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 17:59:34 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 17:59:48 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 17:59:49 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 17:59:49 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:00:10 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:00:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:11,044][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:14,128][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.08s/it, est. speed input: 163.73 toks/s, output: 9.40 toks/s]
[2025-01-08 18:00:14,406][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:04,  2.34it/s, est. speed input: 901.16 toks/s, output: 54.43 toks/s]
[2025-01-08 18:00:14,576][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:03<00:02,  3.19it/s, est. speed input: 1143.82 toks/s, output: 75.31 toks/s]
[2025-01-08 18:00:14,820][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:03<00:01,  4.62it/s, est. speed input: 1470.97 toks/s, output: 109.10 toks/s]
[2025-01-08 18:00:14,973][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:03<00:00,  7.27it/s, est. speed input: 1927.83 toks/s, output: 162.62 toks/s]
[2025-01-08 18:00:16,124][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.15it/s, est. speed input: 1590.67 toks/s, output: 151.59 toks/s]
WARNING 01-08 18:00:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:16,350][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:19,713][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:50,  3.36s/it, est. speed input: 207.86 toks/s, output: 15.76 toks/s]
[2025-01-08 18:00:19,967][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:21,  1.53s/it, est. speed input: 386.46 toks/s, output: 31.24 toks/s]
[2025-01-08 18:00:20,172][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.57it/s, est. speed input: 731.60 toks/s, output: 62.80 toks/s]
[2025-01-08 18:00:21,356][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:05<00:06,  1.62it/s, est. speed input: 837.69 toks/s, output: 82.09 toks/s]
[2025-01-08 18:00:21,558][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:03,  2.45it/s, est. speed input: 1073.62 toks/s, output: 120.76 toks/s]
[2025-01-08 18:00:21,717][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  3.47it/s, est. speed input: 1302.36 toks/s, output: 160.23 toks/s]
[2025-01-08 18:00:22,062][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  4.03it/s, est. speed input: 1468.44 toks/s, output: 194.85 toks/s]
[2025-01-08 18:00:22,471][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:06<00:00,  3.57it/s, est. speed input: 1484.42 toks/s, output: 206.48 toks/s]
[2025-01-08 18:00:22,604][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  4.92it/s, est. speed input: 1676.62 toks/s, output: 251.85 toks/s]
[2025-01-08 18:00:23,308][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  3.27it/s, est. speed input: 1607.36 toks/s, output: 255.10 toks/s]
[2025-01-08 18:00:23,308][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.30it/s, est. speed input: 1607.36 toks/s, output: 255.10 toks/s]
WARNING 01-08 18:00:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:23,546][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:25,473][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.93s/it, est. speed input: 318.61 toks/s, output: 15.05 toks/s]
[2025-01-08 18:00:25,706][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:02<00:01,  3.60it/s, est. speed input: 1718.54 toks/s, output: 84.75 toks/s]
[2025-01-08 18:00:25,845][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:02<00:00,  5.61it/s, est. speed input: 2447.62 toks/s, output: 135.30 toks/s]
[2025-01-08 18:00:26,844][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  3.68it/s, est. speed input: 2096.00 toks/s, output: 150.10 toks/s]
[2025-01-08 18:00:27,682][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.90it/s, est. speed input: 1845.98 toks/s, output: 154.76 toks/s]
WARNING 01-08 18:00:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:27,908][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:29,087][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.18s/it, est. speed input: 683.64 toks/s, output: 24.60 toks/s]
[2025-01-08 18:00:30,182][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.93it/s, est. speed input: 1509.60 toks/s, output: 79.59 toks/s]
[2025-01-08 18:00:30,183][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.76it/s, est. speed input: 1509.60 toks/s, output: 79.59 toks/s]
WARNING 01-08 18:00:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:30,389][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:31,449][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.06s/it, est. speed input: 601.10 toks/s, output: 27.36 toks/s]
[2025-01-08 18:00:31,704][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.70it/s, est. speed input: 968.61 toks/s, output: 53.98 toks/s]
[2025-01-08 18:00:32,025][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.13it/s, est. speed input: 1558.37 toks/s, output: 107.56 toks/s]
[2025-01-08 18:00:32,025][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.44it/s, est. speed input: 1558.37 toks/s, output: 107.56 toks/s]
WARNING 01-08 18:00:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:32,248][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:36,124][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:03<00:42,  3.88s/it, est. speed input: 268.33 toks/s, output: 18.06 toks/s]
[2025-01-08 18:00:36,725][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:04<00:19,  1.95s/it, est. speed input: 464.30 toks/s, output: 35.51 toks/s]
[2025-01-08 18:00:36,986][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:06,  1.24it/s, est. speed input: 895.73 toks/s, output: 73.45 toks/s]
[2025-01-08 18:00:37,421][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:05<00:04,  1.44it/s, est. speed input: 1031.63 toks/s, output: 89.30 toks/s]
[2025-01-08 18:00:37,615][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:05<00:01,  2.99it/s, est. speed input: 1615.48 toks/s, output: 152.23 toks/s]
[2025-01-08 18:00:37,747][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:05<00:00,  3.43it/s, est. speed input: 1780.89 toks/s, output: 171.83 toks/s]
[2025-01-08 18:00:38,970][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  2.88it/s, est. speed input: 1943.82 toks/s, output: 209.00 toks/s]
[2025-01-08 18:00:38,970][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.79it/s, est. speed input: 1943.82 toks/s, output: 209.00 toks/s]
WARNING 01-08 18:00:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:39,189][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:41,161][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.97s/it, est. speed input: 369.69 toks/s, output: 14.71 toks/s]
[2025-01-08 18:00:41,839][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:02<00:01,  2.77it/s, est. speed input: 1662.94 toks/s, output: 76.22 toks/s]
[2025-01-08 18:00:42,225][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  2.73it/s, est. speed input: 1717.86 toks/s, output: 90.92 toks/s]
[2025-01-08 18:00:42,353][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  3.90it/s, est. speed input: 2121.78 toks/s, output: 137.15 toks/s]
[2025-01-08 18:00:42,665][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:03<00:00,  3.74it/s, est. speed input: 2169.80 toks/s, output: 152.77 toks/s]
[2025-01-08 18:00:43,729][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.23it/s, est. speed input: 1871.19 toks/s, output: 152.21 toks/s]
[2025-01-08 18:00:43,729][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.42it/s, est. speed input: 1871.19 toks/s, output: 152.21 toks/s]
WARNING 01-08 18:00:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:43,942][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:45,434][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.49s/it, est. speed input: 896.69 toks/s, output: 19.43 toks/s]
[2025-01-08 18:00:45,943][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:02,  1.09it/s, est. speed input: 1223.03 toks/s, output: 40.48 toks/s]
[2025-01-08 18:00:46,494][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.34it/s, est. speed input: 1398.70 toks/s, output: 62.70 toks/s]
[2025-01-08 18:00:46,623][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.99it/s, est. speed input: 1826.94 toks/s, output: 91.78 toks/s]
[2025-01-08 18:00:46,843][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.49it/s, est. speed input: 2091.07 toks/s, output: 118.93 toks/s]
[2025-01-08 18:00:46,843][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.72it/s, est. speed input: 2091.07 toks/s, output: 118.93 toks/s]
WARNING 01-08 18:00:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:47,078][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:48,313][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.23s/it, est. speed input: 609.06 toks/s, output: 23.49 toks/s]
[2025-01-08 18:00:48,636][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.43it/s, est. speed input: 976.29 toks/s, output: 46.86 toks/s]
[2025-01-08 18:00:48,953][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:01<00:01,  1.91it/s, est. speed input: 1231.48 toks/s, output: 70.93 toks/s]
[2025-01-08 18:00:49,778][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.56it/s, est. speed input: 1136.50 toks/s, output: 88.16 toks/s]
[2025-01-08 18:00:49,862][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.80it/s, est. speed input: 1374.66 toks/s, output: 125.00 toks/s]
WARNING 01-08 18:00:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:50,100][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:53,872][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:03<00:37,  3.77s/it, est. speed input: 366.90 toks/s, output: 15.64 toks/s]
[2025-01-08 18:00:54,086][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:03<00:15,  1.68s/it, est. speed input: 700.46 toks/s, output: 31.36 toks/s]
[2025-01-08 18:00:54,375][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:04<00:08,  1.04s/it, est. speed input: 999.64 toks/s, output: 47.02 toks/s]
[2025-01-08 18:00:54,596][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:04<00:05,  1.39it/s, est. speed input: 1283.15 toks/s, output: 63.39 toks/s]
[2025-01-08 18:00:54,704][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:02,  2.00it/s, est. speed input: 1559.83 toks/s, output: 81.02 toks/s]
[2025-01-08 18:00:55,405][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:05<00:02,  1.76it/s, est. speed input: 1634.89 toks/s, output: 92.18 toks/s]
[2025-01-08 18:00:55,711][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:05<00:01,  2.07it/s, est. speed input: 1812.75 toks/s, output: 110.14 toks/s]
[2025-01-08 18:00:55,854][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:05<00:00,  4.37it/s, est. speed input: 2560.07 toks/s, output: 177.09 toks/s]
[2025-01-08 18:00:55,922][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  1.89it/s, est. speed input: 2788.07 toks/s, output: 199.06 toks/s]
WARNING 01-08 18:00:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:00:56,206][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:00:57,944][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.74s/it, est. speed input: 944.72 toks/s, output: 16.69 toks/s]
[2025-01-08 18:00:58,632][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:02<00:03,  1.12s/it, est. speed input: 1372.37 toks/s, output: 36.69 toks/s]
[2025-01-08 18:00:58,988][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.89it/s, est. speed input: 2247.51 toks/s, output: 83.05 toks/s]
[2025-01-08 18:01:01,034][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:04<00:00,  1.00it/s, est. speed input: 1614.23 toks/s, output: 89.28 toks/s]
[2025-01-08 18:01:01,035][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:04<00:00,  1.04it/s, est. speed input: 1614.23 toks/s, output: 89.28 toks/s]
WARNING 01-08 18:01:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:01:01,267][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:01:02,835][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 1146.25 toks/s, output: 44.65 toks/s]
[2025-01-08 18:01:02,835][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 1146.25 toks/s, output: 44.65 toks/s]
[2025-01-08 18:01:09,555][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:01:09,608][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:01:11,361][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 18:01:13,042][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:01:14,705][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:01:15,229][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:01:15,230][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:01:25,543][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:01:26,026][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:01:26,078][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:01:27,943][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 18:01:29,546][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:01:31,077][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:01:31,573][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:01:31,573][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:01:46,746][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:01:47,086][root][INFO] - Loading VLLM model.
WARNING 01-08 18:01:47 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:01:47 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:01:47 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:01:47 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:01:48,016][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:01:49,341][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:01:49,737][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:01:51,044][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:01:52,391][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:01:52,392][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:01:52 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:02:06 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:02:07 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:02:07 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:02:28 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:02:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:28,845][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:31,449][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.60s/it, est. speed input: 193.99 toks/s, output: 9.99 toks/s]
[2025-01-08 18:02:31,557][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:15,  1.14s/it, est. speed input: 372.44 toks/s, output: 20.28 toks/s]
[2025-01-08 18:02:31,772][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:02<00:00,  6.50it/s, est. speed input: 1897.85 toks/s, output: 111.03 toks/s]
[2025-01-08 18:02:32,287][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:03<00:00,  6.29it/s, est. speed input: 2054.14 toks/s, output: 144.11 toks/s]
[2025-01-08 18:02:32,430][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.16it/s, est. speed input: 2254.10 toks/s, output: 176.59 toks/s]
[2025-01-08 18:02:32,430][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.46it/s, est. speed input: 2254.10 toks/s, output: 176.59 toks/s]
WARNING 01-08 18:02:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:32,632][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:33,395][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 747.60 toks/s, output: 38.04 toks/s]
[2025-01-08 18:02:33,395][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 747.60 toks/s, output: 38.04 toks/s]
WARNING 01-08 18:02:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:33,615][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:35,945][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 300.05 toks/s, output: 12.45 toks/s]
[2025-01-08 18:02:36,615][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:17,  1.35s/it, est. speed input: 466.07 toks/s, output: 25.67 toks/s]
[2025-01-08 18:02:36,750][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:09,  1.25it/s, est. speed input: 669.00 toks/s, output: 41.15 toks/s]
[2025-01-08 18:02:36,913][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:06,  1.83it/s, est. speed input: 847.82 toks/s, output: 56.40 toks/s]
[2025-01-08 18:02:37,100][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:04,  2.40it/s, est. speed input: 1002.94 toks/s, output: 71.45 toks/s]
[2025-01-08 18:02:37,372][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:03<00:01,  4.57it/s, est. speed input: 1488.66 toks/s, output: 120.06 toks/s]
[2025-01-08 18:02:37,528][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:03<00:01,  4.88it/s, est. speed input: 1607.97 toks/s, output: 135.47 toks/s]
[2025-01-08 18:02:37,685][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:04<00:00,  7.69it/s, est. speed input: 2060.97 toks/s, output: 191.40 toks/s]
[2025-01-08 18:02:38,038][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:04<00:00,  6.90it/s, est. speed input: 2212.70 toks/s, output: 222.49 toks/s]
[2025-01-08 18:02:38,038][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.39it/s, est. speed input: 2370.63 toks/s, output: 245.99 toks/s]
WARNING 01-08 18:02:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:38,257][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:40,379][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.12s/it, est. speed input: 289.40 toks/s, output: 13.67 toks/s]
[2025-01-08 18:02:40,851][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:02<00:00,  4.96it/s, est. speed input: 2391.96 toks/s, output: 119.94 toks/s]
[2025-01-08 18:02:41,005][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:02<00:00,  6.42it/s, est. speed input: 2965.44 toks/s, output: 172.51 toks/s]
[2025-01-08 18:02:41,023][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.06it/s, est. speed input: 3183.15 toks/s, output: 192.77 toks/s]
WARNING 01-08 18:02:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:41,227][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:42,119][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 897.93 toks/s, output: 32.51 toks/s]
[2025-01-08 18:02:43,338][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.08s/it, est. speed input: 710.48 toks/s, output: 62.05 toks/s]
[2025-01-08 18:02:43,338][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.06s/it, est. speed input: 710.48 toks/s, output: 62.05 toks/s]
WARNING 01-08 18:02:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:43,540][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:44,393][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 803.39 toks/s, output: 34.01 toks/s]
[2025-01-08 18:02:44,893][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.55it/s, est. speed input: 971.31 toks/s, output: 65.05 toks/s]
[2025-01-08 18:02:44,893][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.48it/s, est. speed input: 971.31 toks/s, output: 65.05 toks/s]
WARNING 01-08 18:02:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:45,119][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:48,815][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:48,  3.70s/it, est. speed input: 280.35 toks/s, output: 14.88 toks/s]
[2025-01-08 18:02:49,137][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:04<00:07,  1.27it/s, est. speed input: 1041.53 toks/s, output: 58.25 toks/s]
[2025-01-08 18:02:49,252][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.60it/s, est. speed input: 1774.44 toks/s, output: 105.76 toks/s]
[2025-01-08 18:02:49,599][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.19it/s, est. speed input: 2102.60 toks/s, output: 131.93 toks/s]
[2025-01-08 18:02:50,045][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  3.52it/s, est. speed input: 2348.30 toks/s, output: 158.76 toks/s]
[2025-01-08 18:02:50,430][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.30it/s, est. speed input: 2382.15 toks/s, output: 170.23 toks/s]
[2025-01-08 18:02:50,614][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  3.60it/s, est. speed input: 2493.81 toks/s, output: 188.55 toks/s]
[2025-01-08 18:02:51,761][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.08it/s, est. speed input: 2213.92 toks/s, output: 186.10 toks/s]
[2025-01-08 18:02:51,762][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.11it/s, est. speed input: 2213.92 toks/s, output: 186.10 toks/s]
WARNING 01-08 18:02:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:52,018][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:54,185][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.17s/it, est. speed input: 336.39 toks/s, output: 13.38 toks/s]
[2025-01-08 18:02:54,401][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:02<00:00,  5.60it/s, est. speed input: 3086.50 toks/s, output: 125.88 toks/s]
[2025-01-08 18:02:54,739][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.31it/s, est. speed input: 3568.14 toks/s, output: 168.30 toks/s]
[2025-01-08 18:02:54,740][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  4.78it/s, est. speed input: 3568.14 toks/s, output: 168.30 toks/s]
WARNING 01-08 18:02:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:54,945][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:56,071][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.13s/it, est. speed input: 1116.56 toks/s, output: 25.76 toks/s]
[2025-01-08 18:02:56,494][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.40it/s, est. speed input: 1529.22 toks/s, output: 52.33 toks/s]
[2025-01-08 18:02:57,338][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.29it/s, est. speed input: 1441.50 toks/s, output: 76.51 toks/s]
[2025-01-08 18:02:57,338][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.25it/s, est. speed input: 1441.50 toks/s, output: 76.51 toks/s]
WARNING 01-08 18:02:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:57,545][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:02:58,547][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.00s/it, est. speed input: 798.72 toks/s, output: 28.95 toks/s]
[2025-01-08 18:02:58,878][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.65it/s, est. speed input: 1190.76 toks/s, output: 57.06 toks/s]
[2025-01-08 18:02:59,045][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 1569.46 toks/s, output: 88.67 toks/s]
[2025-01-08 18:02:59,046][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.00it/s, est. speed input: 1569.46 toks/s, output: 88.67 toks/s]
WARNING 01-08 18:02:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:02:59,274][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:03:03,295][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:04<00:48,  4.02s/it, est. speed input: 341.04 toks/s, output: 13.68 toks/s]
[2025-01-08 18:03:03,497][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:19,  1.77s/it, est. speed input: 658.84 toks/s, output: 27.47 toks/s]
[2025-01-08 18:03:03,623][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.43it/s, est. speed input: 1273.84 toks/s, output: 56.11 toks/s]
[2025-01-08 18:03:03,854][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.80it/s, est. speed input: 1527.98 toks/s, output: 69.22 toks/s]
[2025-01-08 18:03:03,965][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:02,  2.38it/s, est. speed input: 1807.20 toks/s, output: 84.01 toks/s]
[2025-01-08 18:03:04,099][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:01,  3.01it/s, est. speed input: 2045.46 toks/s, output: 98.67 toks/s]
[2025-01-08 18:03:04,241][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  5.84it/s, est. speed input: 2828.89 toks/s, output: 147.79 toks/s]
[2025-01-08 18:03:04,596][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  5.77it/s, est. speed input: 3179.11 toks/s, output: 176.46 toks/s]
[2025-01-08 18:03:04,917][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.30it/s, est. speed input: 3250.54 toks/s, output: 188.56 toks/s]
WARNING 01-08 18:03:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:03:05,203][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:03:06,696][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.49s/it, est. speed input: 1061.76 toks/s, output: 19.43 toks/s]
[2025-01-08 18:03:07,332][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:01,  1.01it/s, est. speed input: 1419.63 toks/s, output: 41.82 toks/s]
[2025-01-08 18:03:07,644][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:02<00:00,  1.47it/s, est. speed input: 1877.05 toks/s, output: 68.02 toks/s]
[2025-01-08 18:03:07,898][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.95it/s, est. speed input: 2243.05 toks/s, output: 95.75 toks/s]
[2025-01-08 18:03:07,898][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.48it/s, est. speed input: 2243.05 toks/s, output: 95.75 toks/s]
[2025-01-08 18:03:13,801][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:03:13,855][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:03:15,543][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:03:17,150][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:03:18,742][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:03:19,259][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:03:19,259][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:03:29,468][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:03:30,033][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:03:30,085][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:03:31,877][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 18:03:33,462][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 18:03:35,026][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:03:35,519][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:03:35,519][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:03:50,060][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:03:50,378][root][INFO] - Loading VLLM model.
WARNING 01-08 18:03:50 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:03:50 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:03:51 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:03:51 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:03:51,530][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:03:52,854][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:03:53,242][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:03:54,550][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:03:55,898][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:03:55,898][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:03:56 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:04:09 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:04:10 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:04:10 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:04:31 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:04:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:32,267][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:34,773][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.51s/it, est. speed input: 201.54 toks/s, output: 11.57 toks/s]
[2025-01-08 18:04:34,791][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.34it/s, est. speed input: 3201.94 toks/s, output: 184.27 toks/s]
WARNING 01-08 18:04:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:35,019][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:38,698][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:55,  3.68s/it, est. speed input: 190.04 toks/s, output: 16.58 toks/s]
[2025-01-08 18:04:39,170][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:25,  1.79s/it, est. speed input: 336.81 toks/s, output: 32.52 toks/s]
[2025-01-08 18:04:39,410][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:08,  1.34it/s, est. speed input: 636.75 toks/s, output: 66.50 toks/s]
[2025-01-08 18:04:39,541][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:04,  2.36it/s, est. speed input: 927.62 toks/s, output: 101.96 toks/s]
[2025-01-08 18:04:39,747][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:04<00:03,  2.71it/s, est. speed input: 1034.88 toks/s, output: 116.96 toks/s]
[2025-01-08 18:04:39,859][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:04<00:01,  4.21it/s, est. speed input: 1299.84 toks/s, output: 153.52 toks/s]
[2025-01-08 18:04:40,303][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:01,  4.32it/s, est. speed input: 1455.35 toks/s, output: 181.33 toks/s]
[2025-01-08 18:04:40,461][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:05<00:00,  4.63it/s, est. speed input: 1541.48 toks/s, output: 198.29 toks/s]
[2025-01-08 18:04:40,634][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:05<00:00,  4.85it/s, est. speed input: 1618.44 toks/s, output: 215.15 toks/s]
[2025-01-08 18:04:41,228][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:06<00:00,  3.30it/s, est. speed input: 1576.14 toks/s, output: 220.17 toks/s]
[2025-01-08 18:04:41,614][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  3.08it/s, est. speed input: 1589.93 toks/s, output: 234.58 toks/s]
[2025-01-08 18:04:41,949][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  3.05it/s, est. speed input: 1613.83 toks/s, output: 252.09 toks/s]
[2025-01-08 18:04:41,950][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:06<00:00,  2.31it/s, est. speed input: 1613.83 toks/s, output: 252.09 toks/s]
WARNING 01-08 18:04:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:42,169][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:44,369][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.20s/it, est. speed input: 281.79 toks/s, output: 13.18 toks/s]
[2025-01-08 18:04:44,370][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.82it/s, est. speed input: 4206.98 toks/s, output: 197.65 toks/s]
WARNING 01-08 18:04:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:44,575][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:45,367][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1204.56 toks/s, output: 36.62 toks/s]
[2025-01-08 18:04:45,368][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1204.56 toks/s, output: 36.62 toks/s]
WARNING 01-08 18:04:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:45,569][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:46,307][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 833.25 toks/s, output: 39.35 toks/s]
[2025-01-08 18:04:46,307][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 833.25 toks/s, output: 39.35 toks/s]
WARNING 01-08 18:04:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:46,555][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:49,899][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:46,  3.34s/it, est. speed input: 313.73 toks/s, output: 11.96 toks/s]
[2025-01-08 18:04:50,653][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:04<00:23,  1.82s/it, est. speed input: 508.33 toks/s, output: 24.65 toks/s]
[2025-01-08 18:04:50,757][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:04<00:12,  1.04s/it, est. speed input: 747.41 toks/s, output: 39.27 toks/s]
[2025-01-08 18:04:51,090][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:04<00:08,  1.32it/s, est. speed input: 924.71 toks/s, output: 52.71 toks/s]
[2025-01-08 18:04:51,249][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:05,  1.84it/s, est. speed input: 1117.95 toks/s, output: 67.75 toks/s]
[2025-01-08 18:04:51,669][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:05<00:04,  2.00it/s, est. speed input: 1236.04 toks/s, output: 80.38 toks/s]
[2025-01-08 18:04:51,886][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:05<00:01,  4.05it/s, est. speed input: 1787.27 toks/s, output: 131.88 toks/s]
[2025-01-08 18:04:52,157][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:05<00:01,  3.97it/s, est. speed input: 1903.97 toks/s, output: 145.50 toks/s]
[2025-01-08 18:04:52,358][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:05<00:00,  5.17it/s, est. speed input: 2215.99 toks/s, output: 180.96 toks/s]
[2025-01-08 18:04:52,644][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:06<00:00,  4.68it/s, est. speed input: 2286.88 toks/s, output: 194.64 toks/s]
[2025-01-08 18:04:52,809][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:06<00:00,  4.95it/s, est. speed input: 2403.55 toks/s, output: 212.52 toks/s]
[2025-01-08 18:04:53,434][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  3.24it/s, est. speed input: 2353.77 toks/s, output: 219.53 toks/s]
[2025-01-08 18:04:53,434][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.18it/s, est. speed input: 2353.77 toks/s, output: 219.53 toks/s]
WARNING 01-08 18:04:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:53,678][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:55,896][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.22s/it, est. speed input: 331.43 toks/s, output: 11.27 toks/s]
[2025-01-08 18:04:56,038][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:12,  1.00it/s, est. speed input: 620.50 toks/s, output: 22.89 toks/s]
[2025-01-08 18:04:56,038][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.36it/s, est. speed input: 4639.20 toks/s, output: 182.64 toks/s]
WARNING 01-08 18:04:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:56,242][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:04:59,615][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.37s/it, est. speed input: 372.64 toks/s, output: 53.06 toks/s]
[2025-01-08 18:04:59,616][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.37s/it, est. speed input: 372.64 toks/s, output: 53.06 toks/s]
WARNING 01-08 18:04:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:04:59,826][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:05:00,697][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 837.09 toks/s, output: 33.30 toks/s]
[2025-01-08 18:05:00,697][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1753.73 toks/s, output: 66.57 toks/s]
WARNING 01-08 18:05:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:05:00,930][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:05:04,706][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:49,  3.78s/it, est. speed input: 361.00 toks/s, output: 10.59 toks/s]
[2025-01-08 18:05:05,299][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:04<00:22,  1.90s/it, est. speed input: 634.04 toks/s, output: 22.20 toks/s]
[2025-01-08 18:05:05,435][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:04<00:12,  1.10s/it, est. speed input: 918.80 toks/s, output: 35.07 toks/s]
[2025-01-08 18:05:05,758][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:04<00:07,  1.26it/s, est. speed input: 1162.67 toks/s, output: 47.43 toks/s]
[2025-01-08 18:05:06,277][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:05<00:06,  1.44it/s, est. speed input: 1318.99 toks/s, output: 59.28 toks/s]
[2025-01-08 18:05:06,390][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:05<00:02,  2.70it/s, est. speed input: 1828.51 toks/s, output: 91.21 toks/s]
[2025-01-08 18:05:06,687][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:05<00:02,  2.85it/s, est. speed input: 1987.09 toks/s, output: 104.40 toks/s]
[2025-01-08 18:05:07,014][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:06<00:01,  2.91it/s, est. speed input: 2116.75 toks/s, output: 117.85 toks/s]
[2025-01-08 18:05:07,297][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:06<00:01,  3.06it/s, est. speed input: 2248.55 toks/s, output: 132.71 toks/s]
[2025-01-08 18:05:07,631][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:06<00:00,  3.04it/s, est. speed input: 2365.33 toks/s, output: 147.45 toks/s]
[2025-01-08 18:05:07,805][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  4.55it/s, est. speed input: 2757.21 toks/s, output: 187.20 toks/s]
[2025-01-08 18:05:07,958][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  4.91it/s, est. speed input: 2910.83 toks/s, output: 206.04 toks/s]
[2025-01-08 18:05:07,958][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.99it/s, est. speed input: 2910.83 toks/s, output: 206.04 toks/s]
WARNING 01-08 18:05:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:05:08,257][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:05:10,133][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.88s/it, est. speed input: 750.41 toks/s, output: 39.47 toks/s]
[2025-01-08 18:05:12,043][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.90s/it, est. speed input: 825.02 toks/s, output: 68.95 toks/s]
[2025-01-08 18:05:12,044][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.89s/it, est. speed input: 825.02 toks/s, output: 68.95 toks/s]
[2025-01-08 18:05:17,889][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:05:17,943][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:05:19,645][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 18:05:21,278][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 18:05:22,862][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:05:23,397][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 18:05:23,397][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:05:33,113][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:05:33,595][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:05:33,648][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:05:35,571][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 18:05:37,234][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 18:05:38,859][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 18:05:39,373][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:05:39,373][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 18:05:54,435][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:05:54,744][root][INFO] - Loading VLLM model.
WARNING 01-08 18:05:54 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:05:54 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:05:55 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:05:55 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:05:55,758][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:05:57,135][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 18:05:57,535][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 18:05:58,895][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 18:06:00,300][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:06:00,300][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 18:06:00 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:06:14 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:06:14 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:06:14 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:06:35 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:06:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:36,260][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:39,207][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.95s/it, est. speed input: 171.40 toks/s, output: 9.84 toks/s]
[2025-01-08 18:06:39,207][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.43it/s, est. speed input: 2741.87 toks/s, output: 157.45 toks/s]
WARNING 01-08 18:06:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:39,410][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:40,202][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 715.21 toks/s, output: 39.17 toks/s]
[2025-01-08 18:06:40,202][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 715.21 toks/s, output: 39.17 toks/s]
WARNING 01-08 18:06:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:40,425][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:42,758][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 299.74 toks/s, output: 12.44 toks/s]
[2025-01-08 18:06:43,110][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:15,  1.17s/it, est. speed input: 520.73 toks/s, output: 25.33 toks/s]
[2025-01-08 18:06:43,279][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.41it/s, est. speed input: 734.98 toks/s, output: 39.25 toks/s]
[2025-01-08 18:06:43,540][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:05,  1.87it/s, est. speed input: 897.87 toks/s, output: 52.66 toks/s]
[2025-01-08 18:06:43,912][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:04,  2.10it/s, est. speed input: 1002.51 toks/s, output: 65.40 toks/s]
[2025-01-08 18:06:44,054][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:02,  3.70it/s, est. speed input: 1348.39 toks/s, output: 99.76 toks/s]
[2025-01-08 18:06:44,326][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:03<00:00,  5.66it/s, est. speed input: 1792.17 toks/s, output: 149.47 toks/s]
[2025-01-08 18:06:45,267][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  4.25it/s, est. speed input: 1876.92 toks/s, output: 181.35 toks/s]
[2025-01-08 18:06:45,433][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:05<00:00,  4.47it/s, est. speed input: 1954.18 toks/s, output: 202.49 toks/s]
[2025-01-08 18:06:45,736][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  4.19it/s, est. speed input: 1974.43 toks/s, output: 219.94 toks/s]
[2025-01-08 18:06:45,736][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.82it/s, est. speed input: 1974.43 toks/s, output: 219.94 toks/s]
WARNING 01-08 18:06:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:45,969][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:48,156][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.19s/it, est. speed input: 280.78 toks/s, output: 13.26 toks/s]
[2025-01-08 18:06:48,156][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.86it/s, est. speed input: 4221.29 toks/s, output: 198.86 toks/s]
WARNING 01-08 18:06:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:48,374][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:50,024][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 423.78 toks/s, output: 49.71 toks/s]
[2025-01-08 18:06:50,024][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.65s/it, est. speed input: 423.78 toks/s, output: 49.71 toks/s]
WARNING 01-08 18:06:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:50,234][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:51,020][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 861.20 toks/s, output: 39.43 toks/s]
[2025-01-08 18:06:51,020][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 861.20 toks/s, output: 39.43 toks/s]
WARNING 01-08 18:06:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:51,244][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:06:55,103][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:54,  3.86s/it, est. speed input: 265.63 toks/s, output: 14.25 toks/s]
[2025-01-08 18:06:55,355][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:04<00:22,  1.74s/it, est. speed input: 503.38 toks/s, output: 28.47 toks/s]
[2025-01-08 18:06:55,707][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:05,  1.73it/s, est. speed input: 1149.70 toks/s, output: 71.25 toks/s]
[2025-01-08 18:06:55,909][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:04<00:03,  2.60it/s, est. speed input: 1552.37 toks/s, output: 101.19 toks/s]
[2025-01-08 18:06:56,016][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:04<00:01,  3.80it/s, est. speed input: 1952.42 toks/s, output: 133.50 toks/s]
[2025-01-08 18:06:57,050][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:05<00:01,  2.86it/s, est. speed input: 1975.47 toks/s, output: 148.31 toks/s]
[2025-01-08 18:06:57,582][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:06<00:00,  3.10it/s, est. speed input: 2152.81 toks/s, output: 180.68 toks/s]
[2025-01-08 18:06:58,427][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:07<00:00,  2.37it/s, est. speed input: 2044.91 toks/s, output: 187.27 toks/s]
[2025-01-08 18:06:58,427][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  2.09it/s, est. speed input: 2197.98 toks/s, output: 215.11 toks/s]
WARNING 01-08 18:06:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:06:58,645][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:07:00,774][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.13s/it, est. speed input: 342.49 toks/s, output: 13.62 toks/s]
[2025-01-08 18:07:00,774][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.11it/s, est. speed input: 4439.80 toks/s, output: 177.07 toks/s]
WARNING 01-08 18:07:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:07:00,981][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:07:02,150][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.17s/it, est. speed input: 1111.46 toks/s, output: 24.81 toks/s]
[2025-01-08 18:07:03,051][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.57it/s, est. speed input: 1792.25 toks/s, output: 69.10 toks/s]
[2025-01-08 18:07:03,051][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.45it/s, est. speed input: 1792.25 toks/s, output: 69.10 toks/s]
WARNING 01-08 18:07:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:07:03,257][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:07:04,239][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 736.43 toks/s, output: 29.54 toks/s]
[2025-01-08 18:07:04,273][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.95it/s, est. speed input: 2204.72 toks/s, output: 87.60 toks/s]
WARNING 01-08 18:07:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:07:04,502][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:07:08,724][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:04<00:50,  4.22s/it, est. speed input: 320.80 toks/s, output: 14.45 toks/s]
[2025-01-08 18:07:08,960][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:20,  1.88s/it, est. speed input: 619.05 toks/s, output: 28.94 toks/s]
[2025-01-08 18:07:09,205][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.29it/s, est. speed input: 1166.58 toks/s, output: 58.28 toks/s]
[2025-01-08 18:07:09,320][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.75it/s, est. speed input: 1430.58 toks/s, output: 73.48 toks/s]
[2025-01-08 18:07:09,431][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:04<00:03,  2.32it/s, est. speed input: 1685.50 toks/s, output: 88.87 toks/s]
[2025-01-08 18:07:09,886][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:05<00:02,  2.28it/s, est. speed input: 1799.19 toks/s, output: 100.12 toks/s]
[2025-01-08 18:07:10,112][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:05<00:01,  2.67it/s, est. speed input: 1973.03 toks/s, output: 115.70 toks/s]
[2025-01-08 18:07:10,690][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:06<00:01,  2.99it/s, est. speed input: 2254.31 toks/s, output: 144.81 toks/s]
[2025-01-08 18:07:10,883][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  4.17it/s, est. speed input: 2659.40 toks/s, output: 185.27 toks/s]
[2025-01-08 18:07:11,475][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  3.15it/s, est. speed input: 2636.21 toks/s, output: 195.49 toks/s]
[2025-01-08 18:07:11,475][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.86it/s, est. speed input: 2636.21 toks/s, output: 195.49 toks/s]
WARNING 01-08 18:07:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:07:11,799][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:07:13,489][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:03,  1.69s/it, est. speed input: 947.83 toks/s, output: 28.99 toks/s]
[2025-01-08 18:07:14,317][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:02<00:01,  1.18s/it, est. speed input: 1196.84 toks/s, output: 56.80 toks/s]
[2025-01-08 18:07:15,230][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.06s/it, est. speed input: 1363.90 toks/s, output: 84.81 toks/s]
[2025-01-08 18:07:15,231][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.14s/it, est. speed input: 1363.90 toks/s, output: 84.81 toks/s]
[2025-01-08 18:07:21,218][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:07:21,271][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:07:22,979][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.71s/it]
[2025-01-08 18:07:24,638][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 18:07:26,216][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:07:26,741][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 18:07:26,741][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:07:36,261][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:07:36,756][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:07:36,809][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:07:38,642][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 18:07:40,232][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 18:07:41,802][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 18:07:42,304][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:07:42,304][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:07:57,066][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:07:57,383][root][INFO] - Loading VLLM model.
WARNING 01-08 18:07:57 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:07:57 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:07:58 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:07:58 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:07:58,544][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:07:59,872][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
[2025-01-08 18:08:00,265][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:08:01,562][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:08:02,898][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:08:02,898][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:08:03 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:08:16 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:08:17 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:08:17 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:08:38 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:08:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:38,928][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:41,347][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 208.78 toks/s, output: 11.99 toks/s]
[2025-01-08 18:08:41,348][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.61it/s, est. speed input: 3339.58 toks/s, output: 191.78 toks/s]
WARNING 01-08 18:08:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:41,548][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:42,447][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 629.46 toks/s, output: 34.48 toks/s]
[2025-01-08 18:08:42,447][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 629.46 toks/s, output: 34.48 toks/s]
WARNING 01-08 18:08:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:42,664][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:45,015][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.35s/it, est. speed input: 297.38 toks/s, output: 12.34 toks/s]
[2025-01-08 18:08:45,368][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:15,  1.18s/it, est. speed input: 517.11 toks/s, output: 25.15 toks/s]
[2025-01-08 18:08:45,537][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.40it/s, est. speed input: 730.15 toks/s, output: 39.00 toks/s]
[2025-01-08 18:08:45,798][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:05,  1.86it/s, est. speed input: 892.38 toks/s, output: 52.34 toks/s]
[2025-01-08 18:08:46,170][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:04,  2.10it/s, est. speed input: 997.00 toks/s, output: 65.04 toks/s]
[2025-01-08 18:08:46,313][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:02,  3.69it/s, est. speed input: 1341.26 toks/s, output: 99.23 toks/s]
[2025-01-08 18:08:46,585][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:03<00:00,  5.65it/s, est. speed input: 1783.16 toks/s, output: 148.72 toks/s]
[2025-01-08 18:08:46,913][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  6.74it/s, est. speed input: 2138.76 toks/s, output: 199.35 toks/s]
[2025-01-08 18:08:47,226][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:04<00:00,  5.68it/s, est. speed input: 2145.51 toks/s, output: 210.47 toks/s]
[2025-01-08 18:08:47,611][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  4.61it/s, est. speed input: 2119.65 toks/s, output: 221.57 toks/s]
[2025-01-08 18:08:47,611][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.03it/s, est. speed input: 2119.65 toks/s, output: 221.57 toks/s]
WARNING 01-08 18:08:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:47,831][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:50,020][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.19s/it, est. speed input: 280.50 toks/s, output: 13.25 toks/s]
[2025-01-08 18:08:50,021][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.85it/s, est. speed input: 4214.21 toks/s, output: 198.65 toks/s]
WARNING 01-08 18:08:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:50,235][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:51,806][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 445.08 toks/s, output: 49.03 toks/s]
[2025-01-08 18:08:51,807][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.57s/it, est. speed input: 445.08 toks/s, output: 49.03 toks/s]
WARNING 01-08 18:08:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:52,025][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:52,803][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 877.66 toks/s, output: 39.83 toks/s]
[2025-01-08 18:08:52,804][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 877.66 toks/s, output: 39.83 toks/s]
WARNING 01-08 18:08:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:08:53,043][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:08:56,308][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:45,  3.26s/it, est. speed input: 311.82 toks/s, output: 11.95 toks/s]
[2025-01-08 18:08:56,631][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:19,  1.53s/it, est. speed input: 563.11 toks/s, output: 24.25 toks/s]
[2025-01-08 18:08:56,768][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:10,  1.12it/s, est. speed input: 817.60 toks/s, output: 37.32 toks/s]
[2025-01-08 18:08:57,166][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:04<00:07,  1.43it/s, est. speed input: 991.65 toks/s, output: 49.24 toks/s]
[2025-01-08 18:08:57,324][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:05,  1.98it/s, est. speed input: 1201.00 toks/s, output: 63.54 toks/s]
[2025-01-08 18:08:57,653][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:04<00:04,  2.25it/s, est. speed input: 1341.96 toks/s, output: 76.37 toks/s]
[2025-01-08 18:08:57,767][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:04<00:02,  2.97it/s, est. speed input: 1533.22 toks/s, output: 92.31 toks/s]
[2025-01-08 18:08:58,322][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:05<00:01,  3.25it/s, est. speed input: 1767.09 toks/s, output: 118.79 toks/s]
[2025-01-08 18:08:58,519][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:05<00:01,  3.58it/s, est. speed input: 1894.14 toks/s, output: 135.15 toks/s]
[2025-01-08 18:08:58,657][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:05<00:00,  4.14it/s, est. speed input: 2035.76 toks/s, output: 153.02 toks/s]
[2025-01-08 18:08:59,164][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:06<00:00,  4.05it/s, est. speed input: 2207.96 toks/s, output: 183.32 toks/s]
[2025-01-08 18:08:59,440][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:06<00:00,  3.94it/s, est. speed input: 2282.57 toks/s, output: 200.27 toks/s]
[2025-01-08 18:09:00,116][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  2.78it/s, est. speed input: 2221.25 toks/s, output: 209.27 toks/s]
[2025-01-08 18:09:00,116][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  2.12it/s, est. speed input: 2221.25 toks/s, output: 209.27 toks/s]
WARNING 01-08 18:09:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:00,338][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:02,591][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.25s/it, est. speed input: 323.64 toks/s, output: 12.87 toks/s]
[2025-01-08 18:09:02,675][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.99it/s, est. speed input: 4344.22 toks/s, output: 175.87 toks/s]
WARNING 01-08 18:09:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:02,880][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:04,744][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.86s/it, est. speed input: 566.72 toks/s, output: 41.32 toks/s]
[2025-01-08 18:09:04,879][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.18it/s, est. speed input: 1178.07 toks/s, output: 81.04 toks/s]
[2025-01-08 18:09:04,880][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.00it/s, est. speed input: 1178.07 toks/s, output: 81.04 toks/s]
WARNING 01-08 18:09:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:05,084][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:05,954][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 838.60 toks/s, output: 33.36 toks/s]
[2025-01-08 18:09:05,988][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1692.40 toks/s, output: 66.41 toks/s]
WARNING 01-08 18:09:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:06,220][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:10,623][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:04<00:57,  4.40s/it, est. speed input: 300.77 toks/s, output: 13.40 toks/s]
[2025-01-08 18:09:10,867][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:04<00:23,  1.96s/it, est. speed input: 585.46 toks/s, output: 26.91 toks/s]
[2025-01-08 18:09:10,968][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:04<00:12,  1.11s/it, est. speed input: 857.50 toks/s, output: 40.86 toks/s]
[2025-01-08 18:09:11,225][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:05<00:07,  1.29it/s, est. speed input: 1092.86 toks/s, output: 54.15 toks/s]
[2025-01-08 18:09:11,377][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:05<00:04,  1.82it/s, est. speed input: 1350.12 toks/s, output: 68.46 toks/s]
[2025-01-08 18:09:11,542][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:05<00:01,  4.02it/s, est. speed input: 2089.32 toks/s, output: 114.26 toks/s]
[2025-01-08 18:09:11,872][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:00,  4.58it/s, est. speed input: 2469.42 toks/s, output: 141.39 toks/s]
[2025-01-08 18:09:11,983][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  5.10it/s, est. speed input: 2668.28 toks/s, output: 157.22 toks/s]
[2025-01-08 18:09:12,352][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:06<00:00,  4.25it/s, est. speed input: 2736.73 toks/s, output: 168.16 toks/s]
[2025-01-08 18:09:13,730][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:07<00:00,  1.93it/s, est. speed input: 2445.05 toks/s, output: 163.93 toks/s]
[2025-01-08 18:09:13,730][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.86it/s, est. speed input: 2635.46 toks/s, output: 190.55 toks/s]
WARNING 01-08 18:09:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:14,051][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:16,548][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:02<00:07,  2.50s/it, est. speed input: 666.66 toks/s, output: 29.25 toks/s]
[2025-01-08 18:09:16,794][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:02<00:02,  1.17s/it, est. speed input: 1221.60 toks/s, output: 57.62 toks/s]
[2025-01-08 18:09:17,585][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:03<00:00,  1.00it/s, est. speed input: 1468.21 toks/s, output: 80.95 toks/s]
[2025-01-08 18:09:18,802][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.08s/it, est. speed input: 1389.37 toks/s, output: 102.31 toks/s]
[2025-01-08 18:09:18,802][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.19s/it, est. speed input: 1389.37 toks/s, output: 102.31 toks/s]
WARNING 01-08 18:09:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:09:19,035][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:09:19,902][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1926.15 toks/s, output: 33.49 toks/s]
[2025-01-08 18:09:19,902][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1926.15 toks/s, output: 33.49 toks/s]
[2025-01-08 18:09:26,080][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:09:26,134][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:09:27,784][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.65s/it]
[2025-01-08 18:09:29,401][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 18:09:30,978][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:09:31,497][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:09:31,498][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 18:09:41,179][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:09:41,777][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:09:41,830][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:09:43,694][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 18:09:45,359][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 18:09:46,998][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 18:09:47,504][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:09:47,505][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 18:10:02,563][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:10:02,854][root][INFO] - Loading VLLM model.
WARNING 01-08 18:10:03 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:10:03 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:10:03 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:10:03 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:10:03,990][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:10:05,359][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 18:10:05,765][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 18:10:07,127][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 18:10:08,532][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:10:08,533][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 18:10:08 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:10:22 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:10:23 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:10:23 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:10:44 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:10:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:10:45,129][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:10:48,023][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.89s/it, est. speed input: 174.55 toks/s, output: 10.02 toks/s]
[2025-01-08 18:10:48,024][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.53it/s, est. speed input: 2791.89 toks/s, output: 160.33 toks/s]
WARNING 01-08 18:10:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:10:48,257][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:10:49,047][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 717.19 toks/s, output: 39.28 toks/s]
[2025-01-08 18:10:49,047][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 717.19 toks/s, output: 39.28 toks/s]
WARNING 01-08 18:10:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:10:49,263][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:10:51,596][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 299.70 toks/s, output: 12.43 toks/s]
[2025-01-08 18:10:51,949][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:15,  1.17s/it, est. speed input: 520.62 toks/s, output: 25.32 toks/s]
[2025-01-08 18:10:52,118][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.41it/s, est. speed input: 734.80 toks/s, output: 39.25 toks/s]
[2025-01-08 18:10:52,368][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:03,  2.63it/s, est. speed input: 1125.88 toks/s, output: 67.33 toks/s]
[2025-01-08 18:10:52,662][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:03<00:03,  2.82it/s, est. speed input: 1234.20 toks/s, output: 79.75 toks/s]
[2025-01-08 18:10:52,849][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:03<00:01,  5.17it/s, est. speed input: 1754.47 toks/s, output: 130.80 toks/s]
[2025-01-08 18:10:53,739][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:04<00:00,  4.19it/s, est. speed input: 1874.37 toks/s, output: 161.56 toks/s]
[2025-01-08 18:10:53,898][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  4.44it/s, est. speed input: 1960.99 toks/s, output: 181.49 toks/s]
[2025-01-08 18:10:54,245][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:04<00:00,  4.01it/s, est. speed input: 1964.42 toks/s, output: 196.32 toks/s]
[2025-01-08 18:10:54,948][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.86it/s, est. speed input: 1844.44 toks/s, output: 203.53 toks/s]
[2025-01-08 18:10:54,949][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.64it/s, est. speed input: 1844.44 toks/s, output: 203.53 toks/s]
WARNING 01-08 18:10:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:10:55,176][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:10:57,277][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.10s/it, est. speed input: 292.36 toks/s, output: 13.81 toks/s]
[2025-01-08 18:10:57,544][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  7.88it/s, est. speed input: 3640.83 toks/s, output: 178.24 toks/s]
[2025-01-08 18:10:57,544][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.91it/s, est. speed input: 3640.83 toks/s, output: 178.24 toks/s]
WARNING 01-08 18:10:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:10:57,747][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:10:58,646][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 990.23 toks/s, output: 32.27 toks/s]
[2025-01-08 18:10:59,948][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.14s/it, est. speed input: 721.79 toks/s, output: 61.78 toks/s]
[2025-01-08 18:10:59,949][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.10s/it, est. speed input: 721.79 toks/s, output: 61.78 toks/s]
WARNING 01-08 18:11:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:00,151][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:01,001][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.18it/s, est. speed input: 722.33 toks/s, output: 34.12 toks/s]
[2025-01-08 18:11:01,035][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.26it/s, est. speed input: 1460.31 toks/s, output: 67.87 toks/s]
WARNING 01-08 18:11:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:01,262][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:04,384][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:40,  3.12s/it, est. speed input: 326.11 toks/s, output: 12.49 toks/s]
[2025-01-08 18:11:04,590][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:16,  1.41s/it, est. speed input: 613.66 toks/s, output: 25.24 toks/s]
[2025-01-08 18:11:04,822][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:09,  1.15it/s, est. speed input: 861.56 toks/s, output: 38.20 toks/s]
[2025-01-08 18:11:05,107][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.57it/s, est. speed input: 1067.63 toks/s, output: 51.25 toks/s]
[2025-01-08 18:11:05,337][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:02,  2.77it/s, est. speed input: 1518.54 toks/s, output: 80.50 toks/s]
[2025-01-08 18:11:05,881][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.43it/s, est. speed input: 1556.76 toks/s, output: 90.30 toks/s]
[2025-01-08 18:11:06,154][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.44it/s, est. speed input: 1914.00 toks/s, output: 124.29 toks/s]
[2025-01-08 18:11:06,407][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:01,  3.55it/s, est. speed input: 2022.96 toks/s, output: 139.76 toks/s]
[2025-01-08 18:11:06,658][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  4.58it/s, est. speed input: 2316.41 toks/s, output: 177.39 toks/s]
[2025-01-08 18:11:06,768][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  5.16it/s, est. speed input: 2479.37 toks/s, output: 197.27 toks/s]
[2025-01-08 18:11:07,106][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  4.37it/s, est. speed input: 2512.77 toks/s, output: 211.36 toks/s]
[2025-01-08 18:11:07,106][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.40it/s, est. speed input: 2512.77 toks/s, output: 211.36 toks/s]
WARNING 01-08 18:11:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:07,328][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:09,582][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.25s/it, est. speed input: 320.74 toks/s, output: 12.87 toks/s]
[2025-01-08 18:11:09,583][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.21it/s, est. speed input: 4520.12 toks/s, output: 180.06 toks/s]
WARNING 01-08 18:11:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:09,804][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:11,584][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.78s/it, est. speed input: 670.47 toks/s, output: 41.59 toks/s]
[2025-01-08 18:11:12,579][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.32s/it, est. speed input: 819.07 toks/s, output: 74.59 toks/s]
[2025-01-08 18:11:12,580][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.39s/it, est. speed input: 819.07 toks/s, output: 74.59 toks/s]
WARNING 01-08 18:11:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:12,833][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:16,889][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:04<01:00,  4.05s/it, est. speed input: 328.24 toks/s, output: 9.62 toks/s]
[2025-01-08 18:11:17,113][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:04<00:25,  1.80s/it, est. speed input: 626.17 toks/s, output: 19.63 toks/s]
[2025-01-08 18:11:17,841][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:05<00:17,  1.31s/it, est. speed input: 845.70 toks/s, output: 29.75 toks/s]
[2025-01-08 18:11:17,946][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:05<00:10,  1.20it/s, est. speed input: 1092.67 toks/s, output: 42.45 toks/s]
[2025-01-08 18:11:18,170][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:05<00:04,  2.21it/s, est. speed input: 1593.99 toks/s, output: 67.45 toks/s]
[2025-01-08 18:11:18,292][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:05<00:03,  2.77it/s, est. speed input: 1823.91 toks/s, output: 80.42 toks/s]
[2025-01-08 18:11:18,404][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:05<00:01,  4.40it/s, est. speed input: 2274.58 toks/s, output: 108.07 toks/s]
[2025-01-08 18:11:18,532][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:00,  6.10it/s, est. speed input: 2708.10 toks/s, output: 135.83 toks/s]
[2025-01-08 18:11:19,102][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:06<00:00,  4.83it/s, est. speed input: 2909.36 toks/s, output: 157.61 toks/s]
[2025-01-08 18:11:19,369][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:06<00:00,  4.56it/s, est. speed input: 3002.74 toks/s, output: 170.47 toks/s]
[2025-01-08 18:11:19,570][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  4.65it/s, est. speed input: 3118.04 toks/s, output: 185.69 toks/s]
[2025-01-08 18:11:19,909][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  4.08it/s, est. speed input: 3161.90 toks/s, output: 199.00 toks/s]
[2025-01-08 18:11:19,909][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.26it/s, est. speed input: 3161.90 toks/s, output: 199.00 toks/s]
WARNING 01-08 18:11:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:20,217][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:21,086][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 832.23 toks/s, output: 33.38 toks/s]
[2025-01-08 18:11:21,120][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1673.23 toks/s, output: 66.44 toks/s]
WARNING 01-08 18:11:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:11:21,326][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:11:23,189][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.86s/it, est. speed input: 903.59 toks/s, output: 39.19 toks/s]
[2025-01-08 18:11:23,257][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.04it/s, est. speed input: 1712.72 toks/s, output: 77.69 toks/s]
[2025-01-08 18:11:29,384][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:11:29,437][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:11:31,117][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 18:11:32,724][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:11:34,311][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:11:34,856][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:11:34,857][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:11:44,358][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:11:44,870][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:11:44,922][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:11:46,803][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 18:11:48,449][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 18:11:50,071][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:11:50,583][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:11:50,583][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 18:12:05,390][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:12:05,705][root][INFO] - Loading VLLM model.
WARNING 01-08 18:12:05 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:12:05 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:12:06 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:12:06 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:12:06,686][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:12:08,045][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 18:12:08,445][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.26it/s]
[2025-01-08 18:12:09,788][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 18:12:11,175][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
[2025-01-08 18:12:11,176][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
INFO 01-08 18:12:11 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:12:25 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:12:25 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:12:25 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:12:48 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:12:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:12:48,619][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:12:51,383][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.76s/it, est. speed input: 182.69 toks/s, output: 10.49 toks/s]
[2025-01-08 18:12:51,384][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.79it/s, est. speed input: 2922.42 toks/s, output: 167.82 toks/s]
WARNING 01-08 18:12:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:12:51,603][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:12:52,394][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 715.59 toks/s, output: 39.19 toks/s]
[2025-01-08 18:12:52,395][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 715.59 toks/s, output: 39.19 toks/s]
WARNING 01-08 18:12:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:12:52,625][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:12:54,956][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 299.83 toks/s, output: 12.44 toks/s]
[2025-01-08 18:12:55,309][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:15,  1.17s/it, est. speed input: 520.78 toks/s, output: 25.33 toks/s]
[2025-01-08 18:12:55,411][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.47it/s, est. speed input: 752.73 toks/s, output: 39.48 toks/s]
[2025-01-08 18:12:55,725][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:03,  2.60it/s, est. speed input: 1127.34 toks/s, output: 66.45 toks/s]
[2025-01-08 18:12:56,019][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:03<00:03,  2.79it/s, est. speed input: 1235.58 toks/s, output: 78.95 toks/s]
[2025-01-08 18:12:56,207][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:03<00:01,  5.13it/s, est. speed input: 1756.12 toks/s, output: 130.08 toks/s]
[2025-01-08 18:12:56,362][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:03<00:00,  7.59it/s, est. speed input: 2244.89 toks/s, output: 182.52 toks/s]
[2025-01-08 18:12:56,934][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:04<00:00,  5.64it/s, est. speed input: 2271.14 toks/s, output: 204.00 toks/s]
[2025-01-08 18:12:57,772][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  3.42it/s, est. speed input: 2037.13 toks/s, output: 201.09 toks/s]
[2025-01-08 18:12:57,772][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.91it/s, est. speed input: 2037.13 toks/s, output: 201.09 toks/s]
WARNING 01-08 18:12:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:12:58,003][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:12:59,995][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:01<00:23,  1.99s/it, est. speed input: 308.21 toks/s, output: 14.56 toks/s]
[2025-01-08 18:12:59,996][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:01<00:00,  6.52it/s, est. speed input: 4023.65 toks/s, output: 189.19 toks/s]
WARNING 01-08 18:13:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:00,235][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:01,280][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.04s/it, est. speed input: 822.30 toks/s, output: 27.76 toks/s]
[2025-01-08 18:13:01,537][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.72it/s, est. speed input: 1335.89 toks/s, output: 55.31 toks/s]
[2025-01-08 18:13:02,289][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.52it/s, est. speed input: 1186.87 toks/s, output: 77.89 toks/s]
[2025-01-08 18:13:02,289][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.46it/s, est. speed input: 1186.87 toks/s, output: 77.89 toks/s]
WARNING 01-08 18:13:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:02,521][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:03,470][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.05it/s, est. speed input: 653.67 toks/s, output: 30.57 toks/s]
[2025-01-08 18:13:03,470][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.16it/s, est. speed input: 2020.19 toks/s, output: 91.68 toks/s]
WARNING 01-08 18:13:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:03,706][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:06,284][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.58s/it, est. speed input: 391.00 toks/s, output: 11.25 toks/s]
[2025-01-08 18:13:06,616][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:13,  1.26s/it, est. speed input: 696.27 toks/s, output: 23.37 toks/s]
[2025-01-08 18:13:07,010][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:05,  1.69it/s, est. speed input: 1232.51 toks/s, output: 49.03 toks/s]
[2025-01-08 18:13:07,352][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:04,  1.94it/s, est. speed input: 1401.28 toks/s, output: 61.99 toks/s]
[2025-01-08 18:13:07,946][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:04<00:01,  2.99it/s, est. speed input: 1942.84 toks/s, output: 105.18 toks/s]
[2025-01-08 18:13:08,125][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  4.03it/s, est. speed input: 2342.21 toks/s, output: 143.25 toks/s]
[2025-01-08 18:13:08,670][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:04<00:00,  3.25it/s, est. speed input: 2294.97 toks/s, output: 152.30 toks/s]
[2025-01-08 18:13:08,964][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.28it/s, est. speed input: 2360.13 toks/s, output: 170.22 toks/s]
[2025-01-08 18:13:09,471][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.83it/s, est. speed input: 2334.44 toks/s, output: 184.56 toks/s]
[2025-01-08 18:13:09,471][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.25it/s, est. speed input: 2334.44 toks/s, output: 184.56 toks/s]
WARNING 01-08 18:13:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:09,714][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:11,867][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.15s/it, est. speed input: 338.57 toks/s, output: 13.47 toks/s]
[2025-01-08 18:13:11,868][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.04it/s, est. speed input: 4405.82 toks/s, output: 175.04 toks/s]
WARNING 01-08 18:13:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:12,075][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:14,482][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:02<00:04,  2.41s/it, est. speed input: 440.74 toks/s, output: 38.22 toks/s]
[2025-01-08 18:13:15,162][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:03<00:01,  1.39s/it, est. speed input: 722.20 toks/s, output: 71.60 toks/s]
[2025-01-08 18:13:16,363][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.30s/it, est. speed input: 800.40 toks/s, output: 98.18 toks/s]
[2025-01-08 18:13:16,363][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.43s/it, est. speed input: 800.40 toks/s, output: 98.18 toks/s]
WARNING 01-08 18:13:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:16,568][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:17,435][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 847.37 toks/s, output: 33.43 toks/s]
[2025-01-08 18:13:17,436][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1759.56 toks/s, output: 66.83 toks/s]
WARNING 01-08 18:13:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:17,667][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:21,318][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:47,  3.65s/it, est. speed input: 364.54 toks/s, output: 10.68 toks/s]
[2025-01-08 18:13:21,423][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:18,  1.57s/it, est. speed input: 711.92 toks/s, output: 21.57 toks/s]
[2025-01-08 18:13:21,650][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.53it/s, est. speed input: 1360.92 toks/s, output: 43.44 toks/s]
[2025-01-08 18:13:22,075][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:05,  1.71it/s, est. speed input: 1536.26 toks/s, output: 53.55 toks/s]
[2025-01-08 18:13:22,186][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.67it/s, est. speed input: 2416.99 toks/s, output: 95.81 toks/s]
[2025-01-08 18:13:22,604][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:00,  4.00it/s, est. speed input: 2807.71 toks/s, output: 120.74 toks/s]
[2025-01-08 18:13:22,712][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  5.42it/s, est. speed input: 3312.78 toks/s, output: 153.02 toks/s]
[2025-01-08 18:13:24,230][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.70it/s, est. speed input: 2981.38 toks/s, output: 161.20 toks/s]
[2025-01-08 18:13:24,230][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.13it/s, est. speed input: 2981.38 toks/s, output: 161.20 toks/s]
WARNING 01-08 18:13:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:24,531][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:25,294][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 964.61 toks/s, output: 38.06 toks/s]
[2025-01-08 18:13:25,294][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 964.61 toks/s, output: 38.06 toks/s]
WARNING 01-08 18:13:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:25,509][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:28,181][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:02<00:02,  2.67s/it, est. speed input: 590.18 toks/s, output: 44.16 toks/s]
[2025-01-08 18:13:28,504][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.29s/it, est. speed input: 1005.20 toks/s, output: 85.16 toks/s]
[2025-01-08 18:13:28,504][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.50s/it, est. speed input: 1005.20 toks/s, output: 85.16 toks/s]
WARNING 01-08 18:13:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:28,731][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:31,673][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.94s/it, est. speed input: 595.60 toks/s, output: 51.33 toks/s]
[2025-01-08 18:13:31,673][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:02<00:00,  2.94s/it, est. speed input: 595.60 toks/s, output: 51.33 toks/s]
WARNING 01-08 18:13:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:13:31,876][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:13:33,175][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.30s/it, est. speed input: 1484.50 toks/s, output: 33.11 toks/s]
[2025-01-08 18:13:33,175][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.30s/it, est. speed input: 1484.50 toks/s, output: 33.11 toks/s]
[2025-01-08 18:13:39,617][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:13:39,671][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:13:41,524][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 18:13:43,156][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 18:13:44,713][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 18:13:45,245][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 18:13:45,246][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 18:13:54,993][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:13:55,503][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:13:55,556][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:13:57,414][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 18:13:59,013][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:14:00,578][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 18:14:01,076][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:14:01,076][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:14:15,676][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:14:15,973][root][INFO] - Loading VLLM model.
WARNING 01-08 18:14:16 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:14:16 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:14:16 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:14:16 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:14:17,111][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:14:18,446][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.34s/it]
[2025-01-08 18:14:18,835][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.28it/s]
[2025-01-08 18:14:20,137][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:14:21,475][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:14:21,475][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:14:21 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:14:35 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:14:36 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:14:36 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:14:57 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:14:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:14:57,617][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:00,580][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.96s/it, est. speed input: 170.42 toks/s, output: 9.79 toks/s]
[2025-01-08 18:15:00,581][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.40it/s, est. speed input: 2726.15 toks/s, output: 156.55 toks/s]
WARNING 01-08 18:15:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:00,786][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:01,585][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.40 toks/s, output: 38.80 toks/s]
[2025-01-08 18:15:01,585][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.40 toks/s, output: 38.80 toks/s]
WARNING 01-08 18:15:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:01,810][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:04,152][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.34s/it, est. speed input: 298.51 toks/s, output: 12.38 toks/s]
[2025-01-08 18:15:04,488][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.37it/s, est. speed input: 783.06 toks/s, output: 36.22 toks/s]
[2025-01-08 18:15:05,270][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:08,  1.33it/s, est. speed input: 808.08 toks/s, output: 46.24 toks/s]
[2025-01-08 18:15:05,419][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:02,  3.02it/s, est. speed input: 1355.84 toks/s, output: 99.48 toks/s]
[2025-01-08 18:15:05,553][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:03<00:02,  3.47it/s, est. speed input: 1493.77 toks/s, output: 115.40 toks/s]
[2025-01-08 18:15:05,782][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:03<00:00,  5.41it/s, est. speed input: 1935.91 toks/s, output: 166.68 toks/s]
[2025-01-08 18:15:06,446][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  4.32it/s, est. speed input: 1960.01 toks/s, output: 187.01 toks/s]
[2025-01-08 18:15:07,402][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:05<00:00,  2.74it/s, est. speed input: 1749.98 toks/s, output: 185.08 toks/s]
[2025-01-08 18:15:07,503][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  3.23it/s, est. speed input: 1841.69 toks/s, output: 212.36 toks/s]
[2025-01-08 18:15:07,503][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.63it/s, est. speed input: 1841.69 toks/s, output: 212.36 toks/s]
WARNING 01-08 18:15:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:07,721][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:09,730][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.01s/it, est. speed input: 305.70 toks/s, output: 14.44 toks/s]
[2025-01-08 18:15:09,730][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.47it/s, est. speed input: 3993.74 toks/s, output: 187.64 toks/s]
WARNING 01-08 18:15:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:09,939][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:10,956][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.02s/it, est. speed input: 906.03 toks/s, output: 27.54 toks/s]
[2025-01-08 18:15:11,126][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  3.06it/s, est. speed input: 2098.31 toks/s, output: 80.09 toks/s]
[2025-01-08 18:15:11,126][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.53it/s, est. speed input: 2098.31 toks/s, output: 80.09 toks/s]
WARNING 01-08 18:15:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:11,357][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:12,203][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.18it/s, est. speed input: 726.45 toks/s, output: 34.31 toks/s]
[2025-01-08 18:15:12,203][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.36it/s, est. speed input: 1459.32 toks/s, output: 68.59 toks/s]
WARNING 01-08 18:15:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:12,431][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:15,160][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.73s/it, est. speed input: 289.93 toks/s, output: 10.63 toks/s]
[2025-01-08 18:15:15,502][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:15,  1.32s/it, est. speed input: 589.19 toks/s, output: 22.15 toks/s]
[2025-01-08 18:15:16,297][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:11,  1.08s/it, est. speed input: 737.57 toks/s, output: 33.89 toks/s]
[2025-01-08 18:15:16,455][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:04<00:07,  1.39it/s, est. speed input: 967.33 toks/s, output: 49.46 toks/s]
[2025-01-08 18:15:16,604][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:04,  1.95it/s, est. speed input: 1184.77 toks/s, output: 65.18 toks/s]
[2025-01-08 18:15:16,794][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  3.32it/s, est. speed input: 1605.38 toks/s, output: 97.41 toks/s]
[2025-01-08 18:15:16,952][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:01,  3.81it/s, est. speed input: 1784.20 toks/s, output: 113.03 toks/s]
[2025-01-08 18:15:17,222][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.78it/s, est. speed input: 1893.98 toks/s, output: 126.91 toks/s]
[2025-01-08 18:15:17,429][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:04<00:00,  4.03it/s, est. speed input: 2025.12 toks/s, output: 142.86 toks/s]
[2025-01-08 18:15:17,716][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:05<00:00,  3.86it/s, est. speed input: 2115.12 toks/s, output: 157.64 toks/s]
[2025-01-08 18:15:18,386][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  2.64it/s, est. speed input: 2051.40 toks/s, output: 165.42 toks/s]
[2025-01-08 18:15:18,533][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  3.22it/s, est. speed input: 2173.09 toks/s, output: 187.65 toks/s]
[2025-01-08 18:15:18,601][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.27it/s, est. speed input: 2335.01 toks/s, output: 212.16 toks/s]
WARNING 01-08 18:15:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:18,838][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:21,093][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.25s/it, est. speed input: 323.38 toks/s, output: 12.86 toks/s]
[2025-01-08 18:15:21,700][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.27it/s, est. speed input: 3554.75 toks/s, output: 155.16 toks/s]
[2025-01-08 18:15:21,700][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  4.89it/s, est. speed input: 3554.75 toks/s, output: 155.16 toks/s]
WARNING 01-08 18:15:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:21,908][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:22,863][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1281.37 toks/s, output: 29.34 toks/s]
[2025-01-08 18:15:24,704][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.48s/it, est. speed input: 858.80 toks/s, output: 59.02 toks/s]
[2025-01-08 18:15:24,704][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:02<00:00,  1.40s/it, est. speed input: 858.80 toks/s, output: 59.02 toks/s]
WARNING 01-08 18:15:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:24,945][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:28,602][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:54,  3.66s/it, est. speed input: 356.92 toks/s, output: 7.93 toks/s]
[2025-01-08 18:15:28,966][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:04<00:14,  1.08s/it, est. speed input: 997.71 toks/s, output: 24.13 toks/s]
[2025-01-08 18:15:29,070][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:04<00:08,  1.34it/s, est. speed input: 1237.62 toks/s, output: 33.70 toks/s]
[2025-01-08 18:15:29,441][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:04<00:06,  1.61it/s, est. speed input: 1438.47 toks/s, output: 42.71 toks/s]
[2025-01-08 18:15:29,763][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:04<00:05,  1.91it/s, est. speed input: 1629.88 toks/s, output: 52.93 toks/s]
[2025-01-08 18:15:30,056][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:05<00:02,  2.91it/s, est. speed input: 2095.83 toks/s, output: 77.09 toks/s]
[2025-01-08 18:15:30,164][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:05<00:01,  4.42it/s, est. speed input: 2587.14 toks/s, output: 104.24 toks/s]
[2025-01-08 18:15:30,892][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:05<00:01,  2.95it/s, est. speed input: 2511.55 toks/s, output: 109.31 toks/s]
[2025-01-08 18:15:31,342][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:06<00:00,  3.40it/s, est. speed input: 2773.39 toks/s, output: 138.51 toks/s]
[2025-01-08 18:15:31,691][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:06<00:00,  3.27it/s, est. speed input: 2865.00 toks/s, output: 152.55 toks/s]
[2025-01-08 18:15:31,839][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:06<00:00,  3.72it/s, est. speed input: 3018.91 toks/s, output: 171.18 toks/s]
[2025-01-08 18:15:32,668][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.43it/s, est. speed input: 2885.00 toks/s, output: 178.69 toks/s]
[2025-01-08 18:15:32,668][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.07it/s, est. speed input: 2885.00 toks/s, output: 178.69 toks/s]
WARNING 01-08 18:15:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:32,951][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:33,962][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 715.43 toks/s, output: 28.70 toks/s]
[2025-01-08 18:15:33,996][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.87it/s, est. speed input: 2155.28 toks/s, output: 85.18 toks/s]
WARNING 01-08 18:15:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:34,212][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:35,819][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.61s/it, est. speed input: 1073.90 toks/s, output: 42.96 toks/s]
[2025-01-08 18:15:35,819][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.61s/it, est. speed input: 1073.90 toks/s, output: 42.96 toks/s]
WARNING 01-08 18:15:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:36,069][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:37,327][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.26s/it, est. speed input: 1278.50 toks/s, output: 22.26 toks/s]
[2025-01-08 18:15:37,566][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.41it/s, est. speed input: 3141.18 toks/s, output: 66.14 toks/s]
[2025-01-08 18:15:37,566][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.00it/s, est. speed input: 3141.18 toks/s, output: 66.14 toks/s]
WARNING 01-08 18:15:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:15:37,781][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:15:38,837][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.06s/it, est. speed input: 1404.92 toks/s, output: 27.47 toks/s]
[2025-01-08 18:15:38,838][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.89it/s, est. speed input: 3004.51 toks/s, output: 54.92 toks/s]
[2025-01-08 18:15:45,076][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:15:45,131][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:15:46,808][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 18:15:48,433][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 18:15:50,006][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:15:50,524][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:15:50,525][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:16:00,271][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:16:00,759][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:16:00,812][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:16:02,734][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 18:16:04,406][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 18:16:06,016][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 18:16:06,520][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:16:06,521][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 18:16:21,486][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:16:21,828][root][INFO] - Loading VLLM model.
WARNING 01-08 18:16:22 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:16:22 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:16:22 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:16:22 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:16:22,835][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:16:24,203][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 18:16:24,608][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 18:16:25,967][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 18:16:27,306][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.17s/it]
[2025-01-08 18:16:27,306][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.12s/it]
INFO 01-08 18:16:27 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:16:41 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:16:41 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:16:41 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:17:03 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:17:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:03,823][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:06,857][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.03s/it, est. speed input: 166.47 toks/s, output: 9.56 toks/s]
[2025-01-08 18:17:06,858][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.27it/s, est. speed input: 2662.97 toks/s, output: 152.92 toks/s]
WARNING 01-08 18:17:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:07,072][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:07,866][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.62 toks/s, output: 39.08 toks/s]
[2025-01-08 18:17:07,866][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.62 toks/s, output: 39.08 toks/s]
WARNING 01-08 18:17:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:08,081][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:10,417][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 299.39 toks/s, output: 12.42 toks/s]
[2025-01-08 18:17:10,753][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:02<00:08,  1.37it/s, est. speed input: 784.96 toks/s, output: 36.31 toks/s]
[2025-01-08 18:17:11,535][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:08,  1.34it/s, est. speed input: 809.60 toks/s, output: 46.33 toks/s]
[2025-01-08 18:17:11,837][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:03<00:02,  3.32it/s, est. speed input: 1489.04 toks/s, output: 113.97 toks/s]
[2025-01-08 18:17:12,181][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:04<00:00,  4.47it/s, est. speed input: 1875.55 toks/s, output: 162.94 toks/s]
[2025-01-08 18:17:12,524][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  4.79it/s, est. speed input: 2045.72 toks/s, output: 194.96 toks/s]
[2025-01-08 18:17:13,624][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:05<00:00,  2.79it/s, est. speed input: 1765.75 toks/s, output: 186.21 toks/s]
[2025-01-08 18:17:14,193][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.50it/s, est. speed input: 1715.77 toks/s, output: 201.60 toks/s]
[2025-01-08 18:17:14,193][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.45it/s, est. speed input: 1715.77 toks/s, output: 201.60 toks/s]
WARNING 01-08 18:17:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:14,408][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:16,445][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:26,  2.04s/it, est. speed input: 301.49 toks/s, output: 13.26 toks/s]
[2025-01-08 18:17:16,513][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.65it/s, est. speed input: 4112.67 toks/s, output: 191.95 toks/s]
WARNING 01-08 18:17:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:16,718][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:17,625][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 1051.57 toks/s, output: 31.97 toks/s]
[2025-01-08 18:17:17,759][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  2.21it/s, est. speed input: 1588.11 toks/s, output: 63.41 toks/s]
[2025-01-08 18:17:17,759][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.92it/s, est. speed input: 1588.11 toks/s, output: 63.41 toks/s]
WARNING 01-08 18:17:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:17,961][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:18,818][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 724.32 toks/s, output: 33.88 toks/s]
[2025-01-08 18:17:18,852][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1464.14 toks/s, output: 67.42 toks/s]
WARNING 01-08 18:17:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:19,078][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:21,844][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.77s/it, est. speed input: 364.45 toks/s, output: 10.48 toks/s]
[2025-01-08 18:17:22,176][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:09,  1.19it/s, est. speed input: 979.40 toks/s, output: 31.31 toks/s]
[2025-01-08 18:17:22,870][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.27it/s, est. speed input: 1074.99 toks/s, output: 41.67 toks/s]
[2025-01-08 18:17:22,985][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  2.93it/s, est. speed input: 1848.81 toks/s, output: 89.33 toks/s]
[2025-01-08 18:17:23,272][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:04<00:01,  3.71it/s, est. speed input: 2220.48 toks/s, output: 118.99 toks/s]
[2025-01-08 18:17:23,986][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  3.34it/s, est. speed input: 2336.45 toks/s, output: 145.06 toks/s]
[2025-01-08 18:17:24,414][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  3.69it/s, est. speed input: 2543.09 toks/s, output: 178.05 toks/s]
[2025-01-08 18:17:24,970][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.07it/s, est. speed input: 2497.29 toks/s, output: 188.90 toks/s]
[2025-01-08 18:17:24,970][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.38it/s, est. speed input: 2497.29 toks/s, output: 188.90 toks/s]
WARNING 01-08 18:17:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:25,211][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:27,367][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.16s/it, est. speed input: 335.45 toks/s, output: 13.45 toks/s]
[2025-01-08 18:17:27,367][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.03it/s, est. speed input: 4403.02 toks/s, output: 174.86 toks/s]
WARNING 01-08 18:17:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:27,582][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:28,753][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.17s/it, est. speed input: 1163.52 toks/s, output: 24.77 toks/s]
[2025-01-08 18:17:29,451][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.12it/s, est. speed input: 1404.51 toks/s, output: 51.36 toks/s]
[2025-01-08 18:17:29,604][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.80it/s, est. speed input: 1801.38 toks/s, output: 85.10 toks/s]
[2025-01-08 18:17:29,604][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.48it/s, est. speed input: 1801.38 toks/s, output: 85.10 toks/s]
WARNING 01-08 18:17:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:29,819][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:30,818][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.00it/s, est. speed input: 735.72 toks/s, output: 29.03 toks/s]
[2025-01-08 18:17:30,853][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.90it/s, est. speed input: 2197.16 toks/s, output: 86.14 toks/s]
WARNING 01-08 18:17:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:31,082][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:34,971][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:46,  3.89s/it, est. speed input: 337.16 toks/s, output: 13.37 toks/s]
[2025-01-08 18:17:35,274][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:19,  1.78s/it, est. speed input: 642.78 toks/s, output: 26.96 toks/s]
[2025-01-08 18:17:35,429][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:06,  1.40it/s, est. speed input: 1262.74 toks/s, output: 55.67 toks/s]
[2025-01-08 18:17:35,660][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:04<00:04,  1.77it/s, est. speed input: 1485.52 toks/s, output: 69.03 toks/s]
[2025-01-08 18:17:35,823][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:02,  2.97it/s, est. speed input: 2023.84 toks/s, output: 99.37 toks/s]
[2025-01-08 18:17:36,299][root][ERROR] - Processed prompts:  62%|######1   | 8/13 [00:05<00:01,  2.69it/s, est. speed input: 2115.83 toks/s, output: 109.27 toks/s]
[2025-01-08 18:17:36,464][root][ERROR] - Processed prompts:  69%|######9   | 9/13 [00:05<00:01,  3.15it/s, est. speed input: 2324.34 toks/s, output: 125.62 toks/s]
[2025-01-08 18:17:36,664][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:05<00:00,  3.51it/s, est. speed input: 2502.30 toks/s, output: 141.72 toks/s]
[2025-01-08 18:17:37,682][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:06<00:00,  2.61it/s, est. speed input: 2544.31 toks/s, output: 163.64 toks/s]
[2025-01-08 18:17:37,683][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.97it/s, est. speed input: 2745.87 toks/s, output: 189.39 toks/s]
WARNING 01-08 18:17:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:17:37,971][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:17:39,249][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.28s/it, est. speed input: 1307.62 toks/s, output: 22.69 toks/s]
[2025-01-08 18:17:39,654][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.31it/s, est. speed input: 1808.04 toks/s, output: 47.53 toks/s]
[2025-01-08 18:17:40,279][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.43it/s, est. speed input: 2016.47 toks/s, output: 72.81 toks/s]
[2025-01-08 18:17:40,279][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.30it/s, est. speed input: 2016.47 toks/s, output: 72.81 toks/s]
[2025-01-08 18:17:46,537][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:17:46,591][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:17:48,270][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 18:17:49,895][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 18:17:51,502][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:17:52,031][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:17:52,031][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:18:02,536][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:18:03,049][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:18:03,102][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:18:04,930][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 18:18:06,540][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:18:08,113][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 18:18:08,616][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:18:08,616][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:18:23,146][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:18:23,518][root][INFO] - Loading VLLM model.
WARNING 01-08 18:18:23 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:18:23 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:18:24 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:18:24 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:18:24,520][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:18:25,847][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
[2025-01-08 18:18:26,241][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:18:27,553][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:18:28,900][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:18:28,900][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:18:29 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:18:42 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:18:43 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:18:43 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:19:05 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:19:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:05,316][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:08,290][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.97s/it, est. speed input: 169.84 toks/s, output: 9.75 toks/s]
[2025-01-08 18:19:08,291][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.38it/s, est. speed input: 2716.83 toks/s, output: 156.02 toks/s]
WARNING 01-08 18:19:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:08,490][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:09,293][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 704.94 toks/s, output: 38.61 toks/s]
[2025-01-08 18:19:09,293][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 704.94 toks/s, output: 38.61 toks/s]
WARNING 01-08 18:19:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:09,510][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:11,815][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.31s/it, est. speed input: 303.23 toks/s, output: 12.15 toks/s]
[2025-01-08 18:19:12,779][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:03,  2.60it/s, est. speed input: 1496.87 toks/s, output: 71.89 toks/s]
[2025-01-08 18:19:12,886][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:03<00:02,  2.98it/s, est. speed input: 1656.27 toks/s, output: 89.15 toks/s]
[2025-01-08 18:19:13,030][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:03<00:00,  4.71it/s, est. speed input: 2184.17 toks/s, output: 144.87 toks/s]
[2025-01-08 18:19:13,152][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:03<00:00,  5.94it/s, est. speed input: 2494.95 toks/s, output: 181.48 toks/s]
[2025-01-08 18:19:14,218][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.63it/s, est. speed input: 2226.85 toks/s, output: 188.17 toks/s]
[2025-01-08 18:19:14,219][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.19it/s, est. speed input: 2226.85 toks/s, output: 188.17 toks/s]
WARNING 01-08 18:19:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:14,468][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:16,470][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.00s/it, est. speed input: 309.74 toks/s, output: 14.49 toks/s]
[2025-01-08 18:19:16,470][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.49it/s, est. speed input: 4016.47 toks/s, output: 188.29 toks/s]
WARNING 01-08 18:19:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:16,685][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:17,707][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.02s/it, est. speed input: 804.63 toks/s, output: 28.39 toks/s]
[2025-01-08 18:19:17,891][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  3.00it/s, est. speed input: 1909.34 toks/s, output: 81.28 toks/s]
[2025-01-08 18:19:17,891][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.49it/s, est. speed input: 1909.34 toks/s, output: 81.28 toks/s]
WARNING 01-08 18:19:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:18,097][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:19,054][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.04it/s, est. speed input: 641.39 toks/s, output: 30.29 toks/s]
[2025-01-08 18:19:19,088][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.03it/s, est. speed input: 1933.34 toks/s, output: 89.76 toks/s]
WARNING 01-08 18:19:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:19,321][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:21,926][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:31,  2.60s/it, est. speed input: 386.96 toks/s, output: 11.13 toks/s]
[2025-01-08 18:19:22,553][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:03<00:04,  1.92it/s, est. speed input: 1572.72 toks/s, output: 51.67 toks/s]
[2025-01-08 18:19:22,852][root][ERROR] - Processed prompts:  46%|####6     | 6/13 [00:03<00:03,  2.13it/s, est. speed input: 1734.81 toks/s, output: 64.87 toks/s]
[2025-01-08 18:19:22,957][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:03<00:02,  2.64it/s, est. speed input: 1971.82 toks/s, output: 81.14 toks/s]
[2025-01-08 18:19:23,118][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:03<00:00,  4.75it/s, est. speed input: 2705.09 toks/s, output: 133.02 toks/s]
[2025-01-08 18:19:23,414][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  5.27it/s, est. speed input: 3042.70 toks/s, output: 165.41 toks/s]
[2025-01-08 18:19:23,854][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  4.21it/s, est. speed input: 2977.82 toks/s, output: 174.50 toks/s]
[2025-01-08 18:19:23,854][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  2.87it/s, est. speed input: 2977.82 toks/s, output: 174.50 toks/s]
WARNING 01-08 18:19:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:24,075][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:26,237][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.16s/it, est. speed input: 339.99 toks/s, output: 13.41 toks/s]
[2025-01-08 18:19:26,238][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.01it/s, est. speed input: 4404.73 toks/s, output: 174.34 toks/s]
WARNING 01-08 18:19:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:26,446][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:27,560][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 978.27 toks/s, output: 26.03 toks/s]
[2025-01-08 18:19:27,762][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.73it/s, est. speed input: 1602.19 toks/s, output: 52.42 toks/s]
[2025-01-08 18:19:28,438][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.61it/s, est. speed input: 1623.41 toks/s, output: 74.79 toks/s]
[2025-01-08 18:19:28,438][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.51it/s, est. speed input: 1623.41 toks/s, output: 74.79 toks/s]
WARNING 01-08 18:19:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:28,653][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:29,649][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.00it/s, est. speed input: 731.93 toks/s, output: 29.12 toks/s]
[2025-01-08 18:19:29,683][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.91it/s, est. speed input: 2191.81 toks/s, output: 86.39 toks/s]
WARNING 01-08 18:19:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:29,914][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:32,978][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:36,  3.06s/it, est. speed input: 429.86 toks/s, output: 9.47 toks/s]
[2025-01-08 18:19:34,129][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:04<00:08,  1.12it/s, est. speed input: 1255.15 toks/s, output: 36.54 toks/s]
[2025-01-08 18:19:34,239][root][ERROR] - Processed prompts:  54%|#####3    | 7/13 [00:04<00:02,  2.31it/s, est. speed input: 2170.18 toks/s, output: 83.48 toks/s]
[2025-01-08 18:19:34,404][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:04<00:00,  3.72it/s, est. speed input: 3032.31 toks/s, output: 130.74 toks/s]
[2025-01-08 18:19:35,041][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:05<00:00,  3.53it/s, est. speed input: 3204.74 toks/s, output: 152.74 toks/s]
[2025-01-08 18:19:35,346][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.39it/s, est. speed input: 3298.84 toks/s, output: 168.10 toks/s]
WARNING 01-08 18:19:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:19:35,660][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:19:36,890][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.23s/it, est. speed input: 1132.96 toks/s, output: 23.59 toks/s]
[2025-01-08 18:19:37,092][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.60it/s, est. speed input: 1908.09 toks/s, output: 48.19 toks/s]
[2025-01-08 18:19:38,192][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.19it/s, est. speed input: 1665.77 toks/s, output: 68.73 toks/s]
[2025-01-08 18:19:38,192][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.18it/s, est. speed input: 1665.77 toks/s, output: 68.73 toks/s]
[2025-01-08 18:19:44,676][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:19:44,731][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:19:46,443][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.71s/it]
[2025-01-08 18:19:48,139][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:19:49,784][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:19:50,312][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:19:50,312][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:19:59,998][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:20:00,567][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:20:00,621][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:20:02,464][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 18:20:04,118][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 18:20:05,748][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:20:06,253][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:20:06,253][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:20:20,498][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:20:20,801][root][INFO] - Loading VLLM model.
WARNING 01-08 18:20:20 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:20:20 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:20:21 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:20:21 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:20:21,794][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:20:23,108][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:20:23,503][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:20:24,799][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 18:20:26,134][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:20:26,134][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:20:26 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:20:40 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:20:40 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:20:40 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:21:02 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:21:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:02,341][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:05,281][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.94s/it, est. speed input: 171.78 toks/s, output: 9.86 toks/s]
[2025-01-08 18:21:05,282][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.44it/s, est. speed input: 2747.93 toks/s, output: 157.80 toks/s]
WARNING 01-08 18:21:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:05,485][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:06,284][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.79 toks/s, output: 38.82 toks/s]
[2025-01-08 18:21:06,284][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.79 toks/s, output: 38.82 toks/s]
WARNING 01-08 18:21:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:06,502][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:08,804][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.79 toks/s, output: 12.17 toks/s]
[2025-01-08 18:21:09,056][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:02<00:00,  5.21it/s, est. speed input: 2737.17 toks/s, output: 116.69 toks/s]
[2025-01-08 18:21:09,588][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:03<00:00,  5.33it/s, est. speed input: 2945.33 toks/s, output: 145.86 toks/s]
[2025-01-08 18:21:10,663][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.75it/s, est. speed input: 2520.36 toks/s, output: 154.56 toks/s]
[2025-01-08 18:21:10,663][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.61it/s, est. speed input: 2520.36 toks/s, output: 154.56 toks/s]
WARNING 01-08 18:21:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:10,911][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:13,021][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.85 toks/s, output: 13.74 toks/s]
[2025-01-08 18:21:13,022][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4104.16 toks/s, output: 192.37 toks/s]
WARNING 01-08 18:21:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:13,235][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:14,133][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 870.19 toks/s, output: 32.31 toks/s]
[2025-01-08 18:21:14,767][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.35it/s, est. speed input: 966.09 toks/s, output: 62.66 toks/s]
[2025-01-08 18:21:14,767][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.31it/s, est. speed input: 966.09 toks/s, output: 62.66 toks/s]
WARNING 01-08 18:21:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:14,971][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:15,828][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 797.40 toks/s, output: 33.86 toks/s]
[2025-01-08 18:21:15,828][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.33it/s, est. speed input: 1520.48 toks/s, output: 67.68 toks/s]
WARNING 01-08 18:21:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:16,053][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:18,766][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.71s/it, est. speed input: 371.62 toks/s, output: 10.69 toks/s]
[2025-01-08 18:21:19,003][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:02<00:01,  3.60it/s, est. speed input: 2734.87 toks/s, output: 81.70 toks/s]
[2025-01-08 18:21:19,257][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:03<00:00,  4.22it/s, est. speed input: 3156.41 toks/s, output: 102.69 toks/s]
[2025-01-08 18:21:19,667][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.39it/s, est. speed input: 3364.30 toks/s, output: 127.57 toks/s]
[2025-01-08 18:21:19,977][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.83it/s, est. speed input: 3645.76 toks/s, output: 157.52 toks/s]
[2025-01-08 18:21:19,977][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.57it/s, est. speed input: 3645.76 toks/s, output: 157.52 toks/s]
WARNING 01-08 18:21:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:20,196][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:22,477][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.26 toks/s, output: 12.72 toks/s]
[2025-01-08 18:21:22,478][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4489.50 toks/s, output: 177.97 toks/s]
WARNING 01-08 18:21:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:22,709][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:23,657][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1150.25 toks/s, output: 30.60 toks/s]
[2025-01-08 18:21:24,282][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.32it/s, est. speed input: 1357.82 toks/s, output: 60.39 toks/s]
[2025-01-08 18:21:24,282][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.27it/s, est. speed input: 1357.82 toks/s, output: 60.39 toks/s]
WARNING 01-08 18:21:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:24,488][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:25,392][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 883.37 toks/s, output: 32.10 toks/s]
[2025-01-08 18:21:25,392][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1689.64 toks/s, output: 64.18 toks/s]
WARNING 01-08 18:21:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:25,625][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:28,828][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.20s/it, est. speed input: 411.18 toks/s, output: 9.05 toks/s]
[2025-01-08 18:21:29,076][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:03<00:02,  2.69it/s, est. speed input: 2669.76 toks/s, output: 61.43 toks/s]
[2025-01-08 18:21:29,451][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  3.16it/s, est. speed input: 3101.92 toks/s, output: 79.46 toks/s]
[2025-01-08 18:21:29,846][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  3.56it/s, est. speed input: 3482.76 toks/s, output: 104.72 toks/s]
[2025-01-08 18:21:29,969][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  3.95it/s, est. speed input: 3708.65 toks/s, output: 119.25 toks/s]
[2025-01-08 18:21:30,153][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  4.18it/s, est. speed input: 3854.86 toks/s, output: 133.40 toks/s]
[2025-01-08 18:21:31,169][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.42it/s, est. speed input: 3393.14 toks/s, output: 135.29 toks/s]
[2025-01-08 18:21:31,169][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.53it/s, est. speed input: 3393.14 toks/s, output: 135.29 toks/s]
WARNING 01-08 18:21:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:21:31,483][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:21:32,506][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1361.81 toks/s, output: 28.35 toks/s]
[2025-01-08 18:21:33,133][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.27it/s, est. speed input: 1688.14 toks/s, output: 57.58 toks/s]
[2025-01-08 18:21:33,134][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.21it/s, est. speed input: 1688.14 toks/s, output: 57.58 toks/s]
[2025-01-08 18:21:39,586][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:21:39,641][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:21:41,309][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 18:21:42,903][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.62s/it]
[2025-01-08 18:21:44,465][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 18:21:44,982][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 18:21:44,983][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 18:21:54,555][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:21:55,092][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:21:55,144][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:21:56,994][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 18:21:58,630][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 18:22:00,222][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.66s/it]
[2025-01-08 18:22:00,720][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 18:22:00,720][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 18:22:14,509][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:22:14,903][root][INFO] - Loading VLLM model.
WARNING 01-08 18:22:15 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:22:15 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:22:15 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:22:15 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:22:16,030][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:22:17,351][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:22:17,743][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:22:19,049][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:22:20,390][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:22:20,390][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:22:20 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:22:34 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:22:35 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:22:35 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:22:56 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:22:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:22:56,787][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:22:59,542][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.75s/it, est. speed input: 183.37 toks/s, output: 10.53 toks/s]
[2025-01-08 18:22:59,542][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.81it/s, est. speed input: 2933.25 toks/s, output: 168.44 toks/s]
WARNING 01-08 18:22:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:22:59,755][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:00,560][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 703.54 toks/s, output: 38.53 toks/s]
[2025-01-08 18:23:00,560][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 703.54 toks/s, output: 38.53 toks/s]
WARNING 01-08 18:23:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:00,778][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:03,082][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.43 toks/s, output: 12.15 toks/s]
[2025-01-08 18:23:03,374][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:02<00:00,  6.67it/s, est. speed input: 3500.86 toks/s, output: 149.87 toks/s]
[2025-01-08 18:23:04,785][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.74it/s, est. speed input: 2617.07 toks/s, output: 144.52 toks/s]
WARNING 01-08 18:23:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:05,004][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:07,121][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.12s/it, est. speed input: 293.01 toks/s, output: 13.71 toks/s]
[2025-01-08 18:23:07,121][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.61it/s, est. speed input: 4098.11 toks/s, output: 191.82 toks/s]
WARNING 01-08 18:23:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:07,327][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:08,223][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 779.91 toks/s, output: 32.36 toks/s]
[2025-01-08 18:23:08,224][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1650.55 toks/s, output: 64.68 toks/s]
WARNING 01-08 18:23:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:08,426][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:09,301][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 708.85 toks/s, output: 33.16 toks/s]
[2025-01-08 18:23:09,335][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1433.85 toks/s, output: 66.02 toks/s]
WARNING 01-08 18:23:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:09,562][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:12,274][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.71s/it, est. speed input: 371.68 toks/s, output: 10.69 toks/s]
[2025-01-08 18:23:12,536][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:02<00:00,  5.41it/s, est. speed input: 4071.11 toks/s, output: 121.37 toks/s]
[2025-01-08 18:23:14,749][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.70it/s, est. speed input: 2747.70 toks/s, output: 115.30 toks/s]
WARNING 01-08 18:23:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:14,969][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:17,253][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 321.88 toks/s, output: 12.70 toks/s]
[2025-01-08 18:23:17,254][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.13it/s, est. speed input: 4489.18 toks/s, output: 177.75 toks/s]
WARNING 01-08 18:23:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:17,479][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:18,427][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1063.55 toks/s, output: 30.60 toks/s]
[2025-01-08 18:23:18,427][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2212.36 toks/s, output: 61.16 toks/s]
WARNING 01-08 18:23:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:18,647][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:19,524][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 838.17 toks/s, output: 33.07 toks/s]
[2025-01-08 18:23:19,558][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.19it/s, est. speed input: 1678.18 toks/s, output: 65.85 toks/s]
WARNING 01-08 18:23:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:19,790][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:22,994][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.20s/it, est. speed input: 411.06 toks/s, output: 9.05 toks/s]
[2025-01-08 18:23:23,318][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  3.39it/s, est. speed input: 3365.39 toks/s, output: 77.66 toks/s]
[2025-01-08 18:23:23,660][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  3.78it/s, est. speed input: 3745.13 toks/s, output: 98.70 toks/s]
[2025-01-08 18:23:24,213][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  3.74it/s, est. speed input: 3922.20 toks/s, output: 124.35 toks/s]
[2025-01-08 18:23:24,213][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.17it/s, est. speed input: 4236.46 toks/s, output: 143.33 toks/s]
WARNING 01-08 18:23:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:23:24,517][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:23:25,533][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1290.92 toks/s, output: 28.56 toks/s]
[2025-01-08 18:23:25,533][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2667.47 toks/s, output: 57.09 toks/s]
[2025-01-08 18:23:31,970][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:23:32,024][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:23:33,710][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:23:35,344][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 18:23:36,942][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:23:37,458][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:23:37,459][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:23:47,150][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:23:47,849][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:23:47,902][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:23:49,674][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 18:23:51,272][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 18:23:52,852][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:23:53,353][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:23:53,353][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:24:07,068][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:24:07,386][root][INFO] - Loading VLLM model.
WARNING 01-08 18:24:07 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:24:07 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:24:08 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:24:08 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:24:08,485][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:24:09,805][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:24:10,197][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:24:11,504][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:24:12,843][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:24:12,844][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:24:13 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:24:26 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:24:27 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:24:27 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:24:49 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:24:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:24:49,339][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:24:52,316][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.98s/it, est. speed input: 169.65 toks/s, output: 9.74 toks/s]
[2025-01-08 18:24:52,317][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.37it/s, est. speed input: 2713.82 toks/s, output: 155.84 toks/s]
WARNING 01-08 18:24:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:24:52,526][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:24:53,329][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 704.95 toks/s, output: 38.61 toks/s]
[2025-01-08 18:24:53,329][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 704.95 toks/s, output: 38.61 toks/s]
WARNING 01-08 18:24:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:24:53,550][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:24:55,857][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.31s/it, est. speed input: 303.04 toks/s, output: 12.14 toks/s]
[2025-01-08 18:24:56,445][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.67it/s, est. speed input: 3622.59 toks/s, output: 161.35 toks/s]
[2025-01-08 18:24:56,445][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.18it/s, est. speed input: 3622.59 toks/s, output: 161.35 toks/s]
WARNING 01-08 18:24:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:24:56,666][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:24:58,837][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.17s/it, est. speed input: 285.64 toks/s, output: 13.36 toks/s]
[2025-01-08 18:24:58,837][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.45it/s, est. speed input: 3997.75 toks/s, output: 186.99 toks/s]
WARNING 01-08 18:24:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:24:59,044][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:24:59,945][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 776.38 toks/s, output: 32.21 toks/s]
[2025-01-08 18:24:59,945][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.22it/s, est. speed input: 1643.08 toks/s, output: 64.39 toks/s]
WARNING 01-08 18:25:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:00,153][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:01,021][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 714.46 toks/s, output: 33.42 toks/s]
[2025-01-08 18:25:01,055][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.22it/s, est. speed input: 1444.88 toks/s, output: 66.53 toks/s]
WARNING 01-08 18:25:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:01,283][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:04,006][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.72s/it, est. speed input: 370.21 toks/s, output: 10.65 toks/s]
[2025-01-08 18:25:04,672][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.55it/s, est. speed input: 3579.47 toks/s, output: 112.44 toks/s]
[2025-01-08 18:25:04,929][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.47it/s, est. speed input: 3603.84 toks/s, output: 125.37 toks/s]
[2025-01-08 18:25:05,487][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.72it/s, est. speed input: 3365.36 toks/s, output: 134.66 toks/s]
[2025-01-08 18:25:05,487][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.33it/s, est. speed input: 3365.36 toks/s, output: 134.66 toks/s]
WARNING 01-08 18:25:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:05,740][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:08,045][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.30s/it, est. speed input: 318.95 toks/s, output: 12.58 toks/s]
[2025-01-08 18:25:08,045][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.07it/s, est. speed input: 4456.29 toks/s, output: 176.13 toks/s]
WARNING 01-08 18:25:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:08,264][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:09,214][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1062.24 toks/s, output: 30.56 toks/s]
[2025-01-08 18:25:09,214][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2209.96 toks/s, output: 61.09 toks/s]
WARNING 01-08 18:25:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:09,422][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:10,306][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.13it/s, est. speed input: 831.44 toks/s, output: 32.80 toks/s]
[2025-01-08 18:25:10,340][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.18it/s, est. speed input: 1671.80 toks/s, output: 65.35 toks/s]
WARNING 01-08 18:25:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:10,574][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:13,763][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.19s/it, est. speed input: 413.04 toks/s, output: 9.09 toks/s]
[2025-01-08 18:25:14,319][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  3.84it/s, est. speed input: 3878.45 toks/s, output: 91.87 toks/s]
[2025-01-08 18:25:15,602][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:05<00:00,  2.93it/s, est. speed input: 3441.62 toks/s, output: 112.78 toks/s]
[2025-01-08 18:25:15,721][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.21it/s, est. speed input: 3616.54 toks/s, output: 134.46 toks/s]
[2025-01-08 18:25:15,721][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.72it/s, est. speed input: 3616.54 toks/s, output: 134.46 toks/s]
WARNING 01-08 18:25:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:25:16,042][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:25:17,288][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.25s/it, est. speed input: 1122.73 toks/s, output: 23.27 toks/s]
[2025-01-08 18:25:17,729][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.29it/s, est. speed input: 1609.97 toks/s, output: 48.61 toks/s]
[2025-01-08 18:25:18,153][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.63it/s, est. speed input: 2013.18 toks/s, output: 75.81 toks/s]
[2025-01-08 18:25:18,153][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.42it/s, est. speed input: 2013.18 toks/s, output: 75.81 toks/s]
[2025-01-08 18:25:24,601][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:25:24,655][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:25:26,344][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:25:27,965][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 18:25:29,546][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:25:30,065][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:25:30,066][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:25:39,757][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:25:40,232][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:25:40,285][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:25:42,143][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 18:25:43,780][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 18:25:45,391][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 18:25:45,893][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 18:25:45,894][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:25:59,527][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:25:59,819][root][INFO] - Loading VLLM model.
WARNING 01-08 18:26:00 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:26:00 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:26:01 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:26:02 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:26:02,225][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:26:03,547][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:26:03,935][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:26:05,246][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:26:06,587][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:26:06,587][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:26:06 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:26:20 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:26:21 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:26:21 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:26:42 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:26:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:43,003][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:45,512][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.51s/it, est. speed input: 201.29 toks/s, output: 11.56 toks/s]
[2025-01-08 18:26:45,513][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.38it/s, est. speed input: 3219.62 toks/s, output: 184.89 toks/s]
WARNING 01-08 18:26:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:45,717][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:46,512][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.24 toks/s, output: 39.01 toks/s]
[2025-01-08 18:26:46,513][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.24 toks/s, output: 39.01 toks/s]
WARNING 01-08 18:26:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:46,728][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:49,039][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.31s/it, est. speed input: 302.53 toks/s, output: 12.12 toks/s]
[2025-01-08 18:26:49,075][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.39it/s, est. speed input: 4468.07 toks/s, output: 184.94 toks/s]
WARNING 01-08 18:26:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:49,291][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:51,401][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 294.01 toks/s, output: 13.75 toks/s]
[2025-01-08 18:26:51,401][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.64it/s, est. speed input: 4114.90 toks/s, output: 192.47 toks/s]
WARNING 01-08 18:26:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:51,602][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:52,499][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 779.80 toks/s, output: 32.35 toks/s]
[2025-01-08 18:26:52,500][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1650.32 toks/s, output: 64.67 toks/s]
WARNING 01-08 18:26:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:52,700][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:53,555][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 725.91 toks/s, output: 33.95 toks/s]
[2025-01-08 18:26:53,589][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1467.15 toks/s, output: 67.56 toks/s]
WARNING 01-08 18:26:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:53,812][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:56,515][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 372.90 toks/s, output: 10.73 toks/s]
[2025-01-08 18:26:57,073][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.59it/s, est. speed input: 4326.85 toks/s, output: 134.60 toks/s]
[2025-01-08 18:26:57,074][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.29it/s, est. speed input: 4326.85 toks/s, output: 134.60 toks/s]
WARNING 01-08 18:26:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:57,322][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:26:59,599][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 320.17 toks/s, output: 12.74 toks/s]
[2025-01-08 18:26:59,600][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4504.76 toks/s, output: 178.26 toks/s]
WARNING 01-08 18:26:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:26:59,814][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:27:00,762][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1063.36 toks/s, output: 30.59 toks/s]
[2025-01-08 18:27:00,762][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2212.37 toks/s, output: 61.16 toks/s]
WARNING 01-08 18:27:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:27:00,964][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:27:01,833][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 838.53 toks/s, output: 33.36 toks/s]
[2025-01-08 18:27:01,868][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1692.03 toks/s, output: 66.40 toks/s]
WARNING 01-08 18:27:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:27:02,098][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:27:05,269][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 413.39 toks/s, output: 9.14 toks/s]
[2025-01-08 18:27:05,885][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.13it/s, est. speed input: 4167.14 toks/s, output: 99.82 toks/s]
[2025-01-08 18:27:06,124][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  4.58it/s, est. speed input: 4580.60 toks/s, output: 126.93 toks/s]
[2025-01-08 18:27:06,124][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.48it/s, est. speed input: 4580.60 toks/s, output: 126.93 toks/s]
WARNING 01-08 18:27:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:27:06,414][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:27:07,422][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1307.51 toks/s, output: 28.79 toks/s]
[2025-01-08 18:27:07,422][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2689.47 toks/s, output: 57.56 toks/s]
[2025-01-08 18:27:13,940][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:27:13,995][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:27:15,650][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.65s/it]
[2025-01-08 18:27:17,244][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.62s/it]
[2025-01-08 18:27:18,814][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 18:27:19,329][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 18:27:19,329][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.33s/it]
[2025-01-08 18:27:29,121][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:27:29,641][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:27:29,694][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:27:31,504][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 18:27:33,095][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 18:27:34,633][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:27:35,120][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 18:27:35,120][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:27:48,873][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:27:49,202][root][INFO] - Loading VLLM model.
WARNING 01-08 18:27:49 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:27:49 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:27:49 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:27:49 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:27:50,260][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:27:51,579][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:27:51,967][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 18:27:53,272][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:27:54,621][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:27:54,621][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:27:54 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:28:08 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:28:09 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:28:09 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:28:30 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:28:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:30,905][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:33,720][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.81s/it, est. speed input: 179.41 toks/s, output: 10.30 toks/s]
[2025-01-08 18:28:33,720][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.68it/s, est. speed input: 2869.85 toks/s, output: 164.80 toks/s]
WARNING 01-08 18:28:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:33,922][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:34,716][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.53 toks/s, output: 39.08 toks/s]
[2025-01-08 18:28:34,716][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.53 toks/s, output: 39.08 toks/s]
WARNING 01-08 18:28:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:34,935][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:37,232][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 304.38 toks/s, output: 12.19 toks/s]
[2025-01-08 18:28:37,818][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.70it/s, est. speed input: 3636.85 toks/s, output: 161.98 toks/s]
[2025-01-08 18:28:37,818][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.20it/s, est. speed input: 3636.85 toks/s, output: 161.98 toks/s]
WARNING 01-08 18:28:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:38,062][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:40,171][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.91 toks/s, output: 13.75 toks/s]
[2025-01-08 18:28:40,172][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4113.60 toks/s, output: 192.41 toks/s]
WARNING 01-08 18:28:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:40,380][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:41,273][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 783.37 toks/s, output: 32.50 toks/s]
[2025-01-08 18:28:41,273][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1657.92 toks/s, output: 64.97 toks/s]
WARNING 01-08 18:28:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:41,479][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:42,331][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 728.03 toks/s, output: 34.05 toks/s]
[2025-01-08 18:28:42,365][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.26it/s, est. speed input: 1471.26 toks/s, output: 67.75 toks/s]
WARNING 01-08 18:28:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:42,609][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:45,310][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.27 toks/s, output: 10.74 toks/s]
[2025-01-08 18:28:45,976][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.58it/s, est. speed input: 3602.76 toks/s, output: 113.17 toks/s]
[2025-01-08 18:28:46,160][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.66it/s, est. speed input: 3700.30 toks/s, output: 127.60 toks/s]
[2025-01-08 18:28:48,150][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.20it/s, est. speed input: 2552.93 toks/s, output: 116.05 toks/s]
[2025-01-08 18:28:48,151][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.53it/s, est. speed input: 2552.93 toks/s, output: 116.05 toks/s]
WARNING 01-08 18:28:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:48,409][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:50,685][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 323.05 toks/s, output: 12.75 toks/s]
[2025-01-08 18:28:50,685][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4510.89 toks/s, output: 178.40 toks/s]
WARNING 01-08 18:28:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:50,906][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:51,866][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 1049.74 toks/s, output: 30.20 toks/s]
[2025-01-08 18:28:51,867][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 2183.99 toks/s, output: 60.38 toks/s]
WARNING 01-08 18:28:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:52,076][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:52,946][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 845.24 toks/s, output: 33.35 toks/s]
[2025-01-08 18:28:52,980][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1698.50 toks/s, output: 66.39 toks/s]
WARNING 01-08 18:28:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:53,215][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:56,402][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.19s/it, est. speed input: 413.20 toks/s, output: 9.10 toks/s]
[2025-01-08 18:28:56,825][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  3.28it/s, est. speed input: 3293.31 toks/s, output: 77.00 toks/s]
[2025-01-08 18:28:57,195][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  3.63it/s, est. speed input: 3664.36 toks/s, output: 100.25 toks/s]
[2025-01-08 18:28:57,441][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  3.69it/s, est. speed input: 3761.21 toks/s, output: 111.92 toks/s]
[2025-01-08 18:28:58,237][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.24it/s, est. speed input: 3720.37 toks/s, output: 133.21 toks/s]
[2025-01-08 18:28:58,237][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.79it/s, est. speed input: 3720.37 toks/s, output: 133.21 toks/s]
WARNING 01-08 18:28:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:28:58,536][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:28:59,545][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1306.71 toks/s, output: 28.77 toks/s]
[2025-01-08 18:28:59,545][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2693.77 toks/s, output: 57.52 toks/s]
[2025-01-08 18:29:06,221][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:29:06,274][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:29:08,023][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 18:29:09,686][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:29:11,332][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 18:29:11,872][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:29:11,872][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:29:21,420][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:29:21,994][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:29:22,047][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:29:23,843][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.80s/it]
[2025-01-08 18:29:25,476][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:29:27,029][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:29:27,526][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:29:27,526][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:29:41,299][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:29:41,603][root][INFO] - Loading VLLM model.
WARNING 01-08 18:29:41 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:29:41 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:29:42 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:29:42 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:29:42,552][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:29:43,861][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:29:44,250][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 18:29:45,549][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 18:29:46,882][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:29:46,882][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 18:29:47 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:30:00 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:30:01 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:30:01 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:30:22 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:30:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:23,029][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:25,626][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.60s/it, est. speed input: 194.51 toks/s, output: 11.17 toks/s]
[2025-01-08 18:30:25,627][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.16it/s, est. speed input: 3111.34 toks/s, output: 178.67 toks/s]
WARNING 01-08 18:30:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:25,829][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:26,622][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.51 toks/s, output: 39.08 toks/s]
[2025-01-08 18:30:26,623][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 713.51 toks/s, output: 39.08 toks/s]
WARNING 01-08 18:30:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:26,844][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:29,140][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 304.38 toks/s, output: 12.19 toks/s]
[2025-01-08 18:30:29,727][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.70it/s, est. speed input: 3637.00 toks/s, output: 161.99 toks/s]
[2025-01-08 18:30:29,727][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.20it/s, est. speed input: 3637.00 toks/s, output: 161.99 toks/s]
WARNING 01-08 18:30:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:29,958][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:32,064][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 294.43 toks/s, output: 13.77 toks/s]
[2025-01-08 18:30:32,065][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.65it/s, est. speed input: 4120.87 toks/s, output: 192.75 toks/s]
WARNING 01-08 18:30:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:32,269][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:33,162][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 783.17 toks/s, output: 32.49 toks/s]
[2025-01-08 18:30:33,162][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1657.48 toks/s, output: 64.95 toks/s]
WARNING 01-08 18:30:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:33,366][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:34,222][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 724.49 toks/s, output: 33.89 toks/s]
[2025-01-08 18:30:34,256][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1464.45 toks/s, output: 67.43 toks/s]
WARNING 01-08 18:30:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:34,483][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:37,201][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.72s/it, est. speed input: 370.91 toks/s, output: 10.67 toks/s]
[2025-01-08 18:30:37,923][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  4.08it/s, est. speed input: 3233.28 toks/s, output: 102.34 toks/s]
[2025-01-08 18:30:38,064][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.29it/s, est. speed input: 3387.20 toks/s, output: 117.57 toks/s]
[2025-01-08 18:30:39,372][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  2.95it/s, est. speed input: 2893.20 toks/s, output: 131.11 toks/s]
[2025-01-08 18:30:39,372][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  2.86it/s, est. speed input: 2893.20 toks/s, output: 131.11 toks/s]
WARNING 01-08 18:30:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:39,624][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:41,901][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.83 toks/s, output: 12.74 toks/s]
[2025-01-08 18:30:41,901][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4510.45 toks/s, output: 178.27 toks/s]
WARNING 01-08 18:30:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:42,118][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:43,061][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1068.82 toks/s, output: 30.75 toks/s]
[2025-01-08 18:30:43,061][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2223.56 toks/s, output: 61.47 toks/s]
WARNING 01-08 18:30:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:43,266][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:44,135][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 845.71 toks/s, output: 33.37 toks/s]
[2025-01-08 18:30:44,169][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1699.46 toks/s, output: 66.43 toks/s]
WARNING 01-08 18:30:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:44,401][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:47,582][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 414.04 toks/s, output: 9.12 toks/s]
[2025-01-08 18:30:48,026][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:03<00:01,  3.63it/s, est. speed input: 3644.80 toks/s, output: 85.26 toks/s]
[2025-01-08 18:30:48,927][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  3.17it/s, est. speed input: 3514.41 toks/s, output: 101.66 toks/s]
[2025-01-08 18:30:49,056][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  3.46it/s, est. speed input: 3707.17 toks/s, output: 119.89 toks/s]
[2025-01-08 18:30:50,526][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.06it/s, est. speed input: 3051.29 toks/s, output: 121.31 toks/s]
[2025-01-08 18:30:50,526][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.29it/s, est. speed input: 3051.29 toks/s, output: 121.31 toks/s]
WARNING 01-08 18:30:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:30:50,820][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:30:51,832][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1301.65 toks/s, output: 28.66 toks/s]
[2025-01-08 18:30:51,832][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2683.33 toks/s, output: 57.30 toks/s]
[2025-01-08 18:30:58,518][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:30:58,571][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:31:00,323][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 18:31:02,004][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:31:03,634][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 18:31:04,161][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:31:04,162][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:31:13,989][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:31:14,458][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:31:14,510][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:31:16,378][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 18:31:18,032][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 18:31:19,632][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:31:20,160][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:31:20,161][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:31:33,954][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:31:34,287][root][INFO] - Loading VLLM model.
WARNING 01-08 18:31:34 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:31:34 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:31:35 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:31:35 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:31:35,436][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:31:36,753][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:31:37,146][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:31:38,445][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 18:31:39,781][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:31:39,781][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:31:40 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:31:53 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:31:54 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:31:54 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:32:16 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:32:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:16,853][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:19,740][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.89s/it, est. speed input: 174.97 toks/s, output: 10.05 toks/s]
[2025-01-08 18:32:19,740][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.54it/s, est. speed input: 2798.92 toks/s, output: 160.73 toks/s]
WARNING 01-08 18:32:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:19,955][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:20,752][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 710.81 toks/s, output: 38.93 toks/s]
[2025-01-08 18:32:20,752][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 710.81 toks/s, output: 38.93 toks/s]
WARNING 01-08 18:32:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:20,982][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:23,283][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.82 toks/s, output: 12.17 toks/s]
[2025-01-08 18:32:23,319][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4486.88 toks/s, output: 185.72 toks/s]
WARNING 01-08 18:32:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:23,546][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:25,658][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.66 toks/s, output: 13.74 toks/s]
[2025-01-08 18:32:25,659][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4110.09 toks/s, output: 192.25 toks/s]
WARNING 01-08 18:32:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:25,875][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:26,771][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 780.34 toks/s, output: 32.37 toks/s]
[2025-01-08 18:32:26,772][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1651.35 toks/s, output: 64.71 toks/s]
WARNING 01-08 18:32:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:27,009][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:27,865][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 724.56 toks/s, output: 33.89 toks/s]
[2025-01-08 18:32:27,899][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1464.52 toks/s, output: 67.44 toks/s]
WARNING 01-08 18:32:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:28,137][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:30,838][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.24 toks/s, output: 10.74 toks/s]
[2025-01-08 18:32:31,396][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4330.64 toks/s, output: 134.72 toks/s]
[2025-01-08 18:32:31,396][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4330.64 toks/s, output: 134.72 toks/s]
WARNING 01-08 18:32:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:31,646][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:33,927][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.23 toks/s, output: 12.71 toks/s]
[2025-01-08 18:32:33,928][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4504.78 toks/s, output: 177.95 toks/s]
WARNING 01-08 18:32:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:34,145][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:35,091][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1065.48 toks/s, output: 30.65 toks/s]
[2025-01-08 18:32:35,091][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2216.67 toks/s, output: 61.28 toks/s]
WARNING 01-08 18:32:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:35,306][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:36,178][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 836.11 toks/s, output: 33.26 toks/s]
[2025-01-08 18:32:36,213][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1687.20 toks/s, output: 66.21 toks/s]
WARNING 01-08 18:32:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:36,456][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:39,787][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:43,  3.33s/it, est. speed input: 395.46 toks/s, output: 8.71 toks/s]
[2025-01-08 18:32:40,539][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  4.12it/s, est. speed input: 4200.49 toks/s, output: 102.39 toks/s]
[2025-01-08 18:32:40,759][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  4.16it/s, est. speed input: 4290.00 toks/s, output: 116.44 toks/s]
[2025-01-08 18:32:40,759][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.25it/s, est. speed input: 4290.00 toks/s, output: 116.44 toks/s]
WARNING 01-08 18:32:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:41,084][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:42,078][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 1401.62 toks/s, output: 28.17 toks/s]
[2025-01-08 18:32:42,096][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2679.04 toks/s, output: 56.35 toks/s]
WARNING 01-08 18:32:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:32:42,316][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:32:43,345][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.03s/it, est. speed input: 1332.29 toks/s, output: 28.18 toks/s]
[2025-01-08 18:32:43,346][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.94it/s, est. speed input: 2764.61 toks/s, output: 56.34 toks/s]
[2025-01-08 18:32:50,234][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:32:50,287][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:32:52,070][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.78s/it]
[2025-01-08 18:32:53,777][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 18:32:55,416][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:32:55,961][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 18:32:55,961][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 18:33:05,789][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:33:06,339][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:33:06,392][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:33:08,268][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 18:33:09,946][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 18:33:11,599][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 18:33:12,146][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.25s/it]
[2025-01-08 18:33:12,147][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.44s/it]
[2025-01-08 18:33:25,803][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:33:26,239][root][INFO] - Loading VLLM model.
WARNING 01-08 18:33:26 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:33:26 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:33:27 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:33:27 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:33:27,225][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:33:28,573][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.35s/it]
[2025-01-08 18:33:28,963][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.27it/s]
[2025-01-08 18:33:30,270][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:33:31,616][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:33:31,617][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 18:33:31 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:33:45 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:33:46 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:33:46 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:34:07 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:34:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:08,135][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:10,783][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.65s/it, est. speed input: 190.72 toks/s, output: 10.95 toks/s]
[2025-01-08 18:34:10,783][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.04it/s, est. speed input: 3050.69 toks/s, output: 175.19 toks/s]
WARNING 01-08 18:34:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:10,991][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:11,790][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.88 toks/s, output: 38.82 toks/s]
[2025-01-08 18:34:11,790][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.88 toks/s, output: 38.82 toks/s]
WARNING 01-08 18:34:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:12,013][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:14,314][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.79 toks/s, output: 12.17 toks/s]
[2025-01-08 18:34:14,350][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4486.32 toks/s, output: 185.70 toks/s]
WARNING 01-08 18:34:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:14,572][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:16,682][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.88 toks/s, output: 13.75 toks/s]
[2025-01-08 18:34:16,683][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4113.14 toks/s, output: 192.39 toks/s]
WARNING 01-08 18:34:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:16,890][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:17,785][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 781.35 toks/s, output: 32.42 toks/s]
[2025-01-08 18:34:17,786][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1653.59 toks/s, output: 64.80 toks/s]
WARNING 01-08 18:34:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:17,994][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:18,848][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 726.45 toks/s, output: 33.98 toks/s]
[2025-01-08 18:34:18,882][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1468.21 toks/s, output: 67.61 toks/s]
WARNING 01-08 18:34:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:19,114][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:21,810][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.91 toks/s, output: 10.76 toks/s]
[2025-01-08 18:34:22,367][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4337.99 toks/s, output: 134.95 toks/s]
[2025-01-08 18:34:22,367][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4337.99 toks/s, output: 134.95 toks/s]
WARNING 01-08 18:34:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:22,590][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:24,868][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 320.08 toks/s, output: 12.73 toks/s]
[2025-01-08 18:34:24,869][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4506.14 toks/s, output: 178.21 toks/s]
WARNING 01-08 18:34:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:25,095][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:26,038][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1069.03 toks/s, output: 30.76 toks/s]
[2025-01-08 18:34:26,039][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2224.13 toks/s, output: 61.49 toks/s]
WARNING 01-08 18:34:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:26,249][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:27,287][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.04s/it, est. speed input: 702.27 toks/s, output: 27.94 toks/s]
[2025-01-08 18:34:27,322][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.86it/s, est. speed input: 1425.84 toks/s, output: 55.95 toks/s]
WARNING 01-08 18:34:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:27,571][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:30,740][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 413.75 toks/s, output: 9.15 toks/s]
[2025-01-08 18:34:31,253][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.28it/s, est. speed input: 4287.67 toks/s, output: 101.31 toks/s]
[2025-01-08 18:34:31,533][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.65it/s, est. speed input: 4656.73 toks/s, output: 126.98 toks/s]
[2025-01-08 18:34:31,533][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.53it/s, est. speed input: 4656.73 toks/s, output: 126.98 toks/s]
WARNING 01-08 18:34:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:34:31,841][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:34:32,854][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1299.88 toks/s, output: 28.62 toks/s]
[2025-01-08 18:34:32,855][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2673.72 toks/s, output: 57.22 toks/s]
[2025-01-08 18:34:39,461][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:34:39,514][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:34:41,268][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 18:34:42,967][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 18:34:44,614][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:34:45,144][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:34:45,144][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:34:55,104][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:34:55,707][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:34:55,760][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:34:57,606][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 18:34:59,274][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 18:35:00,872][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:35:01,379][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 18:35:01,379][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:35:15,156][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:35:15,432][root][INFO] - Loading VLLM model.
WARNING 01-08 18:35:19 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:35:19 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:35:19 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:35:19 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:35:19,933][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:35:21,246][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:35:21,635][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 18:35:22,943][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:35:24,282][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:35:24,282][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:35:24 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:35:38 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:35:38 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:35:38 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:36:00 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:36:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:00,809][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:03,763][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.95s/it, est. speed input: 170.93 toks/s, output: 9.82 toks/s]
[2025-01-08 18:36:03,764][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.41it/s, est. speed input: 2734.19 toks/s, output: 157.01 toks/s]
WARNING 01-08 18:36:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:03,965][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:04,779][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 695.59 toks/s, output: 38.10 toks/s]
[2025-01-08 18:36:04,779][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 695.59 toks/s, output: 38.10 toks/s]
WARNING 01-08 18:36:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:04,997][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:07,299][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.67 toks/s, output: 12.16 toks/s]
[2025-01-08 18:36:07,335][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4484.71 toks/s, output: 185.63 toks/s]
WARNING 01-08 18:36:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:07,552][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:09,664][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.57 toks/s, output: 13.73 toks/s]
[2025-01-08 18:36:09,665][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4108.83 toks/s, output: 192.19 toks/s]
WARNING 01-08 18:36:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:09,868][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:10,766][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 779.00 toks/s, output: 32.32 toks/s]
[2025-01-08 18:36:10,766][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1648.66 toks/s, output: 64.61 toks/s]
WARNING 01-08 18:36:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:10,969][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:11,825][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 724.56 toks/s, output: 33.89 toks/s]
[2025-01-08 18:36:11,859][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1464.47 toks/s, output: 67.43 toks/s]
WARNING 01-08 18:36:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:12,083][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:14,784][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.22 toks/s, output: 10.74 toks/s]
[2025-01-08 18:36:15,341][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4330.94 toks/s, output: 134.73 toks/s]
[2025-01-08 18:36:15,342][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4330.94 toks/s, output: 134.73 toks/s]
WARNING 01-08 18:36:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:15,578][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:17,859][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 319.63 toks/s, output: 12.71 toks/s]
[2025-01-08 18:36:17,860][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4491.86 toks/s, output: 177.96 toks/s]
WARNING 01-08 18:36:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:18,080][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:19,029][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1062.63 toks/s, output: 30.57 toks/s]
[2025-01-08 18:36:19,029][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2210.82 toks/s, output: 61.12 toks/s]
WARNING 01-08 18:36:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:19,236][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:20,111][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 833.45 toks/s, output: 33.15 toks/s]
[2025-01-08 18:36:20,146][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1681.75 toks/s, output: 65.99 toks/s]
WARNING 01-08 18:36:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:20,399][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:23,567][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 413.86 toks/s, output: 9.15 toks/s]
[2025-01-08 18:36:23,894][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:03<00:01,  3.81it/s, est. speed input: 3762.31 toks/s, output: 87.00 toks/s]
[2025-01-08 18:36:24,169][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.27it/s, est. speed input: 4182.52 toks/s, output: 108.22 toks/s]
[2025-01-08 18:36:24,413][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  4.85it/s, est. speed input: 4592.15 toks/s, output: 134.06 toks/s]
[2025-01-08 18:36:24,413][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.49it/s, est. speed input: 4592.15 toks/s, output: 134.06 toks/s]
WARNING 01-08 18:36:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:36:24,715][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:36:25,940][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1075.37 toks/s, output: 23.68 toks/s]
[2025-01-08 18:36:25,941][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.45it/s, est. speed input: 3361.30 toks/s, output: 71.01 toks/s]
[2025-01-08 18:36:32,567][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:36:32,621][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:36:34,326][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 18:36:35,964][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 18:36:37,547][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:36:38,071][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:36:38,072][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:36:47,692][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:36:48,245][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:36:48,298][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:36:50,122][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 18:36:51,730][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:36:53,285][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:36:53,795][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:36:53,795][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:37:07,434][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:37:07,734][root][INFO] - Loading VLLM model.
WARNING 01-08 18:37:07 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:37:07 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:37:08 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:37:08 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:37:08,784][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:37:10,107][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:37:10,496][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:37:11,803][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:37:13,147][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:37:13,148][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:37:13 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:37:27 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:37:27 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:37:27 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:37:49 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:37:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:49,611][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:37:52,128][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.52s/it, est. speed input: 200.70 toks/s, output: 11.53 toks/s]
[2025-01-08 18:37:52,128][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.36it/s, est. speed input: 3210.43 toks/s, output: 184.36 toks/s]
WARNING 01-08 18:37:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:52,330][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:37:53,143][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 696.11 toks/s, output: 38.13 toks/s]
[2025-01-08 18:37:53,144][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 696.11 toks/s, output: 38.13 toks/s]
WARNING 01-08 18:37:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:53,361][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:37:55,663][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.68 toks/s, output: 12.16 toks/s]
[2025-01-08 18:37:55,700][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4484.89 toks/s, output: 185.64 toks/s]
WARNING 01-08 18:37:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:55,926][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:37:58,102][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.18s/it, est. speed input: 284.97 toks/s, output: 13.33 toks/s]
[2025-01-08 18:37:58,103][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.43it/s, est. speed input: 3988.51 toks/s, output: 186.56 toks/s]
WARNING 01-08 18:37:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:58,305][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:37:59,214][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 769.85 toks/s, output: 31.94 toks/s]
[2025-01-08 18:37:59,214][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1629.33 toks/s, output: 63.85 toks/s]
WARNING 01-08 18:37:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:37:59,416][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:00,271][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 725.74 toks/s, output: 33.94 toks/s]
[2025-01-08 18:38:00,305][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1466.60 toks/s, output: 67.53 toks/s]
WARNING 01-08 18:38:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:00,544][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:03,241][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.81 toks/s, output: 10.75 toks/s]
[2025-01-08 18:38:03,799][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4335.78 toks/s, output: 134.88 toks/s]
[2025-01-08 18:38:03,799][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4335.78 toks/s, output: 134.88 toks/s]
WARNING 01-08 18:38:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:04,032][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:06,319][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.29s/it, est. speed input: 318.74 toks/s, output: 12.68 toks/s]
[2025-01-08 18:38:06,320][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.12it/s, est. speed input: 4471.65 toks/s, output: 177.47 toks/s]
WARNING 01-08 18:38:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:06,537][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:07,481][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1067.82 toks/s, output: 30.72 toks/s]
[2025-01-08 18:38:07,481][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2221.63 toks/s, output: 61.42 toks/s]
WARNING 01-08 18:38:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:07,687][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:08,558][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 836.95 toks/s, output: 33.29 toks/s]
[2025-01-08 18:38:08,592][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1689.01 toks/s, output: 66.28 toks/s]
WARNING 01-08 18:38:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:08,822][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:11,983][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.16s/it, est. speed input: 414.87 toks/s, output: 9.18 toks/s]
[2025-01-08 18:38:12,488][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:03<00:02,  2.83it/s, est. speed input: 2866.39 toks/s, output: 68.48 toks/s]
[2025-01-08 18:38:12,785][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  2.91it/s, est. speed input: 2982.13 toks/s, output: 78.48 toks/s]
[2025-01-08 18:38:12,998][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:04<00:00,  4.26it/s, est. speed input: 3781.00 toks/s, output: 120.93 toks/s]
[2025-01-08 18:38:13,168][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  5.18it/s, est. speed input: 4236.83 toks/s, output: 150.73 toks/s]
[2025-01-08 18:38:13,168][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.22it/s, est. speed input: 4236.83 toks/s, output: 150.73 toks/s]
WARNING 01-08 18:38:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:38:13,461][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:38:14,472][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1302.57 toks/s, output: 28.68 toks/s]
[2025-01-08 18:38:14,473][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2678.71 toks/s, output: 57.33 toks/s]
[2025-01-08 18:38:21,421][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:38:21,474][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:38:23,207][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 18:38:24,888][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:38:26,537][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:38:27,063][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:38:27,063][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:38:36,626][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:38:37,140][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:38:37,192][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:38:39,038][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 18:38:40,645][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:38:42,208][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 18:38:42,703][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:38:42,704][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:38:56,153][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:38:56,445][root][INFO] - Loading VLLM model.
WARNING 01-08 18:38:56 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:38:56 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:38:57 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:38:57 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:38:57,442][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:38:58,761][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:38:59,151][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:39:00,467][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:39:01,806][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:39:01,807][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:39:02 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:39:15 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:39:16 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:39:16 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:39:37 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:39:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:38,200][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:40,886][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.69s/it, est. speed input: 188.04 toks/s, output: 10.80 toks/s]
[2025-01-08 18:39:40,887][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.96it/s, est. speed input: 3007.85 toks/s, output: 172.73 toks/s]
WARNING 01-08 18:39:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:41,093][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:41,906][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 696.45 toks/s, output: 38.14 toks/s]
[2025-01-08 18:39:41,906][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 696.45 toks/s, output: 38.14 toks/s]
WARNING 01-08 18:39:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:42,124][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:44,425][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.74 toks/s, output: 12.17 toks/s]
[2025-01-08 18:39:44,461][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4485.69 toks/s, output: 185.67 toks/s]
WARNING 01-08 18:39:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:44,678][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:46,789][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.80 toks/s, output: 13.74 toks/s]
[2025-01-08 18:39:46,789][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4112.00 toks/s, output: 192.33 toks/s]
WARNING 01-08 18:39:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:46,992][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:47,886][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 782.69 toks/s, output: 32.47 toks/s]
[2025-01-08 18:39:47,886][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1656.46 toks/s, output: 64.91 toks/s]
WARNING 01-08 18:39:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:48,092][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:48,947][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 725.10 toks/s, output: 33.92 toks/s]
[2025-01-08 18:39:48,981][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1465.60 toks/s, output: 67.49 toks/s]
WARNING 01-08 18:39:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:49,206][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:51,902][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.93 toks/s, output: 10.76 toks/s]
[2025-01-08 18:39:52,459][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4337.95 toks/s, output: 134.95 toks/s]
[2025-01-08 18:39:52,459][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4337.95 toks/s, output: 134.95 toks/s]
WARNING 01-08 18:39:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:52,678][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:54,939][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.26s/it, est. speed input: 322.52 toks/s, output: 12.83 toks/s]
[2025-01-08 18:39:54,940][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.19it/s, est. speed input: 4527.24 toks/s, output: 179.57 toks/s]
WARNING 01-08 18:39:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:55,158][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:56,103][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1066.76 toks/s, output: 30.69 toks/s]
[2025-01-08 18:39:56,104][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2219.08 toks/s, output: 61.35 toks/s]
WARNING 01-08 18:39:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:56,321][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:39:57,197][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 832.32 toks/s, output: 33.11 toks/s]
[2025-01-08 18:39:57,231][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1680.19 toks/s, output: 65.93 toks/s]
WARNING 01-08 18:39:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:39:57,467][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:40:00,635][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 413.82 toks/s, output: 9.15 toks/s]
[2025-01-08 18:40:01,326][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:03<00:02,  2.65it/s, est. speed input: 2724.07 toks/s, output: 66.86 toks/s]
[2025-01-08 18:40:01,664][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:00,  3.53it/s, est. speed input: 3450.83 toks/s, output: 105.07 toks/s]
[2025-01-08 18:40:02,031][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  3.88it/s, est. speed input: 3747.97 toks/s, output: 131.68 toks/s]
[2025-01-08 18:40:02,167][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  4.19it/s, est. speed input: 3918.89 toks/s, output: 148.74 toks/s]
[2025-01-08 18:40:02,167][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  2.98it/s, est. speed input: 3918.89 toks/s, output: 148.74 toks/s]
WARNING 01-08 18:40:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:40:02,468][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:40:03,489][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1290.57 toks/s, output: 28.42 toks/s]
[2025-01-08 18:40:03,489][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.96it/s, est. speed input: 2654.63 toks/s, output: 56.81 toks/s]
[2025-01-08 18:40:10,338][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:40:10,392][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:40:12,141][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 18:40:13,832][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:40:15,496][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:40:16,027][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:40:16,028][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:40:25,679][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:40:26,158][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:40:26,210][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:40:28,027][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 18:40:29,593][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 18:40:31,144][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:40:31,654][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:40:31,655][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:40:45,203][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:40:45,555][root][INFO] - Loading VLLM model.
WARNING 01-08 18:40:45 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:40:45 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:40:46 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:40:46 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:40:46,763][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:40:48,132][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 18:40:48,533][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 18:40:49,902][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 18:40:51,301][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:40:51,301][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 18:40:51 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:41:05 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:41:05 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:41:05 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:41:27 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:41:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:27,387][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:30,421][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.03s/it, est. speed input: 166.44 toks/s, output: 9.56 toks/s]
[2025-01-08 18:41:30,422][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.27it/s, est. speed input: 2662.54 toks/s, output: 152.90 toks/s]
WARNING 01-08 18:41:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:30,628][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:31,420][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 714.88 toks/s, output: 39.15 toks/s]
[2025-01-08 18:41:31,420][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 714.88 toks/s, output: 39.15 toks/s]
WARNING 01-08 18:41:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:31,640][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:33,941][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.89 toks/s, output: 12.17 toks/s]
[2025-01-08 18:41:33,977][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4487.73 toks/s, output: 185.76 toks/s]
WARNING 01-08 18:41:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:34,212][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:36,321][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 294.08 toks/s, output: 13.76 toks/s]
[2025-01-08 18:41:36,322][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.64it/s, est. speed input: 4115.93 toks/s, output: 192.52 toks/s]
WARNING 01-08 18:41:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:36,529][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:37,421][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 783.99 toks/s, output: 32.53 toks/s]
[2025-01-08 18:41:37,421][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1659.21 toks/s, output: 65.02 toks/s]
WARNING 01-08 18:41:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:37,630][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:38,483][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 726.86 toks/s, output: 34.00 toks/s]
[2025-01-08 18:41:38,518][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1468.80 toks/s, output: 67.63 toks/s]
WARNING 01-08 18:41:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:38,746][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:41,487][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.74s/it, est. speed input: 367.79 toks/s, output: 10.58 toks/s]
[2025-01-08 18:41:42,044][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.53it/s, est. speed input: 4278.94 toks/s, output: 133.11 toks/s]
[2025-01-08 18:41:42,044][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.24it/s, est. speed input: 4278.94 toks/s, output: 133.11 toks/s]
WARNING 01-08 18:41:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:42,283][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:44,581][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.30s/it, est. speed input: 317.27 toks/s, output: 12.62 toks/s]
[2025-01-08 18:41:44,582][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.09it/s, est. speed input: 4461.26 toks/s, output: 176.64 toks/s]
WARNING 01-08 18:41:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:44,807][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:45,749][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1070.84 toks/s, output: 30.81 toks/s]
[2025-01-08 18:41:45,749][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2227.76 toks/s, output: 61.59 toks/s]
WARNING 01-08 18:41:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:45,966][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:46,833][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 841.37 toks/s, output: 33.47 toks/s]
[2025-01-08 18:41:46,867][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.22it/s, est. speed input: 1697.72 toks/s, output: 66.62 toks/s]
WARNING 01-08 18:41:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:47,101][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:50,267][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 414.08 toks/s, output: 9.16 toks/s]
[2025-01-08 18:41:50,823][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  3.86it/s, est. speed input: 3885.55 toks/s, output: 92.42 toks/s]
[2025-01-08 18:41:51,126][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:04<00:00,  4.23it/s, est. speed input: 4254.48 toks/s, output: 117.27 toks/s]
[2025-01-08 18:41:51,144][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.46it/s, est. speed input: 4560.44 toks/s, output: 134.33 toks/s]
WARNING 01-08 18:41:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:41:51,438][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:41:52,444][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1309.31 toks/s, output: 28.83 toks/s]
[2025-01-08 18:41:52,444][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.99it/s, est. speed input: 2693.15 toks/s, output: 57.64 toks/s]
[2025-01-08 18:41:58,705][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:41:58,758][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:42:00,445][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:42:02,050][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:42:03,648][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:42:04,172][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:42:04,172][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:42:13,802][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:42:14,278][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:42:14,331][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:42:16,170][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 18:42:17,811][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 18:42:19,476][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 18:42:19,983][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:42:19,983][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 18:42:33,418][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:42:33,691][root][INFO] - Loading VLLM model.
WARNING 01-08 18:42:33 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:42:33 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:42:34 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:42:34 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:42:34,596][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:42:35,908][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:42:36,292][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 18:42:37,590][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 18:42:38,933][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:42:38,934][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 18:42:39 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:42:53 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:42:53 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:42:53 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:43:15 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:43:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:15,486][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:18,031][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.54s/it, est. speed input: 198.46 toks/s, output: 11.40 toks/s]
[2025-01-08 18:43:18,032][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.29it/s, est. speed input: 3174.56 toks/s, output: 182.30 toks/s]
WARNING 01-08 18:43:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:18,234][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:19,049][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 694.56 toks/s, output: 38.04 toks/s]
[2025-01-08 18:43:19,049][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 694.56 toks/s, output: 38.04 toks/s]
WARNING 01-08 18:43:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:19,269][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:21,567][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 304.20 toks/s, output: 12.19 toks/s]
[2025-01-08 18:43:21,603][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.43it/s, est. speed input: 4492.17 toks/s, output: 185.94 toks/s]
WARNING 01-08 18:43:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:21,825][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:23,936][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.79 toks/s, output: 13.74 toks/s]
[2025-01-08 18:43:23,936][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4111.81 toks/s, output: 192.33 toks/s]
WARNING 01-08 18:43:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:24,139][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:25,033][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 782.27 toks/s, output: 32.45 toks/s]
[2025-01-08 18:43:25,033][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1655.57 toks/s, output: 64.88 toks/s]
WARNING 01-08 18:43:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:25,235][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:26,088][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 727.06 toks/s, output: 34.01 toks/s]
[2025-01-08 18:43:26,122][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.26it/s, est. speed input: 1469.34 toks/s, output: 67.66 toks/s]
WARNING 01-08 18:43:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:26,348][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:29,042][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.69s/it, est. speed input: 374.19 toks/s, output: 10.77 toks/s]
[2025-01-08 18:43:29,599][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.61it/s, est. speed input: 4339.96 toks/s, output: 135.01 toks/s]
[2025-01-08 18:43:29,600][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.31it/s, est. speed input: 4339.96 toks/s, output: 135.01 toks/s]
WARNING 01-08 18:43:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:29,821][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:32,097][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 320.39 toks/s, output: 12.74 toks/s]
[2025-01-08 18:43:32,097][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4513.08 toks/s, output: 178.38 toks/s]
WARNING 01-08 18:43:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:32,318][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:33,261][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1070.03 toks/s, output: 30.78 toks/s]
[2025-01-08 18:43:33,261][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2225.86 toks/s, output: 61.53 toks/s]
WARNING 01-08 18:43:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:33,480][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:34,349][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 838.82 toks/s, output: 33.37 toks/s]
[2025-01-08 18:43:34,384][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1692.75 toks/s, output: 66.42 toks/s]
WARNING 01-08 18:43:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:34,617][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:37,790][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 413.19 toks/s, output: 9.14 toks/s]
[2025-01-08 18:43:38,364][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.19it/s, est. speed input: 4212.74 toks/s, output: 100.34 toks/s]
[2025-01-08 18:43:39,465][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.33it/s, est. speed input: 3806.54 toks/s, output: 116.96 toks/s]
[2025-01-08 18:43:39,465][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  2.89it/s, est. speed input: 3806.54 toks/s, output: 116.96 toks/s]
WARNING 01-08 18:43:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:43:39,772][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:43:40,781][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1380.79 toks/s, output: 28.75 toks/s]
[2025-01-08 18:43:41,693][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.05it/s, est. speed input: 1410.71 toks/s, output: 58.30 toks/s]
[2025-01-08 18:43:41,693][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.04it/s, est. speed input: 1410.71 toks/s, output: 58.30 toks/s]
[2025-01-08 18:43:47,972][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:43:48,026][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:43:49,707][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 18:43:51,339][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 18:43:52,909][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:43:53,431][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:43:53,431][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:44:03,650][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:44:04,157][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:44:04,210][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:44:06,068][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 18:44:07,670][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 18:44:09,236][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 18:44:09,727][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:44:09,727][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:44:23,245][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:44:23,527][root][INFO] - Loading VLLM model.
WARNING 01-08 18:44:23 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:44:23 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:44:24 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:44:24 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:44:24,539][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:44:25,907][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 18:44:26,300][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.26it/s]
[2025-01-08 18:44:27,654][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 18:44:29,067][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:44:29,067][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 18:44:29 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:44:43 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:44:43 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:44:43 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:45:04 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:45:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:05,157][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:07,648][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.49s/it, est. speed input: 202.81 toks/s, output: 11.65 toks/s]
[2025-01-08 18:45:07,648][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.42it/s, est. speed input: 3244.04 toks/s, output: 186.29 toks/s]
WARNING 01-08 18:45:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:07,850][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:08,645][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.01 toks/s, output: 39.00 toks/s]
[2025-01-08 18:45:08,646][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.01 toks/s, output: 39.00 toks/s]
WARNING 01-08 18:45:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:08,865][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:11,167][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.71 toks/s, output: 12.17 toks/s]
[2025-01-08 18:45:11,203][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4485.33 toks/s, output: 185.66 toks/s]
WARNING 01-08 18:45:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:11,422][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:13,531][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 294.00 toks/s, output: 13.75 toks/s]
[2025-01-08 18:45:13,531][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.64it/s, est. speed input: 4114.87 toks/s, output: 192.47 toks/s]
WARNING 01-08 18:45:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:13,732][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:14,645][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 765.82 toks/s, output: 31.77 toks/s]
[2025-01-08 18:45:14,645][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.19it/s, est. speed input: 1620.79 toks/s, output: 63.52 toks/s]
WARNING 01-08 18:45:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:14,846][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:15,703][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 723.82 toks/s, output: 33.86 toks/s]
[2025-01-08 18:45:15,737][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1462.99 toks/s, output: 67.37 toks/s]
WARNING 01-08 18:45:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:15,962][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:18,659][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.84 toks/s, output: 10.76 toks/s]
[2025-01-08 18:45:19,216][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4337.90 toks/s, output: 134.94 toks/s]
[2025-01-08 18:45:19,216][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4337.90 toks/s, output: 134.94 toks/s]
WARNING 01-08 18:45:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:19,436][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:21,715][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.49 toks/s, output: 12.72 toks/s]
[2025-01-08 18:45:21,716][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4508.29 toks/s, output: 178.09 toks/s]
WARNING 01-08 18:45:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:21,934][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:22,879][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1067.03 toks/s, output: 30.70 toks/s]
[2025-01-08 18:45:22,879][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2219.61 toks/s, output: 61.36 toks/s]
WARNING 01-08 18:45:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:23,097][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:23,970][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 841.97 toks/s, output: 33.22 toks/s]
[2025-01-08 18:45:24,004][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1692.34 toks/s, output: 66.15 toks/s]
WARNING 01-08 18:45:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:24,236][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:27,411][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 414.75 toks/s, output: 9.13 toks/s]
[2025-01-08 18:45:27,986][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.18it/s, est. speed input: 4221.40 toks/s, output: 100.26 toks/s]
[2025-01-08 18:45:28,646][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.89it/s, est. speed input: 4185.55 toks/s, output: 120.18 toks/s]
[2025-01-08 18:45:28,646][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.17it/s, est. speed input: 4185.55 toks/s, output: 120.18 toks/s]
WARNING 01-08 18:45:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:45:28,952][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:45:29,969][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1295.93 toks/s, output: 28.54 toks/s]
[2025-01-08 18:45:29,969][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2671.54 toks/s, output: 57.05 toks/s]
[2025-01-08 18:45:36,226][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:45:36,280][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:45:37,985][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 18:45:39,575][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:45:41,137][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 18:45:41,674][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:45:41,674][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:45:51,287][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:45:51,796][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:45:51,849][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:45:53,658][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 18:45:55,276][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:45:56,862][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 18:45:57,358][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:45:57,358][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:46:10,955][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:46:11,250][root][INFO] - Loading VLLM model.
WARNING 01-08 18:46:11 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:46:11 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:46:12 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:46:12 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:46:12,752][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:46:14,077][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:46:14,470][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:46:15,789][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:46:17,134][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:46:17,134][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 18:46:17 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:46:31 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:46:31 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:46:31 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:46:53 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:46:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:46:53,521][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:46:56,065][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.54s/it, est. speed input: 198.52 toks/s, output: 11.40 toks/s]
[2025-01-08 18:46:56,066][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.29it/s, est. speed input: 3175.35 toks/s, output: 182.35 toks/s]
WARNING 01-08 18:46:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:46:56,272][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:46:57,073][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 707.43 toks/s, output: 38.75 toks/s]
[2025-01-08 18:46:57,073][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 707.43 toks/s, output: 38.75 toks/s]
WARNING 01-08 18:46:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:46:57,295][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:46:59,598][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.59 toks/s, output: 12.16 toks/s]
[2025-01-08 18:46:59,634][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.41it/s, est. speed input: 4483.51 toks/s, output: 185.58 toks/s]
WARNING 01-08 18:46:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:46:59,859][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:01,971][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.61 toks/s, output: 13.73 toks/s]
[2025-01-08 18:47:01,971][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4109.29 toks/s, output: 192.21 toks/s]
WARNING 01-08 18:47:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:02,176][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:03,072][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 781.09 toks/s, output: 32.40 toks/s]
[2025-01-08 18:47:03,072][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1653.09 toks/s, output: 64.78 toks/s]
WARNING 01-08 18:47:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:03,278][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:04,132][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 726.17 toks/s, output: 33.97 toks/s]
[2025-01-08 18:47:04,166][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1467.67 toks/s, output: 67.58 toks/s]
WARNING 01-08 18:47:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:04,397][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:07,095][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.63 toks/s, output: 10.75 toks/s]
[2025-01-08 18:47:07,653][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4334.62 toks/s, output: 134.84 toks/s]
[2025-01-08 18:47:07,653][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4334.62 toks/s, output: 134.84 toks/s]
WARNING 01-08 18:47:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:07,898][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:10,178][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.46 toks/s, output: 12.72 toks/s]
[2025-01-08 18:47:10,178][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4510.30 toks/s, output: 178.06 toks/s]
WARNING 01-08 18:47:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:10,419][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:11,375][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1054.63 toks/s, output: 30.34 toks/s]
[2025-01-08 18:47:11,375][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.09it/s, est. speed input: 2194.09 toks/s, output: 60.66 toks/s]
WARNING 01-08 18:47:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:11,595][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:12,469][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 841.22 toks/s, output: 33.19 toks/s]
[2025-01-08 18:47:12,503][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1690.80 toks/s, output: 66.09 toks/s]
WARNING 01-08 18:47:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:12,740][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:15,924][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 413.75 toks/s, output: 9.11 toks/s]
[2025-01-08 18:47:16,386][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.72it/s, est. speed input: 4704.46 toks/s, output: 109.74 toks/s]
[2025-01-08 18:47:17,180][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.15it/s, est. speed input: 4159.41 toks/s, output: 112.40 toks/s]
WARNING 01-08 18:47:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:47:17,477][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:47:18,514][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.04s/it, est. speed input: 1270.52 toks/s, output: 27.98 toks/s]
[2025-01-08 18:47:18,514][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.93it/s, est. speed input: 2619.13 toks/s, output: 55.93 toks/s]
[2025-01-08 18:47:24,835][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:47:24,888][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:47:26,570][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 18:47:28,176][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:47:29,778][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 18:47:30,294][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:47:30,295][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:47:39,824][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:47:40,358][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:47:40,411][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:47:42,218][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 18:47:43,832][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 18:47:45,378][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:47:45,877][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:47:45,877][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 18:47:59,288][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:47:59,587][root][INFO] - Loading VLLM model.
WARNING 01-08 18:47:59 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:47:59 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:48:00 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:48:00 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:48:00,555][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:48:01,868][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:48:02,257][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 18:48:03,576][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:48:04,912][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:48:04,912][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:48:05 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:48:18 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:48:19 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:48:19 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:48:40 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:48:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:41,242][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:43,700][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 205.49 toks/s, output: 11.80 toks/s]
[2025-01-08 18:48:43,700][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.51it/s, est. speed input: 3287.00 toks/s, output: 188.76 toks/s]
WARNING 01-08 18:48:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:43,902][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:44,703][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 706.31 toks/s, output: 38.68 toks/s]
[2025-01-08 18:48:44,704][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 706.31 toks/s, output: 38.68 toks/s]
WARNING 01-08 18:48:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:44,920][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:47,259][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.34s/it, est. speed input: 298.93 toks/s, output: 12.40 toks/s]
[2025-01-08 18:48:47,259][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.41it/s, est. speed input: 4482.79 toks/s, output: 185.98 toks/s]
WARNING 01-08 18:48:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:47,478][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:49,676][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.20s/it, est. speed input: 282.10 toks/s, output: 13.19 toks/s]
[2025-01-08 18:48:49,676][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.82it/s, est. speed input: 4230.30 toks/s, output: 197.87 toks/s]
WARNING 01-08 18:48:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:49,877][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:50,649][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 905.20 toks/s, output: 37.55 toks/s]
[2025-01-08 18:48:50,649][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 905.20 toks/s, output: 37.55 toks/s]
WARNING 01-08 18:48:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:50,851][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:51,629][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 877.63 toks/s, output: 39.83 toks/s]
[2025-01-08 18:48:51,629][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 877.63 toks/s, output: 39.83 toks/s]
WARNING 01-08 18:48:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:51,853][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:54,686][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.83s/it, est. speed input: 355.90 toks/s, output: 10.24 toks/s]
[2025-01-08 18:48:55,244][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  5.79it/s, est. speed input: 4459.88 toks/s, output: 138.04 toks/s]
[2025-01-08 18:48:55,244][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  4.42it/s, est. speed input: 4459.88 toks/s, output: 138.04 toks/s]
WARNING 01-08 18:48:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:55,470][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:57,859][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:33,  2.39s/it, est. speed input: 307.65 toks/s, output: 12.14 toks/s]
[2025-01-08 18:48:57,860][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.28it/s, est. speed input: 4611.04 toks/s, output: 182.03 toks/s]
WARNING 01-08 18:48:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:58,083][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:58,872][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1278.06 toks/s, output: 36.77 toks/s]
[2025-01-08 18:48:58,872][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1278.06 toks/s, output: 36.77 toks/s]
WARNING 01-08 18:48:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:48:59,073][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:48:59,870][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1004.02 toks/s, output: 38.90 toks/s]
[2025-01-08 18:48:59,870][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1004.02 toks/s, output: 38.90 toks/s]
WARNING 01-08 18:49:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:49:00,113][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:49:03,454][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:46,  3.34s/it, est. speed input: 394.18 toks/s, output: 8.68 toks/s]
[2025-01-08 18:49:04,148][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  4.85it/s, est. speed input: 4903.29 toks/s, output: 117.98 toks/s]
[2025-01-08 18:49:04,148][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.72it/s, est. speed input: 4903.29 toks/s, output: 117.98 toks/s]
WARNING 01-08 18:49:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:49:04,455][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:49:05,285][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1586.98 toks/s, output: 34.94 toks/s]
[2025-01-08 18:49:05,285][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1586.98 toks/s, output: 34.94 toks/s]
[2025-01-08 18:49:11,578][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:49:11,631][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:49:13,326][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:49:14,933][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:49:16,504][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:49:17,022][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:49:17,023][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:49:26,630][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:49:27,153][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:49:27,205][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:49:29,051][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 18:49:30,652][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:49:32,231][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 18:49:32,742][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 18:49:32,742][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 18:49:46,216][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:49:46,507][root][INFO] - Loading VLLM model.
WARNING 01-08 18:49:46 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:49:46 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:49:47 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:49:47 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:49:47,451][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:49:48,770][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 18:49:49,162][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:49:50,466][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:49:51,815][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:49:51,815][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:49:52 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:50:05 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:50:06 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:50:06 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:50:27 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:50:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:28,261][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:31,272][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.01s/it, est. speed input: 167.77 toks/s, output: 9.63 toks/s]
[2025-01-08 18:50:31,272][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.31it/s, est. speed input: 2683.71 toks/s, output: 154.11 toks/s]
WARNING 01-08 18:50:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:31,473][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:32,273][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 707.65 toks/s, output: 38.76 toks/s]
[2025-01-08 18:50:32,273][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 707.65 toks/s, output: 38.76 toks/s]
WARNING 01-08 18:50:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:32,495][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:34,805][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.31s/it, est. speed input: 302.60 toks/s, output: 12.12 toks/s]
[2025-01-08 18:50:34,842][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.39it/s, est. speed input: 4468.89 toks/s, output: 184.98 toks/s]
WARNING 01-08 18:50:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:35,069][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:37,191][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.12s/it, est. speed input: 292.32 toks/s, output: 13.67 toks/s]
[2025-01-08 18:50:37,191][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.60it/s, est. speed input: 4091.18 toks/s, output: 191.36 toks/s]
WARNING 01-08 18:50:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:37,397][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:38,305][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 770.26 toks/s, output: 31.96 toks/s]
[2025-01-08 18:50:38,305][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1630.14 toks/s, output: 63.88 toks/s]
WARNING 01-08 18:50:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:38,506][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:39,360][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 726.47 toks/s, output: 33.98 toks/s]
[2025-01-08 18:50:39,394][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1467.73 toks/s, output: 67.58 toks/s]
WARNING 01-08 18:50:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:39,617][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:42,314][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.72 toks/s, output: 10.75 toks/s]
[2025-01-08 18:50:42,872][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4336.13 toks/s, output: 134.89 toks/s]
[2025-01-08 18:50:42,872][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4336.13 toks/s, output: 134.89 toks/s]
WARNING 01-08 18:50:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:43,091][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:45,367][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.98 toks/s, output: 12.74 toks/s]
[2025-01-08 18:50:45,367][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4517.81 toks/s, output: 178.36 toks/s]
WARNING 01-08 18:50:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:45,573][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:46,516][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1069.28 toks/s, output: 30.76 toks/s]
[2025-01-08 18:50:46,516][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 2224.46 toks/s, output: 61.50 toks/s]
WARNING 01-08 18:50:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:46,739][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:47,609][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 844.75 toks/s, output: 33.33 toks/s]
[2025-01-08 18:50:47,643][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1697.64 toks/s, output: 66.36 toks/s]
WARNING 01-08 18:50:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:47,874][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:51,074][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.20s/it, est. speed input: 411.64 toks/s, output: 9.06 toks/s]
[2025-01-08 18:50:51,460][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.84it/s, est. speed input: 4782.68 toks/s, output: 111.00 toks/s]
[2025-01-08 18:50:52,322][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.15it/s, est. speed input: 4152.00 toks/s, output: 112.20 toks/s]
WARNING 01-08 18:50:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:50:52,637][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:50:53,647][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1303.69 toks/s, output: 28.71 toks/s]
[2025-01-08 18:50:53,647][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2687.51 toks/s, output: 57.39 toks/s]
[2025-01-08 18:50:59,971][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:51:00,024][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:51:01,690][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.67s/it]
[2025-01-08 18:51:03,306][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 18:51:04,876][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:51:05,396][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 18:51:05,396][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 18:51:14,974][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:51:15,502][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:51:15,554][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:51:17,347][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 18:51:18,934][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 18:51:20,478][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 18:51:20,968][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 18:51:20,969][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 18:51:34,530][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:51:34,821][root][INFO] - Loading VLLM model.
WARNING 01-08 18:51:34 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:51:34 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:51:35 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:51:35 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:51:35,708][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:51:37,016][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:51:37,399][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 18:51:38,689][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.00s/it]
[2025-01-08 18:51:40,022][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
[2025-01-08 18:51:40,022][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 18:51:40 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:51:54 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:51:54 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:51:54 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:52:16 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:52:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:16,496][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:19,615][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.12s/it, est. speed input: 161.92 toks/s, output: 9.30 toks/s]
[2025-01-08 18:52:19,616][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.13it/s, est. speed input: 2590.06 toks/s, output: 148.74 toks/s]
WARNING 01-08 18:52:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:19,834][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:20,632][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 709.89 toks/s, output: 38.88 toks/s]
[2025-01-08 18:52:20,632][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 709.89 toks/s, output: 38.88 toks/s]
WARNING 01-08 18:52:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:20,866][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:23,167][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.93 toks/s, output: 12.17 toks/s]
[2025-01-08 18:52:23,203][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4488.35 toks/s, output: 185.78 toks/s]
WARNING 01-08 18:52:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:23,424][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:25,532][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 294.14 toks/s, output: 13.76 toks/s]
[2025-01-08 18:52:25,533][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.64it/s, est. speed input: 4116.66 toks/s, output: 192.55 toks/s]
WARNING 01-08 18:52:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:25,740][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:26,634][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 782.27 toks/s, output: 32.45 toks/s]
[2025-01-08 18:52:26,634][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1655.57 toks/s, output: 64.88 toks/s]
WARNING 01-08 18:52:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:26,841][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:27,701][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 720.69 toks/s, output: 33.71 toks/s]
[2025-01-08 18:52:27,735][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1456.86 toks/s, output: 67.08 toks/s]
WARNING 01-08 18:52:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:27,965][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:30,662][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.81 toks/s, output: 10.75 toks/s]
[2025-01-08 18:52:31,219][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4336.48 toks/s, output: 134.90 toks/s]
[2025-01-08 18:52:31,220][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4336.48 toks/s, output: 134.90 toks/s]
WARNING 01-08 18:52:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:31,444][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:33,722][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.77 toks/s, output: 12.73 toks/s]
[2025-01-08 18:52:33,722][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.15it/s, est. speed input: 4514.89 toks/s, output: 178.24 toks/s]
WARNING 01-08 18:52:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:33,936][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:34,915][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.02it/s, est. speed input: 1030.18 toks/s, output: 29.64 toks/s]
[2025-01-08 18:52:34,915][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.04it/s, est. speed input: 2143.31 toks/s, output: 59.25 toks/s]
WARNING 01-08 18:52:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:35,125][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:35,996][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 843.67 toks/s, output: 33.29 toks/s]
[2025-01-08 18:52:36,030][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1695.45 toks/s, output: 66.27 toks/s]
WARNING 01-08 18:52:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:36,267][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:39,438][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.17s/it, est. speed input: 415.36 toks/s, output: 9.15 toks/s]
[2025-01-08 18:52:39,861][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.81it/s, est. speed input: 4771.61 toks/s, output: 111.30 toks/s]
[2025-01-08 18:52:40,655][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.19it/s, est. speed input: 4207.76 toks/s, output: 113.71 toks/s]
WARNING 01-08 18:52:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:52:40,962][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:52:41,975][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1301.10 toks/s, output: 28.65 toks/s]
[2025-01-08 18:52:41,976][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2681.81 toks/s, output: 57.27 toks/s]
[2025-01-08 18:52:48,347][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:52:48,401][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:52:50,157][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 18:52:51,826][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:52:53,462][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 18:52:54,010][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:52:54,010][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:53:03,998][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:53:04,497][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:53:04,549][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:53:06,480][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.93s/it]
[2025-01-08 18:53:08,225][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.82s/it]
[2025-01-08 18:53:09,914][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.76s/it]
[2025-01-08 18:53:10,445][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.28s/it]
[2025-01-08 18:53:10,445][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.47s/it]
[2025-01-08 18:53:23,878][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:53:24,205][root][INFO] - Loading VLLM model.
WARNING 01-08 18:53:24 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:53:24 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:53:24 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:53:24 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:53:25,191][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:53:26,564][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 18:53:26,966][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 18:53:28,322][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 18:53:29,714][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:53:29,715][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 18:53:30 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:53:43 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:53:44 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:53:44 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:54:06 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:54:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:07,205][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:10,190][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.98s/it, est. speed input: 169.20 toks/s, output: 9.72 toks/s]
[2025-01-08 18:54:10,190][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.36it/s, est. speed input: 2706.65 toks/s, output: 155.43 toks/s]
WARNING 01-08 18:54:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:10,414][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:11,209][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.08 toks/s, output: 39.00 toks/s]
[2025-01-08 18:54:11,209][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 712.08 toks/s, output: 39.00 toks/s]
WARNING 01-08 18:54:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:11,429][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:13,731][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.75 toks/s, output: 12.17 toks/s]
[2025-01-08 18:54:13,767][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4485.81 toks/s, output: 185.68 toks/s]
WARNING 01-08 18:54:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:13,985][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:16,096][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.76 toks/s, output: 13.74 toks/s]
[2025-01-08 18:54:16,096][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4111.45 toks/s, output: 192.31 toks/s]
WARNING 01-08 18:54:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:16,300][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:17,218][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.09it/s, est. speed input: 761.52 toks/s, output: 31.59 toks/s]
[2025-01-08 18:54:17,219][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.18it/s, est. speed input: 1611.63 toks/s, output: 63.16 toks/s]
WARNING 01-08 18:54:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:17,437][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:18,298][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 720.51 toks/s, output: 33.70 toks/s]
[2025-01-08 18:54:18,332][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1456.63 toks/s, output: 67.07 toks/s]
WARNING 01-08 18:54:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:18,556][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:21,257][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.19 toks/s, output: 10.74 toks/s]
[2025-01-08 18:54:21,814][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.60it/s, est. speed input: 4330.88 toks/s, output: 134.73 toks/s]
[2025-01-08 18:54:21,815][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.30it/s, est. speed input: 4330.88 toks/s, output: 134.73 toks/s]
WARNING 01-08 18:54:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:22,034][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:24,315][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.23 toks/s, output: 12.71 toks/s]
[2025-01-08 18:54:24,316][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.14it/s, est. speed input: 4507.38 toks/s, output: 177.95 toks/s]
WARNING 01-08 18:54:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:24,531][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:25,477][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1065.92 toks/s, output: 30.67 toks/s]
[2025-01-08 18:54:25,478][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 2217.67 toks/s, output: 61.31 toks/s]
WARNING 01-08 18:54:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:25,680][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:26,554][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 841.39 toks/s, output: 33.20 toks/s]
[2025-01-08 18:54:26,588][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1690.50 toks/s, output: 66.08 toks/s]
WARNING 01-08 18:54:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:26,821][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:30,012][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.19s/it, est. speed input: 412.76 toks/s, output: 9.09 toks/s]
[2025-01-08 18:54:30,367][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.29it/s, est. speed input: 5207.03 toks/s, output: 120.41 toks/s]
[2025-01-08 18:54:30,368][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.95it/s, est. speed input: 5207.03 toks/s, output: 120.41 toks/s]
WARNING 01-08 18:54:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:54:30,686][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:54:31,703][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1295.58 toks/s, output: 28.53 toks/s]
[2025-01-08 18:54:31,704][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2670.78 toks/s, output: 57.03 toks/s]
[2025-01-08 18:54:38,350][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:54:38,406][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:54:40,137][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 18:54:41,816][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:54:43,455][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 18:54:43,988][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:54:43,988][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:54:53,554][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:54:54,234][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:54:54,286][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:54:56,082][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 18:54:57,758][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 18:54:59,383][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:54:59,892][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:54:59,892][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 18:55:13,473][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:55:13,766][root][INFO] - Loading VLLM model.
WARNING 01-08 18:55:13 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:55:13 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:55:14 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:55:14 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:55:14,748][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:55:16,058][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 18:55:16,442][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 18:55:17,739][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 18:55:19,083][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 18:55:19,083][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 18:55:19 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:55:33 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:55:33 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:55:33 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:55:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 18:55:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:55:55,160][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:55:57,658][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 202.26 toks/s, output: 11.61 toks/s]
[2025-01-08 18:55:57,658][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.41it/s, est. speed input: 3235.32 toks/s, output: 185.79 toks/s]
WARNING 01-08 18:55:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:55:57,930][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:55:58,730][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.11 toks/s, output: 38.78 toks/s]
[2025-01-08 18:55:58,730][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 708.11 toks/s, output: 38.78 toks/s]
WARNING 01-08 18:55:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:55:58,947][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:01,288][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.34s/it, est. speed input: 298.66 toks/s, output: 12.39 toks/s]
[2025-01-08 18:56:01,288][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.41it/s, est. speed input: 4478.69 toks/s, output: 185.81 toks/s]
WARNING 01-08 18:56:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:01,507][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:03,703][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.20s/it, est. speed input: 282.37 toks/s, output: 13.21 toks/s]
[2025-01-08 18:56:03,703][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.83it/s, est. speed input: 4234.39 toks/s, output: 198.06 toks/s]
WARNING 01-08 18:56:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:03,914][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:04,685][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 907.00 toks/s, output: 37.63 toks/s]
[2025-01-08 18:56:04,685][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 907.00 toks/s, output: 37.63 toks/s]
WARNING 01-08 18:56:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:04,885][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:05,665][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 876.25 toks/s, output: 39.77 toks/s]
[2025-01-08 18:56:05,665][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 876.25 toks/s, output: 39.77 toks/s]
WARNING 01-08 18:56:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:05,891][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:08,724][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.83s/it, est. speed input: 355.93 toks/s, output: 10.24 toks/s]
[2025-01-08 18:56:09,280][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  5.79it/s, est. speed input: 4461.40 toks/s, output: 138.09 toks/s]
[2025-01-08 18:56:09,281][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  4.43it/s, est. speed input: 4461.40 toks/s, output: 138.09 toks/s]
WARNING 01-08 18:56:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:09,516][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:11,901][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:33,  2.39s/it, est. speed input: 308.14 toks/s, output: 12.16 toks/s]
[2025-01-08 18:56:11,902][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.29it/s, est. speed input: 4618.07 toks/s, output: 182.31 toks/s]
WARNING 01-08 18:56:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:12,123][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:12,907][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 1285.47 toks/s, output: 36.98 toks/s]
[2025-01-08 18:56:12,908][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1285.47 toks/s, output: 36.98 toks/s]
WARNING 01-08 18:56:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:13,109][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:13,905][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1006.00 toks/s, output: 38.98 toks/s]
[2025-01-08 18:56:13,905][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1006.00 toks/s, output: 38.98 toks/s]
WARNING 01-08 18:56:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:14,150][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:17,486][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:46,  3.34s/it, est. speed input: 394.79 toks/s, output: 8.69 toks/s]
[2025-01-08 18:56:17,841][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  5.46it/s, est. speed input: 5359.26 toks/s, output: 123.54 toks/s]
[2025-01-08 18:56:17,842][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  4.06it/s, est. speed input: 5359.26 toks/s, output: 123.54 toks/s]
WARNING 01-08 18:56:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:56:18,142][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:56:18,968][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1594.46 toks/s, output: 35.11 toks/s]
[2025-01-08 18:56:18,969][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1594.46 toks/s, output: 35.11 toks/s]
[2025-01-08 18:56:25,622][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:56:25,676][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:56:27,366][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 18:56:28,980][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 18:56:30,591][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 18:56:31,115][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 18:56:31,116][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 18:56:40,952][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:56:41,474][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:56:41,527][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:56:43,447][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 18:56:45,074][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 18:56:46,687][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 18:56:47,196][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:56:47,196][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 18:57:00,603][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:57:00,909][root][INFO] - Loading VLLM model.
WARNING 01-08 18:57:01 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:57:01 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:57:01 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:57:02 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:57:02,190][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:57:03,575][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 18:57:03,979][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 18:57:05,335][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 18:57:06,739][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 18:57:06,740][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 18:57:07 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:57:20 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:57:21 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:57:21 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:57:42 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:57:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:43,132][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:46,072][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.94s/it, est. speed input: 171.79 toks/s, output: 9.86 toks/s]
[2025-01-08 18:57:46,073][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.44it/s, est. speed input: 2747.99 toks/s, output: 157.81 toks/s]
WARNING 01-08 18:57:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:46,275][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:47,073][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 709.60 toks/s, output: 38.86 toks/s]
[2025-01-08 18:57:47,074][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 709.60 toks/s, output: 38.86 toks/s]
WARNING 01-08 18:57:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:47,292][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:49,592][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.91 toks/s, output: 12.17 toks/s]
[2025-01-08 18:57:49,628][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4488.17 toks/s, output: 185.78 toks/s]
WARNING 01-08 18:57:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:49,853][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:51,964][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:27,  2.11s/it, est. speed input: 293.70 toks/s, output: 13.74 toks/s]
[2025-01-08 18:57:51,965][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.63it/s, est. speed input: 4110.51 toks/s, output: 192.27 toks/s]
WARNING 01-08 18:57:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:52,167][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:53,065][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 778.65 toks/s, output: 32.30 toks/s]
[2025-01-08 18:57:53,065][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1647.89 toks/s, output: 64.58 toks/s]
WARNING 01-08 18:57:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:53,269][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:54,126][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 723.79 toks/s, output: 33.85 toks/s]
[2025-01-08 18:57:54,160][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.25it/s, est. speed input: 1462.99 toks/s, output: 67.37 toks/s]
WARNING 01-08 18:57:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:54,384][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:57:57,085][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.21 toks/s, output: 10.74 toks/s]
[2025-01-08 18:57:57,644][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.59it/s, est. speed input: 4329.62 toks/s, output: 134.69 toks/s]
[2025-01-08 18:57:57,644][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.29it/s, est. speed input: 4329.62 toks/s, output: 134.69 toks/s]
WARNING 01-08 18:57:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:57:57,898][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:58:00,180][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.28s/it, est. speed input: 322.01 toks/s, output: 12.71 toks/s]
[2025-01-08 18:58:00,181][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.13it/s, est. speed input: 4504.14 toks/s, output: 177.82 toks/s]
WARNING 01-08 18:58:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:58:00,400][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:58:01,360][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 1049.76 toks/s, output: 30.20 toks/s]
[2025-01-08 18:58:01,360][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 2184.05 toks/s, output: 60.38 toks/s]
WARNING 01-08 18:58:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:58:01,564][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:58:02,439][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 840.10 toks/s, output: 33.15 toks/s]
[2025-01-08 18:58:02,473][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1688.38 toks/s, output: 65.99 toks/s]
WARNING 01-08 18:58:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:58:02,704][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:58:05,891][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.19s/it, est. speed input: 413.29 toks/s, output: 9.10 toks/s]
[2025-01-08 18:58:06,203][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.99it/s, est. speed input: 4891.61 toks/s, output: 112.61 toks/s]
[2025-01-08 18:58:06,609][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.59it/s, est. speed input: 4728.67 toks/s, output: 118.82 toks/s]
WARNING 01-08 18:58:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:58:06,901][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:58:07,922][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1290.68 toks/s, output: 28.42 toks/s]
[2025-01-08 18:58:07,922][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.96it/s, est. speed input: 2660.67 toks/s, output: 56.82 toks/s]
[2025-01-08 18:58:14,583][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:58:14,638][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:58:16,357][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 18:58:18,039][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 18:58:19,689][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 18:58:20,217][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 18:58:20,217][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 18:58:29,832][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 18:58:30,312][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 18:58:30,365][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:58:32,271][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 18:58:33,956][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 18:58:35,577][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 18:58:36,080][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 18:58:36,080][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 18:58:49,605][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 18:58:49,921][root][INFO] - Loading VLLM model.
WARNING 01-08 18:58:50 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 18:58:50 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 18:58:50 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 18:58:50 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 18:58:51,098][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 18:58:52,434][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.34s/it]
[2025-01-08 18:58:52,822][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 18:58:54,127][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 18:58:55,467][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 18:58:55,467][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 18:58:55 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 18:59:09 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 18:59:10 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 18:59:10 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 18:59:31 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 18:59:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:31,903][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:34,894][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.99s/it, est. speed input: 168.86 toks/s, output: 9.70 toks/s]
[2025-01-08 18:59:34,895][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.35it/s, est. speed input: 2701.09 toks/s, output: 155.11 toks/s]
WARNING 01-08 18:59:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:35,096][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:36,034][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 604.00 toks/s, output: 33.08 toks/s]
[2025-01-08 18:59:36,034][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1207.49 toks/s, output: 66.13 toks/s]
WARNING 01-08 18:59:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:36,251][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:38,456][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.20s/it, est. speed input: 317.11 toks/s, output: 12.70 toks/s]
[2025-01-08 18:59:38,490][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.25it/s, est. speed input: 4371.26 toks/s, output: 180.91 toks/s]
WARNING 01-08 18:59:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:38,717][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:40,728][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.01s/it, est. speed input: 308.26 toks/s, output: 14.42 toks/s]
[2025-01-08 18:59:40,729][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.46it/s, est. speed input: 4006.16 toks/s, output: 187.38 toks/s]
WARNING 01-08 18:59:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:40,933][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:41,947][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 689.53 toks/s, output: 28.61 toks/s]
[2025-01-08 18:59:41,948][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.96it/s, est. speed input: 2148.50 toks/s, output: 85.78 toks/s]
WARNING 01-08 18:59:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:42,150][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:43,116][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.04it/s, est. speed input: 642.11 toks/s, output: 30.03 toks/s]
[2025-01-08 18:59:43,153][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.99it/s, est. speed input: 1980.24 toks/s, output: 90.74 toks/s]
WARNING 01-08 18:59:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:43,378][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:45,930][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.55s/it, est. speed input: 395.03 toks/s, output: 11.36 toks/s]
[2025-01-08 18:59:45,930][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.09it/s, est. speed input: 5134.24 toks/s, output: 147.71 toks/s]
WARNING 01-08 18:59:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:46,148][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:48,359][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.21s/it, est. speed input: 332.48 toks/s, output: 13.12 toks/s]
[2025-01-08 18:59:48,359][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.88it/s, est. speed input: 4320.84 toks/s, output: 170.48 toks/s]
WARNING 01-08 18:59:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:48,569][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:49,674][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 911.93 toks/s, output: 26.24 toks/s]
[2025-01-08 18:59:49,675][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.71it/s, est. speed input: 2808.82 toks/s, output: 78.68 toks/s]
WARNING 01-08 18:59:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:49,901][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:50,910][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 728.97 toks/s, output: 28.76 toks/s]
[2025-01-08 18:59:50,947][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.87it/s, est. speed input: 2233.19 toks/s, output: 87.03 toks/s]
WARNING 01-08 18:59:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:51,178][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:54,158][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.98s/it, est. speed input: 441.99 toks/s, output: 9.73 toks/s]
[2025-01-08 18:59:54,397][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:03<00:00,  5.03it/s, est. speed input: 4909.68 toks/s, output: 112.15 toks/s]
[2025-01-08 18:59:54,837][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  3.55it/s, est. speed input: 4679.27 toks/s, output: 117.25 toks/s]
WARNING 01-08 18:59:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 18:59:55,136][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 18:59:56,354][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1081.13 toks/s, output: 23.81 toks/s]
[2025-01-08 18:59:56,355][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 3309.54 toks/s, output: 71.39 toks/s]
[2025-01-08 19:00:03,049][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:00:03,103][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:00:04,781][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 19:00:06,392][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 19:00:07,984][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:00:08,497][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:00:08,497][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:00:18,143][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:00:18,716][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:00:18,768][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:00:20,538][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 19:00:22,113][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:00:23,673][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:00:24,165][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 19:00:24,166][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:00:37,820][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:00:38,107][root][INFO] - Loading VLLM model.
WARNING 01-08 19:00:38 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:00:38 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:00:38 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:00:38 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:00:39,207][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:00:40,514][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 19:00:40,898][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 19:00:42,189][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.00s/it]
[2025-01-08 19:00:43,519][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
[2025-01-08 19:00:43,520][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 19:00:43 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:00:57 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:00:58 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:00:58 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:01:19 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:01:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:19,990][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:23,012][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.02s/it, est. speed input: 167.11 toks/s, output: 9.60 toks/s]
[2025-01-08 19:01:23,013][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.29it/s, est. speed input: 2673.20 toks/s, output: 153.51 toks/s]
WARNING 01-08 19:01:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:23,216][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:24,114][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 630.56 toks/s, output: 34.54 toks/s]
[2025-01-08 19:01:24,114][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1260.57 toks/s, output: 69.04 toks/s]
WARNING 01-08 19:01:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:24,359][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:26,583][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.22s/it, est. speed input: 314.27 toks/s, output: 12.59 toks/s]
[2025-01-08 19:01:26,618][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.20it/s, est. speed input: 4332.54 toks/s, output: 179.30 toks/s]
WARNING 01-08 19:01:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:26,835][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:28,841][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.00s/it, est. speed input: 309.25 toks/s, output: 14.46 toks/s]
[2025-01-08 19:01:28,841][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.48it/s, est. speed input: 4019.17 toks/s, output: 187.99 toks/s]
WARNING 01-08 19:01:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:29,046][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:30,047][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.00s/it, est. speed input: 698.64 toks/s, output: 27.99 toks/s]
[2025-01-08 19:01:30,068][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.94it/s, est. speed input: 2134.34 toks/s, output: 84.24 toks/s]
WARNING 01-08 19:01:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:30,271][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:31,135][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.16it/s, est. speed input: 717.48 toks/s, output: 33.56 toks/s]
[2025-01-08 19:01:31,169][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1450.24 toks/s, output: 66.78 toks/s]
WARNING 01-08 19:01:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:31,397][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:34,111][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.71s/it, est. speed input: 371.45 toks/s, output: 10.69 toks/s]
[2025-01-08 19:01:34,112][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.16it/s, est. speed input: 5115.48 toks/s, output: 149.58 toks/s]
WARNING 01-08 19:01:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:34,336][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:36,607][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.27s/it, est. speed input: 323.58 toks/s, output: 12.77 toks/s]
[2025-01-08 19:01:36,642][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.07it/s, est. speed input: 4440.02 toks/s, output: 176.94 toks/s]
WARNING 01-08 19:01:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:36,867][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:37,823][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1054.93 toks/s, output: 30.35 toks/s]
[2025-01-08 19:01:37,823][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.09it/s, est. speed input: 2194.79 toks/s, output: 60.68 toks/s]
WARNING 01-08 19:01:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:38,040][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:38,922][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.13it/s, est. speed input: 833.77 toks/s, output: 32.90 toks/s]
[2025-01-08 19:01:38,956][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.18it/s, est. speed input: 1676.35 toks/s, output: 65.52 toks/s]
WARNING 01-08 19:01:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:39,192][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:42,318][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:40,  3.13s/it, est. speed input: 348.69 toks/s, output: 8.96 toks/s]
[2025-01-08 19:01:42,848][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.67it/s, est. speed input: 4620.61 toks/s, output: 110.22 toks/s]
[2025-01-08 19:01:43,406][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.32it/s, est. speed input: 4321.29 toks/s, output: 116.75 toks/s]
WARNING 01-08 19:01:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:43,708][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:44,917][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.21s/it, est. speed input: 1089.25 toks/s, output: 23.98 toks/s]
[2025-01-08 19:01:44,918][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.48it/s, est. speed input: 3214.45 toks/s, output: 71.93 toks/s]
WARNING 01-08 19:01:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:45,132][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:45,944][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 984.93 toks/s, output: 38.17 toks/s]
[2025-01-08 19:01:45,945][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 984.93 toks/s, output: 38.17 toks/s]
WARNING 01-08 19:01:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:01:46,151][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:01:47,005][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1735.05 toks/s, output: 33.97 toks/s]
[2025-01-08 19:01:47,005][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1735.05 toks/s, output: 33.97 toks/s]
[2025-01-08 19:01:53,590][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:01:53,644][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:01:55,311][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.67s/it]
[2025-01-08 19:01:56,958][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:01:58,557][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:01:59,080][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:01:59,080][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:02:08,791][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:02:09,276][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:02:09,329][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:02:11,163][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 19:02:12,802][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 19:02:14,362][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 19:02:14,864][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:02:14,865][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:02:28,409][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:02:28,706][root][INFO] - Loading VLLM model.
WARNING 01-08 19:02:28 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:02:28 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:02:29 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:02:29 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:02:29,674][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:02:30,995][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:02:31,385][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:02:32,711][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
[2025-01-08 19:02:34,063][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:02:34,063][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 19:02:34 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:02:48 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:02:48 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:02:48 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:03:10 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:03:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:10,551][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:13,057][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 201.60 toks/s, output: 11.58 toks/s]
[2025-01-08 19:03:13,057][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.39it/s, est. speed input: 3224.84 toks/s, output: 185.19 toks/s]
WARNING 01-08 19:03:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:13,267][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:14,377][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.11s/it, est. speed input: 510.26 toks/s, output: 27.95 toks/s]
[2025-01-08 19:03:14,544][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.92it/s, est. speed input: 1773.22 toks/s, output: 104.95 toks/s]
[2025-01-08 19:03:14,544][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.13it/s, est. speed input: 1773.22 toks/s, output: 104.95 toks/s]
WARNING 01-08 19:03:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:14,765][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:16,788][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.02s/it, est. speed input: 345.66 toks/s, output: 14.34 toks/s]
[2025-01-08 19:03:16,805][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.88it/s, est. speed input: 4112.05 toks/s, output: 171.09 toks/s]
WARNING 01-08 19:03:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:17,055][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:18,971][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.92s/it, est. speed input: 323.66 toks/s, output: 15.14 toks/s]
[2025-01-08 19:03:18,971][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:01<00:00,  6.26it/s, est. speed input: 3882.76 toks/s, output: 181.61 toks/s]
WARNING 01-08 19:03:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:19,182][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:20,190][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.01s/it, est. speed input: 506.03 toks/s, output: 20.84 toks/s]
[2025-01-08 19:03:20,348][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.97it/s, est. speed input: 1037.37 toks/s, output: 42.90 toks/s]
[2025-01-08 19:03:20,348][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.43it/s, est. speed input: 2236.38 toks/s, output: 92.65 toks/s]
WARNING 01-08 19:03:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:20,557][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:21,581][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.02s/it, est. speed input: 667.25 toks/s, output: 30.28 toks/s]
[2025-01-08 19:03:21,581][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.93it/s, est. speed input: 2000.92 toks/s, output: 90.82 toks/s]
WARNING 01-08 19:03:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:21,809][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:24,317][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.51s/it, est. speed input: 401.96 toks/s, output: 11.56 toks/s]
[2025-01-08 19:03:25,060][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  5.08it/s, est. speed input: 3896.35 toks/s, output: 129.50 toks/s]
[2025-01-08 19:03:25,060][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  4.00it/s, est. speed input: 3896.35 toks/s, output: 129.50 toks/s]
WARNING 01-08 19:03:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:25,296][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:27,464][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.17s/it, est. speed input: 339.19 toks/s, output: 13.38 toks/s]
[2025-01-08 19:03:27,464][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.00it/s, est. speed input: 4383.05 toks/s, output: 173.92 toks/s]
WARNING 01-08 19:03:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:27,692][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:28,798][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 912.21 toks/s, output: 26.24 toks/s]
[2025-01-08 19:03:28,798][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.71it/s, est. speed input: 2735.49 toks/s, output: 78.70 toks/s]
WARNING 01-08 19:03:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:29,038][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:30,095][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.06s/it, est. speed input: 756.77 toks/s, output: 29.32 toks/s]
[2025-01-08 19:03:30,096][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.84it/s, est. speed input: 2269.52 toks/s, output: 87.94 toks/s]
WARNING 01-08 19:03:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:30,327][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:33,285][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.96s/it, est. speed input: 445.36 toks/s, output: 9.81 toks/s]
[2025-01-08 19:03:33,674][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:03<00:00,  4.35it/s, est. speed input: 4196.03 toks/s, output: 100.99 toks/s]
[2025-01-08 19:03:34,596][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  3.59it/s, est. speed input: 3916.18 toks/s, output: 120.65 toks/s]
[2025-01-08 19:03:34,596][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:04<00:00,  3.05it/s, est. speed input: 3916.18 toks/s, output: 120.65 toks/s]
WARNING 01-08 19:03:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:34,875][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:35,652][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 1031.59 toks/s, output: 37.30 toks/s]
[2025-01-08 19:03:35,653][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 1031.59 toks/s, output: 37.30 toks/s]
WARNING 01-08 19:03:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:35,863][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:37,079][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1083.61 toks/s, output: 23.86 toks/s]
[2025-01-08 19:03:37,079][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.47it/s, est. speed input: 3249.75 toks/s, output: 71.56 toks/s]
WARNING 01-08 19:03:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:03:37,304][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:03:38,128][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1435.91 toks/s, output: 35.23 toks/s]
[2025-01-08 19:03:38,128][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1435.91 toks/s, output: 35.23 toks/s]
[2025-01-08 19:03:44,780][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:03:44,835][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:03:46,560][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 19:03:48,179][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:03:49,775][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:03:50,303][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:03:50,303][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:04:00,100][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:04:00,622][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:04:00,674][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:04:02,527][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 19:04:04,127][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 19:04:05,736][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.66s/it]
[2025-01-08 19:04:06,238][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:04:06,239][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 19:04:19,623][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:04:19,936][root][INFO] - Loading VLLM model.
WARNING 01-08 19:04:20 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:04:20 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:04:20 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:04:20 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:04:20,907][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:04:22,228][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:04:22,616][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:04:23,936][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:04:25,275][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:04:25,275][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:04:25 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:04:39 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:04:39 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:04:39 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:05:01 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:05:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:01,764][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:04,314][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.55s/it, est. speed input: 198.13 toks/s, output: 11.38 toks/s]
[2025-01-08 19:05:04,314][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.28it/s, est. speed input: 3169.21 toks/s, output: 181.99 toks/s]
WARNING 01-08 19:05:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:04,529][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:06,069][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.54s/it, est. speed input: 367.47 toks/s, output: 20.13 toks/s]
[2025-01-08 19:05:06,104][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.08it/s, est. speed input: 2875.65 toks/s, output: 158.77 toks/s]
WARNING 01-08 19:05:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:06,319][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:07,878][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.56s/it, est. speed input: 448.32 toks/s, output: 18.60 toks/s]
[2025-01-08 19:05:07,912][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.02it/s, est. speed input: 3509.49 toks/s, output: 146.85 toks/s]
WARNING 01-08 19:05:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:08,127][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:09,604][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.48s/it, est. speed input: 419.86 toks/s, output: 19.64 toks/s]
[2025-01-08 19:05:09,604][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.42it/s, est. speed input: 3357.73 toks/s, output: 157.05 toks/s]
WARNING 01-08 19:05:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:09,816][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:11,324][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.51s/it, est. speed input: 463.63 toks/s, output: 17.91 toks/s]
[2025-01-08 19:05:11,410][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.02it/s, est. speed input: 3390.31 toks/s, output: 145.58 toks/s]
WARNING 01-08 19:05:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:11,624][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:13,113][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.49s/it, est. speed input: 458.63 toks/s, output: 20.82 toks/s]
[2025-01-08 19:05:13,114][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.70it/s, est. speed input: 3209.36 toks/s, output: 145.67 toks/s]
WARNING 01-08 19:05:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:13,333][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:15,269][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.94s/it, est. speed input: 520.60 toks/s, output: 14.98 toks/s]
[2025-01-08 19:05:15,304][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.57it/s, est. speed input: 4386.81 toks/s, output: 133.44 toks/s]
WARNING 01-08 19:05:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:15,525][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:17,214][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.69s/it, est. speed input: 435.31 toks/s, output: 17.18 toks/s]
[2025-01-08 19:05:17,232][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.27it/s, est. speed input: 3844.38 toks/s, output: 153.56 toks/s]
WARNING 01-08 19:05:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:17,467][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:19,118][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.65s/it, est. speed input: 609.33 toks/s, output: 16.35 toks/s]
[2025-01-08 19:05:19,168][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.12it/s, est. speed input: 4147.88 toks/s, output: 118.19 toks/s]
WARNING 01-08 19:05:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:19,380][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:20,907][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.53s/it, est. speed input: 524.08 toks/s, output: 19.00 toks/s]
[2025-01-08 19:05:20,956][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.44it/s, est. speed input: 3554.41 toks/s, output: 136.46 toks/s]
WARNING 01-08 19:05:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:21,177][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:23,411][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:17,  2.23s/it, est. speed input: 589.61 toks/s, output: 12.98 toks/s]
[2025-01-08 19:05:24,070][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:02<00:00,  3.01it/s, est. speed input: 3037.77 toks/s, output: 81.91 toks/s]
[2025-01-08 19:05:24,768][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:03<00:00,  2.52it/s, est. speed input: 2814.55 toks/s, output: 93.58 toks/s]
[2025-01-08 19:05:24,802][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.48it/s, est. speed input: 3151.20 toks/s, output: 120.55 toks/s]
WARNING 01-08 19:05:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:25,071][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:25,985][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.09it/s, est. speed input: 870.08 toks/s, output: 32.83 toks/s]
[2025-01-08 19:05:26,002][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.15it/s, est. speed input: 1778.45 toks/s, output: 65.51 toks/s]
WARNING 01-08 19:05:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:26,219][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:28,013][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.79s/it, est. speed input: 734.45 toks/s, output: 16.17 toks/s]
[2025-01-08 19:05:28,435][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:02<00:00,  2.80it/s, est. speed input: 2970.40 toks/s, output: 75.83 toks/s]
[2025-01-08 19:05:28,858][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.69it/s, est. speed input: 2993.82 toks/s, output: 92.87 toks/s]
[2025-01-08 19:05:28,858][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.27it/s, est. speed input: 2993.82 toks/s, output: 92.87 toks/s]
WARNING 01-08 19:05:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:05:29,102][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:05:30,126][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.02s/it, est. speed input: 1286.42 toks/s, output: 28.33 toks/s]
[2025-01-08 19:05:30,127][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.95it/s, est. speed input: 2449.71 toks/s, output: 56.63 toks/s]
[2025-01-08 19:05:36,912][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:05:36,966][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:05:38,689][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 19:05:40,376][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 19:05:42,018][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 19:05:42,546][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:05:42,546][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 19:05:52,645][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:05:53,151][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:05:53,204][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:05:55,097][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.89s/it]
[2025-01-08 19:05:56,747][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 19:05:58,360][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:05:58,872][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:05:58,872][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 19:06:12,210][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:06:12,529][root][INFO] - Loading VLLM model.
WARNING 01-08 19:06:12 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:06:12 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:06:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:06:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:06:13,433][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:06:14,794][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 19:06:15,197][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:06:16,555][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:06:17,953][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:06:17,953][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:06:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:06:31 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:06:32 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:06:32 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:06:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:06:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:06:54,356][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:06:57,308][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.95s/it, est. speed input: 171.10 toks/s, output: 9.83 toks/s]
[2025-01-08 19:06:57,309][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.42it/s, est. speed input: 2736.96 toks/s, output: 157.17 toks/s]
WARNING 01-08 19:06:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:06:57,522][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:06:59,035][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.51s/it, est. speed input: 374.11 toks/s, output: 20.49 toks/s]
[2025-01-08 19:06:59,069][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.17it/s, est. speed input: 2926.13 toks/s, output: 161.56 toks/s]
WARNING 01-08 19:06:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:06:59,283][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:00,843][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.56s/it, est. speed input: 448.31 toks/s, output: 18.60 toks/s]
[2025-01-08 19:07:00,877][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.02it/s, est. speed input: 3509.39 toks/s, output: 146.85 toks/s]
WARNING 01-08 19:07:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:01,092][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:02,575][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.48s/it, est. speed input: 418.33 toks/s, output: 19.57 toks/s]
[2025-01-08 19:07:02,575][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.40it/s, est. speed input: 3345.44 toks/s, output: 156.48 toks/s]
WARNING 01-08 19:07:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:02,789][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:04,300][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.51s/it, est. speed input: 462.63 toks/s, output: 17.87 toks/s]
[2025-01-08 19:07:04,386][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.01it/s, est. speed input: 3383.59 toks/s, output: 145.29 toks/s]
WARNING 01-08 19:07:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:04,601][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:06,095][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.49s/it, est. speed input: 457.11 toks/s, output: 20.75 toks/s]
[2025-01-08 19:07:06,095][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.68it/s, est. speed input: 3198.83 toks/s, output: 145.19 toks/s]
WARNING 01-08 19:07:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:06,313][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:08,252][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.94s/it, est. speed input: 520.07 toks/s, output: 14.96 toks/s]
[2025-01-08 19:07:08,286][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.56it/s, est. speed input: 4382.49 toks/s, output: 133.31 toks/s]
WARNING 01-08 19:07:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:08,504][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:10,199][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.69s/it, est. speed input: 433.66 toks/s, output: 17.11 toks/s]
[2025-01-08 19:07:10,217][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.26it/s, est. speed input: 3829.96 toks/s, output: 152.99 toks/s]
WARNING 01-08 19:07:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:10,443][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:12,097][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.65s/it, est. speed input: 608.50 toks/s, output: 16.33 toks/s]
[2025-01-08 19:07:12,147][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.11it/s, est. speed input: 4142.43 toks/s, output: 118.04 toks/s]
WARNING 01-08 19:07:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:12,361][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:13,895][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.53s/it, est. speed input: 521.76 toks/s, output: 18.91 toks/s]
[2025-01-08 19:07:13,944][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.42it/s, est. speed input: 3539.10 toks/s, output: 135.88 toks/s]
WARNING 01-08 19:07:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:14,191][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:16,448][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.26s/it, est. speed input: 583.63 toks/s, output: 12.85 toks/s]
[2025-01-08 19:07:16,945][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:02<00:00,  3.23it/s, est. speed input: 3192.32 toks/s, output: 83.18 toks/s]
[2025-01-08 19:07:17,332][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:03<00:00,  3.09it/s, est. speed input: 3218.48 toks/s, output: 96.50 toks/s]
[2025-01-08 19:07:17,754][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.91it/s, est. speed input: 3206.10 toks/s, output: 112.83 toks/s]
[2025-01-08 19:07:17,755][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.53it/s, est. speed input: 3206.10 toks/s, output: 112.83 toks/s]
WARNING 01-08 19:07:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:18,021][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:18,919][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 885.69 toks/s, output: 32.31 toks/s]
[2025-01-08 19:07:18,953][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.15it/s, est. speed input: 1777.12 toks/s, output: 64.39 toks/s]
WARNING 01-08 19:07:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:19,174][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:21,096][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:11,  1.92s/it, est. speed input: 683.29 toks/s, output: 14.05 toks/s]
[2025-01-08 19:07:21,146][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  3.55it/s, est. speed input: 4737.88 toks/s, output: 101.93 toks/s]
WARNING 01-08 19:07:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:07:21,400][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:07:22,396][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.00it/s, est. speed input: 1321.65 toks/s, output: 29.10 toks/s]
[2025-01-08 19:07:22,397][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.01it/s, est. speed input: 2516.86 toks/s, output: 58.18 toks/s]
[2025-01-08 19:07:29,118][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:07:29,172][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:07:30,860][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 19:07:32,481][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 19:07:34,100][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:07:34,627][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:07:34,627][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:07:44,713][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:07:45,244][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:07:45,296][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:07:47,124][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 19:07:48,698][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:07:50,250][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:07:50,761][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:07:50,761][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:08:04,371][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:08:04,694][root][INFO] - Loading VLLM model.
WARNING 01-08 19:08:04 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:08:04 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:08:05 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:08:05 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:08:05,715][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:08:07,034][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:08:07,421][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:08:08,715][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 19:08:10,051][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:08:10,051][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 19:08:10 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:08:24 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:08:24 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:08:24 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:08:45 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:08:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:46,253][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:49,265][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.01s/it, est. speed input: 167.66 toks/s, output: 9.63 toks/s]
[2025-01-08 19:08:49,320][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.22it/s, est. speed input: 2634.15 toks/s, output: 152.90 toks/s]
WARNING 01-08 19:08:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:49,543][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:51,763][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.22s/it, est. speed input: 256.37 toks/s, output: 13.97 toks/s]
[2025-01-08 19:08:52,337][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.91it/s, est. speed input: 3040.21 toks/s, output: 180.01 toks/s]
[2025-01-08 19:08:52,338][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.37it/s, est. speed input: 3040.21 toks/s, output: 180.01 toks/s]
WARNING 01-08 19:08:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:52,545][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:53,317][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 905.79 toks/s, output: 37.58 toks/s]
[2025-01-08 19:08:53,317][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 905.79 toks/s, output: 37.58 toks/s]
WARNING 01-08 19:08:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:53,522][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:54,283][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 814.68 toks/s, output: 38.11 toks/s]
[2025-01-08 19:08:54,283][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 814.68 toks/s, output: 38.11 toks/s]
WARNING 01-08 19:08:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:54,504][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:56,804][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.30s/it, est. speed input: 303.91 toks/s, output: 12.61 toks/s]
[2025-01-08 19:08:56,988][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  8.19it/s, est. speed input: 3992.20 toks/s, output: 179.52 toks/s]
[2025-01-08 19:08:56,989][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.04it/s, est. speed input: 3992.20 toks/s, output: 179.52 toks/s]
WARNING 01-08 19:08:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:57,212][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:08:59,499][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.29s/it, est. speed input: 299.99 toks/s, output: 13.56 toks/s]
[2025-01-08 19:08:59,599][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  8.05it/s, est. speed input: 4003.56 toks/s, output: 183.44 toks/s]
[2025-01-08 19:08:59,600][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.86it/s, est. speed input: 4003.56 toks/s, output: 183.44 toks/s]
WARNING 01-08 19:08:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:08:59,831][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:00,736][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 651.06 toks/s, output: 32.05 toks/s]
[2025-01-08 19:09:00,736][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1764.42 toks/s, output: 64.08 toks/s]
WARNING 01-08 19:09:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:00,951][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:01,760][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.24it/s, est. speed input: 879.88 toks/s, output: 30.94 toks/s]
[2025-01-08 19:09:01,827][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.28it/s, est. speed input: 1651.83 toks/s, output: 61.69 toks/s]
WARNING 01-08 19:09:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:02,054][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:04,715][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.66s/it, est. speed input: 378.97 toks/s, output: 10.90 toks/s]
[2025-01-08 19:09:04,715][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.26it/s, est. speed input: 5157.60 toks/s, output: 152.60 toks/s]
WARNING 01-08 19:09:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:04,979][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:07,471][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.49s/it, est. speed input: 311.04 toks/s, output: 11.64 toks/s]
[2025-01-08 19:09:07,593][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  7.88it/s, est. speed input: 4581.62 toks/s, output: 178.27 toks/s]
[2025-01-08 19:09:07,593][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.74it/s, est. speed input: 4581.62 toks/s, output: 178.27 toks/s]
WARNING 01-08 19:09:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:07,801][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:08,643][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1566.17 toks/s, output: 34.49 toks/s]
[2025-01-08 19:09:08,643][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1566.17 toks/s, output: 34.49 toks/s]
WARNING 01-08 19:09:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:08,890][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:12,167][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:45,  3.28s/it, est. speed input: 342.38 toks/s, output: 8.85 toks/s]
[2025-01-08 19:09:12,323][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:03<00:00,  4.78it/s, est. speed input: 4422.60 toks/s, output: 103.40 toks/s]
[2025-01-08 19:09:13,082][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:04<00:00,  3.58it/s, est. speed input: 4518.12 toks/s, output: 131.68 toks/s]
WARNING 01-08 19:09:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:13,357][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:14,138][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 1139.41 toks/s, output: 37.13 toks/s]
[2025-01-08 19:09:14,139][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 1139.41 toks/s, output: 37.13 toks/s]
WARNING 01-08 19:09:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:14,351][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:15,572][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1152.43 toks/s, output: 23.75 toks/s]
[2025-01-08 19:09:15,573][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 3328.42 toks/s, output: 71.24 toks/s]
WARNING 01-08 19:09:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:09:15,799][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:09:16,624][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1454.91 toks/s, output: 35.13 toks/s]
[2025-01-08 19:09:16,625][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1454.91 toks/s, output: 35.13 toks/s]
[2025-01-08 19:09:23,387][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:09:23,440][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:09:25,111][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 19:09:26,759][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:09:28,361][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:09:28,877][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:09:28,877][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:09:39,364][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:09:39,937][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:09:39,988][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:09:41,790][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.80s/it]
[2025-01-08 19:09:43,346][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:09:44,904][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:09:45,397][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 19:09:45,397][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:09:58,820][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:09:59,116][root][INFO] - Loading VLLM model.
WARNING 01-08 19:09:59 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:09:59 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:09:59 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:09:59 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:10:00,102][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:10:01,421][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:10:01,811][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:10:03,114][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 19:10:04,450][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:10:04,450][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:10:04 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:10:18 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:10:19 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:10:19 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:10:40 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:10:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:40,982][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:44,030][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.05s/it, est. speed input: 165.68 toks/s, output: 9.51 toks/s]
[2025-01-08 19:10:44,086][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.16it/s, est. speed input: 2603.60 toks/s, output: 151.12 toks/s]
WARNING 01-08 19:10:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:44,304][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:46,513][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.21s/it, est. speed input: 257.60 toks/s, output: 14.03 toks/s]
[2025-01-08 19:10:47,120][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.83it/s, est. speed input: 3016.77 toks/s, output: 179.34 toks/s]
[2025-01-08 19:10:47,120][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.33it/s, est. speed input: 3016.77 toks/s, output: 179.34 toks/s]
WARNING 01-08 19:10:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:47,323][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:48,084][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 918.48 toks/s, output: 38.10 toks/s]
[2025-01-08 19:10:48,085][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 918.48 toks/s, output: 38.10 toks/s]
WARNING 01-08 19:10:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:48,286][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:49,033][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 830.17 toks/s, output: 38.83 toks/s]
[2025-01-08 19:10:49,033][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 830.17 toks/s, output: 38.83 toks/s]
WARNING 01-08 19:10:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:49,249][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:51,585][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.34s/it, est. speed input: 218.39 toks/s, output: 12.42 toks/s]
[2025-01-08 19:10:51,586][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4407.71 toks/s, output: 186.22 toks/s]
WARNING 01-08 19:10:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:51,808][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:54,048][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.24s/it, est. speed input: 318.38 toks/s, output: 12.06 toks/s]
[2025-01-08 19:10:54,190][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:13,  1.01s/it, est. speed input: 587.57 toks/s, output: 24.36 toks/s]
[2025-01-08 19:10:54,190][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.30it/s, est. speed input: 4318.34 toks/s, output: 193.58 toks/s]
WARNING 01-08 19:10:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:54,411][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:55,205][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1270.32 toks/s, output: 36.55 toks/s]
[2025-01-08 19:10:55,205][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1270.32 toks/s, output: 36.55 toks/s]
WARNING 01-08 19:10:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:55,422][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:56,299][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 838.42 toks/s, output: 33.08 toks/s]
[2025-01-08 19:10:56,333][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1662.38 toks/s, output: 65.88 toks/s]
WARNING 01-08 19:10:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:56,558][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:10:59,260][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.10 toks/s, output: 10.73 toks/s]
[2025-01-08 19:10:59,260][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.18it/s, est. speed input: 5222.18 toks/s, output: 150.24 toks/s]
WARNING 01-08 19:10:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:10:59,494][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:11:01,956][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:32,  2.46s/it, est. speed input: 326.19 toks/s, output: 12.59 toks/s]
[2025-01-08 19:11:01,957][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.69it/s, est. speed input: 4552.13 toks/s, output: 176.25 toks/s]
WARNING 01-08 19:11:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:11:02,161][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:11:03,114][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 853.80 toks/s, output: 30.45 toks/s]
[2025-01-08 19:11:03,114][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.10it/s, est. speed input: 2236.00 toks/s, output: 60.89 toks/s]
WARNING 01-08 19:11:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:11:03,326][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:11:04,132][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1112.03 toks/s, output: 38.47 toks/s]
[2025-01-08 19:11:04,133][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1112.03 toks/s, output: 38.47 toks/s]
WARNING 01-08 19:11:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:11:04,362][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:11:07,540][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 414.51 toks/s, output: 9.13 toks/s]
[2025-01-08 19:11:07,909][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.51it/s, est. speed input: 4455.44 toks/s, output: 103.18 toks/s]
[2025-01-08 19:11:08,129][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.01it/s, est. speed input: 4895.40 toks/s, output: 128.24 toks/s]
[2025-01-08 19:11:08,129][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.72it/s, est. speed input: 4895.40 toks/s, output: 128.24 toks/s]
WARNING 01-08 19:11:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:11:08,417][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:11:09,222][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1394.16 toks/s, output: 36.03 toks/s]
[2025-01-08 19:11:09,223][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1394.16 toks/s, output: 36.03 toks/s]
[2025-01-08 19:11:15,895][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:11:15,948][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:11:17,687][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 19:11:19,369][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:11:21,016][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:11:21,549][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:11:21,550][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:11:31,913][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:11:32,416][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:11:32,468][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:11:34,305][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 19:11:35,892][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:11:37,464][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:11:37,963][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:11:37,964][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:11:51,244][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:11:51,587][root][INFO] - Loading VLLM model.
WARNING 01-08 19:11:51 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:11:51 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:11:52 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:11:52 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:11:52,689][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:11:54,008][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:11:54,400][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:11:55,704][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:11:57,044][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:11:57,044][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:11:57 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:12:11 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:12:11 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:12:11 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:12:33 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:12:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:33,531][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:36,530][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  3.00s/it, est. speed input: 168.39 toks/s, output: 9.67 toks/s]
[2025-01-08 19:12:36,586][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.24it/s, est. speed input: 2645.36 toks/s, output: 153.55 toks/s]
WARNING 01-08 19:12:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:36,803][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:39,011][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.21s/it, est. speed input: 257.66 toks/s, output: 14.04 toks/s]
[2025-01-08 19:12:39,631][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.79it/s, est. speed input: 3003.41 toks/s, output: 181.37 toks/s]
[2025-01-08 19:12:39,631][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.30it/s, est. speed input: 3003.41 toks/s, output: 181.37 toks/s]
WARNING 01-08 19:12:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:39,835][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:40,594][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 921.43 toks/s, output: 38.23 toks/s]
[2025-01-08 19:12:40,594][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 921.43 toks/s, output: 38.23 toks/s]
WARNING 01-08 19:12:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:40,793][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:41,542][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 827.45 toks/s, output: 38.70 toks/s]
[2025-01-08 19:12:41,543][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 827.45 toks/s, output: 38.70 toks/s]
WARNING 01-08 19:12:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:41,760][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:44,094][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 218.46 toks/s, output: 12.42 toks/s]
[2025-01-08 19:12:44,095][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 4409.17 toks/s, output: 186.28 toks/s]
WARNING 01-08 19:12:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:44,332][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:46,570][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.24s/it, est. speed input: 318.66 toks/s, output: 12.07 toks/s]
[2025-01-08 19:12:46,712][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:13,  1.00s/it, est. speed input: 588.03 toks/s, output: 24.38 toks/s]
[2025-01-08 19:12:46,786][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.11it/s, est. speed input: 4195.31 toks/s, output: 191.18 toks/s]
WARNING 01-08 19:12:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:46,995][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:47,784][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1277.39 toks/s, output: 36.75 toks/s]
[2025-01-08 19:12:47,785][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1277.39 toks/s, output: 36.75 toks/s]
WARNING 01-08 19:12:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:47,991][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:48,952][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 765.20 toks/s, output: 30.19 toks/s]
[2025-01-08 19:12:48,986][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.01it/s, est. speed input: 1522.01 toks/s, output: 60.32 toks/s]
WARNING 01-08 19:12:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:49,233][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:51,932][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 373.52 toks/s, output: 10.75 toks/s]
[2025-01-08 19:12:51,933][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.19it/s, est. speed input: 5228.00 toks/s, output: 150.41 toks/s]
WARNING 01-08 19:12:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:52,168][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:54,645][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:32,  2.48s/it, est. speed input: 324.32 toks/s, output: 12.52 toks/s]
[2025-01-08 19:12:54,719][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.49it/s, est. speed input: 4401.63 toks/s, output: 173.32 toks/s]
WARNING 01-08 19:12:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:54,935][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:55,892][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 849.80 toks/s, output: 30.31 toks/s]
[2025-01-08 19:12:56,535][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.30it/s, est. speed input: 1331.87 toks/s, output: 60.03 toks/s]
[2025-01-08 19:12:56,535][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.25it/s, est. speed input: 1331.87 toks/s, output: 60.03 toks/s]
WARNING 01-08 19:12:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:56,747][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:12:57,551][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1114.69 toks/s, output: 38.57 toks/s]
[2025-01-08 19:12:57,551][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1114.69 toks/s, output: 38.57 toks/s]
WARNING 01-08 19:12:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:12:57,780][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:13:00,964][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:41,  3.18s/it, est. speed input: 413.69 toks/s, output: 9.11 toks/s]
[2025-01-08 19:13:01,570][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  4.48it/s, est. speed input: 4518.65 toks/s, output: 108.21 toks/s]
[2025-01-08 19:13:01,823][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:04<00:00,  3.46it/s, est. speed input: 4560.89 toks/s, output: 120.47 toks/s]
WARNING 01-08 19:13:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:13:02,113][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:13:02,916][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1398.43 toks/s, output: 36.14 toks/s]
[2025-01-08 19:13:02,916][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1398.43 toks/s, output: 36.14 toks/s]
[2025-01-08 19:13:09,821][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:13:09,873][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:13:11,638][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 19:13:13,339][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 19:13:15,039][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 19:13:15,601][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.26s/it]
[2025-01-08 19:13:15,602][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 19:13:26,071][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:13:26,577][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:13:26,629][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:13:28,621][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.99s/it]
[2025-01-08 19:13:30,328][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.82s/it]
[2025-01-08 19:13:32,000][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.75s/it]
[2025-01-08 19:13:32,529][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.27s/it]
[2025-01-08 19:13:32,530][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.48s/it]
[2025-01-08 19:13:45,944][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:13:46,292][root][INFO] - Loading VLLM model.
WARNING 01-08 19:13:46 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:13:46 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:13:46 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:13:47 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:13:47,228][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:13:48,642][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.41s/it]
[2025-01-08 19:13:49,054][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.21it/s]
[2025-01-08 19:13:50,459][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.09s/it]
[2025-01-08 19:13:51,912][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.23s/it]
[2025-01-08 19:13:51,913][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.17s/it]
INFO 01-08 19:13:52 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:14:05 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:14:06 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:14:06 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:14:28 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:14:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:29,147][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:32,137][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.99s/it, est. speed input: 168.89 toks/s, output: 9.70 toks/s]
[2025-01-08 19:14:32,200][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.24it/s, est. speed input: 2646.61 toks/s, output: 155.26 toks/s]
WARNING 01-08 19:14:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:32,435][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:34,492][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:26,  2.06s/it, est. speed input: 276.12 toks/s, output: 14.10 toks/s]
[2025-01-08 19:14:34,612][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:02<00:01,  4.94it/s, est. speed input: 2082.10 toks/s, output: 113.94 toks/s]
[2025-01-08 19:14:34,656][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.30it/s, est. speed input: 3570.75 toks/s, output: 204.85 toks/s]
WARNING 01-08 19:14:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:34,874][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:35,751][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 797.21 toks/s, output: 33.07 toks/s]
[2025-01-08 19:14:35,751][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.28it/s, est. speed input: 1593.70 toks/s, output: 66.12 toks/s]
WARNING 01-08 19:14:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:35,970][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:36,823][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.17it/s, est. speed input: 727.32 toks/s, output: 34.02 toks/s]
[2025-01-08 19:14:36,874][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.21it/s, est. speed input: 1376.12 toks/s, output: 67.53 toks/s]
WARNING 01-08 19:14:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:37,105][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:39,339][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.23s/it, est. speed input: 312.99 toks/s, output: 12.98 toks/s]
[2025-01-08 19:14:39,356][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.22it/s, est. speed input: 4263.52 toks/s, output: 180.81 toks/s]
WARNING 01-08 19:14:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:39,591][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:41,748][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.16s/it, est. speed input: 316.68 toks/s, output: 14.37 toks/s]
[2025-01-08 19:14:41,840][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.78it/s, est. speed input: 3960.80 toks/s, output: 188.10 toks/s]
WARNING 01-08 19:14:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:42,046][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:43,102][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.06s/it, est. speed input: 954.84 toks/s, output: 27.47 toks/s]
[2025-01-08 19:14:43,103][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.84it/s, est. speed input: 2457.21 toks/s, output: 82.38 toks/s]
WARNING 01-08 19:14:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:43,308][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:44,290][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 748.55 toks/s, output: 29.53 toks/s]
[2025-01-08 19:14:44,343][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.90it/s, est. speed input: 2080.88 toks/s, output: 87.95 toks/s]
WARNING 01-08 19:14:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:44,565][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:47,116][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.55s/it, est. speed input: 395.22 toks/s, output: 11.37 toks/s]
[2025-01-08 19:14:47,116][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.10it/s, est. speed input: 5136.66 toks/s, output: 147.78 toks/s]
WARNING 01-08 19:14:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:47,336][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:49,670][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.33s/it, est. speed input: 342.82 toks/s, output: 13.28 toks/s]
[2025-01-08 19:14:49,763][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.36it/s, est. speed input: 4306.28 toks/s, output: 174.34 toks/s]
WARNING 01-08 19:14:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:50,003][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:51,160][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.16s/it, est. speed input: 1138.88 toks/s, output: 25.08 toks/s]
[2025-01-08 19:14:51,803][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.86it/s, est. speed input: 1954.20 toks/s, output: 69.47 toks/s]
[2025-01-08 19:14:51,803][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  1.67it/s, est. speed input: 1954.20 toks/s, output: 69.47 toks/s]
WARNING 01-08 19:14:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:52,020][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:52,806][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1009.05 toks/s, output: 38.17 toks/s]
[2025-01-08 19:14:52,807][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1009.05 toks/s, output: 38.17 toks/s]
WARNING 01-08 19:14:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:53,048][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:56,029][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.98s/it, est. speed input: 441.78 toks/s, output: 9.73 toks/s]
[2025-01-08 19:14:56,501][root][ERROR] - Processed prompts:  85%|########4 | 11/13 [00:03<00:00,  4.18it/s, est. speed input: 4196.07 toks/s, output: 99.06 toks/s]
[2025-01-08 19:14:57,010][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  4.13it/s, est. speed input: 4321.53 toks/s, output: 120.40 toks/s]
[2025-01-08 19:14:57,010][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  3.28it/s, est. speed input: 4321.53 toks/s, output: 120.40 toks/s]
WARNING 01-08 19:14:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:14:57,292][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:14:58,108][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1461.10 toks/s, output: 35.58 toks/s]
[2025-01-08 19:14:58,108][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1461.10 toks/s, output: 35.58 toks/s]
[2025-01-08 19:15:05,044][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:15:05,098][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:15:06,860][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 19:15:08,486][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:15:10,082][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:15:10,603][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:15:10,603][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:15:21,108][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:15:21,621][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:15:21,674][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:15:23,527][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 19:15:25,137][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:15:26,718][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 19:15:27,224][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:15:27,224][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 19:15:40,649][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:15:40,983][root][INFO] - Loading VLLM model.
WARNING 01-08 19:15:41 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:15:41 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:15:41 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:15:41 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:15:42,445][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:15:43,775][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
[2025-01-08 19:15:44,166][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:15:45,489][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.03s/it]
[2025-01-08 19:15:46,841][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:15:46,841][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 19:15:47 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:16:00 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:16:01 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:16:01 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:16:23 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:16:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:23,410][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:26,350][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.94s/it, est. speed input: 171.82 toks/s, output: 9.87 toks/s]
[2025-01-08 19:16:26,452][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:03<00:00,  6.34it/s, est. speed input: 2324.36 toks/s, output: 139.72 toks/s]
[2025-01-08 19:16:26,453][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.26it/s, est. speed input: 2656.02 toks/s, output: 161.40 toks/s]
WARNING 01-08 19:16:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:26,677][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:28,378][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:15,  1.70s/it, est. speed input: 332.90 toks/s, output: 18.23 toks/s]
[2025-01-08 19:16:28,483][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:01<00:00,  4.40it/s, est. speed input: 1882.77 toks/s, output: 110.78 toks/s]
[2025-01-08 19:16:28,483][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.54it/s, est. speed input: 3139.62 toks/s, output: 188.30 toks/s]
WARNING 01-08 19:16:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:28,693][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:30,050][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.36s/it, est. speed input: 515.18 toks/s, output: 21.37 toks/s]
[2025-01-08 19:16:30,050][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.42it/s, est. speed input: 3090.06 toks/s, output: 128.20 toks/s]
WARNING 01-08 19:16:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:30,260][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:31,559][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.30s/it, est. speed input: 478.31 toks/s, output: 23.11 toks/s]
[2025-01-08 19:16:31,623][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.40it/s, est. speed input: 2742.46 toks/s, output: 140.86 toks/s]
WARNING 01-08 19:16:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:31,834][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:33,594][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:15,  1.76s/it, est. speed input: 397.11 toks/s, output: 16.48 toks/s]
[2025-01-08 19:16:33,595][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.68it/s, est. speed input: 3862.60 toks/s, output: 164.70 toks/s]
WARNING 01-08 19:16:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:33,809][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:35,612][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:16,  1.80s/it, est. speed input: 380.41 toks/s, output: 17.19 toks/s]
[2025-01-08 19:16:35,718][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:01<00:02,  2.70it/s, est. speed input: 1436.30 toks/s, output: 68.10 toks/s]
[2025-01-08 19:16:35,718][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.24it/s, est. speed input: 3594.28 toks/s, output: 178.06 toks/s]
WARNING 01-08 19:16:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:35,931][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:37,468][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.54s/it, est. speed input: 655.98 toks/s, output: 18.87 toks/s]
[2025-01-08 19:16:37,468][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.90it/s, est. speed input: 3934.53 toks/s, output: 113.20 toks/s]
WARNING 01-08 19:16:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:37,692][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:39,066][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.37s/it, est. speed input: 536.70 toks/s, output: 21.85 toks/s]
[2025-01-08 19:16:39,131][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.17it/s, est. speed input: 3090.56 toks/s, output: 133.46 toks/s]
WARNING 01-08 19:16:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:39,366][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:41,450][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.08s/it, est. speed input: 483.70 toks/s, output: 13.92 toks/s]
[2025-01-08 19:16:41,451][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.80it/s, est. speed input: 4742.17 toks/s, output: 139.12 toks/s]
WARNING 01-08 19:16:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:41,675][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:43,620][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:17,  1.95s/it, est. speed input: 412.83 toks/s, output: 15.94 toks/s]
[2025-01-08 19:16:43,727][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:02<00:02,  2.52it/s, est. speed input: 1567.66 toks/s, output: 63.37 toks/s]
[2025-01-08 19:16:43,727][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.87it/s, est. speed input: 3929.67 toks/s, output: 165.71 toks/s]
WARNING 01-08 19:16:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:43,942][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:45,659][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.72s/it, est. speed input: 767.29 toks/s, output: 16.31 toks/s]
[2025-01-08 19:16:46,257][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  3.17it/s, est. speed input: 3414.13 toks/s, output: 89.44 toks/s]
[2025-01-08 19:16:46,257][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.59it/s, est. speed input: 3414.13 toks/s, output: 89.44 toks/s]
WARNING 01-08 19:16:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:16:46,515][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:16:49,153][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:26,  2.64s/it, est. speed input: 499.37 toks/s, output: 11.00 toks/s]
[2025-01-08 19:16:49,612][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:03<00:00,  4.21it/s, est. speed input: 4215.88 toks/s, output: 101.71 toks/s]
[2025-01-08 19:16:49,630][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  3.53it/s, est. speed input: 4615.05 toks/s, output: 118.80 toks/s]
[2025-01-08 19:16:56,703][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:16:56,756][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:16:58,497][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 19:17:00,180][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:17:01,818][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:17:02,344][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:17:02,344][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:17:12,854][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:17:13,361][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:17:13,413][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:17:15,298][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 19:17:16,945][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 19:17:18,570][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:17:19,077][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:17:19,078][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 19:17:32,599][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:17:32,879][root][INFO] - Loading VLLM model.
WARNING 01-08 19:17:33 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:17:33 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:17:33 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:17:33 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:17:33,802][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:17:35,175][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:17:35,573][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:17:36,931][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:17:38,336][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:17:38,337][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:17:38 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:17:52 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:17:52 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:17:52 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:18:14 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:18:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:14,981][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:17,455][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.47s/it, est. speed input: 204.22 toks/s, output: 12.13 toks/s]
[2025-01-08 19:18:17,559][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:02<00:04,  2.56it/s, est. speed input: 979.62 toks/s, output: 61.30 toks/s]
[2025-01-08 19:18:17,577][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.17it/s, est. speed input: 3113.54 toks/s, output: 201.15 toks/s]
WARNING 01-08 19:18:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:17,793][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:19,286][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.49s/it, est. speed input: 379.88 toks/s, output: 22.78 toks/s]
[2025-01-08 19:18:19,310][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.61it/s, est. speed input: 2626.01 toks/s, output: 160.83 toks/s]
WARNING 01-08 19:18:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:19,523][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:21,192][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.67s/it, est. speed input: 419.10 toks/s, output: 17.39 toks/s]
[2025-01-08 19:18:21,192][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.39it/s, est. speed input: 3770.75 toks/s, output: 156.44 toks/s]
WARNING 01-08 19:18:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:21,405][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:23,096][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.69s/it, est. speed input: 369.06 toks/s, output: 19.52 toks/s]
[2025-01-08 19:18:23,096][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.32it/s, est. speed input: 3320.55 toks/s, output: 175.61 toks/s]
WARNING 01-08 19:18:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:23,314][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:24,779][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.47s/it, est. speed input: 477.09 toks/s, output: 19.79 toks/s]
[2025-01-08 19:18:24,779][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.78it/s, est. speed input: 3338.55 toks/s, output: 138.51 toks/s]
WARNING 01-08 19:18:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:24,992][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:26,578][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.59s/it, est. speed input: 435.15 toks/s, output: 22.07 toks/s]
[2025-01-08 19:18:26,578][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.41it/s, est. speed input: 3044.98 toks/s, output: 154.45 toks/s]
WARNING 01-08 19:18:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:26,802][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:28,774][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.97s/it, est. speed input: 511.38 toks/s, output: 14.71 toks/s]
[2025-01-08 19:18:28,774][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.56it/s, est. speed input: 4601.01 toks/s, output: 132.37 toks/s]
WARNING 01-08 19:18:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:29,014][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:30,819][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:14,  1.81s/it, est. speed input: 411.61 toks/s, output: 18.28 toks/s]
[2025-01-08 19:18:30,820][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.98it/s, est. speed input: 3703.22 toks/s, output: 164.48 toks/s]
WARNING 01-08 19:18:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:31,042][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:32,734][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.69s/it, est. speed input: 595.92 toks/s, output: 17.14 toks/s]
[2025-01-08 19:18:32,734][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.14it/s, est. speed input: 4170.14 toks/s, output: 119.97 toks/s]
WARNING 01-08 19:18:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:32,959][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:34,644][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.69s/it, est. speed input: 481.25 toks/s, output: 20.77 toks/s]
[2025-01-08 19:18:34,645][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.15it/s, est. speed input: 3367.84 toks/s, output: 145.34 toks/s]
WARNING 01-08 19:18:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:34,868][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:37,129][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.26s/it, est. speed input: 582.72 toks/s, output: 12.83 toks/s]
[2025-01-08 19:18:37,907][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  3.69it/s, est. speed input: 3900.46 toks/s, output: 101.02 toks/s]
[2025-01-08 19:18:37,908][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.96it/s, est. speed input: 3900.46 toks/s, output: 101.02 toks/s]
WARNING 01-08 19:18:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:18:38,191][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:18:40,131][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:11,  1.94s/it, est. speed input: 678.78 toks/s, output: 14.95 toks/s]
[2025-01-08 19:18:40,620][root][ERROR] - Processed prompts:  57%|#####7    | 4/7 [00:02<00:01,  2.00it/s, est. speed input: 2168.51 toks/s, output: 56.81 toks/s]
[2025-01-08 19:18:40,784][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:02<00:00,  2.46it/s, est. speed input: 2539.24 toks/s, output: 75.96 toks/s]
[2025-01-08 19:18:41,024][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:02<00:00,  2.79it/s, est. speed input: 2789.23 toks/s, output: 94.95 toks/s]
[2025-01-08 19:18:41,532][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  2.49it/s, est. speed input: 2759.67 toks/s, output: 111.06 toks/s]
[2025-01-08 19:18:41,532][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  2.10it/s, est. speed input: 2759.67 toks/s, output: 111.06 toks/s]
[2025-01-08 19:18:48,606][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:18:48,659][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:18:50,323][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.66s/it]
[2025-01-08 19:18:51,927][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 19:18:53,500][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 19:18:54,031][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:18:54,031][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 19:19:04,508][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:19:05,018][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:19:05,070][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:19:06,925][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 19:19:08,559][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 19:19:10,195][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:19:10,704][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:19:10,704][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:19:24,448][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:19:24,735][root][INFO] - Loading VLLM model.
WARNING 01-08 19:19:24 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:19:24 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:19:25 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:19:25 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:19:25,755][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:19:27,130][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:19:27,533][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:19:28,889][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 19:19:30,293][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:19:30,293][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:19:30 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:19:44 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:19:44 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:19:44 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:20:06 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:20:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:06,426][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:09,496][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.07s/it, est. speed input: 164.50 toks/s, output: 10.42 toks/s]
[2025-01-08 19:20:09,532][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.15it/s, est. speed input: 2601.45 toks/s, output: 169.35 toks/s]
WARNING 01-08 19:20:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:09,742][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:10,935][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.19s/it, est. speed input: 477.88 toks/s, output: 29.34 toks/s]
[2025-01-08 19:20:10,935][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.35it/s, est. speed input: 1909.06 toks/s, output: 117.33 toks/s]
WARNING 01-08 19:20:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:11,155][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:13,176][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.02s/it, est. speed input: 345.94 toks/s, output: 14.35 toks/s]
[2025-01-08 19:20:13,177][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.94it/s, est. speed input: 4150.15 toks/s, output: 172.18 toks/s]
WARNING 01-08 19:20:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:13,395][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:15,443][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.05s/it, est. speed input: 304.73 toks/s, output: 16.12 toks/s]
[2025-01-08 19:20:15,443][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.86it/s, est. speed input: 3655.78 toks/s, output: 193.33 toks/s]
WARNING 01-08 19:20:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:15,650][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:16,787][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.14s/it, est. speed input: 614.61 toks/s, output: 25.50 toks/s]
[2025-01-08 19:20:16,788][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.52it/s, est. speed input: 2457.32 toks/s, output: 101.95 toks/s]
WARNING 01-08 19:20:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:17,008][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:18,236][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.23s/it, est. speed input: 562.58 toks/s, output: 28.49 toks/s]
[2025-01-08 19:20:18,237][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.26it/s, est. speed input: 2247.83 toks/s, output: 113.94 toks/s]
WARNING 01-08 19:20:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:18,458][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:20,890][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.43s/it, est. speed input: 414.46 toks/s, output: 11.92 toks/s]
[2025-01-08 19:20:20,891][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  4.93it/s, est. speed input: 4972.14 toks/s, output: 143.05 toks/s]
WARNING 01-08 19:20:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:21,123][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:23,324][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:24,  2.20s/it, est. speed input: 337.61 toks/s, output: 14.99 toks/s]
[2025-01-08 19:20:23,325][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.45it/s, est. speed input: 4050.12 toks/s, output: 179.88 toks/s]
WARNING 01-08 19:20:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:23,544][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:24,835][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.29s/it, est. speed input: 781.01 toks/s, output: 22.47 toks/s]
[2025-01-08 19:20:24,835][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.10it/s, est. speed input: 3123.03 toks/s, output: 89.85 toks/s]
WARNING 01-08 19:20:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:25,045][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:26,331][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.29s/it, est. speed input: 631.80 toks/s, output: 27.23 toks/s]
[2025-01-08 19:20:26,331][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.11it/s, est. speed input: 2524.71 toks/s, output: 108.89 toks/s]
WARNING 01-08 19:20:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:26,561][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:29,389][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:31,  2.83s/it, est. speed input: 465.79 toks/s, output: 10.26 toks/s]
[2025-01-08 19:20:29,779][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:03<00:00,  4.09it/s, est. speed input: 4093.87 toks/s, output: 96.05 toks/s]
[2025-01-08 19:20:29,834][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.67it/s, est. speed input: 4829.39 toks/s, output: 125.29 toks/s]
WARNING 01-08 19:20:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:20:30,130][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:20:31,537][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.41s/it, est. speed input: 936.52 toks/s, output: 20.62 toks/s]
[2025-01-08 19:20:32,032][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  1.82it/s, est. speed input: 2077.56 toks/s, output: 59.94 toks/s]
[2025-01-08 19:20:32,286][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  2.24it/s, est. speed input: 2443.83 toks/s, output: 85.82 toks/s]
[2025-01-08 19:20:32,286][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:02<00:00,  1.86it/s, est. speed input: 2443.83 toks/s, output: 85.82 toks/s]
[2025-01-08 19:20:39,343][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:20:39,397][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:20:41,103][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.71s/it]
[2025-01-08 19:20:42,731][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:20:44,336][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:20:44,862][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:20:44,863][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:20:55,184][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:20:55,670][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:20:55,723][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:20:57,558][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 19:20:59,147][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:21:00,738][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 19:21:01,236][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:21:01,236][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:21:14,740][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:21:15,026][root][INFO] - Loading VLLM model.
WARNING 01-08 19:21:15 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:21:15 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:21:15 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:21:15 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:21:16,187][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:21:17,500][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 19:21:17,885][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:21:19,183][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 19:21:20,514][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:21:20,514][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 19:21:20 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:21:34 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:21:35 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:21:35 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:21:56 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:21:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:21:56,791][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:21:59,726][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.93s/it, est. speed input: 172.11 toks/s, output: 10.91 toks/s]
[2025-01-08 19:21:59,864][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.16it/s, est. speed input: 2629.24 toks/s, output: 173.44 toks/s]
[2025-01-08 19:21:59,865][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.21it/s, est. speed input: 2629.24 toks/s, output: 173.44 toks/s]
WARNING 01-08 19:22:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:00,077][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:01,636][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.56s/it, est. speed input: 374.14 toks/s, output: 21.18 toks/s]
[2025-01-08 19:22:01,685][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.98it/s, est. speed input: 2844.74 toks/s, output: 171.73 toks/s]
WARNING 01-08 19:22:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:01,897][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:03,449][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.55s/it, est. speed input: 450.60 toks/s, output: 18.69 toks/s]
[2025-01-08 19:22:03,449][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.16it/s, est. speed input: 3603.64 toks/s, output: 149.51 toks/s]
WARNING 01-08 19:22:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:03,660][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:05,244][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.58s/it, est. speed input: 393.84 toks/s, output: 20.83 toks/s]
[2025-01-08 19:22:05,245][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.05it/s, est. speed input: 3149.75 toks/s, output: 166.57 toks/s]
WARNING 01-08 19:22:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:05,457][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:07,023][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.57s/it, est. speed input: 446.27 toks/s, output: 18.51 toks/s]
[2025-01-08 19:22:07,024][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  5.11it/s, est. speed input: 3569.06 toks/s, output: 148.07 toks/s]
WARNING 01-08 19:22:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:07,237][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:09,014][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:14,  1.78s/it, est. speed input: 387.93 toks/s, output: 18.58 toks/s]
[2025-01-08 19:22:09,065][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.93it/s, est. speed input: 3407.25 toks/s, output: 169.68 toks/s]
WARNING 01-08 19:22:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:09,310][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:11,012][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.70s/it, est. speed input: 592.66 toks/s, output: 17.05 toks/s]
[2025-01-08 19:22:11,012][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.11it/s, est. speed input: 4147.11 toks/s, output: 119.31 toks/s]
WARNING 01-08 19:22:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:11,232][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:12,832][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.60s/it, est. speed input: 464.52 toks/s, output: 20.63 toks/s]
[2025-01-08 19:22:12,833][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.37it/s, est. speed input: 3250.55 toks/s, output: 144.37 toks/s]
WARNING 01-08 19:22:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:13,061][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:15,029][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.97s/it, est. speed input: 512.28 toks/s, output: 14.74 toks/s]
[2025-01-08 19:22:15,029][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.57it/s, est. speed input: 4609.34 toks/s, output: 132.61 toks/s]
WARNING 01-08 19:22:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:15,246][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:17,132][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.89s/it, est. speed input: 428.37 toks/s, output: 17.50 toks/s]
[2025-01-08 19:22:17,185][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.64it/s, est. speed input: 3769.78 toks/s, output: 160.40 toks/s]
WARNING 01-08 19:22:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:17,403][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:19,342][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:11,  1.94s/it, est. speed input: 679.28 toks/s, output: 14.96 toks/s]
[2025-01-08 19:22:19,853][root][ERROR] - Processed prompts:  57%|#####7    | 4/7 [00:02<00:01,  1.98it/s, est. speed input: 2150.12 toks/s, output: 56.73 toks/s]
[2025-01-08 19:22:20,062][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:02<00:00,  3.03it/s, est. speed input: 2971.93 toks/s, output: 96.66 toks/s]
[2025-01-08 19:22:20,653][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  2.55it/s, est. speed input: 2836.22 toks/s, output: 109.22 toks/s]
[2025-01-08 19:22:20,653][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  2.15it/s, est. speed input: 2836.22 toks/s, output: 109.22 toks/s]
WARNING 01-08 19:22:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:22:20,920][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:22:23,389][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:22,  2.47s/it, est. speed input: 533.62 toks/s, output: 11.75 toks/s]
[2025-01-08 19:22:23,810][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:02<00:02,  2.19it/s, est. speed input: 2331.58 toks/s, output: 56.07 toks/s]
[2025-01-08 19:22:24,323][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:01,  2.62it/s, est. speed input: 2753.96 toks/s, output: 81.99 toks/s]
[2025-01-08 19:22:24,573][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  3.43it/s, est. speed input: 3287.15 toks/s, output: 118.01 toks/s]
[2025-01-08 19:22:25,672][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.21it/s, est. speed input: 2804.00 toks/s, output: 121.66 toks/s]
[2025-01-08 19:22:25,672][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.10it/s, est. speed input: 2804.00 toks/s, output: 121.66 toks/s]
[2025-01-08 19:22:32,788][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:22:32,842][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:22:34,602][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 19:22:36,229][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:22:37,843][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 19:22:38,368][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 19:22:38,368][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:22:48,910][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:22:49,367][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:22:49,420][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:22:51,238][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 19:22:52,825][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:22:54,367][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:22:54,860][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 19:22:54,860][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:23:08,699][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:23:09,061][root][INFO] - Loading VLLM model.
WARNING 01-08 19:23:09 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:23:09 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:23:10 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:23:10 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:23:10,545][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:23:11,866][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:23:12,255][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:23:13,564][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:23:14,910][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:23:14,911][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:23:15 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:23:28 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:23:29 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:23:29 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:23:51 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:23:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:23:51,416][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:23:54,430][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.01s/it, est. speed input: 167.61 toks/s, output: 10.62 toks/s]
[2025-01-08 19:23:54,464][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 2651.60 toks/s, output: 172.29 toks/s]
WARNING 01-08 19:23:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:23:54,674][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:23:55,861][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.19s/it, est. speed input: 479.50 toks/s, output: 29.49 toks/s]
[2025-01-08 19:23:55,862][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.37it/s, est. speed input: 1918.03 toks/s, output: 117.93 toks/s]
WARNING 01-08 19:23:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:23:56,099][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:23:58,112][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.01s/it, est. speed input: 347.43 toks/s, output: 14.41 toks/s]
[2025-01-08 19:23:58,112][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.96it/s, est. speed input: 4167.84 toks/s, output: 172.91 toks/s]
WARNING 01-08 19:23:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:23:58,351][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:00,393][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.04s/it, est. speed input: 305.60 toks/s, output: 16.16 toks/s]
[2025-01-08 19:24:00,745][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  6.57it/s, est. speed input: 3128.32 toks/s, output: 174.21 toks/s]
[2025-01-08 19:24:00,745][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.01it/s, est. speed input: 3128.32 toks/s, output: 174.21 toks/s]
WARNING 01-08 19:24:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:00,966][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:02,094][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.13s/it, est. speed input: 620.14 toks/s, output: 25.73 toks/s]
[2025-01-08 19:24:02,094][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.55it/s, est. speed input: 2479.60 toks/s, output: 102.87 toks/s]
WARNING 01-08 19:24:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:02,307][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:03,545][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 557.69 toks/s, output: 28.29 toks/s]
[2025-01-08 19:24:03,545][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.23it/s, est. speed input: 2230.75 toks/s, output: 113.11 toks/s]
WARNING 01-08 19:24:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:03,774][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:06,198][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.42s/it, est. speed input: 415.92 toks/s, output: 11.97 toks/s]
[2025-01-08 19:24:06,198][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  4.95it/s, est. speed input: 4989.91 toks/s, output: 143.56 toks/s]
WARNING 01-08 19:24:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:06,422][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:08,617][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:24,  2.20s/it, est. speed input: 338.42 toks/s, output: 15.03 toks/s]
[2025-01-08 19:24:08,618][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.46it/s, est. speed input: 4069.57 toks/s, output: 180.32 toks/s]
WARNING 01-08 19:24:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:08,832][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:10,082][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.25s/it, est. speed input: 807.06 toks/s, output: 23.22 toks/s]
[2025-01-08 19:24:10,082][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.20it/s, est. speed input: 3227.22 toks/s, output: 92.85 toks/s]
WARNING 01-08 19:24:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:10,295][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:11,571][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.28s/it, est. speed input: 635.43 toks/s, output: 27.42 toks/s]
[2025-01-08 19:24:11,572][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.13it/s, est. speed input: 2541.63 toks/s, output: 109.65 toks/s]
WARNING 01-08 19:24:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:11,805][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:14,624][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:31,  2.82s/it, est. speed input: 467.21 toks/s, output: 10.29 toks/s]
[2025-01-08 19:24:15,275][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:03<00:01,  2.93it/s, est. speed input: 3036.16 toks/s, output: 74.92 toks/s]
[2025-01-08 19:24:15,453][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  3.17it/s, est. speed input: 3249.18 toks/s, output: 89.09 toks/s]
[2025-01-08 19:24:15,602][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  4.15it/s, est. speed input: 3816.01 toks/s, output: 121.96 toks/s]
[2025-01-08 19:24:15,906][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  3.96it/s, est. speed input: 3853.53 toks/s, output: 135.08 toks/s]
[2025-01-08 19:24:15,907][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.93it/s, est. speed input: 3853.53 toks/s, output: 135.08 toks/s]
WARNING 01-08 19:24:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:24:16,197][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:24:17,770][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.57s/it, est. speed input: 837.21 toks/s, output: 18.43 toks/s]
[2025-01-08 19:24:18,345][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.61it/s, est. speed input: 1898.90 toks/s, output: 53.55 toks/s]
[2025-01-08 19:24:18,927][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.22it/s, est. speed input: 2458.76 toks/s, output: 98.17 toks/s]
[2025-01-08 19:24:18,927][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.83it/s, est. speed input: 2458.76 toks/s, output: 98.17 toks/s]
[2025-01-08 19:24:26,029][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:24:26,083][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:24:27,828][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 19:24:29,530][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 19:24:31,186][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:24:31,719][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:24:31,719][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:24:42,079][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:24:42,620][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:24:42,672][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:24:44,487][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 19:24:46,093][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:24:47,667][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:24:48,176][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:24:48,176][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:25:01,783][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:25:02,168][root][INFO] - Loading VLLM model.
WARNING 01-08 19:25:02 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:25:02 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:25:02 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:25:03 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:25:03,174][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:25:04,493][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:25:04,886][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:25:06,190][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:25:07,530][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:25:07,530][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:25:07 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:25:21 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:25:22 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:25:22 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:25:43 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:25:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:43,930][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:46,969][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.04s/it, est. speed input: 166.24 toks/s, output: 10.53 toks/s]
[2025-01-08 19:25:47,107][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.93it/s, est. speed input: 2543.59 toks/s, output: 167.79 toks/s]
[2025-01-08 19:25:47,107][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.04it/s, est. speed input: 2543.59 toks/s, output: 167.79 toks/s]
WARNING 01-08 19:25:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:47,329][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:48,609][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.28s/it, est. speed input: 445.58 toks/s, output: 25.80 toks/s]
[2025-01-08 19:25:48,649][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.79it/s, est. speed input: 2168.00 toks/s, output: 129.58 toks/s]
WARNING 01-08 19:25:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:48,887][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:50,757][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.87s/it, est. speed input: 373.70 toks/s, output: 14.43 toks/s]
[2025-01-08 19:25:50,817][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.70it/s, est. speed input: 3983.83 toks/s, output: 164.24 toks/s]
WARNING 01-08 19:25:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:51,036][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:52,948][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 326.33 toks/s, output: 17.26 toks/s]
[2025-01-08 19:25:52,949][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.75it/s, est. speed input: 3589.18 toks/s, output: 189.78 toks/s]
WARNING 01-08 19:25:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:53,155][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:54,394][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 564.34 toks/s, output: 23.41 toks/s]
[2025-01-08 19:25:54,395][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.04it/s, est. speed input: 2820.65 toks/s, output: 117.02 toks/s]
WARNING 01-08 19:25:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:54,604][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:56,030][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.43s/it, est. speed input: 492.40 toks/s, output: 23.15 toks/s]
[2025-01-08 19:25:56,076][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.08it/s, est. speed input: 2816.55 toks/s, output: 141.37 toks/s]
WARNING 01-08 19:25:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:56,295][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:25:58,354][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.06s/it, est. speed input: 488.68 toks/s, output: 13.12 toks/s]
[2025-01-08 19:25:58,411][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.73it/s, est. speed input: 4762.16 toks/s, output: 136.09 toks/s]
WARNING 01-08 19:25:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:25:58,628][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:26:00,565][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:17,  1.94s/it, est. speed input: 383.67 toks/s, output: 17.04 toks/s]
[2025-01-08 19:26:00,565][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.16it/s, est. speed input: 3836.08 toks/s, output: 170.35 toks/s]
WARNING 01-08 19:26:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:26:00,777][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:26:02,309][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.53s/it, est. speed input: 657.87 toks/s, output: 18.93 toks/s]
[2025-01-08 19:26:02,310][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.91it/s, est. speed input: 3946.01 toks/s, output: 113.53 toks/s]
WARNING 01-08 19:26:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:26:02,521][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:26:04,031][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.51s/it, est. speed input: 543.88 toks/s, output: 21.86 toks/s]
[2025-01-08 19:26:04,077][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.86it/s, est. speed input: 3129.67 toks/s, output: 133.72 toks/s]
WARNING 01-08 19:26:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:26:04,302][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:26:06,718][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:21,  2.42s/it, est. speed input: 543.50 toks/s, output: 11.18 toks/s]
[2025-01-08 19:26:07,412][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:03<00:03,  1.55it/s, est. speed input: 1692.44 toks/s, output: 44.37 toks/s]
[2025-01-08 19:26:07,734][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:03<00:02,  1.80it/s, est. speed input: 1917.29 toks/s, output: 59.43 toks/s]
[2025-01-08 19:26:07,920][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:03<00:01,  2.22it/s, est. speed input: 2182.82 toks/s, output: 76.83 toks/s]
[2025-01-08 19:26:08,165][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:01,  2.56it/s, est. speed input: 2385.55 toks/s, output: 93.97 toks/s]
[2025-01-08 19:26:08,463][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:04<00:00,  3.55it/s, est. speed input: 2847.43 toks/s, output: 132.41 toks/s]
[2025-01-08 19:26:09,293][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.41it/s, est. speed input: 2638.13 toks/s, output: 140.46 toks/s]
[2025-01-08 19:26:09,293][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.00it/s, est. speed input: 2638.13 toks/s, output: 140.46 toks/s]
WARNING 01-08 19:26:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:26:09,607][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:26:11,548][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:11,  1.94s/it, est. speed input: 678.63 toks/s, output: 14.94 toks/s]
[2025-01-08 19:26:11,934][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:02<00:00,  3.27it/s, est. speed input: 3442.81 toks/s, output: 83.82 toks/s]
[2025-01-08 19:26:12,036][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:02<00:00,  3.77it/s, est. speed input: 3840.55 toks/s, output: 103.36 toks/s]
[2025-01-08 19:26:12,036][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:02<00:00,  2.88it/s, est. speed input: 3840.55 toks/s, output: 103.36 toks/s]
[2025-01-08 19:26:19,316][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:26:19,370][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:26:21,108][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 19:26:22,813][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 19:26:24,466][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:26:24,998][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:26:24,999][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:26:35,398][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:26:35,848][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:26:35,900][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:26:37,787][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.89s/it]
[2025-01-08 19:26:39,437][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 19:26:41,076][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 19:26:41,587][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:26:41,587][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 19:26:55,255][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:26:55,581][root][INFO] - Loading VLLM model.
WARNING 01-08 19:26:55 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:26:55 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:26:56 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:26:56 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:26:56,689][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:26:58,002][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 19:26:58,392][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:26:59,685][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 19:27:01,020][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:27:01,020][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 19:27:01 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:27:15 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:27:15 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:27:15 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:27:36 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:27:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:37,207][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:40,279][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.07s/it, est. speed input: 164.40 toks/s, output: 10.42 toks/s]
[2025-01-08 19:27:40,418][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.86it/s, est. speed input: 2516.69 toks/s, output: 166.01 toks/s]
[2025-01-08 19:27:40,418][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.98it/s, est. speed input: 2516.69 toks/s, output: 166.01 toks/s]
WARNING 01-08 19:27:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:40,634][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:41,900][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.27s/it, est. speed input: 450.21 toks/s, output: 26.06 toks/s]
[2025-01-08 19:27:41,940][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.83it/s, est. speed input: 2189.94 toks/s, output: 130.89 toks/s]
WARNING 01-08 19:27:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:42,172][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:44,021][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.85s/it, est. speed input: 378.10 toks/s, output: 14.60 toks/s]
[2025-01-08 19:27:44,080][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.76it/s, est. speed input: 4029.39 toks/s, output: 166.12 toks/s]
WARNING 01-08 19:27:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:44,301][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:46,216][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 325.93 toks/s, output: 17.24 toks/s]
[2025-01-08 19:27:46,217][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.74it/s, est. speed input: 3584.77 toks/s, output: 189.55 toks/s]
WARNING 01-08 19:27:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:46,428][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:47,667][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 564.40 toks/s, output: 23.42 toks/s]
[2025-01-08 19:27:47,667][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.04it/s, est. speed input: 2821.02 toks/s, output: 117.04 toks/s]
WARNING 01-08 19:27:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:47,883][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:49,299][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.42s/it, est. speed input: 486.92 toks/s, output: 23.32 toks/s]
[2025-01-08 19:27:49,339][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.12it/s, est. speed input: 2847.61 toks/s, output: 140.18 toks/s]
WARNING 01-08 19:27:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:49,564][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:51,611][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.05s/it, est. speed input: 491.65 toks/s, output: 13.20 toks/s]
[2025-01-08 19:27:51,668][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.75it/s, est. speed input: 4790.24 toks/s, output: 136.89 toks/s]
WARNING 01-08 19:27:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:51,903][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:53,837][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:17,  1.93s/it, est. speed input: 384.23 toks/s, output: 17.07 toks/s]
[2025-01-08 19:27:53,837][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.17it/s, est. speed input: 3841.56 toks/s, output: 170.60 toks/s]
WARNING 01-08 19:27:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:54,052][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:55,587][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.53s/it, est. speed input: 656.91 toks/s, output: 18.90 toks/s]
[2025-01-08 19:27:55,587][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.91it/s, est. speed input: 3940.20 toks/s, output: 113.36 toks/s]
WARNING 01-08 19:27:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:55,827][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:57,315][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.49s/it, est. speed input: 543.41 toks/s, output: 22.19 toks/s]
[2025-01-08 19:27:57,355][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.93it/s, est. speed input: 3184.51 toks/s, output: 133.56 toks/s]
WARNING 01-08 19:27:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:27:57,585][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:27:59,973][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:21,  2.39s/it, est. speed input: 549.93 toks/s, output: 11.31 toks/s]
[2025-01-08 19:28:00,669][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:03<00:03,  1.56it/s, est. speed input: 1707.27 toks/s, output: 44.76 toks/s]
[2025-01-08 19:28:00,892][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:03<00:02,  1.91it/s, est. speed input: 1990.46 toks/s, output: 60.49 toks/s]
[2025-01-08 19:28:01,018][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  4.52it/s, est. speed input: 3451.68 toks/s, output: 134.58 toks/s]
[2025-01-08 19:28:01,306][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:03<00:00,  2.69it/s, est. speed input: 3538.92 toks/s, output: 147.03 toks/s]
WARNING 01-08 19:28:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:28:01,606][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:28:04,103][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:22,  2.50s/it, est. speed input: 573.89 toks/s, output: 11.61 toks/s]
[2025-01-08 19:28:04,615][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:01,  2.96it/s, est. speed input: 3217.15 toks/s, output: 75.11 toks/s]
[2025-01-08 19:28:04,733][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  3.94it/s, est. speed input: 3938.58 toks/s, output: 108.43 toks/s]
[2025-01-08 19:28:05,814][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.38it/s, est. speed input: 3239.32 toks/s, output: 109.55 toks/s]
WARNING 01-08 19:28:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:28:06,118][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:28:06,956][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1705.28 toks/s, output: 34.61 toks/s]
[2025-01-08 19:28:06,956][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1705.28 toks/s, output: 34.61 toks/s]
[2025-01-08 19:28:14,066][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:28:14,119][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:28:15,801][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 19:28:17,393][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 19:28:18,981][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:28:19,507][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:28:19,508][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:28:30,040][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:28:30,613][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:28:30,666][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:28:32,512][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 19:28:34,112][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 19:28:35,667][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.63s/it]
[2025-01-08 19:28:36,164][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:28:36,164][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:28:50,021][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:28:50,312][root][INFO] - Loading VLLM model.
WARNING 01-08 19:28:50 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:28:50 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:28:51 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:28:51 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:28:51,253][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:28:52,611][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 19:28:53,016][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:28:54,382][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 19:28:55,793][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 19:28:55,794][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 19:28:56 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:29:09 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:29:10 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:29:10 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:29:31 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:29:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:32,218][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:35,271][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.05s/it, est. speed input: 165.45 toks/s, output: 10.48 toks/s]
[2025-01-08 19:29:35,411][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.90it/s, est. speed input: 2531.37 toks/s, output: 167.30 toks/s]
[2025-01-08 19:29:35,411][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.01it/s, est. speed input: 2531.37 toks/s, output: 167.30 toks/s]
WARNING 01-08 19:29:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:35,637][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:36,564][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.08it/s, est. speed input: 628.46 toks/s, output: 35.57 toks/s]
[2025-01-08 19:29:36,599][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 1197.86 toks/s, output: 70.71 toks/s]
WARNING 01-08 19:29:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:36,820][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:39,059][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.24s/it, est. speed input: 312.17 toks/s, output: 12.95 toks/s]
[2025-01-08 19:29:39,060][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.25it/s, est. speed input: 4369.00 toks/s, output: 181.26 toks/s]
WARNING 01-08 19:29:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:39,297][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:41,562][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.27s/it, est. speed input: 275.42 toks/s, output: 14.57 toks/s]
[2025-01-08 19:29:41,563][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.18it/s, est. speed input: 3855.25 toks/s, output: 203.86 toks/s]
WARNING 01-08 19:29:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:41,811][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:42,709][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 778.74 toks/s, output: 32.31 toks/s]
[2025-01-08 19:29:42,709][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1556.79 toks/s, output: 64.59 toks/s]
WARNING 01-08 19:29:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:42,919][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:44,096][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.18s/it, est. speed input: 579.72 toks/s, output: 28.05 toks/s]
[2025-01-08 19:29:44,130][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.30it/s, est. speed input: 2282.54 toks/s, output: 110.70 toks/s]
WARNING 01-08 19:29:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:44,352][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:46,770][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.42s/it, est. speed input: 416.91 toks/s, output: 11.99 toks/s]
[2025-01-08 19:29:46,770][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  4.96it/s, est. speed input: 5001.76 toks/s, output: 143.90 toks/s]
WARNING 01-08 19:29:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:46,989][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:49,202][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:24,  2.21s/it, est. speed input: 335.83 toks/s, output: 14.92 toks/s]
[2025-01-08 19:29:49,202][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.42it/s, est. speed input: 4029.37 toks/s, output: 178.94 toks/s]
WARNING 01-08 19:29:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:49,414][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:50,655][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 812.89 toks/s, output: 23.39 toks/s]
[2025-01-08 19:29:50,655][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.22it/s, est. speed input: 3250.45 toks/s, output: 93.51 toks/s]
WARNING 01-08 19:29:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:50,864][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:52,102][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 646.95 toks/s, output: 26.65 toks/s]
[2025-01-08 19:29:52,136][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.14it/s, est. speed input: 2547.40 toks/s, output: 105.32 toks/s]
WARNING 01-08 19:29:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:52,364][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:55,176][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:30,  2.81s/it, est. speed input: 468.36 toks/s, output: 10.31 toks/s]
[2025-01-08 19:29:55,687][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:03<00:14,  1.46s/it, est. speed input: 792.79 toks/s, output: 22.27 toks/s]
[2025-01-08 19:29:55,898][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:07,  1.13it/s, est. speed input: 1118.05 toks/s, output: 35.66 toks/s]
[2025-01-08 19:29:56,013][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:02,  2.39it/s, est. speed input: 1804.67 toks/s, output: 64.95 toks/s]
[2025-01-08 19:29:56,458][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:04<00:01,  3.70it/s, est. speed input: 2573.32 toks/s, output: 104.05 toks/s]
[2025-01-08 19:29:56,864][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:04<00:00,  4.74it/s, est. speed input: 3219.05 toks/s, output: 149.76 toks/s]
[2025-01-08 19:29:57,017][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  4.98it/s, est. speed input: 3396.64 toks/s, output: 167.64 toks/s]
[2025-01-08 19:29:57,017][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.58it/s, est. speed input: 3396.64 toks/s, output: 167.64 toks/s]
WARNING 01-08 19:29:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:29:57,298][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:29:59,067][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.77s/it, est. speed input: 817.82 toks/s, output: 16.40 toks/s]
[2025-01-08 19:29:59,200][root][ERROR] - Processed prompts:  50%|#####     | 3/6 [00:01<00:01,  1.97it/s, est. speed input: 2200.95 toks/s, output: 48.90 toks/s]
[2025-01-08 19:29:59,528][root][ERROR] - Processed prompts:  67%|######6   | 4/6 [00:02<00:00,  2.24it/s, est. speed input: 2467.96 toks/s, output: 64.58 toks/s]
[2025-01-08 19:29:59,987][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:02<00:00,  2.22it/s, est. speed input: 2536.80 toks/s, output: 81.83 toks/s]
[2025-01-08 19:30:00,292][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.48it/s, est. speed input: 2718.01 toks/s, output: 104.88 toks/s]
[2025-01-08 19:30:00,292][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.00it/s, est. speed input: 2718.01 toks/s, output: 104.88 toks/s]
WARNING 01-08 19:30:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:30:00,557][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:30:01,390][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1687.88 toks/s, output: 34.81 toks/s]
[2025-01-08 19:30:01,391][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1687.88 toks/s, output: 34.81 toks/s]
[2025-01-08 19:30:08,859][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:30:08,912][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:30:10,602][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 19:30:12,197][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 19:30:13,767][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:30:14,284][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:30:14,285][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.34s/it]
[2025-01-08 19:30:24,720][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:30:25,199][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:30:25,252][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:30:27,094][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 19:30:28,707][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:30:30,263][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 19:30:30,754][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:30:30,755][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:30:44,681][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:30:44,982][root][INFO] - Loading VLLM model.
WARNING 01-08 19:30:45 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:30:45 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:30:45 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:30:45 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:30:45,995][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:30:47,319][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:30:47,717][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.28it/s]
[2025-01-08 19:30:49,033][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:30:50,380][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:30:50,380][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 19:30:50 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:31:04 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:31:04 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:31:04 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:31:26 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:31:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:26,864][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:29,504][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.64s/it, est. speed input: 191.31 toks/s, output: 12.12 toks/s]
[2025-01-08 19:31:29,643][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.90it/s, est. speed input: 2908.18 toks/s, output: 191.84 toks/s]
[2025-01-08 19:31:29,643][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.76it/s, est. speed input: 2908.18 toks/s, output: 191.84 toks/s]
WARNING 01-08 19:31:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:29,852][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:31,147][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.29s/it, est. speed input: 440.23 toks/s, output: 25.49 toks/s]
[2025-01-08 19:31:31,224][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.64it/s, est. speed input: 2085.05 toks/s, output: 127.54 toks/s]
WARNING 01-08 19:31:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:31,456][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:33,362][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 366.81 toks/s, output: 15.22 toks/s]
[2025-01-08 19:31:33,363][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 4033.53 toks/s, output: 167.34 toks/s]
WARNING 01-08 19:31:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:33,613][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:35,522][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 326.78 toks/s, output: 17.28 toks/s]
[2025-01-08 19:31:35,523][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.76it/s, est. speed input: 3594.11 toks/s, output: 190.04 toks/s]
WARNING 01-08 19:31:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:35,742][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:36,941][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.20s/it, est. speed input: 583.06 toks/s, output: 24.19 toks/s]
[2025-01-08 19:31:36,942][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.17it/s, est. speed input: 2756.63 toks/s, output: 120.90 toks/s]
WARNING 01-08 19:31:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:37,150][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:38,445][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.30s/it, est. speed input: 531.99 toks/s, output: 25.48 toks/s]
[2025-01-08 19:31:38,489][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.74it/s, est. speed input: 2584.79 toks/s, output: 129.24 toks/s]
WARNING 01-08 19:31:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:38,709][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:40,968][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:22,  2.26s/it, est. speed input: 446.24 toks/s, output: 12.84 toks/s]
[2025-01-08 19:31:40,968][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.87it/s, est. speed input: 4907.44 toks/s, output: 141.19 toks/s]
WARNING 01-08 19:31:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:41,188][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:43,247][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.06s/it, est. speed input: 360.86 toks/s, output: 16.03 toks/s]
[2025-01-08 19:31:43,247][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.34it/s, est. speed input: 3968.89 toks/s, output: 176.25 toks/s]
WARNING 01-08 19:31:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:43,458][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:44,840][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.38s/it, est. speed input: 729.48 toks/s, output: 20.99 toks/s]
[2025-01-08 19:31:44,840][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.62it/s, est. speed input: 3505.15 toks/s, output: 104.90 toks/s]
WARNING 01-08 19:31:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:45,052][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:46,402][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.35s/it, est. speed input: 598.52 toks/s, output: 24.44 toks/s]
[2025-01-08 19:31:46,446][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.59it/s, est. speed input: 2914.97 toks/s, output: 124.12 toks/s]
WARNING 01-08 19:31:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:46,673][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:48,790][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.12s/it, est. speed input: 622.21 toks/s, output: 6.14 toks/s]
[2025-01-08 19:31:49,273][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:10,  1.16s/it, est. speed input: 1013.30 toks/s, output: 16.16 toks/s]
[2025-01-08 19:31:49,595][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:02<00:01,  3.06it/s, est. speed input: 2704.62 toks/s, output: 58.53 toks/s]
[2025-01-08 19:31:49,920][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  3.06it/s, est. speed input: 2839.64 toks/s, output: 69.92 toks/s]
[2025-01-08 19:31:50,372][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  3.47it/s, est. speed input: 3204.44 toks/s, output: 97.87 toks/s]
[2025-01-08 19:31:50,684][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  3.41it/s, est. speed input: 3283.26 toks/s, output: 113.93 toks/s]
[2025-01-08 19:31:51,124][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  3.05it/s, est. speed input: 3255.03 toks/s, output: 129.87 toks/s]
[2025-01-08 19:31:51,124][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.47it/s, est. speed input: 3255.03 toks/s, output: 129.87 toks/s]
WARNING 01-08 19:31:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:31:51,394][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:31:53,690][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.30s/it, est. speed input: 602.94 toks/s, output: 12.63 toks/s]
[2025-01-08 19:31:54,023][root][ERROR] - Processed prompts:  67%|######6   | 6/9 [00:02<00:01,  2.94it/s, est. speed input: 3077.90 toks/s, output: 71.90 toks/s]
[2025-01-08 19:31:54,229][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:02<00:00,  3.19it/s, est. speed input: 3319.37 toks/s, output: 85.74 toks/s]
[2025-01-08 19:31:54,376][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:02<00:00,  3.62it/s, est. speed input: 3597.11 toks/s, output: 102.29 toks/s]
[2025-01-08 19:31:56,504][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  1.38it/s, est. speed input: 2356.67 toks/s, output: 96.48 toks/s]
[2025-01-08 19:31:56,504][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  1.76it/s, est. speed input: 2356.67 toks/s, output: 96.48 toks/s]
[2025-01-08 19:32:04,090][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:32:04,143][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:32:05,822][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 19:32:07,465][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:32:09,074][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:32:09,592][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:32:09,592][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:32:20,067][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:32:20,839][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:32:20,891][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:32:22,618][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 19:32:24,234][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:32:25,776][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:32:26,273][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 19:32:26,274][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:32:40,862][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:32:41,176][root][INFO] - Loading VLLM model.
WARNING 01-08 19:32:41 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:32:41 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:32:41 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:32:41 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:32:42,110][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:32:43,479][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:32:43,879][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:32:45,232][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:32:46,640][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:32:46,640][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:32:46 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:33:00 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:33:01 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:33:01 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:33:22 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:33:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:22,771][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:25,873][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.10s/it, est. speed input: 162.80 toks/s, output: 10.32 toks/s]
[2025-01-08 19:33:26,006][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.81it/s, est. speed input: 2497.62 toks/s, output: 163.52 toks/s]
[2025-01-08 19:33:26,007][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.95it/s, est. speed input: 2497.62 toks/s, output: 163.52 toks/s]
WARNING 01-08 19:33:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:26,239][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:28,114][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.87s/it, est. speed input: 303.51 toks/s, output: 17.60 toks/s]
[2025-01-08 19:33:28,238][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  7.45it/s, est. speed input: 3140.75 toks/s, output: 192.61 toks/s]
[2025-01-08 19:33:28,238][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.50it/s, est. speed input: 3140.75 toks/s, output: 192.61 toks/s]
WARNING 01-08 19:33:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:28,454][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:29,666][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.21s/it, est. speed input: 576.69 toks/s, output: 23.93 toks/s]
[2025-01-08 19:33:29,666][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.12it/s, est. speed input: 2882.37 toks/s, output: 119.58 toks/s]
WARNING 01-08 19:33:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:29,880][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:31,124][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 501.48 toks/s, output: 26.52 toks/s]
[2025-01-08 19:33:31,125][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.02it/s, est. speed input: 2506.51 toks/s, output: 132.56 toks/s]
WARNING 01-08 19:33:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:31,344][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:33,189][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.84s/it, est. speed input: 378.87 toks/s, output: 15.72 toks/s]
[2025-01-08 19:33:33,190][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.96it/s, est. speed input: 3859.01 toks/s, output: 172.85 toks/s]
WARNING 01-08 19:33:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:33,411][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:35,463][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.05s/it, est. speed input: 336.29 toks/s, output: 17.06 toks/s]
[2025-01-08 19:33:35,531][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.19it/s, est. speed input: 3581.70 toks/s, output: 183.54 toks/s]
WARNING 01-08 19:33:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:35,768][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:37,138][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.37s/it, est. speed input: 735.81 toks/s, output: 21.17 toks/s]
[2025-01-08 19:33:37,139][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.65it/s, est. speed input: 3677.93 toks/s, output: 105.81 toks/s]
WARNING 01-08 19:33:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:37,355][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:38,801][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.45s/it, est. speed input: 513.77 toks/s, output: 22.82 toks/s]
[2025-01-08 19:33:38,869][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.96it/s, est. speed input: 2968.97 toks/s, output: 133.42 toks/s]
WARNING 01-08 19:33:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:39,093][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:41,151][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.06s/it, est. speed input: 489.84 toks/s, output: 14.09 toks/s]
[2025-01-08 19:33:41,152][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.86it/s, est. speed input: 4707.74 toks/s, output: 140.89 toks/s]
WARNING 01-08 19:33:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:41,379][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:43,440][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.06s/it, est. speed input: 393.54 toks/s, output: 16.98 toks/s]
[2025-01-08 19:33:43,441][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.85it/s, est. speed input: 3928.89 toks/s, output: 169.79 toks/s]
WARNING 01-08 19:33:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:43,670][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:45,348][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.68s/it, est. speed input: 785.04 toks/s, output: 17.29 toks/s]
[2025-01-08 19:33:45,661][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:01<00:00,  3.16it/s, est. speed input: 3055.32 toks/s, output: 81.39 toks/s]
[2025-01-08 19:33:45,915][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  3.31it/s, est. speed input: 3296.56 toks/s, output: 99.37 toks/s]
[2025-01-08 19:33:45,915][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:02<00:00,  2.67it/s, est. speed input: 3296.56 toks/s, output: 99.37 toks/s]
WARNING 01-08 19:33:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:46,170][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:47,075][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 997.85 toks/s, output: 40.89 toks/s]
[2025-01-08 19:33:47,076][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.10it/s, est. speed input: 997.85 toks/s, output: 40.89 toks/s]
WARNING 01-08 19:33:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:47,317][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:49,400][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.08s/it, est. speed input: 632.47 toks/s, output: 6.24 toks/s]
[2025-01-08 19:33:49,880][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:10,  1.14s/it, est. speed input: 1027.94 toks/s, output: 16.39 toks/s]
[2025-01-08 19:33:50,473][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:03<00:01,  2.66it/s, est. speed input: 2473.77 toks/s, output: 57.67 toks/s]
[2025-01-08 19:33:50,587][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:03<00:00,  3.81it/s, est. speed input: 3193.57 toks/s, output: 89.92 toks/s]
[2025-01-08 19:33:51,280][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  2.86it/s, est. speed input: 2918.39 toks/s, output: 97.42 toks/s]
[2025-01-08 19:33:51,665][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  2.80it/s, est. speed input: 2962.59 toks/s, output: 114.78 toks/s]
[2025-01-08 19:33:52,308][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.34it/s, est. speed input: 2844.99 toks/s, output: 130.26 toks/s]
[2025-01-08 19:33:52,308][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.20it/s, est. speed input: 2844.99 toks/s, output: 130.26 toks/s]
WARNING 01-08 19:33:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:33:52,576][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:33:53,796][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1134.84 toks/s, output: 23.78 toks/s]
[2025-01-08 19:33:53,796][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 3225.46 toks/s, output: 71.31 toks/s]
[2025-01-08 19:34:01,132][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:34:01,185][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:34:02,866][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 19:34:04,563][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:34:06,218][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 19:34:06,777][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:34:06,778][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:34:17,305][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:34:17,817][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:34:17,869][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:34:19,845][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.98s/it]
[2025-01-08 19:34:21,557][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.82s/it]
[2025-01-08 19:34:23,225][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.75s/it]
[2025-01-08 19:34:23,756][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.27s/it]
[2025-01-08 19:34:23,756][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.47s/it]
[2025-01-08 19:34:37,317][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:34:37,641][root][INFO] - Loading VLLM model.
WARNING 01-08 19:34:38 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:34:38 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:34:38 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:34:38 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:34:41,461][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:34:42,885][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.42s/it]
[2025-01-08 19:34:43,301][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.20it/s]
[2025-01-08 19:34:44,716][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.10s/it]
[2025-01-08 19:34:46,166][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.24s/it]
[2025-01-08 19:34:46,166][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
INFO 01-08 19:34:46 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:35:00 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:35:00 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:35:00 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:35:22 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:35:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:23,326][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:26,122][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.80s/it, est. speed input: 180.64 toks/s, output: 11.45 toks/s]
[2025-01-08 19:35:26,256][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.51it/s, est. speed input: 2757.65 toks/s, output: 180.88 toks/s]
[2025-01-08 19:35:26,256][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.46it/s, est. speed input: 2757.65 toks/s, output: 180.88 toks/s]
WARNING 01-08 19:35:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:26,483][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:27,959][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.48s/it, est. speed input: 395.03 toks/s, output: 22.36 toks/s]
[2025-01-08 19:35:28,005][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.60it/s, est. speed input: 2625.84 toks/s, output: 158.29 toks/s]
WARNING 01-08 19:35:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:28,233][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:29,902][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.67s/it, est. speed input: 418.82 toks/s, output: 17.38 toks/s]
[2025-01-08 19:35:29,903][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.39it/s, est. speed input: 3768.23 toks/s, output: 156.34 toks/s]
WARNING 01-08 19:35:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:30,116][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:31,807][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:13,  1.69s/it, est. speed input: 369.10 toks/s, output: 19.52 toks/s]
[2025-01-08 19:35:31,807][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  5.32it/s, est. speed input: 3321.50 toks/s, output: 175.62 toks/s]
WARNING 01-08 19:35:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:32,019][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:33,465][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.45s/it, est. speed input: 483.36 toks/s, output: 20.05 toks/s]
[2025-01-08 19:35:33,466][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.84it/s, est. speed input: 3251.70 toks/s, output: 140.33 toks/s]
WARNING 01-08 19:35:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:33,678][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:35,313][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.64s/it, est. speed input: 417.13 toks/s, output: 20.18 toks/s]
[2025-01-08 19:35:35,362][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.75it/s, est. speed input: 3276.75 toks/s, output: 163.93 toks/s]
WARNING 01-08 19:35:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:35,578][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:37,394][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.82s/it, est. speed input: 555.09 toks/s, output: 15.97 toks/s]
[2025-01-08 19:35:37,395][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.40it/s, est. speed input: 4439.57 toks/s, output: 127.73 toks/s]
WARNING 01-08 19:35:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:37,606][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:39,286][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.68s/it, est. speed input: 442.44 toks/s, output: 19.65 toks/s]
[2025-01-08 19:35:39,304][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.71it/s, est. speed input: 3503.19 toks/s, output: 156.15 toks/s]
WARNING 01-08 19:35:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:39,528][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:41,324][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.80s/it, est. speed input: 561.43 toks/s, output: 16.15 toks/s]
[2025-01-08 19:35:41,324][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.45it/s, est. speed input: 4381.27 toks/s, output: 129.17 toks/s]
WARNING 01-08 19:35:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:41,561][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:43,303][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.74s/it, est. speed input: 460.00 toks/s, output: 18.95 toks/s]
[2025-01-08 19:35:43,352][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.47it/s, est. speed input: 3620.08 toks/s, output: 154.16 toks/s]
WARNING 01-08 19:35:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:43,584][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:45,682][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:02<00:14,  2.10s/it, est. speed input: 627.73 toks/s, output: 13.82 toks/s]
[2025-01-08 19:35:46,054][root][ERROR] - Processed prompts:  38%|###7      | 3/8 [00:02<00:03,  1.47it/s, est. speed input: 1599.71 toks/s, output: 41.30 toks/s]
[2025-01-08 19:35:46,346][root][ERROR] - Processed prompts:  62%|######2   | 5/8 [00:02<00:01,  2.46it/s, est. speed input: 2383.89 toks/s, output: 74.58 toks/s]
[2025-01-08 19:35:46,876][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:03<00:00,  3.50it/s, est. speed input: 3200.41 toks/s, output: 124.84 toks/s]
[2025-01-08 19:35:46,876][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:03<00:00,  2.43it/s, est. speed input: 3200.41 toks/s, output: 124.84 toks/s]
WARNING 01-08 19:35:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:47,142][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:49,585][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:21,  2.44s/it, est. speed input: 539.19 toks/s, output: 11.87 toks/s]
[2025-01-08 19:35:49,887][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:02<00:01,  2.83it/s, est. speed input: 2880.29 toks/s, output: 68.13 toks/s]
[2025-01-08 19:35:50,688][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:01,  2.26it/s, est. speed input: 2601.39 toks/s, output: 74.74 toks/s]
[2025-01-08 19:35:50,934][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:03<00:00,  2.51it/s, est. speed input: 2779.87 toks/s, output: 93.63 toks/s]
[2025-01-08 19:35:51,374][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:04<00:00,  2.45it/s, est. speed input: 2801.89 toks/s, output: 110.83 toks/s]
[2025-01-08 19:35:51,493][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.99it/s, est. speed input: 3027.99 toks/s, output: 135.61 toks/s]
[2025-01-08 19:35:51,493][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:04<00:00,  2.30it/s, est. speed input: 3027.99 toks/s, output: 135.61 toks/s]
WARNING 01-08 19:35:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:35:51,751][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:35:52,590][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1771.48 toks/s, output: 34.59 toks/s]
[2025-01-08 19:35:52,590][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1771.48 toks/s, output: 34.59 toks/s]
[2025-01-08 19:35:59,928][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:35:59,981][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:36:01,731][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 19:36:03,359][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:36:04,964][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:36:05,496][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 19:36:05,496][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:36:15,924][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:36:16,499][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:36:16,551][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:36:18,374][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 19:36:19,940][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 19:36:21,523][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:36:22,032][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:36:22,032][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:36:35,608][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:36:35,945][root][INFO] - Loading VLLM model.
WARNING 01-08 19:36:36 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:36:36 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:36:36 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:36:36 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:36:37,099][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:36:38,420][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:36:38,812][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:36:40,127][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:36:41,469][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:36:41,469][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:36:41 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:36:55 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:36:56 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:36:56 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:37:17 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:37:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:17,817][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:20,520][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.70s/it, est. speed input: 186.83 toks/s, output: 11.84 toks/s]
[2025-01-08 19:37:20,659][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.73it/s, est. speed input: 2843.17 toks/s, output: 187.55 toks/s]
[2025-01-08 19:37:20,659][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.63it/s, est. speed input: 2843.17 toks/s, output: 187.55 toks/s]
WARNING 01-08 19:37:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:20,868][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:22,111][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 458.77 toks/s, output: 26.56 toks/s]
[2025-01-08 19:37:22,189][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.79it/s, est. speed input: 2167.43 toks/s, output: 132.57 toks/s]
WARNING 01-08 19:37:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:22,410][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:24,330][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.92s/it, est. speed input: 364.18 toks/s, output: 15.11 toks/s]
[2025-01-08 19:37:24,331][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.73it/s, est. speed input: 4004.84 toks/s, output: 166.15 toks/s]
WARNING 01-08 19:37:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:24,549][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:26,457][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 327.16 toks/s, output: 17.30 toks/s]
[2025-01-08 19:37:26,457][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 3598.19 toks/s, output: 190.26 toks/s]
WARNING 01-08 19:37:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:26,666][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:27,864][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.20s/it, est. speed input: 583.75 toks/s, output: 24.22 toks/s]
[2025-01-08 19:37:27,864][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.17it/s, est. speed input: 2759.88 toks/s, output: 121.05 toks/s]
WARNING 01-08 19:37:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:28,073][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:29,368][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.29s/it, est. speed input: 532.30 toks/s, output: 25.49 toks/s]
[2025-01-08 19:37:29,411][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.74it/s, est. speed input: 2586.25 toks/s, output: 129.31 toks/s]
WARNING 01-08 19:37:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:29,634][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:31,895][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:22,  2.26s/it, est. speed input: 445.92 toks/s, output: 12.83 toks/s]
[2025-01-08 19:37:31,895][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.86it/s, est. speed input: 4903.92 toks/s, output: 141.08 toks/s]
WARNING 01-08 19:37:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:32,115][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:34,175][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.06s/it, est. speed input: 360.73 toks/s, output: 16.02 toks/s]
[2025-01-08 19:37:34,176][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.34it/s, est. speed input: 3967.33 toks/s, output: 176.18 toks/s]
WARNING 01-08 19:37:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:34,398][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:35,755][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.36s/it, est. speed input: 743.13 toks/s, output: 21.38 toks/s]
[2025-01-08 19:37:35,756][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.68it/s, est. speed input: 3570.34 toks/s, output: 106.85 toks/s]
WARNING 01-08 19:37:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:35,983][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:37,332][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.35s/it, est. speed input: 599.10 toks/s, output: 24.47 toks/s]
[2025-01-08 19:37:37,376][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.59it/s, est. speed input: 2917.73 toks/s, output: 124.23 toks/s]
WARNING 01-08 19:37:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:37,607][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:39,724][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.12s/it, est. speed input: 622.00 toks/s, output: 6.14 toks/s]
[2025-01-08 19:37:40,177][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:10,  1.14s/it, est. speed input: 1024.99 toks/s, output: 15.95 toks/s]
[2025-01-08 19:37:40,623][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  3.44it/s, est. speed input: 3056.36 toks/s, output: 67.63 toks/s]
[2025-01-08 19:37:40,801][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:03<00:00,  3.71it/s, est. speed input: 3298.38 toks/s, output: 81.08 toks/s]
[2025-01-08 19:37:41,251][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  3.25it/s, est. speed input: 3252.26 toks/s, output: 92.19 toks/s]
[2025-01-08 19:37:42,324][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.54it/s, est. speed input: 3071.09 toks/s, output: 118.29 toks/s]
[2025-01-08 19:37:42,324][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:04<00:00,  2.33it/s, est. speed input: 3071.09 toks/s, output: 118.29 toks/s]
WARNING 01-08 19:37:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:37:42,611][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:37:44,366][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.75s/it, est. speed input: 797.44 toks/s, output: 12.54 toks/s]
[2025-01-08 19:37:44,540][root][ERROR] - Processed prompts:  29%|##8       | 2/7 [00:01<00:04,  1.21it/s, est. speed input: 1408.52 toks/s, output: 26.45 toks/s]
[2025-01-08 19:37:45,396][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:02<00:00,  2.28it/s, est. speed input: 2418.06 toks/s, output: 64.63 toks/s]
[2025-01-08 19:37:46,002][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:03<00:00,  2.08it/s, est. speed input: 2374.72 toks/s, output: 83.77 toks/s]
[2025-01-08 19:37:46,239][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  2.40it/s, est. speed input: 2528.89 toks/s, output: 110.83 toks/s]
[2025-01-08 19:37:46,239][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:03<00:00,  1.93it/s, est. speed input: 2528.89 toks/s, output: 110.83 toks/s]
[2025-01-08 19:37:53,712][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:37:53,765][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:37:55,453][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 19:37:57,053][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 19:37:58,629][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:37:59,149][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:37:59,149][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:38:09,568][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:38:10,072][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:38:10,124][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:38:11,967][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 19:38:13,544][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:38:15,101][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:38:15,619][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:38:15,620][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:38:29,336][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:38:29,641][root][INFO] - Loading VLLM model.
WARNING 01-08 19:38:29 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:38:29 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:38:30 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:38:30 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:38:30,579][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:38:31,897][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:38:32,286][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:38:33,596][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:38:34,940][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:38:34,941][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:38:35 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:38:49 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:38:49 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:38:49 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:39:11 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:39:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:11,386][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:14,518][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.13s/it, est. speed input: 161.26 toks/s, output: 10.22 toks/s]
[2025-01-08 19:39:14,656][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.74it/s, est. speed input: 2470.77 toks/s, output: 162.98 toks/s]
[2025-01-08 19:39:14,657][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.89it/s, est. speed input: 2470.77 toks/s, output: 162.98 toks/s]
WARNING 01-08 19:39:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:14,874][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:16,012][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.14s/it, est. speed input: 500.22 toks/s, output: 29.01 toks/s]
[2025-01-08 19:39:16,046][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.41it/s, est. speed input: 1955.01 toks/s, output: 114.35 toks/s]
WARNING 01-08 19:39:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:16,265][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:18,205][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.94s/it, est. speed input: 360.33 toks/s, output: 13.92 toks/s]
[2025-01-08 19:39:18,265][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:01<00:00,  6.00it/s, est. speed input: 4195.24 toks/s, output: 172.05 toks/s]
WARNING 01-08 19:39:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:18,497][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:20,407][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 326.88 toks/s, output: 17.29 toks/s]
[2025-01-08 19:39:20,407][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.76it/s, est. speed input: 3595.14 toks/s, output: 190.10 toks/s]
WARNING 01-08 19:39:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:20,615][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:21,817][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.20s/it, est. speed input: 581.78 toks/s, output: 24.14 toks/s]
[2025-01-08 19:39:21,818][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.16it/s, est. speed input: 2817.87 toks/s, output: 120.63 toks/s]
WARNING 01-08 19:39:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:22,024][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:23,423][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.40s/it, est. speed input: 491.96 toks/s, output: 23.60 toks/s]
[2025-01-08 19:39:23,457][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.19it/s, est. speed input: 2840.18 toks/s, output: 139.60 toks/s]
WARNING 01-08 19:39:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:23,678][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:25,730][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.05s/it, est. speed input: 490.36 toks/s, output: 13.16 toks/s]
[2025-01-08 19:39:25,787][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.74it/s, est. speed input: 4777.81 toks/s, output: 136.54 toks/s]
WARNING 01-08 19:39:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:26,003][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:28,072][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.07s/it, est. speed input: 359.17 toks/s, output: 15.95 toks/s]
[2025-01-08 19:39:28,073][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.83it/s, est. speed input: 3591.25 toks/s, output: 159.48 toks/s]
WARNING 01-08 19:39:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:28,311][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:29,824][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.51s/it, est. speed input: 666.33 toks/s, output: 19.17 toks/s]
[2025-01-08 19:39:29,825][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.96it/s, est. speed input: 3921.37 toks/s, output: 114.98 toks/s]
WARNING 01-08 19:39:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:30,040][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:31,519][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.48s/it, est. speed input: 545.67 toks/s, output: 22.31 toks/s]
[2025-01-08 19:39:31,554][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.96it/s, est. speed input: 3161.93 toks/s, output: 132.16 toks/s]
WARNING 01-08 19:39:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:31,797][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:34,122][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:20,  2.32s/it, est. speed input: 566.60 toks/s, output: 10.76 toks/s]
[2025-01-08 19:39:34,233][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:02<00:02,  2.13it/s, est. speed input: 2161.10 toks/s, output: 44.34 toks/s]
[2025-01-08 19:39:34,364][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:02<00:00,  4.89it/s, est. speed input: 4103.91 toks/s, output: 91.18 toks/s]
[2025-01-08 19:39:35,154][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:03<00:00,  2.98it/s, est. speed input: 3923.07 toks/s, output: 113.23 toks/s]
WARNING 01-08 19:39:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:35,436][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:37,553][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:19,  2.12s/it, est. speed input: 622.02 toks/s, output: 8.03 toks/s]
[2025-01-08 19:39:37,898][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:02<00:08,  1.07s/it, est. speed input: 1102.55 toks/s, output: 18.68 toks/s]
[2025-01-08 19:39:38,054][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:02<00:00,  4.31it/s, est. speed input: 3649.27 toks/s, output: 75.62 toks/s]
[2025-01-08 19:39:39,048][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  3.17it/s, est. speed input: 3342.64 toks/s, output: 96.89 toks/s]
[2025-01-08 19:39:39,083][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:03<00:00,  2.74it/s, est. speed input: 3672.30 toks/s, output: 120.38 toks/s]
WARNING 01-08 19:39:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:39:39,354][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:39:40,183][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1676.05 toks/s, output: 35.02 toks/s]
[2025-01-08 19:39:40,183][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1676.05 toks/s, output: 35.02 toks/s]
[2025-01-08 19:39:47,594][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:39:47,647][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:39:49,340][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 19:39:50,964][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 19:39:52,547][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:39:53,070][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:39:53,070][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:40:03,503][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:40:04,044][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:40:04,096][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:40:05,971][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 19:40:07,557][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 19:40:09,127][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 19:40:09,620][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:40:09,620][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 19:40:23,452][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:40:23,751][root][INFO] - Loading VLLM model.
WARNING 01-08 19:40:24 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:40:24 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:40:24 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:40:24 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:40:24,864][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:40:26,230][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:40:26,618][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.26it/s]
[2025-01-08 19:40:27,922][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:40:29,256][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:40:29,256][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 19:40:29 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:40:43 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:40:43 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:40:43 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:41:05 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:41:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:05,741][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:08,266][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.52s/it, est. speed input: 200.05 toks/s, output: 12.68 toks/s]
[2025-01-08 19:41:08,401][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  8.26it/s, est. speed input: 3038.71 toks/s, output: 199.32 toks/s]
[2025-01-08 19:41:08,401][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.02it/s, est. speed input: 3038.71 toks/s, output: 199.32 toks/s]
WARNING 01-08 19:41:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:08,614][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:10,593][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.98s/it, est. speed input: 288.09 toks/s, output: 16.68 toks/s]
[2025-01-08 19:41:10,700][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  7.84it/s, est. speed input: 3284.56 toks/s, output: 199.50 toks/s]
[2025-01-08 19:41:10,700][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.75it/s, est. speed input: 3284.56 toks/s, output: 199.50 toks/s]
WARNING 01-08 19:41:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:10,908][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:12,013][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.10s/it, est. speed input: 632.66 toks/s, output: 26.25 toks/s]
[2025-01-08 19:41:12,014][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.62it/s, est. speed input: 2529.66 toks/s, output: 104.95 toks/s]
WARNING 01-08 19:41:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:12,221][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:13,368][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.15s/it, est. speed input: 543.95 toks/s, output: 28.77 toks/s]
[2025-01-08 19:41:13,369][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.49it/s, est. speed input: 2175.00 toks/s, output: 115.02 toks/s]
WARNING 01-08 19:41:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:13,586][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:15,580][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.99s/it, est. speed input: 350.54 toks/s, output: 14.54 toks/s]
[2025-01-08 19:41:15,580][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:01<00:00,  6.02it/s, est. speed input: 4015.82 toks/s, output: 174.47 toks/s]
WARNING 01-08 19:41:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:15,796][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:17,919][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:23,  2.12s/it, est. speed input: 325.00 toks/s, output: 15.54 toks/s]
[2025-01-08 19:41:18,057][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  7.21it/s, est. speed input: 3664.82 toks/s, output: 184.46 toks/s]
[2025-01-08 19:41:18,057][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.31it/s, est. speed input: 3664.82 toks/s, output: 184.46 toks/s]
WARNING 01-08 19:41:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:18,279][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:19,644][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.36s/it, est. speed input: 738.64 toks/s, output: 21.25 toks/s]
[2025-01-08 19:41:19,644][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.93it/s, est. speed input: 2953.51 toks/s, output: 84.97 toks/s]
WARNING 01-08 19:41:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:19,858][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:21,188][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.33s/it, est. speed input: 559.03 toks/s, output: 24.83 toks/s]
[2025-01-08 19:41:21,306][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.48it/s, est. speed input: 2592.77 toks/s, output: 118.86 toks/s]
[2025-01-08 19:41:21,306][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.45it/s, est. speed input: 2592.77 toks/s, output: 118.86 toks/s]
WARNING 01-08 19:41:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:21,545][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:23,781][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:22,  2.24s/it, est. speed input: 450.85 toks/s, output: 12.97 toks/s]
[2025-01-08 19:41:23,782][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.92it/s, est. speed input: 4870.91 toks/s, output: 142.64 toks/s]
WARNING 01-08 19:41:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:24,000][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:26,141][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.14s/it, est. speed input: 378.00 toks/s, output: 15.42 toks/s]
[2025-01-08 19:41:26,193][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.02it/s, est. speed input: 4061.50 toks/s, output: 171.91 toks/s]
WARNING 01-08 19:41:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:26,416][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:27,886][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.47s/it, est. speed input: 424.54 toks/s, output: 19.73 toks/s]
[2025-01-08 19:41:28,220][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.25it/s, est. speed input: 1076.16 toks/s, output: 40.47 toks/s]
[2025-01-08 19:41:28,466][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.82it/s, est. speed input: 1589.34 toks/s, output: 62.93 toks/s]
[2025-01-08 19:41:28,986][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.86it/s, est. speed input: 1780.06 toks/s, output: 82.87 toks/s]
[2025-01-08 19:41:29,949][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.45it/s, est. speed input: 1667.64 toks/s, output: 100.19 toks/s]
[2025-01-08 19:41:29,949][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:03<00:00,  1.42it/s, est. speed input: 1667.64 toks/s, output: 100.19 toks/s]
WARNING 01-08 19:41:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:30,164][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:31,122][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.04it/s, est. speed input: 939.79 toks/s, output: 41.77 toks/s]
[2025-01-08 19:41:31,123][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.04it/s, est. speed input: 939.79 toks/s, output: 41.77 toks/s]
WARNING 01-08 19:41:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:31,353][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:33,924][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.57s/it, est. speed input: 512.35 toks/s, output: 4.67 toks/s]
[2025-01-08 19:41:34,340][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:15,  1.30s/it, est. speed input: 882.11 toks/s, output: 12.06 toks/s]
[2025-01-08 19:41:34,502][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.86it/s, est. speed input: 1611.30 toks/s, output: 28.59 toks/s]
[2025-01-08 19:41:35,096][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  5.71it/s, est. speed input: 4263.25 toks/s, output: 93.79 toks/s]
[2025-01-08 19:41:35,225][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:03<00:00,  5.90it/s, est. speed input: 4461.49 toks/s, output: 107.46 toks/s]
[2025-01-08 19:41:35,293][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  3.55it/s, est. speed input: 4718.74 toks/s, output: 123.11 toks/s]
WARNING 01-08 19:41:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:35,559][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:36,527][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.03it/s, est. speed input: 1011.86 toks/s, output: 41.34 toks/s]
[2025-01-08 19:41:36,527][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.03it/s, est. speed input: 1011.86 toks/s, output: 41.34 toks/s]
WARNING 01-08 19:41:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:36,735][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:38,047][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.31s/it, est. speed input: 1063.78 toks/s, output: 18.30 toks/s]
[2025-01-08 19:41:38,150][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:01<00:01,  1.67it/s, est. speed input: 1964.13 toks/s, output: 37.47 toks/s]
[2025-01-08 19:41:38,150][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.83it/s, est. speed input: 3965.69 toks/s, output: 78.47 toks/s]
WARNING 01-08 19:41:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:41:38,377][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:41:39,263][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 832.70 toks/s, output: 41.75 toks/s]
[2025-01-08 19:41:39,264][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 832.70 toks/s, output: 41.75 toks/s]
[2025-01-08 19:41:46,771][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:41:46,825][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:41:48,569][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 19:41:50,184][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 19:41:51,746][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:41:52,265][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:41:52,266][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:42:02,753][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:42:03,280][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:42:03,332][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:42:05,197][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 19:42:06,793][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:42:08,329][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:42:08,825][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:42:08,825][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:42:22,525][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:42:22,813][root][INFO] - Loading VLLM model.
WARNING 01-08 19:42:22 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:42:22 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:42:23 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:42:23 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:42:23,765][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:42:25,081][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:42:25,468][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:42:26,764][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 19:42:28,093][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 19:42:28,093][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 19:42:28 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:42:42 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:42:42 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:42:42 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:43:04 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:43:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:04,318][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:07,413][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.10s/it, est. speed input: 163.14 toks/s, output: 10.34 toks/s]
[2025-01-08 19:43:07,550][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.81it/s, est. speed input: 2499.48 toks/s, output: 164.57 toks/s]
[2025-01-08 19:43:07,551][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.95it/s, est. speed input: 2499.48 toks/s, output: 164.57 toks/s]
WARNING 01-08 19:43:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:07,759][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:09,018][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.26s/it, est. speed input: 463.52 toks/s, output: 26.24 toks/s]
[2025-01-08 19:43:09,058][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.85it/s, est. speed input: 2202.99 toks/s, output: 131.72 toks/s]
WARNING 01-08 19:43:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:09,285][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:11,192][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 366.67 toks/s, output: 15.21 toks/s]
[2025-01-08 19:43:11,192][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 4032.20 toks/s, output: 167.29 toks/s]
WARNING 01-08 19:43:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:11,421][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:13,328][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 327.25 toks/s, output: 17.31 toks/s]
[2025-01-08 19:43:13,329][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 3599.26 toks/s, output: 190.32 toks/s]
WARNING 01-08 19:43:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:13,540][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:14,777][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 565.20 toks/s, output: 23.45 toks/s]
[2025-01-08 19:43:14,778][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.04it/s, est. speed input: 2824.75 toks/s, output: 117.19 toks/s]
WARNING 01-08 19:43:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:15,011][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:16,440][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.43s/it, est. speed input: 477.28 toks/s, output: 23.09 toks/s]
[2025-01-08 19:43:16,480][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.08it/s, est. speed input: 2820.39 toks/s, output: 138.87 toks/s]
WARNING 01-08 19:43:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:16,698][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:18,802][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.10s/it, est. speed input: 479.14 toks/s, output: 13.78 toks/s]
[2025-01-08 19:43:18,803][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.75it/s, est. speed input: 4790.10 toks/s, output: 137.81 toks/s]
WARNING 01-08 19:43:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:19,034][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:20,964][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:17,  1.93s/it, est. speed input: 385.05 toks/s, output: 17.10 toks/s]
[2025-01-08 19:43:20,964][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.18it/s, est. speed input: 3850.01 toks/s, output: 170.97 toks/s]
WARNING 01-08 19:43:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:21,176][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:22,705][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.53s/it, est. speed input: 659.16 toks/s, output: 18.96 toks/s]
[2025-01-08 19:43:22,706][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.92it/s, est. speed input: 3953.69 toks/s, output: 113.75 toks/s]
WARNING 01-08 19:43:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:22,917][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:24,401][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.48s/it, est. speed input: 539.94 toks/s, output: 22.24 toks/s]
[2025-01-08 19:43:24,442][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.94it/s, est. speed input: 3190.96 toks/s, output: 133.86 toks/s]
WARNING 01-08 19:43:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:24,665][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:26,750][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.08s/it, est. speed input: 631.76 toks/s, output: 8.15 toks/s]
[2025-01-08 19:43:27,094][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:02<00:08,  1.06s/it, est. speed input: 1084.53 toks/s, output: 18.94 toks/s]
[2025-01-08 19:43:27,582][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:02<00:00,  3.54it/s, est. speed input: 3160.23 toks/s, output: 73.02 toks/s]
[2025-01-08 19:43:27,931][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:03<00:00,  3.39it/s, est. speed input: 3226.63 toks/s, output: 86.06 toks/s]
[2025-01-08 19:43:28,059][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  3.85it/s, est. speed input: 3492.23 toks/s, output: 104.89 toks/s]
[2025-01-08 19:43:28,144][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:03<00:00,  2.87it/s, est. speed input: 3785.54 toks/s, output: 125.32 toks/s]
WARNING 01-08 19:43:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:28,414][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:30,715][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.30s/it, est. speed input: 608.51 toks/s, output: 12.60 toks/s]
[2025-01-08 19:43:30,901][root][ERROR] - Processed prompts:  33%|###3      | 3/9 [00:02<00:03,  1.50it/s, est. speed input: 1621.97 toks/s, output: 37.79 toks/s]
[2025-01-08 19:43:31,075][root][ERROR] - Processed prompts:  44%|####4     | 4/9 [00:02<00:02,  2.02it/s, est. speed input: 2011.10 toks/s, output: 51.49 toks/s]
[2025-01-08 19:43:31,238][root][ERROR] - Processed prompts:  56%|#####5    | 5/9 [00:02<00:01,  2.60it/s, est. speed input: 2361.70 toks/s, output: 66.23 toks/s]
[2025-01-08 19:43:31,670][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:03<00:00,  3.30it/s, est. speed input: 2879.24 toks/s, output: 94.92 toks/s]
[2025-01-08 19:43:31,982][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:03<00:00,  3.27it/s, est. speed input: 2996.40 toks/s, output: 111.28 toks/s]
[2025-01-08 19:43:31,982][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.52it/s, est. speed input: 3395.32 toks/s, output: 135.94 toks/s]
WARNING 01-08 19:43:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:43:32,234][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:43:33,071][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1690.20 toks/s, output: 34.66 toks/s]
[2025-01-08 19:43:33,071][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1690.20 toks/s, output: 34.66 toks/s]
[2025-01-08 19:43:40,664][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:43:40,718][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:43:42,489][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 19:43:44,176][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 19:43:45,825][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:43:46,357][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:43:46,358][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:43:56,720][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:43:57,184][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:43:57,236][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:43:59,106][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 19:44:00,756][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 19:44:02,372][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:44:02,891][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:44:02,891][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:44:16,694][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:44:17,033][root][INFO] - Loading VLLM model.
WARNING 01-08 19:44:17 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:44:17 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:44:17 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:44:17 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:44:18,008][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:44:19,325][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:44:19,715][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 19:44:21,025][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:44:22,367][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:44:22,368][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:44:22 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:44:36 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:44:36 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:44:36 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:44:58 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:44:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:44:58,880][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:01,831][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.95s/it, est. speed input: 171.12 toks/s, output: 10.84 toks/s]
[2025-01-08 19:45:01,963][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.14it/s, est. speed input: 2621.04 toks/s, output: 171.27 toks/s]
[2025-01-08 19:45:01,963][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.19it/s, est. speed input: 2621.04 toks/s, output: 171.27 toks/s]
WARNING 01-08 19:45:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:02,193][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:04,231][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.04s/it, est. speed input: 279.31 toks/s, output: 15.71 toks/s]
[2025-01-08 19:45:04,313][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.14it/s, est. speed input: 3500.38 toks/s, output: 207.65 toks/s]
WARNING 01-08 19:45:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:04,535][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:05,539][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.00s/it, est. speed input: 696.10 toks/s, output: 28.88 toks/s]
[2025-01-08 19:45:05,540][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.99it/s, est. speed input: 2087.30 toks/s, output: 86.60 toks/s]
WARNING 01-08 19:45:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:05,757][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:06,786][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.03s/it, est. speed input: 606.28 toks/s, output: 32.06 toks/s]
[2025-01-08 19:45:06,787][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.91it/s, est. speed input: 1818.10 toks/s, output: 96.15 toks/s]
WARNING 01-08 19:45:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:07,004][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:09,112][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.11s/it, est. speed input: 331.76 toks/s, output: 13.76 toks/s]
[2025-01-08 19:45:09,112][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.17it/s, est. speed input: 4221.96 toks/s, output: 178.88 toks/s]
WARNING 01-08 19:45:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:09,332][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:11,561][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.23s/it, est. speed input: 305.57 toks/s, output: 14.81 toks/s]
[2025-01-08 19:45:11,609][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.71it/s, est. speed input: 3938.36 toks/s, output: 193.65 toks/s]
WARNING 01-08 19:45:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:11,818][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:12,905][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.09s/it, est. speed input: 926.90 toks/s, output: 26.67 toks/s]
[2025-01-08 19:45:12,906][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.76it/s, est. speed input: 2779.60 toks/s, output: 79.97 toks/s]
WARNING 01-08 19:45:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:13,114][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:14,318][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.20s/it, est. speed input: 617.27 toks/s, output: 27.42 toks/s]
[2025-01-08 19:45:14,352][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.23it/s, est. speed input: 2406.60 toks/s, output: 108.25 toks/s]
WARNING 01-08 19:45:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:14,578][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:16,960][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:26,  2.38s/it, est. speed input: 423.25 toks/s, output: 12.18 toks/s]
[2025-01-08 19:45:16,960][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.04it/s, est. speed input: 4996.00 toks/s, output: 146.09 toks/s]
WARNING 01-08 19:45:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:17,182][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:19,459][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.28s/it, est. speed input: 351.45 toks/s, output: 14.50 toks/s]
[2025-01-08 19:45:19,505][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.17it/s, est. speed input: 4184.13 toks/s, output: 174.82 toks/s]
WARNING 01-08 19:45:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:19,718][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:21,067][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.35s/it, est. speed input: 747.11 toks/s, output: 21.49 toks/s]
[2025-01-08 19:45:21,508][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  1.95it/s, est. speed input: 2034.88 toks/s, output: 62.02 toks/s]
[2025-01-08 19:45:21,660][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.58it/s, est. speed input: 2553.37 toks/s, output: 89.08 toks/s]
[2025-01-08 19:45:21,660][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  2.06it/s, est. speed input: 2553.37 toks/s, output: 89.08 toks/s]
WARNING 01-08 19:45:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:21,875][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:22,743][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1003.71 toks/s, output: 40.33 toks/s]
[2025-01-08 19:45:22,743][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1003.71 toks/s, output: 40.33 toks/s]
WARNING 01-08 19:45:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:22,974][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:25,500][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:32,  2.53s/it, est. speed input: 521.44 toks/s, output: 4.36 toks/s]
[2025-01-08 19:45:25,949][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:15,  1.30s/it, est. speed input: 885.44 toks/s, output: 11.77 toks/s]
[2025-01-08 19:45:26,111][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.86it/s, est. speed input: 1679.41 toks/s, output: 28.37 toks/s]
[2025-01-08 19:45:26,565][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  4.37it/s, est. speed input: 3300.00 toks/s, output: 71.58 toks/s]
[2025-01-08 19:45:26,728][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:03<00:00,  4.59it/s, est. speed input: 3507.64 toks/s, output: 82.86 toks/s]
[2025-01-08 19:45:26,833][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  6.07it/s, est. speed input: 4095.17 toks/s, output: 110.16 toks/s]
[2025-01-08 19:45:28,121][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  3.17it/s, est. speed input: 3581.91 toks/s, output: 120.87 toks/s]
[2025-01-08 19:45:28,121][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.72it/s, est. speed input: 3581.91 toks/s, output: 120.87 toks/s]
WARNING 01-08 19:45:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:28,439][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:30,227][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.79s/it, est. speed input: 736.49 toks/s, output: 11.74 toks/s]
[2025-01-08 19:45:30,427][root][ERROR] - Processed prompts:  29%|##8       | 2/7 [00:01<00:04,  1.17it/s, est. speed input: 1364.59 toks/s, output: 25.15 toks/s]
[2025-01-08 19:45:30,427][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  3.52it/s, est. speed input: 4899.72 toks/s, output: 98.06 toks/s]
WARNING 01-08 19:45:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:45:30,674][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:45:31,517][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1651.58 toks/s, output: 34.41 toks/s]
[2025-01-08 19:45:31,517][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1651.58 toks/s, output: 34.41 toks/s]
[2025-01-08 19:45:39,009][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:45:39,063][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:45:40,787][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 19:45:42,460][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 19:45:44,098][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 19:45:44,656][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:45:44,657][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:45:55,200][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:45:55,827][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:45:55,880][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:45:57,661][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.78s/it]
[2025-01-08 19:45:59,258][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 19:46:00,792][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 19:46:01,285][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 19:46:01,285][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:46:15,314][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:46:15,600][root][INFO] - Loading VLLM model.
WARNING 01-08 19:46:15 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:46:15 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:46:16 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:46:16 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:46:16,833][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:46:18,157][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:46:18,549][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:46:19,870][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:46:21,216][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:46:21,216][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 19:46:21 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:46:35 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:46:35 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:46:35 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:46:57 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:46:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:46:57,710][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:00,385][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.67s/it, est. speed input: 188.83 toks/s, output: 11.97 toks/s]
[2025-01-08 19:47:00,524][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.81it/s, est. speed input: 2872.29 toks/s, output: 189.47 toks/s]
[2025-01-08 19:47:00,524][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.69it/s, est. speed input: 2872.29 toks/s, output: 189.47 toks/s]
WARNING 01-08 19:47:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:00,745][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:01,779][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.03s/it, est. speed input: 564.08 toks/s, output: 31.93 toks/s]
[2025-01-08 19:47:01,813][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.81it/s, est. speed input: 1612.04 toks/s, output: 94.60 toks/s]
WARNING 01-08 19:47:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:02,037][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:04,079][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.04s/it, est. speed input: 342.25 toks/s, output: 13.22 toks/s]
[2025-01-08 19:47:04,142][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  6.17it/s, est. speed input: 4316.16 toks/s, output: 177.17 toks/s]
WARNING 01-08 19:47:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:04,362][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:06,421][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.06s/it, est. speed input: 303.15 toks/s, output: 16.03 toks/s]
[2025-01-08 19:47:06,421][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.83it/s, est. speed input: 3637.39 toks/s, output: 192.34 toks/s]
WARNING 01-08 19:47:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:06,636][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:07,769][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.13s/it, est. speed input: 617.32 toks/s, output: 25.61 toks/s]
[2025-01-08 19:47:07,769][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.53it/s, est. speed input: 2539.72 toks/s, output: 102.40 toks/s]
WARNING 01-08 19:47:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:07,984][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:09,251][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.27s/it, est. speed input: 492.61 toks/s, output: 26.05 toks/s]
[2025-01-08 19:47:09,288][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.83it/s, est. speed input: 2596.30 toks/s, output: 129.58 toks/s]
WARNING 01-08 19:47:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:09,516][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:11,713][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.20s/it, est. speed input: 457.88 toks/s, output: 12.29 toks/s]
[2025-01-08 19:47:11,774][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.87it/s, est. speed input: 4910.75 toks/s, output: 140.42 toks/s]
WARNING 01-08 19:47:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:11,998][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:14,052][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.05s/it, est. speed input: 361.68 toks/s, output: 16.06 toks/s]
[2025-01-08 19:47:14,053][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.35it/s, est. speed input: 3977.96 toks/s, output: 176.66 toks/s]
WARNING 01-08 19:47:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:14,266][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:15,666][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.40s/it, est. speed input: 720.12 toks/s, output: 20.72 toks/s]
[2025-01-08 19:47:15,667][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.57it/s, est. speed input: 3657.37 toks/s, output: 103.56 toks/s]
WARNING 01-08 19:47:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:15,880][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:17,248][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.37s/it, est. speed input: 543.29 toks/s, output: 24.13 toks/s]
[2025-01-08 19:47:17,286][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.56it/s, est. speed input: 2836.12 toks/s, output: 120.28 toks/s]
WARNING 01-08 19:47:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:17,531][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:19,585][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:20,  2.05s/it, est. speed input: 641.32 toks/s, output: 5.36 toks/s]
[2025-01-08 19:47:20,128][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:10,  1.17s/it, est. speed input: 1014.37 toks/s, output: 15.40 toks/s]
[2025-01-08 19:47:20,401][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:02<00:01,  3.13it/s, est. speed input: 2753.93 toks/s, output: 58.20 toks/s]
[2025-01-08 19:47:20,518][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:02<00:01,  3.63it/s, est. speed input: 3087.43 toks/s, output: 71.00 toks/s]
[2025-01-08 19:47:20,687][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:03<00:00,  4.93it/s, est. speed input: 3754.78 toks/s, output: 99.18 toks/s]
[2025-01-08 19:47:21,092][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:03<00:00,  4.06it/s, est. speed input: 3698.35 toks/s, output: 108.99 toks/s]
[2025-01-08 19:47:21,328][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  4.10it/s, est. speed input: 3814.49 toks/s, output: 125.63 toks/s]
[2025-01-08 19:47:21,329][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:03<00:00,  2.90it/s, est. speed input: 3814.49 toks/s, output: 125.63 toks/s]
WARNING 01-08 19:47:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:21,633][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:24,102][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:22,  2.47s/it, est. speed input: 573.32 toks/s, output: 11.34 toks/s]
[2025-01-08 19:47:25,469][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:03<00:00,  2.81it/s, est. speed input: 3241.06 toks/s, output: 86.81 toks/s]
[2025-01-08 19:47:27,125][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.85it/s, est. speed input: 2503.68 toks/s, output: 97.06 toks/s]
[2025-01-08 19:47:27,125][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.82it/s, est. speed input: 2503.68 toks/s, output: 97.06 toks/s]
WARNING 01-08 19:47:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:47:27,392][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:47:28,241][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1854.02 toks/s, output: 34.20 toks/s]
[2025-01-08 19:47:28,241][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1854.02 toks/s, output: 34.20 toks/s]
[2025-01-08 19:47:35,860][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:47:35,913][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:47:37,602][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 19:47:39,236][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 19:47:40,819][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:47:41,341][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 19:47:41,341][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 19:47:51,719][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:47:52,253][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:47:52,304][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:47:54,168][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 19:47:55,854][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 19:47:57,447][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:47:57,954][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:47:57,954][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:48:12,007][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:48:12,309][root][INFO] - Loading VLLM model.
WARNING 01-08 19:48:12 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:48:12 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:48:12 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:48:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:48:13,214][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:48:14,593][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 19:48:14,992][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:48:16,359][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 19:48:17,764][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 19:48:17,764][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 19:48:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:48:31 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:48:32 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:48:32 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:48:53 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:48:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:48:54,125][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:48:57,285][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.16s/it, est. speed input: 159.85 toks/s, output: 10.13 toks/s]
[2025-01-08 19:48:57,413][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.71it/s, est. speed input: 2458.27 toks/s, output: 159.73 toks/s]
[2025-01-08 19:48:57,413][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.87it/s, est. speed input: 2458.27 toks/s, output: 159.73 toks/s]
WARNING 01-08 19:48:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:48:57,632][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:48:59,471][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.84s/it, est. speed input: 309.47 toks/s, output: 17.40 toks/s]
[2025-01-08 19:48:59,551][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.73it/s, est. speed input: 3270.03 toks/s, output: 195.45 toks/s]
WARNING 01-08 19:48:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:48:59,763][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:00,986][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.22s/it, est. speed input: 571.68 toks/s, output: 23.72 toks/s]
[2025-01-08 19:49:00,986][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.09it/s, est. speed input: 2857.32 toks/s, output: 118.54 toks/s]
WARNING 01-08 19:49:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:01,199][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:02,442][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.24s/it, est. speed input: 502.01 toks/s, output: 26.55 toks/s]
[2025-01-08 19:49:02,442][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  4.02it/s, est. speed input: 2509.15 toks/s, output: 132.69 toks/s]
WARNING 01-08 19:49:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:02,659][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:04,547][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:18,  1.89s/it, est. speed input: 370.40 toks/s, output: 15.37 toks/s]
[2025-01-08 19:49:04,564][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 3937.47 toks/s, output: 168.00 toks/s]
WARNING 01-08 19:49:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:04,802][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:06,794][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.99s/it, est. speed input: 346.43 toks/s, output: 16.57 toks/s]
[2025-01-08 19:49:06,843][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.39it/s, est. speed input: 3718.92 toks/s, output: 183.76 toks/s]
WARNING 01-08 19:49:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:07,060][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:08,431][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.37s/it, est. speed input: 735.24 toks/s, output: 21.15 toks/s]
[2025-01-08 19:49:08,431][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.65it/s, est. speed input: 3675.06 toks/s, output: 105.73 toks/s]
WARNING 01-08 19:49:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:08,644][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:09,960][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.32s/it, est. speed input: 565.01 toks/s, output: 25.09 toks/s]
[2025-01-08 19:49:09,960][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.80it/s, est. speed input: 2824.04 toks/s, output: 125.43 toks/s]
WARNING 01-08 19:49:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:10,196][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:12,433][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:22,  2.24s/it, est. speed input: 450.73 toks/s, output: 12.97 toks/s]
[2025-01-08 19:49:12,451][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.88it/s, est. speed input: 4832.79 toks/s, output: 141.96 toks/s]
WARNING 01-08 19:49:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:12,710][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:14,851][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.14s/it, est. speed input: 378.02 toks/s, output: 15.42 toks/s]
[2025-01-08 19:49:14,900][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.02it/s, est. speed input: 4069.74 toks/s, output: 171.28 toks/s]
WARNING 01-08 19:49:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:15,131][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:16,447][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.32s/it, est. speed input: 1000.57 toks/s, output: 14.43 toks/s]
[2025-01-08 19:49:17,114][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:02,  1.07it/s, est. speed input: 1328.52 toks/s, output: 34.30 toks/s]
[2025-01-08 19:49:17,299][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:02<00:01,  1.69it/s, est. speed input: 1822.88 toks/s, output: 58.13 toks/s]
[2025-01-08 19:49:18,015][root][ERROR] - Processed prompts:  80%|########  | 4/5 [00:02<00:00,  1.56it/s, est. speed input: 1826.94 toks/s, output: 77.34 toks/s]
[2025-01-08 19:49:18,066][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.70it/s, est. speed input: 2243.80 toks/s, output: 110.06 toks/s]
WARNING 01-08 19:49:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:18,327][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:21,131][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:30,  2.80s/it, est. speed input: 495.73 toks/s, output: 10.34 toks/s]
[2025-01-08 19:49:21,507][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:03<00:01,  2.86it/s, est. speed input: 2860.69 toks/s, output: 69.18 toks/s]
[2025-01-08 19:49:21,670][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:03<00:01,  3.16it/s, est. speed input: 3115.20 toks/s, output: 81.07 toks/s]
[2025-01-08 19:49:21,848][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:03<00:00,  3.46it/s, est. speed input: 3332.05 toks/s, output: 93.72 toks/s]
[2025-01-08 19:49:22,012][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:03<00:00,  3.83it/s, est. speed input: 3540.95 toks/s, output: 107.72 toks/s]
[2025-01-08 19:49:22,270][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  3.85it/s, est. speed input: 3644.01 toks/s, output: 121.24 toks/s]
[2025-01-08 19:49:24,281][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  1.41it/s, est. speed input: 2634.24 toks/s, output: 113.87 toks/s]
[2025-01-08 19:49:24,281][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.02it/s, est. speed input: 2634.24 toks/s, output: 113.87 toks/s]
WARNING 01-08 19:49:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:49:24,552][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:49:25,604][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.05s/it, est. speed input: 1495.15 toks/s, output: 27.58 toks/s]
[2025-01-08 19:49:26,415][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.10it/s, est. speed input: 1596.54 toks/s, output: 56.90 toks/s]
[2025-01-08 19:49:26,415][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.07it/s, est. speed input: 1596.54 toks/s, output: 56.90 toks/s]
[2025-01-08 19:49:34,244][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:49:34,298][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:49:36,048][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 19:49:37,759][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 19:49:39,377][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:49:39,917][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:49:39,918][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:49:50,413][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:49:51,158][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:49:51,211][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:49:52,929][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 19:49:54,505][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 19:49:56,068][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.60s/it]
[2025-01-08 19:49:56,604][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:49:56,604][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:50:10,421][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:50:10,786][root][INFO] - Loading VLLM model.
WARNING 01-08 19:50:10 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:50:10 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:50:11 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:50:11 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:50:11,882][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:50:13,199][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 19:50:13,592][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 19:50:14,898][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 19:50:16,245][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 19:50:16,246][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 19:50:16 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:50:30 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:50:30 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:50:30 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:50:52 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:50:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:50:52,799][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:50:55,687][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.89s/it, est. speed input: 174.88 toks/s, output: 11.08 toks/s]
[2025-01-08 19:50:55,827][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.26it/s, est. speed input: 2668.96 toks/s, output: 176.39 toks/s]
[2025-01-08 19:50:55,827][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.28it/s, est. speed input: 2668.96 toks/s, output: 176.39 toks/s]
WARNING 01-08 19:50:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:50:56,039][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:50:57,239][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.20s/it, est. speed input: 474.29 toks/s, output: 27.51 toks/s]
[2025-01-08 19:50:57,276][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.23it/s, est. speed input: 1853.54 toks/s, output: 109.93 toks/s]
WARNING 01-08 19:50:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:50:57,498][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:50:59,438][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:01<00:21,  1.94s/it, est. speed input: 360.34 toks/s, output: 13.92 toks/s]
[2025-01-08 19:50:59,498][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:01<00:00,  6.00it/s, est. speed input: 4195.32 toks/s, output: 172.05 toks/s]
WARNING 01-08 19:50:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:50:59,718][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:01,626][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.91s/it, est. speed input: 327.18 toks/s, output: 17.30 toks/s]
[2025-01-08 19:51:01,626][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:01<00:00,  5.77it/s, est. speed input: 3597.89 toks/s, output: 190.27 toks/s]
WARNING 01-08 19:51:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:01,836][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:03,175][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.34s/it, est. speed input: 522.06 toks/s, output: 21.66 toks/s]
[2025-01-08 19:51:03,176][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.73it/s, est. speed input: 2669.89 toks/s, output: 108.26 toks/s]
WARNING 01-08 19:51:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:03,406][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:04,798][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:06,  1.39s/it, est. speed input: 494.14 toks/s, output: 23.70 toks/s]
[2025-01-08 19:51:04,836][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  4.20it/s, est. speed input: 2853.00 toks/s, output: 141.29 toks/s]
WARNING 01-08 19:51:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:05,060][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:07,100][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.04s/it, est. speed input: 493.26 toks/s, output: 13.24 toks/s]
[2025-01-08 19:51:07,157][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.77it/s, est. speed input: 4805.12 toks/s, output: 137.32 toks/s]
WARNING 01-08 19:51:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:07,392][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:09,319][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:17,  1.93s/it, est. speed input: 385.53 toks/s, output: 17.12 toks/s]
[2025-01-08 19:51:09,320][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:01<00:00,  5.19it/s, est. speed input: 3853.94 toks/s, output: 171.17 toks/s]
WARNING 01-08 19:51:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:09,558][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:11,094][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.54s/it, est. speed input: 656.56 toks/s, output: 18.89 toks/s]
[2025-01-08 19:51:11,094][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.91it/s, est. speed input: 3990.79 toks/s, output: 113.30 toks/s]
WARNING 01-08 19:51:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:11,322][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:12,798][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.48s/it, est. speed input: 546.65 toks/s, output: 22.35 toks/s]
[2025-01-08 19:51:12,836][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.96it/s, est. speed input: 3168.83 toks/s, output: 133.44 toks/s]
WARNING 01-08 19:51:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:13,066][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:14,931][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:16,  1.86s/it, est. speed input: 706.39 toks/s, output: 5.36 toks/s]
[2025-01-08 19:51:15,189][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:02<00:07,  1.09it/s, est. speed input: 1240.88 toks/s, output: 13.66 toks/s]
[2025-01-08 19:51:15,463][root][ERROR] - Processed prompts:  30%|###       | 3/10 [00:02<00:04,  1.60it/s, est. speed input: 1648.71 toks/s, output: 24.20 toks/s]
[2025-01-08 19:51:15,788][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:02<00:01,  3.53it/s, est. speed input: 2903.60 toks/s, output: 58.42 toks/s]
[2025-01-08 19:51:16,099][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:00,  3.45it/s, est. speed input: 3039.97 toks/s, output: 71.23 toks/s]
[2025-01-08 19:51:16,631][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:03<00:00,  2.85it/s, est. speed input: 2954.67 toks/s, output: 83.88 toks/s]
[2025-01-08 19:51:18,520][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:05<00:00,  1.31it/s, est. speed input: 2172.82 toks/s, output: 88.94 toks/s]
[2025-01-08 19:51:18,757][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.62it/s, est. speed input: 2313.69 toks/s, output: 120.38 toks/s]
[2025-01-08 19:51:18,757][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.76it/s, est. speed input: 2313.69 toks/s, output: 120.38 toks/s]
WARNING 01-08 19:51:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:19,030][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:20,942][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.91s/it, est. speed input: 688.77 toks/s, output: 7.84 toks/s]
[2025-01-08 19:51:21,318][root][ERROR] - Processed prompts:  33%|###3      | 3/9 [00:02<00:03,  1.57it/s, est. speed input: 1786.60 toks/s, output: 26.22 toks/s]
[2025-01-08 19:51:21,479][root][ERROR] - Processed prompts:  67%|######6   | 6/9 [00:02<00:00,  3.59it/s, est. speed input: 3385.76 toks/s, output: 64.51 toks/s]
[2025-01-08 19:51:21,958][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:02<00:00,  3.79it/s, est. speed input: 3731.49 toks/s, output: 92.89 toks/s]
[2025-01-08 19:51:22,077][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  4.28it/s, est. speed input: 4044.43 toks/s, output: 111.25 toks/s]
[2025-01-08 19:51:22,077][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.95it/s, est. speed input: 4044.43 toks/s, output: 111.25 toks/s]
WARNING 01-08 19:51:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:51:22,331][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:51:23,555][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1165.23 toks/s, output: 23.71 toks/s]
[2025-01-08 19:51:23,555][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.45it/s, est. speed input: 3445.44 toks/s, output: 71.12 toks/s]
[2025-01-08 19:51:31,396][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:51:31,450][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:51:33,122][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 19:51:34,760][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 19:51:36,336][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 19:51:36,858][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:51:36,858][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 19:51:47,392][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:51:47,886][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:51:47,938][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:51:49,840][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 19:51:51,516][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 19:51:53,146][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 19:51:53,659][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:51:53,659][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 19:52:07,746][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:52:08,131][root][INFO] - Loading VLLM model.
WARNING 01-08 19:52:08 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:52:08 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:52:08 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:52:09 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:52:09,207][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:52:10,578][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:52:10,977][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:52:12,333][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:52:13,738][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:52:13,739][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:52:14 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:52:27 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:52:28 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:52:28 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:52:50 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:52:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:52:50,307][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:52:53,258][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.95s/it, est. speed input: 171.14 toks/s, output: 10.84 toks/s]
[2025-01-08 19:52:53,373][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:03<00:00,  6.28it/s, est. speed input: 2305.47 toks/s, output: 151.31 toks/s]
[2025-01-08 19:52:53,411][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.15it/s, est. speed input: 2602.88 toks/s, output: 174.60 toks/s]
WARNING 01-08 19:52:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:52:53,630][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:52:55,919][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.29s/it, est. speed input: 248.61 toks/s, output: 14.42 toks/s]
[2025-01-08 19:52:56,010][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.30it/s, est. speed input: 3612.99 toks/s, output: 216.38 toks/s]
WARNING 01-08 19:52:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:52:56,213][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:52:56,975][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 918.39 toks/s, output: 38.10 toks/s]
[2025-01-08 19:52:56,975][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 918.39 toks/s, output: 38.10 toks/s]
WARNING 01-08 19:52:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:52:57,176][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:52:57,988][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 768.18 toks/s, output: 40.62 toks/s]
[2025-01-08 19:52:57,988][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 768.18 toks/s, output: 40.62 toks/s]
WARNING 01-08 19:52:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:52:58,208][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:00,439][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.23s/it, est. speed input: 228.61 toks/s, output: 12.10 toks/s]
[2025-01-08 19:53:00,510][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.52it/s, est. speed input: 4390.22 toks/s, output: 188.08 toks/s]
WARNING 01-08 19:53:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:00,734][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:03,091][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.36s/it, est. speed input: 292.01 toks/s, output: 14.01 toks/s]
[2025-01-08 19:53:03,137][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.83it/s, est. speed input: 4037.28 toks/s, output: 196.49 toks/s]
WARNING 01-08 19:53:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:03,357][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:04,207][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.18it/s, est. speed input: 677.92 toks/s, output: 31.78 toks/s]
[2025-01-08 19:53:04,241][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.26it/s, est. speed input: 1791.59 toks/s, output: 63.34 toks/s]
WARNING 01-08 19:53:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:04,445][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:05,384][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 739.37 toks/s, output: 35.16 toks/s]
[2025-01-08 19:53:05,384][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1530.28 toks/s, output: 70.28 toks/s]
WARNING 01-08 19:53:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:05,610][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:08,287][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.68s/it, est. speed input: 376.62 toks/s, output: 10.84 toks/s]
[2025-01-08 19:53:08,287][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.23it/s, est. speed input: 5198.55 toks/s, output: 151.66 toks/s]
WARNING 01-08 19:53:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:08,527][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:11,069][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.54s/it, est. speed input: 317.59 toks/s, output: 12.99 toks/s]
[2025-01-08 19:53:11,115][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.41it/s, est. speed input: 4396.34 toks/s, output: 182.44 toks/s]
WARNING 01-08 19:53:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:11,335][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:12,122][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.27it/s, est. speed input: 1675.08 toks/s, output: 25.44 toks/s]
[2025-01-08 19:53:12,274][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.42it/s, est. speed input: 2337.44 toks/s, output: 52.20 toks/s]
[2025-01-08 19:53:12,274][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 2337.44 toks/s, output: 52.20 toks/s]
WARNING 01-08 19:53:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:12,488][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:13,324][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 972.71 toks/s, output: 39.48 toks/s]
[2025-01-08 19:53:13,324][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 972.71 toks/s, output: 39.48 toks/s]
WARNING 01-08 19:53:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:13,558][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:16,664][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:43,  3.11s/it, est. speed input: 447.86 toks/s, output: 7.41 toks/s]
[2025-01-08 19:53:16,809][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:17,  1.36s/it, est. speed input: 772.98 toks/s, output: 15.38 toks/s]
[2025-01-08 19:53:17,070][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:03<00:04,  2.22it/s, est. speed input: 1840.93 toks/s, output: 40.44 toks/s]
[2025-01-08 19:53:17,251][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:03<00:03,  2.62it/s, est. speed input: 2107.21 toks/s, output: 49.56 toks/s]
[2025-01-08 19:53:17,362][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:03<00:01,  4.96it/s, est. speed input: 3084.48 toks/s, output: 82.55 toks/s]
[2025-01-08 19:53:17,606][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:04<00:00,  5.71it/s, est. speed input: 3549.70 toks/s, output: 104.02 toks/s]
[2025-01-08 19:53:18,845][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:05<00:00,  3.14it/s, est. speed input: 3215.84 toks/s, output: 117.09 toks/s]
[2025-01-08 19:53:20,440][root][ERROR] - Processed prompts:  93%|#########3| 14/15 [00:06<00:00,  1.80it/s, est. speed input: 2661.92 toks/s, output: 119.02 toks/s]
[2025-01-08 19:53:20,440][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.18it/s, est. speed input: 2853.19 toks/s, output: 148.08 toks/s]
WARNING 01-08 19:53:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:53:20,711][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:53:23,058][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.35s/it, est. speed input: 596.23 toks/s, output: 12.36 toks/s]
[2025-01-08 19:53:23,075][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:02<00:00,  3.81it/s, est. speed input: 5355.75 toks/s, output: 110.82 toks/s]
[2025-01-08 19:53:30,952][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:53:31,006][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:53:32,684][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 19:53:34,371][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 19:53:36,023][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 19:53:36,555][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:53:36,556][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 19:53:47,089][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:53:47,626][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:53:47,678][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:53:49,583][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 19:53:51,221][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 19:53:52,859][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 19:53:53,367][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 19:53:53,367][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 19:54:07,414][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:54:07,717][root][INFO] - Loading VLLM model.
WARNING 01-08 19:54:07 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:54:07 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:54:08 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:54:08 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:54:08,649][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:54:10,017][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:54:10,416][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:54:11,777][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:54:13,180][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:54:13,180][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:54:13 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:54:27 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:54:27 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:54:27 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:54:49 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 19:54:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:54:49,775][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:54:52,837][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.06s/it, est. speed input: 164.95 toks/s, output: 10.45 toks/s]
[2025-01-08 19:54:52,962][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:03<00:02,  3.40it/s, est. speed input: 1267.99 toks/s, output: 84.11 toks/s]
[2025-01-08 19:54:53,072][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.89it/s, est. speed input: 2451.37 toks/s, output: 175.36 toks/s]
[2025-01-08 19:54:53,072][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.85it/s, est. speed input: 2451.37 toks/s, output: 175.36 toks/s]
WARNING 01-08 19:54:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:54:53,309][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:54:55,718][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 241.28 toks/s, output: 13.70 toks/s]
[2025-01-08 19:54:55,841][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  8.68it/s, est. speed input: 3656.32 toks/s, output: 216.52 toks/s]
[2025-01-08 19:54:55,841][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.32it/s, est. speed input: 3656.32 toks/s, output: 216.52 toks/s]
WARNING 01-08 19:54:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:54:56,085][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:54:58,383][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.30s/it, est. speed input: 304.32 toks/s, output: 11.75 toks/s]
[2025-01-08 19:54:58,456][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.75it/s, est. speed input: 4319.77 toks/s, output: 194.91 toks/s]
WARNING 01-08 19:54:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:54:58,680][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:01,279][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.60s/it, est. speed input: 270.16 toks/s, output: 12.70 toks/s]
[2025-01-08 19:55:01,320][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.06it/s, est. speed input: 4223.96 toks/s, output: 202.33 toks/s]
WARNING 01-08 19:55:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:01,527][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:02,600][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.07s/it, est. speed input: 716.51 toks/s, output: 30.75 toks/s]
[2025-01-08 19:55:02,671][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.62it/s, est. speed input: 2000.32 toks/s, output: 91.76 toks/s]
WARNING 01-08 19:55:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:02,897][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:05,320][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:29,  2.42s/it, est. speed input: 415.20 toks/s, output: 11.14 toks/s]
[2025-01-08 19:55:05,388][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.22it/s, est. speed input: 5026.82 toks/s, output: 150.60 toks/s]
WARNING 01-08 19:55:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:05,624][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:08,035][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 339.74 toks/s, output: 13.69 toks/s]
[2025-01-08 19:55:08,072][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.31it/s, est. speed input: 4335.13 toks/s, output: 176.85 toks/s]
WARNING 01-08 19:55:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:08,294][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:09,316][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.02s/it, est. speed input: 610.39 toks/s, output: 28.37 toks/s]
[2025-01-08 19:55:09,317][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.93it/s, est. speed input: 2390.75 toks/s, output: 85.07 toks/s]
WARNING 01-08 19:55:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:09,539][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:10,940][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.40s/it, est. speed input: 624.72 toks/s, output: 23.56 toks/s]
[2025-01-08 19:55:10,980][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.47it/s, est. speed input: 3048.67 toks/s, output: 118.64 toks/s]
WARNING 01-08 19:55:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:11,219][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:13,159][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:01<00:19,  1.94s/it, est. speed input: 578.38 toks/s, output: 4.64 toks/s]
[2025-01-08 19:55:13,491][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:08,  1.01it/s, est. speed input: 1073.61 toks/s, output: 12.77 toks/s]
[2025-01-08 19:55:13,749][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:02<00:05,  1.52it/s, est. speed input: 1484.81 toks/s, output: 22.93 toks/s]
[2025-01-08 19:55:14,350][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:03<00:04,  1.57it/s, est. speed input: 1557.96 toks/s, output: 34.81 toks/s]
[2025-01-08 19:55:14,503][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:03<00:01,  2.95it/s, est. speed input: 2287.39 toks/s, output: 66.68 toks/s]
[2025-01-08 19:55:14,666][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:03<00:01,  3.44it/s, est. speed input: 2561.64 toks/s, output: 82.11 toks/s]
[2025-01-08 19:55:15,043][root][ERROR] - Processed prompts:  73%|#######2  | 8/11 [00:03<00:00,  3.17it/s, est. speed input: 2652.31 toks/s, output: 95.19 toks/s]
[2025-01-08 19:55:15,410][root][ERROR] - Processed prompts:  82%|########1 | 9/11 [00:04<00:00,  3.03it/s, est. speed input: 2734.13 toks/s, output: 110.47 toks/s]
[2025-01-08 19:55:16,161][root][ERROR] - Processed prompts:  91%|######### | 10/11 [00:04<00:00,  2.21it/s, est. speed input: 2545.74 toks/s, output: 122.02 toks/s]
[2025-01-08 19:55:17,174][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  1.62it/s, est. speed input: 2333.91 toks/s, output: 134.85 toks/s]
[2025-01-08 19:55:17,174][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  1.85it/s, est. speed input: 2333.91 toks/s, output: 134.85 toks/s]
WARNING 01-08 19:55:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:17,465][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:18,311][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1138.25 toks/s, output: 39.05 toks/s]
[2025-01-08 19:55:18,311][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1138.25 toks/s, output: 39.05 toks/s]
WARNING 01-08 19:55:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:18,543][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:20,639][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:02<00:14,  2.09s/it, est. speed input: 442.51 toks/s, output: 13.84 toks/s]
[2025-01-08 19:55:20,859][root][ERROR] - Processed prompts:  88%|########7 | 7/8 [00:02<00:00,  3.97it/s, est. speed input: 3963.28 toks/s, output: 92.84 toks/s]
[2025-01-08 19:55:23,543][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:04<00:00,  1.60it/s, est. speed input: 2099.17 toks/s, output: 83.01 toks/s]
WARNING 01-08 19:55:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:55:23,814][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:55:25,035][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.22s/it, est. speed input: 1157.05 toks/s, output: 23.76 toks/s]
[2025-01-08 19:55:25,035][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 3363.63 toks/s, output: 71.27 toks/s]
[2025-01-08 19:55:32,843][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:55:32,896][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:55:34,669][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 19:55:36,339][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:55:37,997][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:55:38,546][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 19:55:38,546][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:55:49,608][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:55:50,120][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:55:50,172][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:55:52,092][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 19:55:53,803][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.80s/it]
[2025-01-08 19:55:55,440][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.72s/it]
[2025-01-08 19:55:55,968][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.25s/it]
[2025-01-08 19:55:55,968][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.45s/it]
[2025-01-08 19:56:09,649][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:56:09,963][root][INFO] - Loading VLLM model.
WARNING 01-08 19:56:10 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:56:10 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:56:10 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:56:10 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:56:10,993][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:56:12,361][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:56:12,768][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:56:14,122][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 19:56:15,519][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:56:15,519][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:56:15 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:56:29 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:56:30 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:56:30 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:56:51 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:56:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:56:51,845][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:56:54,926][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.08s/it, est. speed input: 163.96 toks/s, output: 10.39 toks/s]
[2025-01-08 19:56:55,028][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:05,  2.08it/s, est. speed input: 793.49 toks/s, output: 52.17 toks/s]
[2025-01-08 19:56:55,083][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.94it/s, est. speed input: 2495.84 toks/s, output: 175.14 toks/s]
WARNING 01-08 19:56:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:56:55,307][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:56:57,717][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 240.29 toks/s, output: 13.70 toks/s]
[2025-01-08 19:56:57,806][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.40it/s, est. speed input: 3703.64 toks/s, output: 218.45 toks/s]
WARNING 01-08 19:56:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:56:58,029][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:00,244][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:33,  2.21s/it, est. speed input: 230.27 toks/s, output: 12.19 toks/s]
[2025-01-08 19:57:00,317][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.99it/s, est. speed input: 4144.52 toks/s, output: 201.91 toks/s]
WARNING 01-08 19:57:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:00,549][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:03,138][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.59s/it, est. speed input: 269.65 toks/s, output: 12.75 toks/s]
[2025-01-08 19:57:03,209][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.01it/s, est. speed input: 4182.04 toks/s, output: 200.74 toks/s]
WARNING 01-08 19:57:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:03,428][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:04,639][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.21s/it, est. speed input: 631.73 toks/s, output: 27.25 toks/s]
[2025-01-08 19:57:04,727][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.08it/s, est. speed input: 2348.55 toks/s, output: 107.00 toks/s]
WARNING 01-08 19:57:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:04,969][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:07,203][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:24,  2.23s/it, est. speed input: 363.06 toks/s, output: 12.09 toks/s]
[2025-01-08 19:57:07,550][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  6.12it/s, est. speed input: 4232.60 toks/s, output: 140.26 toks/s]
[2025-01-08 19:57:07,550][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  4.65it/s, est. speed input: 4232.60 toks/s, output: 140.26 toks/s]
WARNING 01-08 19:57:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:07,781][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:09,933][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.15s/it, est. speed input: 379.73 toks/s, output: 15.34 toks/s]
[2025-01-08 19:57:10,001][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.96it/s, est. speed input: 4037.44 toks/s, output: 165.35 toks/s]
WARNING 01-08 19:57:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:10,221][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:11,506][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.28s/it, est. speed input: 632.71 toks/s, output: 22.57 toks/s]
[2025-01-08 19:57:12,723][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.22it/s, est. speed input: 1660.11 toks/s, output: 87.14 toks/s]
[2025-01-08 19:57:12,723][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.00it/s, est. speed input: 1660.11 toks/s, output: 87.14 toks/s]
WARNING 01-08 19:57:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:12,937][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:14,474][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.54s/it, est. speed input: 563.61 toks/s, output: 21.48 toks/s]
[2025-01-08 19:57:14,512][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.81it/s, est. speed input: 3327.93 toks/s, output: 128.34 toks/s]
WARNING 01-08 19:57:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:14,734][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:17,018][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:20,  2.28s/it, est. speed input: 489.61 toks/s, output: 11.82 toks/s]
[2025-01-08 19:57:17,656][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:02<00:01,  2.55it/s, est. speed input: 2440.09 toks/s, output: 67.43 toks/s]
[2025-01-08 19:57:18,212][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:03<00:01,  2.35it/s, est. speed input: 2428.91 toks/s, output: 79.37 toks/s]
[2025-01-08 19:57:18,579][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:03<00:00,  2.43it/s, est. speed input: 2488.64 toks/s, output: 97.02 toks/s]
[2025-01-08 19:57:18,910][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:04<00:00,  2.55it/s, est. speed input: 2607.01 toks/s, output: 116.88 toks/s]
[2025-01-08 19:57:20,346][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.52it/s, est. speed input: 2174.60 toks/s, output: 122.61 toks/s]
[2025-01-08 19:57:20,346][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.78it/s, est. speed input: 2174.60 toks/s, output: 122.61 toks/s]
WARNING 01-08 19:57:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:20,618][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:22,832][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:17,  2.21s/it, est. speed input: 506.82 toks/s, output: 12.65 toks/s]
[2025-01-08 19:57:23,008][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:02<00:00,  4.46it/s, est. speed input: 4365.90 toks/s, output: 100.03 toks/s]
[2025-01-08 19:57:23,632][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.99it/s, est. speed input: 3833.15 toks/s, output: 103.85 toks/s]
WARNING 01-08 19:57:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:57:23,885][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:57:24,895][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.01s/it, est. speed input: 1238.02 toks/s, output: 28.72 toks/s]
[2025-01-08 19:57:24,896][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.98it/s, est. speed input: 2400.57 toks/s, output: 57.41 toks/s]
[2025-01-08 19:57:32,756][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:57:32,810][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:57:34,584][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 19:57:36,254][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:57:37,924][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 19:57:38,463][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 19:57:38,464][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 19:57:49,567][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:57:50,393][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:57:50,445][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:57:52,229][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.78s/it]
[2025-01-08 19:57:53,884][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 19:57:55,539][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 19:57:56,047][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 19:57:56,048][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 19:58:09,169][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 19:58:09,469][root][INFO] - Loading VLLM model.
WARNING 01-08 19:58:09 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 19:58:09 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 19:58:10 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 19:58:10 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 19:58:10,481][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:58:11,847][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 19:58:12,249][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 19:58:13,609][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 19:58:15,011][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 19:58:15,012][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 19:58:15 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 19:58:29 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 19:58:29 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 19:58:29 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 19:58:50 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 19:58:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:58:51,176][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:58:54,201][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.02s/it, est. speed input: 166.99 toks/s, output: 10.58 toks/s]
[2025-01-08 19:58:54,303][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:05,  2.12it/s, est. speed input: 807.62 toks/s, output: 53.09 toks/s]
[2025-01-08 19:58:54,362][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.02it/s, est. speed input: 2536.45 toks/s, output: 179.25 toks/s]
WARNING 01-08 19:58:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:58:54,590][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:58:56,992][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.40s/it, est. speed input: 241.89 toks/s, output: 13.74 toks/s]
[2025-01-08 19:58:57,108][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  8.73it/s, est. speed input: 3677.31 toks/s, output: 219.98 toks/s]
[2025-01-08 19:58:57,109][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.35it/s, est. speed input: 3677.31 toks/s, output: 219.98 toks/s]
WARNING 01-08 19:58:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:58:57,344][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:58:59,590][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:33,  2.25s/it, est. speed input: 227.08 toks/s, output: 12.91 toks/s]
[2025-01-08 19:58:59,607][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.07it/s, est. speed input: 4105.89 toks/s, output: 205.43 toks/s]
WARNING 01-08 19:58:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:58:59,837][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:02,420][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.58s/it, est. speed input: 269.84 toks/s, output: 12.78 toks/s]
[2025-01-08 19:59:02,480][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.05it/s, est. speed input: 4212.31 toks/s, output: 202.84 toks/s]
WARNING 01-08 19:59:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:02,692][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:03,771][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.08s/it, est. speed input: 715.40 toks/s, output: 30.58 toks/s]
[2025-01-08 19:59:03,825][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.65it/s, est. speed input: 2041.37 toks/s, output: 91.75 toks/s]
WARNING 01-08 19:59:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:04,051][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:06,460][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.52 toks/s, output: 12.04 toks/s]
[2025-01-08 19:59:06,460][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.40it/s, est. speed input: 4872.71 toks/s, output: 156.47 toks/s]
WARNING 01-08 19:59:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:06,685][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:09,097][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 339.68 toks/s, output: 13.69 toks/s]
[2025-01-08 19:59:09,134][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.31it/s, est. speed input: 4324.09 toks/s, output: 176.83 toks/s]
WARNING 01-08 19:59:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:09,344][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:10,321][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.02it/s, est. speed input: 638.67 toks/s, output: 29.68 toks/s]
[2025-01-08 19:59:10,321][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:00<00:00,  3.07it/s, est. speed input: 2108.61 toks/s, output: 89.01 toks/s]
WARNING 01-08 19:59:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:10,538][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:12,076][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.54s/it, est. speed input: 563.08 toks/s, output: 21.46 toks/s]
[2025-01-08 19:59:12,113][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.81it/s, est. speed input: 3371.08 toks/s, output: 128.22 toks/s]
WARNING 01-08 19:59:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:12,340][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:14,572][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:20,  2.23s/it, est. speed input: 590.25 toks/s, output: 11.20 toks/s]
[2025-01-08 19:59:14,687][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:02<00:07,  1.01it/s, est. speed input: 1039.80 toks/s, output: 23.01 toks/s]
[2025-01-08 19:59:15,059][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:02<00:02,  2.06it/s, est. speed input: 1795.06 toks/s, output: 46.36 toks/s]
[2025-01-08 19:59:16,246][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:03<00:03,  1.42it/s, est. speed input: 1536.75 toks/s, output: 55.57 toks/s]
[2025-01-08 19:59:17,242][root][ERROR] - Processed prompts:  60%|######    | 6/10 [00:04<00:03,  1.26it/s, est. speed input: 1493.05 toks/s, output: 71.61 toks/s]
[2025-01-08 19:59:18,529][root][ERROR] - Processed prompts:  70%|#######   | 7/10 [00:06<00:02,  1.06it/s, est. speed input: 1395.27 toks/s, output: 87.74 toks/s]
[2025-01-08 19:59:18,694][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:06<00:01,  1.41it/s, est. speed input: 1566.46 toks/s, output: 116.95 toks/s]
[2025-01-08 19:59:18,694][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:06<00:00,  1.57it/s, est. speed input: 1950.28 toks/s, output: 179.90 toks/s]
WARNING 01-08 19:59:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:18,976][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:19,967][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 965.90 toks/s, output: 33.31 toks/s]
[2025-01-08 19:59:19,968][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.02it/s, est. speed input: 1938.09 toks/s, output: 66.59 toks/s]
WARNING 01-08 19:59:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:20,216][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:22,650][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:21,  2.43s/it, est. speed input: 460.98 toks/s, output: 11.50 toks/s]
[2025-01-08 19:59:22,680][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.06it/s, est. speed input: 5468.34 toks/s, output: 117.31 toks/s]
WARNING 01-08 19:59:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 19:59:22,948][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 19:59:24,016][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.07s/it, est. speed input: 1100.73 toks/s, output: 27.17 toks/s]
[2025-01-08 19:59:25,105][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.47it/s, est. speed input: 1316.79 toks/s, output: 70.48 toks/s]
[2025-01-08 19:59:25,105][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:02<00:00,  1.39it/s, est. speed input: 1316.79 toks/s, output: 70.48 toks/s]
[2025-01-08 19:59:32,379][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:59:32,432][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:59:34,169][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 19:59:35,800][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 19:59:37,394][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 19:59:37,924][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 19:59:37,924][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 19:59:49,003][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 19:59:49,583][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 19:59:49,636][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 19:59:51,478][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 19:59:53,071][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 19:59:54,631][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 19:59:55,126][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 19:59:55,126][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:00:08,198][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:00:08,484][root][INFO] - Loading VLLM model.
WARNING 01-08 20:00:08 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:00:08 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:00:09 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:00:09 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:00:09,546][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:00:10,918][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:00:11,316][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:00:12,677][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:00:14,076][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:00:14,076][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:00:14 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:00:28 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:00:28 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:00:28 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:00:49 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:00:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:00:50,231][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:00:53,039][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.81s/it, est. speed input: 179.88 toks/s, output: 11.40 toks/s]
[2025-01-08 20:00:53,173][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:02<00:00,  5.57it/s, est. speed input: 2060.00 toks/s, output: 137.33 toks/s]
[2025-01-08 20:00:53,173][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.44it/s, est. speed input: 2746.34 toks/s, output: 187.62 toks/s]
WARNING 01-08 20:00:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:00:53,392][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:00:55,618][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:31,  2.23s/it, est. speed input: 255.66 toks/s, output: 13.93 toks/s]
[2025-01-08 20:00:55,729][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:02<00:00,  7.61it/s, est. speed input: 3210.32 toks/s, output: 183.60 toks/s]
[2025-01-08 20:00:55,729][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.42it/s, est. speed input: 3705.06 toks/s, output: 213.54 toks/s]
WARNING 01-08 20:00:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:00:55,936][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:00:56,734][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 876.01 toks/s, output: 36.34 toks/s]
[2025-01-08 20:00:56,735][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 876.01 toks/s, output: 36.34 toks/s]
WARNING 01-08 20:00:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:00:56,937][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:00:57,751][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 767.36 toks/s, output: 40.58 toks/s]
[2025-01-08 20:00:57,751][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 767.36 toks/s, output: 40.58 toks/s]
WARNING 01-08 20:00:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:00:57,968][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:00,174][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:30,  2.20s/it, est. speed input: 317.04 toks/s, output: 12.25 toks/s]
[2025-01-08 20:01:00,283][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:02<00:00,  7.69it/s, est. speed input: 3682.20 toks/s, output: 162.50 toks/s]
[2025-01-08 20:01:03,100][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.92it/s, est. speed input: 1859.02 toks/s, output: 118.28 toks/s]
WARNING 01-08 20:01:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:03,318][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:05,551][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.23s/it, est. speed input: 312.64 toks/s, output: 14.78 toks/s]
[2025-01-08 20:01:05,588][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.73it/s, est. speed input: 3981.90 toks/s, output: 190.35 toks/s]
WARNING 01-08 20:01:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:05,817][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:06,810][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.01it/s, est. speed input: 756.02 toks/s, output: 27.22 toks/s]
[2025-01-08 20:01:06,847][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.91it/s, est. speed input: 2465.56 toks/s, output: 82.57 toks/s]
WARNING 01-08 20:01:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:07,056][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:08,372][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.32s/it, est. speed input: 584.95 toks/s, output: 25.07 toks/s]
[2025-01-08 20:01:08,390][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.75it/s, est. speed input: 2741.24 toks/s, output: 124.43 toks/s]
WARNING 01-08 20:01:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:08,626][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:10,783][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.16s/it, est. speed input: 377.95 toks/s, output: 12.52 toks/s]
[2025-01-08 20:01:11,145][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.72it/s, est. speed input: 4247.33 toks/s, output: 132.99 toks/s]
[2025-01-08 20:01:11,145][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  4.37it/s, est. speed input: 4247.33 toks/s, output: 132.99 toks/s]
WARNING 01-08 20:01:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:11,392][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:13,535][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.14s/it, est. speed input: 381.42 toks/s, output: 15.41 toks/s]
[2025-01-08 20:01:13,535][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.13it/s, est. speed input: 4181.45 toks/s, output: 169.42 toks/s]
WARNING 01-08 20:01:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:13,744][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:14,808][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:04,  1.06s/it, est. speed input: 1237.19 toks/s, output: 15.03 toks/s]
[2025-01-08 20:01:15,091][root][ERROR] - Processed prompts:  40%|####      | 2/5 [00:01<00:01,  1.65it/s, est. speed input: 1582.50 toks/s, output: 33.40 toks/s]
[2025-01-08 20:01:15,091][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.71it/s, est. speed input: 3633.27 toks/s, output: 97.96 toks/s]
WARNING 01-08 20:01:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:15,299][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:16,540][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 716.38 toks/s, output: 26.59 toks/s]
[2025-01-08 20:01:16,558][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.18it/s, est. speed input: 2689.27 toks/s, output: 105.66 toks/s]
WARNING 01-08 20:01:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:16,786][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:19,407][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:28,  2.62s/it, est. speed input: 502.58 toks/s, output: 9.16 toks/s]
[2025-01-08 20:01:19,563][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:06,  1.36it/s, est. speed input: 1352.06 toks/s, output: 28.81 toks/s]
[2025-01-08 20:01:20,274][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:03<00:03,  1.85it/s, est. speed input: 1851.62 toks/s, output: 47.01 toks/s]
[2025-01-08 20:01:20,467][root][ERROR] - Processed prompts:  67%|######6   | 8/12 [00:03<00:01,  3.43it/s, est. speed input: 2779.72 toks/s, output: 92.63 toks/s]
[2025-01-08 20:01:21,177][root][ERROR] - Processed prompts:  75%|#######5  | 9/12 [00:04<00:01,  2.67it/s, est. speed input: 2630.32 toks/s, output: 99.29 toks/s]
[2025-01-08 20:01:22,835][root][ERROR] - Processed prompts:  83%|########3 | 10/12 [00:06<00:01,  1.52it/s, est. speed input: 2127.29 toks/s, output: 101.18 toks/s]
[2025-01-08 20:01:23,275][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:06<00:00,  1.65it/s, est. speed input: 2185.93 toks/s, output: 125.14 toks/s]
[2025-01-08 20:01:23,275][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:06<00:00,  1.85it/s, est. speed input: 2388.81 toks/s, output: 155.96 toks/s]
WARNING 01-08 20:01:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:23,531][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:24,357][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1151.74 toks/s, output: 38.75 toks/s]
[2025-01-08 20:01:24,357][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1151.74 toks/s, output: 38.75 toks/s]
WARNING 01-08 20:01:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:24,591][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:26,786][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:02<00:15,  2.19s/it, est. speed input: 635.87 toks/s, output: 13.22 toks/s]
[2025-01-08 20:01:27,259][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:02<00:00,  3.83it/s, est. speed input: 4286.15 toks/s, output: 97.46 toks/s]
[2025-01-08 20:01:27,260][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:02<00:00,  3.00it/s, est. speed input: 4286.15 toks/s, output: 97.46 toks/s]
WARNING 01-08 20:01:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:01:27,512][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:01:28,475][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 1567.85 toks/s, output: 29.09 toks/s]
[2025-01-08 20:01:28,492][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.04it/s, est. speed input: 2485.87 toks/s, output: 58.17 toks/s]
[2025-01-08 20:01:35,702][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:01:35,757][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:01:37,481][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 20:01:39,083][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:01:40,657][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:01:41,176][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:01:41,176][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:01:52,286][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:01:52,846][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:01:52,898][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:01:54,809][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 20:01:56,471][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 20:01:58,030][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 20:01:58,525][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.21s/it]
[2025-01-08 20:01:58,526][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:02:12,328][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:02:12,689][root][INFO] - Loading VLLM model.
WARNING 01-08 20:02:12 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:02:12 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:02:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:02:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:02:13,659][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:02:15,026][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:02:15,432][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:02:16,790][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:02:18,194][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:02:18,194][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:02:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:02:32 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:02:32 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:02:32 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:02:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:02:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:02:54,340][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:02:57,529][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.19s/it, est. speed input: 158.38 toks/s, output: 10.04 toks/s]
[2025-01-08 20:02:57,613][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.89it/s, est. speed input: 2468.86 toks/s, output: 164.39 toks/s]
WARNING 01-08 20:02:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:02:57,861][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:00,062][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.20s/it, est. speed input: 262.66 toks/s, output: 15.00 toks/s]
[2025-01-08 20:03:00,099][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.26it/s, est. speed input: 3608.59 toks/s, output: 207.83 toks/s]
WARNING 01-08 20:03:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:00,303][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:01,171][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 804.87 toks/s, output: 33.39 toks/s]
[2025-01-08 20:03:01,172][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1609.04 toks/s, output: 66.75 toks/s]
WARNING 01-08 20:03:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:01,376][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:02,295][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.09it/s, est. speed input: 679.34 toks/s, output: 35.93 toks/s]
[2025-01-08 20:03:02,295][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.18it/s, est. speed input: 1358.10 toks/s, output: 71.82 toks/s]
WARNING 01-08 20:03:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:02,519][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:04,721][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.20s/it, est. speed input: 231.70 toks/s, output: 13.17 toks/s]
[2025-01-08 20:03:04,721][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  6.36it/s, est. speed input: 4272.88 toks/s, output: 184.39 toks/s]
WARNING 01-08 20:03:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:04,947][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:07,315][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 292.75 toks/s, output: 13.94 toks/s]
[2025-01-08 20:03:07,315][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.91it/s, est. speed input: 4109.74 toks/s, output: 195.12 toks/s]
WARNING 01-08 20:03:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:07,530][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:08,463][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 1080.51 toks/s, output: 31.09 toks/s]
[2025-01-08 20:03:08,464][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.14it/s, est. speed input: 2160.15 toks/s, output: 62.15 toks/s]
WARNING 01-08 20:03:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:08,669][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:09,613][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 787.87 toks/s, output: 34.99 toks/s]
[2025-01-08 20:03:09,613][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 1574.99 toks/s, output: 69.95 toks/s]
WARNING 01-08 20:03:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:09,840][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:12,484][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.64s/it, est. speed input: 307.51 toks/s, output: 10.97 toks/s]
[2025-01-08 20:03:12,485][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.29it/s, est. speed input: 5188.97 toks/s, output: 153.53 toks/s]
WARNING 01-08 20:03:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:12,710][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:15,266][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.56s/it, est. speed input: 317.75 toks/s, output: 12.91 toks/s]
[2025-01-08 20:03:15,266][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4458.76 toks/s, output: 180.74 toks/s]
WARNING 01-08 20:03:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:15,478][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:16,465][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 1335.29 toks/s, output: 28.39 toks/s]
[2025-01-08 20:03:16,803][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.65it/s, est. speed input: 1988.80 toks/s, output: 57.38 toks/s]
[2025-01-08 20:03:16,803][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.51it/s, est. speed input: 1988.80 toks/s, output: 57.38 toks/s]
WARNING 01-08 20:03:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:17,071][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:19,594][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:32,  2.52s/it, est. speed input: 522.14 toks/s, output: 4.76 toks/s]
[2025-01-08 20:03:19,732][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:02<00:13,  1.12s/it, est. speed input: 989.90 toks/s, output: 10.52 toks/s]
[2025-01-08 20:03:19,934][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:02<00:07,  1.43it/s, est. speed input: 1380.23 toks/s, output: 17.47 toks/s]
[2025-01-08 20:03:20,157][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.95it/s, est. speed input: 1707.18 toks/s, output: 25.60 toks/s]
[2025-01-08 20:03:20,424][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:03<00:01,  4.92it/s, est. speed input: 3084.96 toks/s, output: 61.16 toks/s]
[2025-01-08 20:03:20,992][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:03<00:01,  3.62it/s, est. speed input: 2973.44 toks/s, output: 68.10 toks/s]
[2025-01-08 20:03:21,925][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:04<00:01,  2.90it/s, est. speed input: 2904.46 toks/s, output: 89.42 toks/s]
[2025-01-08 20:03:22,130][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:05<00:00,  3.16it/s, est. speed input: 3047.14 toks/s, output: 108.33 toks/s]
[2025-01-08 20:03:23,707][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:06<00:00,  1.66it/s, est. speed input: 2521.33 toks/s, output: 112.72 toks/s]
[2025-01-08 20:03:23,708][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.11it/s, est. speed input: 2719.67 toks/s, output: 142.85 toks/s]
WARNING 01-08 20:03:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:03:24,012][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:03:26,356][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.34s/it, est. speed input: 585.08 toks/s, output: 11.52 toks/s]
[2025-01-08 20:03:28,506][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:04<00:00,  2.29it/s, est. speed input: 2887.97 toks/s, output: 85.23 toks/s]
[2025-01-08 20:03:28,506][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:04<00:00,  2.00it/s, est. speed input: 2887.97 toks/s, output: 85.23 toks/s]
[2025-01-08 20:03:35,862][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:03:35,916][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:03:37,603][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 20:03:39,221][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:03:40,813][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:03:41,334][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:03:41,334][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:03:52,216][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:03:52,751][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:03:52,803][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:03:54,636][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 20:03:56,210][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:03:57,767][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:03:58,273][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:03:58,274][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:04:12,549][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:04:12,836][root][INFO] - Loading VLLM model.
WARNING 01-08 20:04:13 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:04:13 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:04:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:04:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:04:13,982][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:04:15,350][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:04:15,753][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:04:17,110][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 20:04:18,519][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:04:18,519][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:04:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:04:32 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:04:33 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:04:33 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:04:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:04:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:04:54,708][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:04:57,795][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.09s/it, est. speed input: 163.62 toks/s, output: 10.37 toks/s]
[2025-01-08 20:04:57,887][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.03it/s, est. speed input: 2541.66 toks/s, output: 171.12 toks/s]
WARNING 01-08 20:04:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:04:58,110][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:00,528][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 239.10 toks/s, output: 13.65 toks/s]
[2025-01-08 20:05:00,569][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.51it/s, est. speed input: 3758.59 toks/s, output: 217.19 toks/s]
WARNING 01-08 20:05:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:00,800][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:03,103][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.30s/it, est. speed input: 221.52 toks/s, output: 12.16 toks/s]
[2025-01-08 20:05:03,140][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.84it/s, est. speed input: 4376.83 toks/s, output: 197.92 toks/s]
WARNING 01-08 20:05:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:03,365][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:05,951][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.59s/it, est. speed input: 269.51 toks/s, output: 12.76 toks/s]
[2025-01-08 20:05:05,952][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.18it/s, est. speed input: 4299.00 toks/s, output: 204.11 toks/s]
WARNING 01-08 20:05:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:06,156][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:06,971][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 937.35 toks/s, output: 40.49 toks/s]
[2025-01-08 20:05:06,971][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 937.35 toks/s, output: 40.49 toks/s]
WARNING 01-08 20:05:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:07,211][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:09,962][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.75s/it, est. speed input: 295.27 toks/s, output: 10.18 toks/s]
[2025-01-08 20:05:09,998][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.38it/s, est. speed input: 5145.01 toks/s, output: 155.72 toks/s]
WARNING 01-08 20:05:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:10,245][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:12,904][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.66s/it, est. speed input: 306.94 toks/s, output: 12.41 toks/s]
[2025-01-08 20:05:12,921][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.60it/s, est. speed input: 4563.77 toks/s, output: 185.33 toks/s]
WARNING 01-08 20:05:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:13,137][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:14,257][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.12s/it, est. speed input: 557.28 toks/s, output: 45.55 toks/s]
[2025-01-08 20:05:14,258][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.12s/it, est. speed input: 557.28 toks/s, output: 45.55 toks/s]
WARNING 01-08 20:05:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:14,463][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:15,441][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.02it/s, est. speed input: 896.41 toks/s, output: 33.73 toks/s]
[2025-01-08 20:05:15,442][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.04it/s, est. speed input: 1799.26 toks/s, output: 67.43 toks/s]
WARNING 01-08 20:05:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:15,674][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:18,597][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:37,  2.92s/it, est. speed input: 450.74 toks/s, output: 8.21 toks/s]
[2025-01-08 20:05:18,735][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:15,  1.28s/it, est. speed input: 796.27 toks/s, output: 16.99 toks/s]
[2025-01-08 20:05:19,215][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.59it/s, est. speed input: 1432.47 toks/s, output: 35.03 toks/s]
[2025-01-08 20:05:19,648][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:03<00:03,  2.30it/s, est. speed input: 1939.39 toks/s, output: 57.14 toks/s]
[2025-01-08 20:05:19,785][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:02,  2.78it/s, est. speed input: 2147.70 toks/s, output: 70.56 toks/s]
[2025-01-08 20:05:20,130][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:02,  2.81it/s, est. speed input: 2233.07 toks/s, output: 82.15 toks/s]
[2025-01-08 20:05:20,950][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:05<00:02,  2.07it/s, est. speed input: 2135.70 toks/s, output: 90.05 toks/s]
[2025-01-08 20:05:21,534][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:05<00:02,  1.95it/s, est. speed input: 2147.53 toks/s, output: 103.94 toks/s]
[2025-01-08 20:05:22,998][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:07<00:02,  1.27it/s, est. speed input: 1897.92 toks/s, output: 110.46 toks/s]
[2025-01-08 20:05:22,999][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.91it/s, est. speed input: 2437.28 toks/s, output: 192.38 toks/s]
WARNING 01-08 20:05:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:23,257][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:24,117][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 1103.39 toks/s, output: 39.53 toks/s]
[2025-01-08 20:05:24,118][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 1103.39 toks/s, output: 39.53 toks/s]
WARNING 01-08 20:05:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:24,338][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:26,365][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:02<00:12,  2.03s/it, est. speed input: 771.70 toks/s, output: 14.31 toks/s]
[2025-01-08 20:05:26,990][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:02<00:00,  3.28it/s, est. speed input: 3852.93 toks/s, output: 90.51 toks/s]
[2025-01-08 20:05:26,990][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:02<00:00,  2.64it/s, est. speed input: 3852.93 toks/s, output: 90.51 toks/s]
WARNING 01-08 20:05:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:27,237][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:28,010][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 982.61 toks/s, output: 38.79 toks/s]
[2025-01-08 20:05:28,011][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 982.61 toks/s, output: 38.79 toks/s]
WARNING 01-08 20:05:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:05:28,214][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:05:28,983][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1078.65 toks/s, output: 37.73 toks/s]
[2025-01-08 20:05:28,983][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1078.65 toks/s, output: 37.73 toks/s]
[2025-01-08 20:05:36,662][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:05:36,715][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:05:38,488][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 20:05:40,152][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:05:41,799][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:05:42,332][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:05:42,332][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 20:05:53,288][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:05:53,839][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:05:53,892][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:05:55,804][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 20:05:57,429][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 20:05:58,981][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.66s/it]
[2025-01-08 20:05:59,479][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 20:05:59,480][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 20:06:13,204][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:06:13,605][root][INFO] - Loading VLLM model.
WARNING 01-08 20:06:13 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:06:13 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:06:14 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:06:14 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:06:14,689][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:06:16,003][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 20:06:16,389][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 20:06:17,684][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 20:06:19,015][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 20:06:19,015][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 20:06:19 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:06:33 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:06:33 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:06:33 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:06:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:06:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:06:55,263][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:06:58,377][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.11s/it, est. speed input: 162.17 toks/s, output: 10.60 toks/s]
[2025-01-08 20:06:58,448][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.02it/s, est. speed input: 2537.01 toks/s, output: 174.58 toks/s]
WARNING 01-08 20:06:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:06:58,697][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:01,108][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 240.27 toks/s, output: 13.69 toks/s]
[2025-01-08 20:07:01,146][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.54it/s, est. speed input: 3782.90 toks/s, output: 217.33 toks/s]
WARNING 01-08 20:07:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:01,379][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:03,719][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.34s/it, est. speed input: 298.87 toks/s, output: 11.54 toks/s]
[2025-01-08 20:07:03,826][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  9.00it/s, est. speed input: 4418.12 toks/s, output: 189.71 toks/s]
[2025-01-08 20:07:03,826][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.54it/s, est. speed input: 4418.12 toks/s, output: 189.71 toks/s]
WARNING 01-08 20:07:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:04,048][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:06,522][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.47s/it, est. speed input: 282.18 toks/s, output: 13.34 toks/s]
[2025-01-08 20:07:06,523][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.06it/s, est. speed input: 4228.49 toks/s, output: 200.07 toks/s]
WARNING 01-08 20:07:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:06,729][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:07,513][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 739.30 toks/s, output: 36.96 toks/s]
[2025-01-08 20:07:07,514][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 739.30 toks/s, output: 36.96 toks/s]
WARNING 01-08 20:07:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:07,718][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:08,564][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 820.38 toks/s, output: 41.37 toks/s]
[2025-01-08 20:07:08,564][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 820.38 toks/s, output: 41.37 toks/s]
WARNING 01-08 20:07:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:08,793][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:11,533][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.74s/it, est. speed input: 367.09 toks/s, output: 9.85 toks/s]
[2025-01-08 20:07:11,606][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.33it/s, est. speed input: 5305.19 toks/s, output: 153.93 toks/s]
WARNING 01-08 20:07:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:11,837][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:14,629][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.79s/it, est. speed input: 292.63 toks/s, output: 11.82 toks/s]
[2025-01-08 20:07:14,630][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.73it/s, est. speed input: 4660.54 toks/s, output: 189.07 toks/s]
WARNING 01-08 20:07:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:14,868][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:17,542][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.67s/it, est. speed input: 492.46 toks/s, output: 3.37 toks/s]
[2025-01-08 20:07:17,833][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:02<00:10,  1.25it/s, est. speed input: 1332.40 toks/s, output: 12.14 toks/s]
[2025-01-08 20:07:18,236][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:05,  2.03it/s, est. speed input: 1826.23 toks/s, output: 24.64 toks/s]
[2025-01-08 20:07:18,523][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:04,  2.29it/s, est. speed input: 2043.11 toks/s, output: 33.10 toks/s]
[2025-01-08 20:07:18,826][root][ERROR] - Processed prompts:  44%|####3     | 7/16 [00:03<00:03,  2.50it/s, est. speed input: 2219.69 toks/s, output: 42.70 toks/s]
[2025-01-08 20:07:19,828][root][ERROR] - Processed prompts:  50%|#####     | 8/16 [00:04<00:04,  1.75it/s, est. speed input: 2036.60 toks/s, output: 50.80 toks/s]
[2025-01-08 20:07:21,861][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:06<00:06,  1.01it/s, est. speed input: 1632.88 toks/s, output: 58.49 toks/s]
[2025-01-08 20:07:23,007][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:08<00:06,  1.04s/it, est. speed input: 1540.78 toks/s, output: 74.82 toks/s]
[2025-01-08 20:07:23,008][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.97it/s, est. speed input: 2511.01 toks/s, output: 222.24 toks/s]
WARNING 01-08 20:07:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:23,273][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:24,109][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1061.49 toks/s, output: 39.49 toks/s]
[2025-01-08 20:07:24,110][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1061.49 toks/s, output: 39.49 toks/s]
WARNING 01-08 20:07:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:24,352][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:27,317][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:32,  2.96s/it, est. speed input: 528.54 toks/s, output: 9.11 toks/s]
[2025-01-08 20:07:27,749][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  4.27it/s, est. speed input: 4823.15 toks/s, output: 99.20 toks/s]
[2025-01-08 20:07:29,168][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:04<00:00,  2.49it/s, est. speed input: 3688.76 toks/s, output: 97.59 toks/s]
WARNING 01-08 20:07:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:07:29,448][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:07:30,300][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1400.10 toks/s, output: 36.41 toks/s]
[2025-01-08 20:07:30,300][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1400.10 toks/s, output: 36.41 toks/s]
[2025-01-08 20:07:37,595][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:07:37,649][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:07:39,412][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 20:07:41,099][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:07:42,737][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:07:43,276][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:07:43,276][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:07:54,737][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:07:55,257][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:07:55,310][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:07:57,164][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 20:07:58,780][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:08:00,345][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 20:08:00,837][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:08:00,837][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 20:08:18,551][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:08:18,846][root][INFO] - Loading VLLM model.
WARNING 01-08 20:08:19 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:08:19 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:08:19 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:08:19 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:08:19,949][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:08:21,320][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:08:21,725][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:08:23,084][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:08:24,487][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:08:24,488][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:08:24 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:08:38 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:08:39 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:08:39 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:09:00 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:09:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:00,700][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:03,389][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:40,  2.69s/it, est. speed input: 187.83 toks/s, output: 12.27 toks/s]
[2025-01-08 20:09:03,462][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.79it/s, est. speed input: 2925.85 toks/s, output: 202.06 toks/s]
WARNING 01-08 20:09:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:03,682][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:06,134][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.45s/it, est. speed input: 236.19 toks/s, output: 13.46 toks/s]
[2025-01-08 20:09:06,177][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.41it/s, est. speed input: 3712.53 toks/s, output: 214.45 toks/s]
WARNING 01-08 20:09:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:06,401][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:08,762][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.36s/it, est. speed input: 296.17 toks/s, output: 12.29 toks/s]
[2025-01-08 20:09:08,779][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.73it/s, est. speed input: 4305.90 toks/s, output: 195.55 toks/s]
WARNING 01-08 20:09:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:09,004][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:11,602][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.60s/it, est. speed input: 268.70 toks/s, output: 12.70 toks/s]
[2025-01-08 20:09:11,636][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.08it/s, est. speed input: 4233.58 toks/s, output: 201.36 toks/s]
WARNING 01-08 20:09:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:11,844][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:12,662][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 939.72 toks/s, output: 40.38 toks/s]
[2025-01-08 20:09:12,662][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 939.72 toks/s, output: 40.38 toks/s]
WARNING 01-08 20:09:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:12,892][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:15,626][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.73s/it, est. speed input: 368.72 toks/s, output: 10.24 toks/s]
[2025-01-08 20:09:15,663][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.41it/s, est. speed input: 5176.29 toks/s, output: 156.65 toks/s]
WARNING 01-08 20:09:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:15,902][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:18,455][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 320.05 toks/s, output: 12.93 toks/s]
[2025-01-08 20:09:18,456][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4471.19 toks/s, output: 180.93 toks/s]
WARNING 01-08 20:09:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:18,693][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:19,627][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 1167.76 toks/s, output: 31.07 toks/s]
[2025-01-08 20:09:19,627][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.14it/s, est. speed input: 2037.87 toks/s, output: 62.11 toks/s]
WARNING 01-08 20:09:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:19,842][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:20,815][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.03it/s, est. speed input: 839.35 toks/s, output: 33.90 toks/s]
[2025-01-08 20:09:20,816][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.05it/s, est. speed input: 1749.90 toks/s, output: 67.78 toks/s]
WARNING 01-08 20:09:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:21,050][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:23,409][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.36s/it, est. speed input: 558.49 toks/s, output: 3.82 toks/s]
[2025-01-08 20:09:24,079][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:09,  1.16it/s, est. speed input: 1240.00 toks/s, output: 15.85 toks/s]
[2025-01-08 20:09:24,431][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.46it/s, est. speed input: 1501.14 toks/s, output: 26.03 toks/s]
[2025-01-08 20:09:24,732][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:03<00:05,  1.79it/s, est. speed input: 1735.70 toks/s, output: 37.48 toks/s]
[2025-01-08 20:09:25,277][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:04,  1.81it/s, est. speed input: 1777.40 toks/s, output: 48.97 toks/s]
[2025-01-08 20:09:25,633][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:04<00:03,  2.03it/s, est. speed input: 1926.66 toks/s, output: 63.06 toks/s]
[2025-01-08 20:09:25,873][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:04<00:02,  2.42it/s, est. speed input: 2104.18 toks/s, output: 78.80 toks/s]
[2025-01-08 20:09:26,495][root][ERROR] - Processed prompts:  64%|######4   | 9/14 [00:05<00:02,  2.09it/s, est. speed input: 2069.75 toks/s, output: 91.10 toks/s]
[2025-01-08 20:09:27,780][root][ERROR] - Processed prompts:  71%|#######1  | 10/14 [00:06<00:02,  1.38it/s, est. speed input: 1870.26 toks/s, output: 99.12 toks/s]
[2025-01-08 20:09:28,425][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:07<00:02,  1.43it/s, est. speed input: 1885.34 toks/s, output: 117.57 toks/s]
[2025-01-08 20:09:28,425][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.90it/s, est. speed input: 2394.58 toks/s, output: 198.93 toks/s]
WARNING 01-08 20:09:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:28,702][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:31,022][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.32s/it, est. speed input: 595.30 toks/s, output: 12.07 toks/s]
[2025-01-08 20:09:31,743][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  3.71it/s, est. speed input: 4152.11 toks/s, output: 98.98 toks/s]
[2025-01-08 20:09:31,744][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.96it/s, est. speed input: 4152.11 toks/s, output: 98.98 toks/s]
WARNING 01-08 20:09:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:09:32,001][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:09:32,812][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1501.22 toks/s, output: 35.77 toks/s]
[2025-01-08 20:09:32,812][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1501.22 toks/s, output: 35.77 toks/s]
[2025-01-08 20:09:40,096][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:09:40,150][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:09:41,868][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 20:09:43,451][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 20:09:45,027][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 20:09:45,542][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:09:45,543][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:09:56,514][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:09:57,001][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:09:57,053][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:09:58,963][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 20:10:00,661][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.79s/it]
[2025-01-08 20:10:02,268][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 20:10:02,776][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:10:02,777][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 20:10:16,816][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:10:17,167][root][INFO] - Loading VLLM model.
WARNING 01-08 20:10:17 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:10:17 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:10:17 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:10:17 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:10:18,064][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:10:19,444][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 20:10:19,846][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 20:10:21,206][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:10:22,614][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:10:22,615][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:10:22 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:10:36 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:10:37 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:10:37 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:10:58 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:10:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:10:59,020][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:02,218][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.20s/it, est. speed input: 157.93 toks/s, output: 10.32 toks/s]
[2025-01-08 20:11:02,291][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.89it/s, est. speed input: 2470.49 toks/s, output: 170.61 toks/s]
WARNING 01-08 20:11:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:02,516][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:04,930][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.87 toks/s, output: 13.67 toks/s]
[2025-01-08 20:11:04,984][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.48it/s, est. speed input: 3753.85 toks/s, output: 220.08 toks/s]
WARNING 01-08 20:11:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:05,204][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:07,344][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:32,  2.14s/it, est. speed input: 238.46 toks/s, output: 12.16 toks/s]
[2025-01-08 20:11:07,447][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:02<00:03,  2.94it/s, est. speed input: 1137.22 toks/s, output: 61.10 toks/s]
[2025-01-08 20:11:07,447][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.13it/s, est. speed input: 4144.06 toks/s, output: 203.32 toks/s]
WARNING 01-08 20:11:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:07,669][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:10,065][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:31,  2.40s/it, est. speed input: 289.72 toks/s, output: 13.78 toks/s]
[2025-01-08 20:11:10,111][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.73it/s, est. speed input: 3987.86 toks/s, output: 192.94 toks/s]
WARNING 01-08 20:11:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:10,315][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:11,185][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.15it/s, est. speed input: 664.09 toks/s, output: 33.32 toks/s]
[2025-01-08 20:11:11,186][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.30it/s, est. speed input: 1324.02 toks/s, output: 66.60 toks/s]
WARNING 01-08 20:11:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:11,411][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:13,102][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.69s/it, est. speed input: 453.02 toks/s, output: 19.52 toks/s]
[2025-01-08 20:11:13,151][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.60it/s, est. speed input: 3442.35 toks/s, output: 158.09 toks/s]
WARNING 01-08 20:11:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:13,385][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:15,085][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.70s/it, est. speed input: 478.43 toks/s, output: 15.30 toks/s]
[2025-01-08 20:11:15,180][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.46it/s, est. speed input: 4276.04 toks/s, output: 127.62 toks/s]
WARNING 01-08 20:11:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:15,399][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:17,281][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.88s/it, est. speed input: 407.00 toks/s, output: 17.53 toks/s]
[2025-01-08 20:11:17,315][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.70it/s, est. speed input: 3780.48 toks/s, output: 156.02 toks/s]
WARNING 01-08 20:11:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:17,535][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:18,928][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:08,  1.39s/it, est. speed input: 446.63 toks/s, output: 19.39 toks/s]
[2025-01-08 20:11:18,974][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.87it/s, est. speed input: 3351.61 toks/s, output: 138.32 toks/s]
WARNING 01-08 20:11:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:19,189][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:21,002][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.81s/it, est. speed input: 485.34 toks/s, output: 18.20 toks/s]
[2025-01-08 20:11:21,040][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.32it/s, est. speed input: 3781.64 toks/s, output: 144.80 toks/s]
WARNING 01-08 20:11:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:21,256][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:23,085][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.83s/it, est. speed input: 720.33 toks/s, output: 13.13 toks/s]
[2025-01-08 20:11:23,213][root][ERROR] - Processed prompts:  38%|###7      | 3/8 [00:01<00:02,  1.92it/s, est. speed input: 1795.94 toks/s, output: 40.39 toks/s]
[2025-01-08 20:11:23,834][root][ERROR] - Processed prompts:  50%|#####     | 4/8 [00:02<00:02,  1.80it/s, est. speed input: 1704.56 toks/s, output: 52.37 toks/s]
[2025-01-08 20:11:24,592][root][ERROR] - Processed prompts:  75%|#######5  | 6/8 [00:03<00:00,  2.14it/s, est. speed input: 2048.11 toks/s, output: 85.15 toks/s]
[2025-01-08 20:11:26,555][root][ERROR] - Processed prompts:  88%|########7 | 7/8 [00:05<00:00,  1.16it/s, est. speed input: 1537.85 toks/s, output: 91.35 toks/s]
[2025-01-08 20:11:26,555][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:05<00:00,  1.51it/s, est. speed input: 1786.31 toks/s, output: 129.09 toks/s]
WARNING 01-08 20:11:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:26,779][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:27,932][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.15s/it, est. speed input: 767.73 toks/s, output: 28.63 toks/s]
[2025-01-08 20:11:27,968][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.52it/s, est. speed input: 2352.63 toks/s, output: 85.79 toks/s]
WARNING 01-08 20:11:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:28,200][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:30,822][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:28,  2.62s/it, est. speed input: 458.37 toks/s, output: 9.91 toks/s]
[2025-01-08 20:11:31,414][root][ERROR] - Processed prompts:  92%|#########1| 11/12 [00:03<00:00,  4.41it/s, est. speed input: 4192.90 toks/s, output: 106.71 toks/s]
[2025-01-08 20:11:33,356][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:05<00:00,  2.33it/s, est. speed input: 2869.20 toks/s, output: 99.69 toks/s]
WARNING 01-08 20:11:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:33,612][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:34,461][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1035.84 toks/s, output: 38.89 toks/s]
[2025-01-08 20:11:34,461][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1035.84 toks/s, output: 38.89 toks/s]
WARNING 01-08 20:11:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:34,676][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:36,294][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.62s/it, est. speed input: 733.99 toks/s, output: 17.93 toks/s]
[2025-01-08 20:11:36,294][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.71it/s, est. speed input: 4146.02 toks/s, output: 107.56 toks/s]
WARNING 01-08 20:11:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:11:36,561][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:11:37,376][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1588.50 toks/s, output: 34.37 toks/s]
[2025-01-08 20:11:37,377][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1588.50 toks/s, output: 34.37 toks/s]
[2025-01-08 20:11:44,799][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:11:44,852][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:11:46,630][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.78s/it]
[2025-01-08 20:11:48,317][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:11:49,958][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:11:50,500][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:11:50,500][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:12:01,807][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:12:02,330][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:12:02,382][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:12:04,261][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 20:12:05,872][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:12:07,436][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 20:12:07,929][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:12:07,929][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 20:12:20,805][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:12:21,195][root][INFO] - Loading VLLM model.
WARNING 01-08 20:12:21 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:12:21 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:12:21 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:12:21 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:12:22,163][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:12:23,531][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:12:23,930][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:12:25,294][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:12:26,704][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:12:26,705][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:12:26 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:12:40 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:12:41 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:12:41 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:13:02 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:13:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:02,933][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:05,695][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.76s/it, est. speed input: 182.93 toks/s, output: 11.95 toks/s]
[2025-01-08 20:13:05,768][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.65it/s, est. speed input: 2850.84 toks/s, output: 196.88 toks/s]
WARNING 01-08 20:13:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:06,014][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:08,423][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 240.39 toks/s, output: 13.70 toks/s]
[2025-01-08 20:13:08,446][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.58it/s, est. speed input: 3809.37 toks/s, output: 218.81 toks/s]
WARNING 01-08 20:13:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:08,680][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:10,906][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:33,  2.23s/it, est. speed input: 229.21 toks/s, output: 11.24 toks/s]
[2025-01-08 20:13:11,014][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:02<00:08,  1.62it/s, est. speed input: 817.58 toks/s, output: 34.28 toks/s]
[2025-01-08 20:13:11,234][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00, 10.75it/s, est. speed input: 4084.57 toks/s, output: 183.31 toks/s]
[2025-01-08 20:13:11,234][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.27it/s, est. speed input: 4084.57 toks/s, output: 183.31 toks/s]
WARNING 01-08 20:13:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:11,449][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:13,584][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:23,  2.13s/it, est. speed input: 327.05 toks/s, output: 15.46 toks/s]
[2025-01-08 20:13:13,584][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.62it/s, est. speed input: 3920.26 toks/s, output: 185.50 toks/s]
WARNING 01-08 20:13:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:13,792][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:14,771][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:00<00:02,  1.02it/s, est. speed input: 768.49 toks/s, output: 24.53 toks/s]
[2025-01-08 20:13:14,869][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.72it/s, est. speed input: 2303.65 toks/s, output: 103.11 toks/s]
WARNING 01-08 20:13:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:15,077][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:16,264][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.19s/it, est. speed input: 583.76 toks/s, output: 27.80 toks/s]
[2025-01-08 20:13:16,283][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.32it/s, est. speed input: 2297.26 toks/s, output: 111.09 toks/s]
WARNING 01-08 20:13:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:16,506][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:18,860][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.35s/it, est. speed input: 427.38 toks/s, output: 11.90 toks/s]
[2025-01-08 20:13:18,891][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.03it/s, est. speed input: 4989.83 toks/s, output: 145.11 toks/s]
WARNING 01-08 20:13:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:19,117][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:21,665][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 320.71 toks/s, output: 12.95 toks/s]
[2025-01-08 20:13:21,666][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.49it/s, est. speed input: 4446.09 toks/s, output: 181.31 toks/s]
WARNING 01-08 20:13:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:21,873][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:22,784][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 1152.08 toks/s, output: 30.72 toks/s]
[2025-01-08 20:13:22,802][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.15it/s, est. speed input: 2074.58 toks/s, output: 61.36 toks/s]
WARNING 01-08 20:13:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:23,006][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:23,861][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 950.08 toks/s, output: 39.78 toks/s]
[2025-01-08 20:13:23,861][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 950.08 toks/s, output: 39.78 toks/s]
WARNING 01-08 20:13:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:24,095][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:26,934][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.84s/it, est. speed input: 464.07 toks/s, output: 6.69 toks/s]
[2025-01-08 20:13:27,107][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:09,  1.25it/s, est. speed input: 1241.18 toks/s, output: 20.59 toks/s]
[2025-01-08 20:13:27,241][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:06,  1.76it/s, est. speed input: 1606.98 toks/s, output: 28.62 toks/s]
[2025-01-08 20:13:27,533][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:02,  3.48it/s, est. speed input: 2364.87 toks/s, output: 54.41 toks/s]
[2025-01-08 20:13:28,492][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:04<00:02,  2.80it/s, est. speed input: 2447.68 toks/s, output: 68.70 toks/s]
[2025-01-08 20:13:29,112][root][ERROR] - Processed prompts:  67%|######6   | 10/15 [00:05<00:02,  2.43it/s, est. speed input: 2407.74 toks/s, output: 79.95 toks/s]
[2025-01-08 20:13:30,535][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:06<00:02,  1.56it/s, est. speed input: 2080.02 toks/s, output: 87.12 toks/s]
[2025-01-08 20:13:31,424][root][ERROR] - Processed prompts:  80%|########  | 12/15 [00:07<00:02,  1.42it/s, est. speed input: 2007.43 toks/s, output: 103.84 toks/s]
[2025-01-08 20:13:31,424][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  2.05it/s, est. speed input: 2519.86 toks/s, output: 185.71 toks/s]
WARNING 01-08 20:13:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:31,686][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:32,949][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.26s/it, est. speed input: 696.21 toks/s, output: 26.14 toks/s]
[2025-01-08 20:13:32,966][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.12it/s, est. speed input: 2697.86 toks/s, output: 103.88 toks/s]
WARNING 01-08 20:13:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:33,206][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:35,562][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.36s/it, est. speed input: 667.38 toks/s, output: 11.46 toks/s]
[2025-01-08 20:13:35,914][root][ERROR] - Processed prompts:  89%|########8 | 8/9 [00:02<00:00,  3.85it/s, est. speed input: 4334.50 toks/s, output: 90.88 toks/s]
[2025-01-08 20:13:36,521][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:03<00:00,  2.72it/s, est. speed input: 3959.02 toks/s, output: 98.65 toks/s]
WARNING 01-08 20:13:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:36,784][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:37,637][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1123.43 toks/s, output: 38.70 toks/s]
[2025-01-08 20:13:37,638][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1123.43 toks/s, output: 38.70 toks/s]
WARNING 01-08 20:13:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:37,846][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:38,931][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.08s/it, est. speed input: 1292.57 toks/s, output: 22.14 toks/s]
[2025-01-08 20:13:41,131][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.10s/it, est. speed input: 1148.68 toks/s, output: 63.02 toks/s]
[2025-01-08 20:13:41,132][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.09s/it, est. speed input: 1148.68 toks/s, output: 63.02 toks/s]
WARNING 01-08 20:13:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:41,359][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:41,893][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.87it/s, est. speed input: 2222.00 toks/s, output: 5.62 toks/s]
[2025-01-08 20:13:42,316][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 2786.13 toks/s, output: 32.40 toks/s]
[2025-01-08 20:13:42,316][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.09it/s, est. speed input: 2786.13 toks/s, output: 32.40 toks/s]
WARNING 01-08 20:13:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:13:42,528][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:13:43,396][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1433.05 toks/s, output: 36.86 toks/s]
[2025-01-08 20:13:43,397][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1433.05 toks/s, output: 36.86 toks/s]
[2025-01-08 20:13:50,987][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:13:51,040][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:13:52,695][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.65s/it]
[2025-01-08 20:13:54,278][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.61s/it]
[2025-01-08 20:13:55,844][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.59s/it]
[2025-01-08 20:13:56,367][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 20:13:56,367][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.33s/it]
[2025-01-08 20:14:07,479][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:14:08,135][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:14:08,188][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:14:09,985][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.80s/it]
[2025-01-08 20:14:11,578][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:14:13,137][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:14:13,637][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:14:13,637][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:14:28,073][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:14:28,364][root][INFO] - Loading VLLM model.
WARNING 01-08 20:14:28 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:14:28 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:14:29 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:14:29 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:14:29,554][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:14:30,918][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 20:14:31,327][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:14:32,697][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:14:34,107][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:14:34,107][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:14:34 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:14:48 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:14:48 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:14:48 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:15:10 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:15:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:10,425][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:13,246][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.82s/it, est. speed input: 178.99 toks/s, output: 11.34 toks/s]
[2025-01-08 20:15:13,342][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.49it/s, est. speed input: 2770.07 toks/s, output: 187.53 toks/s]
WARNING 01-08 20:15:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:13,561][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:15,991][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.43s/it, est. speed input: 238.31 toks/s, output: 13.58 toks/s]
[2025-01-08 20:15:15,992][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.58it/s, est. speed input: 3806.63 toks/s, output: 217.26 toks/s]
WARNING 01-08 20:15:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:16,218][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:18,639][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 288.78 toks/s, output: 11.15 toks/s]
[2025-01-08 20:15:18,731][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.37it/s, est. speed input: 4451.26 toks/s, output: 184.27 toks/s]
WARNING 01-08 20:15:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:18,969][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:21,609][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.64s/it, est. speed input: 264.46 toks/s, output: 12.50 toks/s]
[2025-01-08 20:15:21,609][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.06it/s, est. speed input: 4225.24 toks/s, output: 199.99 toks/s]
WARNING 01-08 20:15:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:21,859][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:24,790][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.93s/it, est. speed input: 343.23 toks/s, output: 9.21 toks/s]
[2025-01-08 20:15:24,881][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.29it/s, est. speed input: 5336.26 toks/s, output: 152.87 toks/s]
WARNING 01-08 20:15:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:25,116][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:27,799][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.68s/it, est. speed input: 304.52 toks/s, output: 12.30 toks/s]
[2025-01-08 20:15:27,800][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.59it/s, est. speed input: 4561.84 toks/s, output: 184.46 toks/s]
WARNING 01-08 20:15:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:28,003][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:28,809][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1318.83 toks/s, output: 34.77 toks/s]
[2025-01-08 20:15:28,809][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1318.83 toks/s, output: 34.77 toks/s]
WARNING 01-08 20:15:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:29,012][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:29,865][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 957.80 toks/s, output: 38.69 toks/s]
[2025-01-08 20:15:29,866][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 957.80 toks/s, output: 38.69 toks/s]
WARNING 01-08 20:15:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:30,101][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:32,976][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:40,  2.87s/it, est. speed input: 457.44 toks/s, output: 5.57 toks/s]
[2025-01-08 20:15:33,627][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:20,  1.57s/it, est. speed input: 746.50 toks/s, output: 14.18 toks/s]
[2025-01-08 20:15:33,834][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:11,  1.06it/s, est. speed input: 1056.71 toks/s, output: 24.11 toks/s]
[2025-01-08 20:15:34,505][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:06,  1.67it/s, est. speed input: 1494.03 toks/s, output: 43.59 toks/s]
[2025-01-08 20:15:35,925][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:05<00:07,  1.20it/s, est. speed input: 1356.38 toks/s, output: 51.51 toks/s]
[2025-01-08 20:15:36,385][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:06<00:05,  1.38it/s, est. speed input: 1466.71 toks/s, output: 67.48 toks/s]
[2025-01-08 20:15:38,474][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:08<00:07,  1.13s/it, est. speed input: 1257.92 toks/s, output: 74.52 toks/s]
[2025-01-08 20:15:38,475][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:08<00:00,  1.79it/s, est. speed input: 2358.81 toks/s, output: 241.71 toks/s]
WARNING 01-08 20:15:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:15:38,753][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:15:41,396][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:23,  2.64s/it, est. speed input: 594.89 toks/s, output: 10.22 toks/s]
[2025-01-08 20:15:41,470][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  3.68it/s, est. speed input: 5644.42 toks/s, output: 105.98 toks/s]
[2025-01-08 20:15:49,005][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:15:49,059][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:15:50,764][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 20:15:52,389][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 20:15:53,974][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:15:54,500][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:15:54,500][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:16:05,495][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:16:06,022][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:16:06,074][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:16:07,945][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 20:16:09,571][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 20:16:11,181][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 20:16:11,703][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:16:11,704][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:16:26,380][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:16:26,747][root][INFO] - Loading VLLM model.
WARNING 01-08 20:16:26 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:16:26 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:16:29 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:16:29 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:16:29,852][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:16:31,233][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 20:16:31,648][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.23it/s]
[2025-01-08 20:16:33,015][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.07s/it]
[2025-01-08 20:16:34,421][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:16:34,421][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:16:34 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:16:48 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:16:49 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:16:49 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:17:11 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:17:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:11,722][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:14,796][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.07s/it, est. speed input: 164.29 toks/s, output: 10.41 toks/s]
[2025-01-08 20:17:14,866][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.09it/s, est. speed input: 2570.37 toks/s, output: 167.96 toks/s]
WARNING 01-08 20:17:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:15,114][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:17,531][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 238.73 toks/s, output: 13.65 toks/s]
[2025-01-08 20:17:17,531][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.62it/s, est. speed input: 3818.62 toks/s, output: 218.40 toks/s]
WARNING 01-08 20:17:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:17,769][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:20,197][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.43s/it, est. speed input: 287.90 toks/s, output: 11.53 toks/s]
[2025-01-08 20:17:20,306][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  8.68it/s, est. speed input: 4407.65 toks/s, output: 184.83 toks/s]
[2025-01-08 20:17:20,307][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.30it/s, est. speed input: 4407.65 toks/s, output: 184.83 toks/s]
WARNING 01-08 20:17:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:20,547][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:23,035][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.49s/it, est. speed input: 279.79 toks/s, output: 13.27 toks/s]
[2025-01-08 20:17:23,035][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.03it/s, est. speed input: 4195.93 toks/s, output: 198.94 toks/s]
WARNING 01-08 20:17:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:23,257][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:24,006][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1011.23 toks/s, output: 36.07 toks/s]
[2025-01-08 20:17:24,006][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1011.23 toks/s, output: 36.07 toks/s]
WARNING 01-08 20:17:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:24,227][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:25,068][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 828.35 toks/s, output: 39.27 toks/s]
[2025-01-08 20:17:25,068][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 828.35 toks/s, output: 39.27 toks/s]
WARNING 01-08 20:17:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:25,312][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:28,116][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.80s/it, est. speed input: 359.12 toks/s, output: 9.99 toks/s]
[2025-01-08 20:17:28,204][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.19it/s, est. speed input: 5228.69 toks/s, output: 151.11 toks/s]
WARNING 01-08 20:17:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:28,446][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:31,192][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.75s/it, est. speed input: 296.84 toks/s, output: 12.02 toks/s]
[2025-01-08 20:17:31,192][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.46it/s, est. speed input: 4449.34 toks/s, output: 180.25 toks/s]
WARNING 01-08 20:17:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:31,427][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:32,197][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1380.79 toks/s, output: 35.04 toks/s]
[2025-01-08 20:17:32,198][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1380.79 toks/s, output: 35.04 toks/s]
WARNING 01-08 20:17:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:32,416][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:33,302][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 919.87 toks/s, output: 37.25 toks/s]
[2025-01-08 20:17:33,302][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 919.87 toks/s, output: 37.25 toks/s]
WARNING 01-08 20:17:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:33,569][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:35,985][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:33,  2.42s/it, est. speed input: 545.05 toks/s, output: 1.66 toks/s]
[2025-01-08 20:17:36,094][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:13,  1.06s/it, est. speed input: 1043.00 toks/s, output: 4.36 toks/s]
[2025-01-08 20:17:36,853][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:11,  1.08it/s, est. speed input: 1203.10 toks/s, output: 12.18 toks/s]
[2025-01-08 20:17:37,586][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:06,  1.65it/s, est. speed input: 1639.09 toks/s, output: 30.12 toks/s]
[2025-01-08 20:17:38,038][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:04<00:05,  1.78it/s, est. speed input: 1767.83 toks/s, output: 42.06 toks/s]
[2025-01-08 20:17:39,185][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:05<00:05,  1.36it/s, est. speed input: 1641.35 toks/s, output: 52.53 toks/s]
[2025-01-08 20:17:41,742][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:08<00:08,  1.27s/it, est. speed input: 1288.97 toks/s, output: 60.56 toks/s]
[2025-01-08 20:17:41,742][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:08<00:00,  1.84it/s, est. speed input: 2416.55 toks/s, output: 231.84 toks/s]
WARNING 01-08 20:17:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:17:42,044][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:17:44,835][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:27,  2.79s/it, est. speed input: 562.98 toks/s, output: 9.32 toks/s]
[2025-01-08 20:17:44,937][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.20it/s, est. speed input: 5772.21 toks/s, output: 107.84 toks/s]
[2025-01-08 20:17:44,938][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  3.80it/s, est. speed input: 5772.21 toks/s, output: 107.84 toks/s]
[2025-01-08 20:17:52,388][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:17:52,441][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:17:54,141][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 20:17:55,757][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:17:57,362][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:17:57,887][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:17:57,887][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:18:09,087][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:18:09,584][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:18:09,636][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:18:11,469][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 20:18:13,043][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:18:14,610][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:18:15,109][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:18:15,109][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:18:29,722][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:18:30,017][root][INFO] - Loading VLLM model.
WARNING 01-08 20:18:30 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:18:30 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:18:30 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:18:30 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:18:31,006][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:18:32,323][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:18:32,715][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:18:34,022][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:18:35,364][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:18:35,364][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:18:35 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:18:49 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:18:50 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:18:50 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:19:11 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:19:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:11,944][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:15,101][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.16s/it, est. speed input: 159.98 toks/s, output: 10.14 toks/s]
[2025-01-08 20:19:15,101][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.07it/s, est. speed input: 2559.17 toks/s, output: 162.16 toks/s]
WARNING 01-08 20:19:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:15,322][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:17,570][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:33,  2.25s/it, est. speed input: 256.30 toks/s, output: 12.90 toks/s]
[2025-01-08 20:19:17,700][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:02<00:03,  2.76it/s, est. speed input: 1211.19 toks/s, output: 62.66 toks/s]
[2025-01-08 20:19:17,700][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.73it/s, est. speed input: 3874.67 toks/s, output: 215.28 toks/s]
WARNING 01-08 20:19:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:17,924][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:20,233][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.31s/it, est. speed input: 302.71 toks/s, output: 10.83 toks/s]
[2025-01-08 20:19:20,343][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:14,  1.02s/it, est. speed input: 578.03 toks/s, output: 21.91 toks/s]
[2025-01-08 20:19:20,396][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.47it/s, est. speed input: 4524.63 toks/s, output: 186.10 toks/s]
WARNING 01-08 20:19:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:20,618][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:22,951][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:32,  2.33s/it, est. speed input: 296.33 toks/s, output: 12.44 toks/s]
[2025-01-08 20:19:23,075][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:02<00:03,  2.67it/s, est. speed input: 1408.04 toks/s, output: 60.65 toks/s]
[2025-01-08 20:19:23,076][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.10it/s, est. speed input: 4236.05 toks/s, output: 194.95 toks/s]
WARNING 01-08 20:19:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:23,299][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:24,075][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 965.21 toks/s, output: 37.37 toks/s]
[2025-01-08 20:19:24,075][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 965.21 toks/s, output: 37.37 toks/s]
WARNING 01-08 20:19:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:24,277][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:25,099][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 845.71 toks/s, output: 40.15 toks/s]
[2025-01-08 20:19:25,100][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 845.71 toks/s, output: 40.15 toks/s]
WARNING 01-08 20:19:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:25,340][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:28,136][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.79s/it, est. speed input: 360.31 toks/s, output: 10.02 toks/s]
[2025-01-08 20:19:28,226][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.20it/s, est. speed input: 5240.98 toks/s, output: 151.82 toks/s]
WARNING 01-08 20:19:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:28,469][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:30,988][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:35,  2.52s/it, est. speed input: 319.99 toks/s, output: 11.51 toks/s]
[2025-01-08 20:19:31,130][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:02<00:14,  1.12s/it, est. speed input: 608.76 toks/s, output: 23.30 toks/s]
[2025-01-08 20:19:31,131][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.64it/s, est. speed input: 4575.08 toks/s, output: 184.48 toks/s]
WARNING 01-08 20:19:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:31,347][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:32,145][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1326.24 toks/s, output: 36.35 toks/s]
[2025-01-08 20:19:32,145][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1326.24 toks/s, output: 36.35 toks/s]
WARNING 01-08 20:19:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:32,351][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:33,210][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 947.38 toks/s, output: 38.41 toks/s]
[2025-01-08 20:19:33,211][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 947.38 toks/s, output: 38.41 toks/s]
WARNING 01-08 20:19:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:33,456][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:37,166][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:51,  3.71s/it, est. speed input: 355.00 toks/s, output: 10.51 toks/s]
[2025-01-08 20:19:37,445][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:12,  1.06s/it, est. speed input: 991.89 toks/s, output: 31.59 toks/s]
[2025-01-08 20:19:37,546][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:04<00:08,  1.37it/s, est. speed input: 1289.47 toks/s, output: 43.04 toks/s]
[2025-01-08 20:19:37,705][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:04<00:05,  1.84it/s, est. speed input: 1550.92 toks/s, output: 54.36 toks/s]
[2025-01-08 20:19:42,093][root][ERROR] - Processed prompts:  40%|####      | 6/15 [00:08<00:15,  1.78s/it, est. speed input: 915.55 toks/s, output: 49.91 toks/s]
[2025-01-08 20:19:42,093][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:08<00:00,  1.74it/s, est. speed input: 2287.64 toks/s, output: 258.31 toks/s]
WARNING 01-08 20:19:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:42,371][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:45,120][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:27,  2.75s/it, est. speed input: 561.36 toks/s, output: 8.73 toks/s]
[2025-01-08 20:19:45,241][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:02<00:06,  1.32it/s, est. speed input: 1633.82 toks/s, output: 27.53 toks/s]
[2025-01-08 20:19:45,267][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  3.80it/s, est. speed input: 5878.65 toks/s, output: 106.70 toks/s]
WARNING 01-08 20:19:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:19:45,541][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:19:46,362][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 1729.86 toks/s, output: 34.11 toks/s]
[2025-01-08 20:19:46,362][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 1729.86 toks/s, output: 34.11 toks/s]
[2025-01-08 20:19:53,723][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:19:53,777][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:19:55,571][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 20:19:57,255][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 20:19:58,916][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 20:19:59,454][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 20:19:59,454][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 20:20:10,322][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:20:10,863][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:20:10,914][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:20:12,776][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 20:20:14,414][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 20:20:16,048][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:20:16,558][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:20:16,558][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:20:31,234][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:20:31,576][root][INFO] - Loading VLLM model.
WARNING 01-08 20:20:31 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:20:31 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:20:32 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:20:32 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:20:32,961][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:20:34,332][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:20:34,739][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 20:20:36,096][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:20:37,502][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:20:37,502][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:20:37 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:20:51 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:20:52 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:20:52 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:21:13 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:21:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:13,676][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:16,647][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.97s/it, est. speed input: 170.00 toks/s, output: 9.76 toks/s]
[2025-01-08 20:21:16,726][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 2649.60 toks/s, output: 159.37 toks/s]
WARNING 01-08 20:21:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:16,953][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:19,352][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.40s/it, est. speed input: 239.73 toks/s, output: 13.76 toks/s]
[2025-01-08 20:21:19,353][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.67it/s, est. speed input: 3830.45 toks/s, output: 220.07 toks/s]
WARNING 01-08 20:21:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:19,580][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:21,861][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.28s/it, est. speed input: 306.41 toks/s, output: 10.96 toks/s]
[2025-01-08 20:21:21,970][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:02<00:08,  1.58it/s, est. speed input: 877.45 toks/s, output: 33.47 toks/s]
[2025-01-08 20:21:22,040][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.50it/s, est. speed input: 4469.05 toks/s, output: 186.97 toks/s]
WARNING 01-08 20:21:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:22,263][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:24,742][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 280.06 toks/s, output: 13.32 toks/s]
[2025-01-08 20:21:24,742][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.05it/s, est. speed input: 4193.47 toks/s, output: 199.71 toks/s]
WARNING 01-08 20:21:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:24,949][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:25,709][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 986.02 toks/s, output: 36.86 toks/s]
[2025-01-08 20:21:25,710][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 986.02 toks/s, output: 36.86 toks/s]
WARNING 01-08 20:21:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:25,915][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:26,758][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 823.78 toks/s, output: 39.17 toks/s]
[2025-01-08 20:21:26,758][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 823.78 toks/s, output: 39.17 toks/s]
WARNING 01-08 20:21:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:26,987][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:29,728][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.74s/it, est. speed input: 367.74 toks/s, output: 9.85 toks/s]
[2025-01-08 20:21:29,836][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  7.25it/s, est. speed input: 5238.90 toks/s, output: 152.70 toks/s]
[2025-01-08 20:21:29,836][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.27it/s, est. speed input: 5238.90 toks/s, output: 152.70 toks/s]
WARNING 01-08 20:21:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:30,064][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:32,480][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.42s/it, est. speed input: 336.49 toks/s, output: 13.66 toks/s]
[2025-01-08 20:21:32,481][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.38it/s, est. speed input: 4367.56 toks/s, output: 177.52 toks/s]
WARNING 01-08 20:21:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:32,702][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:33,691][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.01it/s, est. speed input: 1070.13 toks/s, output: 23.29 toks/s]
[2025-01-08 20:21:33,804][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  3.36it/s, est. speed input: 2888.72 toks/s, output: 72.67 toks/s]
[2025-01-08 20:21:33,804][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.72it/s, est. speed input: 2888.72 toks/s, output: 72.67 toks/s]
WARNING 01-08 20:21:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:34,011][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:34,975][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 843.07 toks/s, output: 34.26 toks/s]
[2025-01-08 20:21:34,975][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 1685.22 toks/s, output: 68.49 toks/s]
WARNING 01-08 20:21:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:35,225][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:38,111][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:37,  2.89s/it, est. speed input: 456.46 toks/s, output: 7.62 toks/s]
[2025-01-08 20:21:38,353][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:15,  1.33s/it, est. speed input: 842.24 toks/s, output: 16.31 toks/s]
[2025-01-08 20:21:38,757][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:03<00:03,  2.61it/s, est. speed input: 2131.64 toks/s, output: 51.54 toks/s]
[2025-01-08 20:21:43,066][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:07<00:08,  1.23s/it, est. speed input: 1128.13 toks/s, output: 48.72 toks/s]
[2025-01-08 20:21:43,066][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.79it/s, est. speed input: 2303.32 toks/s, output: 227.27 toks/s]
WARNING 01-08 20:21:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:43,295][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:44,132][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 971.81 toks/s, output: 39.45 toks/s]
[2025-01-08 20:21:44,132][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 971.81 toks/s, output: 39.45 toks/s]
WARNING 01-08 20:21:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:44,378][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:47,382][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:36,  3.00s/it, est. speed input: 463.81 toks/s, output: 7.32 toks/s]
[2025-01-08 20:21:47,551][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:03<00:14,  1.34s/it, est. speed input: 934.46 toks/s, output: 15.44 toks/s]
[2025-01-08 20:21:47,708][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:03<00:00,  6.40it/s, est. speed input: 5445.63 toks/s, output: 103.00 toks/s]
[2025-01-08 20:21:49,450][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:05<00:00,  2.56it/s, est. speed input: 3845.56 toks/s, output: 94.65 toks/s]
WARNING 01-08 20:21:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:21:49,747][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:21:50,555][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1786.82 toks/s, output: 33.43 toks/s]
[2025-01-08 20:21:50,555][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1786.82 toks/s, output: 33.43 toks/s]
[2025-01-08 20:21:57,978][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:21:58,031][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:21:59,811][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.78s/it]
[2025-01-08 20:22:01,471][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:22:03,157][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 20:22:03,693][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 20:22:03,694][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 20:22:14,685][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:22:15,171][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:22:15,223][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:22:17,061][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 20:22:18,720][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 20:22:20,347][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:22:20,859][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:22:20,860][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:22:35,475][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:22:35,857][root][INFO] - Loading VLLM model.
WARNING 01-08 20:22:36 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:22:36 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:22:36 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:22:36 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:22:37,186][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:22:38,557][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:22:38,958][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:22:40,317][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:22:41,725][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:22:41,726][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:22:41 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:22:55 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:22:56 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:22:56 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:23:17 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:23:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:17,827][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:20,899][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.07s/it, est. speed input: 164.40 toks/s, output: 10.42 toks/s]
[2025-01-08 20:23:20,924][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.17it/s, est. speed input: 2608.90 toks/s, output: 167.25 toks/s]
WARNING 01-08 20:23:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:21,169][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:23,583][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 238.67 toks/s, output: 13.67 toks/s]
[2025-01-08 20:23:23,583][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3820.02 toks/s, output: 218.71 toks/s]
WARNING 01-08 20:23:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:23,808][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:26,126][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.32s/it, est. speed input: 301.59 toks/s, output: 11.22 toks/s]
[2025-01-08 20:23:26,232][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:02<00:04,  2.72it/s, est. speed input: 1441.89 toks/s, output: 57.35 toks/s]
[2025-01-08 20:23:26,253][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.54it/s, est. speed input: 4497.41 toks/s, output: 188.57 toks/s]
WARNING 01-08 20:23:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:26,484][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:28,964][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 280.21 toks/s, output: 13.30 toks/s]
[2025-01-08 20:23:28,965][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.05it/s, est. speed input: 4199.62 toks/s, output: 199.52 toks/s]
WARNING 01-08 20:23:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:29,204][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:29,982][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 964.21 toks/s, output: 37.28 toks/s]
[2025-01-08 20:23:29,982][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.28it/s, est. speed input: 964.21 toks/s, output: 37.28 toks/s]
WARNING 01-08 20:23:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:30,184][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:31,004][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 847.71 toks/s, output: 40.25 toks/s]
[2025-01-08 20:23:31,004][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 847.71 toks/s, output: 40.25 toks/s]
WARNING 01-08 20:23:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:31,230][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:33,976][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.75s/it, est. speed input: 366.71 toks/s, output: 9.83 toks/s]
[2025-01-08 20:23:34,842][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  5.27it/s, est. speed input: 4130.40 toks/s, output: 132.61 toks/s]
[2025-01-08 20:23:34,842][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:03<00:00,  4.15it/s, est. speed input: 4130.40 toks/s, output: 132.61 toks/s]
WARNING 01-08 20:23:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:35,070][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:37,622][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 318.98 toks/s, output: 12.93 toks/s]
[2025-01-08 20:23:37,623][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4464.55 toks/s, output: 180.99 toks/s]
WARNING 01-08 20:23:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:37,829][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:38,742][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.09it/s, est. speed input: 1159.18 toks/s, output: 29.55 toks/s]
[2025-01-08 20:23:38,844][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  2.29it/s, est. speed input: 2080.51 toks/s, output: 59.08 toks/s]
[2025-01-08 20:23:38,845][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.97it/s, est. speed input: 2080.51 toks/s, output: 59.08 toks/s]
WARNING 01-08 20:23:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:39,050][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:40,013][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 833.16 toks/s, output: 34.28 toks/s]
[2025-01-08 20:23:40,013][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 1678.10 toks/s, output: 68.54 toks/s]
WARNING 01-08 20:23:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:40,246][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:42,613][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 556.60 toks/s, output: 2.96 toks/s]
[2025-01-08 20:23:43,338][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:03<00:16,  1.40s/it, est. speed input: 851.45 toks/s, output: 11.32 toks/s]
[2025-01-08 20:23:43,499][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:05,  1.74it/s, est. speed input: 1618.87 toks/s, output: 29.82 toks/s]
[2025-01-08 20:23:43,620][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:03<00:03,  2.31it/s, est. speed input: 1951.30 toks/s, output: 39.72 toks/s]
[2025-01-08 20:23:44,998][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:05,  1.38it/s, est. speed input: 1621.96 toks/s, output: 46.10 toks/s]
[2025-01-08 20:23:48,160][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:07<00:10,  1.47s/it, est. speed input: 1140.42 toks/s, output: 52.95 toks/s]
[2025-01-08 20:23:48,161][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.77it/s, est. speed input: 2310.92 toks/s, output: 229.84 toks/s]
WARNING 01-08 20:23:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:48,454][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:51,608][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:37,  3.15s/it, est. speed input: 514.03 toks/s, output: 8.24 toks/s]
[2025-01-08 20:23:51,719][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:03<00:00,  4.18it/s, est. speed input: 4599.03 toks/s, output: 85.75 toks/s]
[2025-01-08 20:23:51,754][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:03<00:00,  3.94it/s, est. speed input: 5916.87 toks/s, output: 112.73 toks/s]
WARNING 01-08 20:23:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:23:52,042][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:23:52,866][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1719.87 toks/s, output: 33.98 toks/s]
[2025-01-08 20:23:52,867][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 1719.87 toks/s, output: 33.98 toks/s]
[2025-01-08 20:24:00,463][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:24:00,517][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:24:02,194][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 20:24:03,808][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 20:24:05,423][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:24:05,946][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:24:05,946][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:24:17,205][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:24:17,726][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:24:17,778][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:24:19,599][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 20:24:21,189][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:24:22,744][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:24:23,249][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:24:23,249][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:24:38,074][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:24:38,401][root][INFO] - Loading VLLM model.
WARNING 01-08 20:24:38 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:24:38 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:24:39 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:24:39 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:24:39,415][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:24:40,732][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:24:41,125][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:24:42,430][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:24:43,781][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:24:43,781][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:24:44 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:24:57 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:24:58 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:24:58 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:25:20 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:25:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:20,322][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:23,418][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.10s/it, est. speed input: 163.13 toks/s, output: 10.34 toks/s]
[2025-01-08 20:25:23,455][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.11it/s, est. speed input: 2579.29 toks/s, output: 168.23 toks/s]
WARNING 01-08 20:25:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:23,686][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:26,097][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.36 toks/s, output: 13.69 toks/s]
[2025-01-08 20:25:26,098][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.64it/s, est. speed input: 3828.43 toks/s, output: 218.98 toks/s]
WARNING 01-08 20:25:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:26,325][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:28,709][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.38s/it, est. speed input: 293.27 toks/s, output: 11.33 toks/s]
[2025-01-08 20:25:28,819][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  8.83it/s, est. speed input: 4485.86 toks/s, output: 186.51 toks/s]
[2025-01-08 20:25:28,819][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.42it/s, est. speed input: 4485.86 toks/s, output: 186.51 toks/s]
WARNING 01-08 20:25:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:29,041][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:31,415][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 293.12 toks/s, output: 13.90 toks/s]
[2025-01-08 20:25:31,416][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.89it/s, est. speed input: 4102.18 toks/s, output: 194.52 toks/s]
WARNING 01-08 20:25:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:31,624][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:32,531][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 830.74 toks/s, output: 31.99 toks/s]
[2025-01-08 20:25:34,930][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.78s/it, est. speed input: 457.75 toks/s, output: 60.81 toks/s]
[2025-01-08 20:25:34,930][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.65s/it, est. speed input: 457.75 toks/s, output: 60.81 toks/s]
WARNING 01-08 20:25:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:35,136][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:36,078][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 739.71 toks/s, output: 35.07 toks/s]
[2025-01-08 20:25:36,078][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 1472.42 toks/s, output: 70.11 toks/s]
WARNING 01-08 20:25:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:36,305][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:38,935][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.63s/it, est. speed input: 382.63 toks/s, output: 10.27 toks/s]
[2025-01-08 20:25:39,044][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:02<00:00,  6.51it/s, est. speed input: 4785.76 toks/s, output: 138.04 toks/s]
[2025-01-08 20:25:39,044][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.11it/s, est. speed input: 5153.40 toks/s, output: 149.35 toks/s]
WARNING 01-08 20:25:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:39,268][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:41,829][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.56s/it, est. speed input: 318.25 toks/s, output: 12.89 toks/s]
[2025-01-08 20:25:41,830][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.47it/s, est. speed input: 4453.90 toks/s, output: 180.36 toks/s]
WARNING 01-08 20:25:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:42,046][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:43,011][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 1100.63 toks/s, output: 30.05 toks/s]
[2025-01-08 20:25:43,011][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.07it/s, est. speed input: 2349.29 toks/s, output: 60.08 toks/s]
WARNING 01-08 20:25:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:43,237][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:44,198][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 847.49 toks/s, output: 34.31 toks/s]
[2025-01-08 20:25:44,199][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 1688.07 toks/s, output: 68.60 toks/s]
WARNING 01-08 20:25:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:44,432][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:47,797][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:43,  3.37s/it, est. speed input: 391.67 toks/s, output: 10.10 toks/s]
[2025-01-08 20:25:48,135][root][ERROR] - Processed prompts:  21%|##1       | 3/14 [00:03<00:10,  1.00it/s, est. speed input: 1067.25 toks/s, output: 30.79 toks/s]
[2025-01-08 20:25:48,390][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:07,  1.35it/s, est. speed input: 1331.13 toks/s, output: 41.94 toks/s]
[2025-01-08 20:25:48,593][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.36it/s, est. speed input: 1899.77 toks/s, output: 66.81 toks/s]
[2025-01-08 20:25:52,351][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:07<00:06,  1.03s/it, est. speed input: 1331.47 toks/s, output: 68.07 toks/s]
[2025-01-08 20:25:52,351][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:07<00:00,  1.77it/s, est. speed input: 2328.90 toks/s, output: 219.60 toks/s]
WARNING 01-08 20:25:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:52,618][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:25:55,955][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:43,  3.34s/it, est. speed input: 420.56 toks/s, output: 7.79 toks/s]
[2025-01-08 20:25:56,095][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:03<00:00,  4.73it/s, est. speed input: 5154.80 toks/s, output: 98.38 toks/s]
[2025-01-08 20:25:59,192][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.13it/s, est. speed input: 3165.27 toks/s, output: 112.88 toks/s]
WARNING 01-08 20:25:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:25:59,481][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:26:00,560][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.08s/it, est. speed input: 1506.95 toks/s, output: 25.95 toks/s]
[2025-01-08 20:26:00,561][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.85it/s, est. speed input: 3139.72 toks/s, output: 51.88 toks/s]
[2025-01-08 20:26:08,077][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:26:08,131][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:26:09,856][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 20:26:11,475][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 20:26:13,036][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:26:13,551][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:26:13,551][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:26:24,495][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:26:25,014][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:26:25,066][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:26:26,937][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 20:26:28,578][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 20:26:30,187][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:26:30,696][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:26:30,696][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:26:45,665][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:26:46,011][root][INFO] - Loading VLLM model.
WARNING 01-08 20:26:46 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:26:46 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:26:47 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:26:47 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:26:47,257][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:26:48,625][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:26:49,029][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:26:50,389][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:26:51,795][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:26:51,795][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:26:52 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:27:05 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:27:06 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:27:06 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:27:27 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:27:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:27,946][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:30,805][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.86s/it, est. speed input: 176.63 toks/s, output: 11.19 toks/s]
[2025-01-08 20:27:30,835][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.54it/s, est. speed input: 2797.54 toks/s, output: 179.35 toks/s]
WARNING 01-08 20:27:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:31,087][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:33,511][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 237.69 toks/s, output: 13.62 toks/s]
[2025-01-08 20:27:33,511][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.60it/s, est. speed input: 3804.38 toks/s, output: 217.82 toks/s]
WARNING 01-08 20:27:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:33,753][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:36,070][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:34,  2.32s/it, est. speed input: 301.70 toks/s, output: 11.22 toks/s]
[2025-01-08 20:27:36,179][root][ERROR] - Processed prompts:  19%|#8        | 3/16 [00:02<00:08,  1.56it/s, est. speed input: 786.65 toks/s, output: 34.22 toks/s]
[2025-01-08 20:27:36,198][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.54it/s, est. speed input: 4496.83 toks/s, output: 188.95 toks/s]
WARNING 01-08 20:27:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:36,419][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:38,898][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 280.39 toks/s, output: 13.31 toks/s]
[2025-01-08 20:27:38,898][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.05it/s, est. speed input: 4204.81 toks/s, output: 199.65 toks/s]
WARNING 01-08 20:27:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:39,104][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:39,891][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 952.69 toks/s, output: 36.84 toks/s]
[2025-01-08 20:27:39,891][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 952.69 toks/s, output: 36.84 toks/s]
WARNING 01-08 20:27:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:40,111][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:40,929][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 849.15 toks/s, output: 40.32 toks/s]
[2025-01-08 20:27:40,930][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 849.15 toks/s, output: 40.32 toks/s]
WARNING 01-08 20:27:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:41,157][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:43,938][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.78s/it, est. speed input: 362.14 toks/s, output: 10.07 toks/s]
[2025-01-08 20:27:44,009][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.26it/s, est. speed input: 5234.08 toks/s, output: 152.89 toks/s]
WARNING 01-08 20:27:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:44,246][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:46,660][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.15 toks/s, output: 13.67 toks/s]
[2025-01-08 20:27:46,661][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.38it/s, est. speed input: 4381.93 toks/s, output: 177.65 toks/s]
WARNING 01-08 20:27:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:46,871][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:47,983][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 980.58 toks/s, output: 26.09 toks/s]
[2025-01-08 20:27:47,983][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.70it/s, est. speed input: 2887.62 toks/s, output: 78.24 toks/s]
WARNING 01-08 20:27:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:48,192][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:49,291][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 740.29 toks/s, output: 30.01 toks/s]
[2025-01-08 20:27:49,292][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.73it/s, est. speed input: 2220.05 toks/s, output: 90.00 toks/s]
WARNING 01-08 20:27:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:49,523][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:27:51,660][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:25,  2.14s/it, est. speed input: 617.68 toks/s, output: 2.34 toks/s]
[2025-01-08 20:27:52,131][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:12,  1.16s/it, est. speed input: 1011.46 toks/s, output: 9.21 toks/s]
[2025-01-08 20:27:52,801][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:03<00:09,  1.07it/s, est. speed input: 1206.40 toks/s, output: 19.53 toks/s]
[2025-01-08 20:27:53,133][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:03<00:06,  1.44it/s, est. speed input: 1460.73 toks/s, output: 31.86 toks/s]
[2025-01-08 20:27:57,414][root][ERROR] - Processed prompts:  38%|###8      | 5/13 [00:07<00:15,  1.99s/it, est. speed input: 810.42 toks/s, output: 39.92 toks/s]
[2025-01-08 20:27:57,415][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:07<00:00,  1.65it/s, est. speed input: 2145.21 toks/s, output: 242.66 toks/s]
WARNING 01-08 20:27:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:27:57,711][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:28:01,150][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:48,  3.44s/it, est. speed input: 398.78 toks/s, output: 6.98 toks/s]
[2025-01-08 20:28:01,260][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:19,  1.48s/it, est. speed input: 829.46 toks/s, output: 14.37 toks/s]
[2025-01-08 20:28:01,373][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:03<00:00,  6.50it/s, est. speed input: 5328.22 toks/s, output: 101.87 toks/s]
[2025-01-08 20:28:03,616][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.54it/s, est. speed input: 3772.95 toks/s, output: 104.67 toks/s]
WARNING 01-08 20:28:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:28:03,905][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:28:05,131][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.23s/it, est. speed input: 1258.89 toks/s, output: 22.03 toks/s]
[2025-01-08 20:28:05,168][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.38it/s, est. speed input: 3580.19 toks/s, output: 67.30 toks/s]
[2025-01-08 20:28:13,001][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:28:13,056][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:28:14,800][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 20:28:16,495][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:28:18,146][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:28:18,693][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 20:28:18,694][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:28:29,736][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:28:30,284][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:28:30,336][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:28:32,154][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 20:28:33,724][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 20:28:35,275][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:28:35,769][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 20:28:35,770][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:28:50,689][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:28:51,072][root][INFO] - Loading VLLM model.
WARNING 01-08 20:28:51 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:28:51 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:28:51 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:28:51 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:28:52,469][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:28:53,802][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
[2025-01-08 20:28:54,191][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:28:55,489][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:28:56,826][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 20:28:56,827][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:28:57 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:29:10 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:29:11 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:29:11 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:29:32 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:29:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:33,043][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:36,129][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.09s/it, est. speed input: 163.67 toks/s, output: 10.37 toks/s]
[2025-01-08 20:29:36,165][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.13it/s, est. speed input: 2588.51 toks/s, output: 168.51 toks/s]
WARNING 01-08 20:29:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:36,386][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:38,832][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.45s/it, est. speed input: 235.95 toks/s, output: 13.49 toks/s]
[2025-01-08 20:29:38,833][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.54it/s, est. speed input: 3773.33 toks/s, output: 215.85 toks/s]
WARNING 01-08 20:29:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:39,071][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:41,454][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.38s/it, est. speed input: 293.35 toks/s, output: 11.33 toks/s]
[2025-01-08 20:29:41,565][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:02<00:00,  8.26it/s, est. speed input: 4203.87 toks/s, output: 174.41 toks/s]
[2025-01-08 20:29:41,599][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.33it/s, est. speed input: 4423.24 toks/s, output: 185.09 toks/s]
WARNING 01-08 20:29:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:41,830][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:44,202][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 293.40 toks/s, output: 13.91 toks/s]
[2025-01-08 20:29:44,203][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.90it/s, est. speed input: 4105.72 toks/s, output: 194.71 toks/s]
WARNING 01-08 20:29:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:44,412][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:45,307][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 842.22 toks/s, output: 32.44 toks/s]
[2025-01-08 20:29:45,307][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.24it/s, est. speed input: 1691.43 toks/s, output: 64.84 toks/s]
WARNING 01-08 20:29:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:45,516][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:46,454][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 742.18 toks/s, output: 35.19 toks/s]
[2025-01-08 20:29:46,455][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1483.78 toks/s, output: 70.35 toks/s]
WARNING 01-08 20:29:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:46,695][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:49,324][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.63s/it, est. speed input: 383.51 toks/s, output: 10.27 toks/s]
[2025-01-08 20:29:49,428][root][ERROR] - Processed prompts:  93%|#########2| 13/14 [00:02<00:00,  6.53it/s, est. speed input: 4795.79 toks/s, output: 137.24 toks/s]
[2025-01-08 20:29:49,446][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.09it/s, est. speed input: 5133.42 toks/s, output: 148.01 toks/s]
WARNING 01-08 20:29:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:49,689][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:52,104][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.57 toks/s, output: 13.67 toks/s]
[2025-01-08 20:29:52,105][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.38it/s, est. speed input: 4386.45 toks/s, output: 177.64 toks/s]
WARNING 01-08 20:29:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:52,350][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:53,460][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 981.40 toks/s, output: 26.13 toks/s]
[2025-01-08 20:29:53,461][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.70it/s, est. speed input: 2900.80 toks/s, output: 78.38 toks/s]
WARNING 01-08 20:29:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:53,673][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:54,911][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 711.08 toks/s, output: 26.67 toks/s]
[2025-01-08 20:29:54,911][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.23it/s, est. speed input: 2680.95 toks/s, output: 106.62 toks/s]
WARNING 01-08 20:29:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:29:55,145][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:29:57,158][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:22,  2.01s/it, est. speed input: 657.86 toks/s, output: 2.48 toks/s]
[2025-01-08 20:29:57,891][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:02<00:12,  1.26s/it, est. speed input: 961.90 toks/s, output: 12.02 toks/s]
[2025-01-08 20:29:58,072][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:02<00:06,  1.30it/s, est. speed input: 1350.87 toks/s, output: 22.89 toks/s]
[2025-01-08 20:29:59,992][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:04<00:09,  1.22s/it, est. speed input: 1087.50 toks/s, output: 34.66 toks/s]
[2025-01-08 20:30:01,038][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:05<00:08,  1.16s/it, est. speed input: 1118.69 toks/s, output: 52.10 toks/s]
[2025-01-08 20:30:02,559][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:07<00:04,  1.05it/s, est. speed input: 1244.41 toks/s, output: 87.27 toks/s]
[2025-01-08 20:30:02,559][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:07<00:00,  1.62it/s, est. speed input: 2132.50 toks/s, output: 222.14 toks/s]
WARNING 01-08 20:30:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:30:02,828][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:30:06,032][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:38,  3.20s/it, est. speed input: 490.95 toks/s, output: 9.05 toks/s]
[2025-01-08 20:30:06,305][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:03<00:00,  3.86it/s, est. speed input: 4306.83 toks/s, output: 88.01 toks/s]
[2025-01-08 20:30:07,465][root][ERROR] - Processed prompts:  92%|#########2| 12/13 [00:04<00:00,  3.01it/s, est. speed input: 3810.84 toks/s, output: 105.89 toks/s]
[2025-01-08 20:30:09,175][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  2.05it/s, est. speed input: 3000.23 toks/s, output: 108.88 toks/s]
WARNING 01-08 20:30:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:30:09,467][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:30:10,635][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.17s/it, est. speed input: 1275.77 toks/s, output: 20.56 toks/s]
[2025-01-08 20:30:10,708][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.42it/s, est. speed input: 3679.82 toks/s, output: 63.69 toks/s]
[2025-01-08 20:30:18,358][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:30:18,412][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:30:20,116][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 20:30:21,732][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:30:23,323][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:30:23,847][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:30:23,848][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:30:34,850][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:30:35,725][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:30:35,777][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:30:37,405][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.63s/it]
[2025-01-08 20:30:38,993][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.60s/it]
[2025-01-08 20:30:40,566][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.59s/it]
[2025-01-08 20:30:41,062][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.16s/it]
[2025-01-08 20:30:41,062][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.32s/it]
[2025-01-08 20:30:55,900][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:30:56,279][root][INFO] - Loading VLLM model.
WARNING 01-08 20:30:56 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:30:56 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:30:57 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:30:57 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:30:57,281][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:30:58,602][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:30:58,994][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:31:00,303][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:31:01,645][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:31:01,646][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:31:01 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:31:15 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:31:16 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:31:16 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:31:37 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:31:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:38,200][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:41,395][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.19s/it, est. speed input: 158.08 toks/s, output: 10.02 toks/s]
[2025-01-08 20:31:41,423][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.96it/s, est. speed input: 2507.36 toks/s, output: 161.36 toks/s]
WARNING 01-08 20:31:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:41,655][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:44,070][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 238.57 toks/s, output: 13.67 toks/s]
[2025-01-08 20:31:44,070][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3819.49 toks/s, output: 218.63 toks/s]
WARNING 01-08 20:31:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:44,295][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:46,634][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.34s/it, est. speed input: 298.78 toks/s, output: 11.97 toks/s]
[2025-01-08 20:31:47,735][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:03<00:00,  5.37it/s, est. speed input: 2827.87 toks/s, output: 143.30 toks/s]
[2025-01-08 20:31:48,020][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.13it/s, est. speed input: 2798.97 toks/s, output: 160.24 toks/s]
[2025-01-08 20:31:48,021][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.29it/s, est. speed input: 2798.97 toks/s, output: 160.24 toks/s]
WARNING 01-08 20:31:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:48,244][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:50,607][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.36s/it, est. speed input: 294.16 toks/s, output: 13.97 toks/s]
[2025-01-08 20:31:50,608][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.92it/s, est. speed input: 4112.10 toks/s, output: 195.49 toks/s]
WARNING 01-08 20:31:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:50,815][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:51,696][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.14it/s, est. speed input: 940.42 toks/s, output: 31.80 toks/s]
[2025-01-08 20:31:51,714][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.23it/s, est. speed input: 1616.10 toks/s, output: 63.48 toks/s]
WARNING 01-08 20:31:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:51,924][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:53,124][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.20s/it, est. speed input: 574.86 toks/s, output: 27.49 toks/s]
[2025-01-08 20:31:53,125][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.33it/s, est. speed input: 2410.88 toks/s, output: 109.93 toks/s]
WARNING 01-08 20:31:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:53,352][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:55,685][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.33s/it, est. speed input: 348.63 toks/s, output: 12.01 toks/s]
[2025-01-08 20:31:56,947][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  4.04it/s, est. speed input: 3256.45 toks/s, output: 116.56 toks/s]
[2025-01-08 20:31:56,948][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:03<00:00,  3.34it/s, est. speed input: 3256.45 toks/s, output: 116.56 toks/s]
WARNING 01-08 20:31:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:57,174][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:31:59,455][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.28s/it, est. speed input: 356.91 toks/s, output: 14.47 toks/s]
[2025-01-08 20:31:59,456][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.26it/s, est. speed input: 4249.81 toks/s, output: 173.59 toks/s]
WARNING 01-08 20:31:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:31:59,689][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:00,930][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 914.49 toks/s, output: 22.58 toks/s]
[2025-01-08 20:32:00,949][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.18it/s, est. speed input: 3244.08 toks/s, output: 90.53 toks/s]
WARNING 01-08 20:32:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:01,180][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:03,045][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:13,  1.87s/it, est. speed input: 468.56 toks/s, output: 17.69 toks/s]
[2025-01-08 20:32:03,046][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.29it/s, est. speed input: 3686.29 toks/s, output: 141.49 toks/s]
WARNING 01-08 20:32:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:03,279][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:04,719][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:10,  1.44s/it, est. speed input: 914.20 toks/s, output: 4.86 toks/s]
[2025-01-08 20:32:04,879][root][ERROR] - Processed prompts:  25%|##5       | 2/8 [00:01<00:04,  1.46it/s, est. speed input: 1646.40 toks/s, output: 12.51 toks/s]
[2025-01-08 20:32:05,300][root][ERROR] - Processed prompts:  38%|###7      | 3/8 [00:02<00:02,  1.77it/s, est. speed input: 1761.58 toks/s, output: 24.75 toks/s]
[2025-01-08 20:32:05,694][root][ERROR] - Processed prompts:  50%|#####     | 4/8 [00:02<00:01,  2.01it/s, est. speed input: 2018.87 toks/s, output: 40.16 toks/s]
[2025-01-08 20:32:07,381][root][ERROR] - Processed prompts:  62%|######2   | 5/8 [00:04<00:02,  1.08it/s, est. speed input: 1509.90 toks/s, output: 53.64 toks/s]
[2025-01-08 20:32:08,957][root][ERROR] - Processed prompts:  75%|#######5  | 6/8 [00:05<00:02,  1.15s/it, est. speed input: 1322.76 toks/s, output: 73.98 toks/s]
[2025-01-08 20:32:08,957][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:05<00:00,  1.41it/s, est. speed input: 1786.59 toks/s, output: 144.42 toks/s]
WARNING 01-08 20:32:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:09,180][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:10,466][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.29s/it, est. speed input: 684.40 toks/s, output: 25.66 toks/s]
[2025-01-08 20:32:10,466][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.11it/s, est. speed input: 2773.26 toks/s, output: 102.63 toks/s]
WARNING 01-08 20:32:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:10,698][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:13,292][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:25,  2.59s/it, est. speed input: 605.73 toks/s, output: 10.02 toks/s]
[2025-01-08 20:32:17,385][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:06<00:03,  1.13it/s, est. speed input: 1402.40 toks/s, output: 55.04 toks/s]
[2025-01-08 20:32:17,385][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:06<00:00,  1.65it/s, est. speed input: 2199.10 toks/s, output: 174.67 toks/s]
WARNING 01-08 20:32:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:17,637][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:18,488][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1104.78 toks/s, output: 38.82 toks/s]
[2025-01-08 20:32:18,488][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1104.78 toks/s, output: 38.82 toks/s]
WARNING 01-08 20:32:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:18,713][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:20,680][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:11,  1.97s/it, est. speed input: 799.33 toks/s, output: 14.24 toks/s]
[2025-01-08 20:32:20,910][root][ERROR] - Processed prompts:  71%|#######1  | 5/7 [00:02<00:00,  2.92it/s, est. speed input: 3104.00 toks/s, output: 70.10 toks/s]
[2025-01-08 20:32:23,864][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.30it/s, est. speed input: 1882.96 toks/s, output: 107.55 toks/s]
[2025-01-08 20:32:23,864][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:05<00:00,  1.36it/s, est. speed input: 1882.96 toks/s, output: 107.55 toks/s]
WARNING 01-08 20:32:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:24,144][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:25,458][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.31s/it, est. speed input: 1291.62 toks/s, output: 21.31 toks/s]
[2025-01-08 20:32:28,362][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.42s/it, est. speed input: 1096.78 toks/s, output: 60.69 toks/s]
[2025-01-08 20:32:28,362][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.41s/it, est. speed input: 1096.78 toks/s, output: 60.69 toks/s]
WARNING 01-08 20:32:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:32:28,596][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:32:32,328][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.73s/it, est. speed input: 400.38 toks/s, output: 53.60 toks/s]
[2025-01-08 20:32:32,328][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.73s/it, est. speed input: 400.38 toks/s, output: 53.60 toks/s]
[2025-01-08 20:32:39,954][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:32:40,008][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:32:41,759][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 20:32:43,398][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:32:45,020][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.66s/it]
[2025-01-08 20:32:45,564][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:32:45,565][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 20:32:56,941][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:32:57,544][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:32:57,596][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:32:59,439][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 20:33:01,053][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:33:02,633][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 20:33:03,133][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 20:33:03,133][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 20:33:17,998][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:33:18,303][root][INFO] - Loading VLLM model.
WARNING 01-08 20:33:18 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:33:18 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:33:19 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:33:19 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:33:19,575][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:33:20,898][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:33:21,289][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:33:22,597][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:33:23,942][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:33:23,942][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:33:24 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:33:37 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:33:38 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:33:38 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:34:00 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:34:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:00,455][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:03,613][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.16s/it, est. speed input: 159.96 toks/s, output: 10.14 toks/s]
[2025-01-08 20:34:03,636][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.03it/s, est. speed input: 2540.75 toks/s, output: 162.26 toks/s]
WARNING 01-08 20:34:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:03,861][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:06,270][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.16 toks/s, output: 13.70 toks/s]
[2025-01-08 20:34:06,270][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.64it/s, est. speed input: 3827.23 toks/s, output: 219.17 toks/s]
WARNING 01-08 20:34:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:06,499][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:08,841][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.34s/it, est. speed input: 298.46 toks/s, output: 11.96 toks/s]
[2025-01-08 20:34:09,067][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:02<00:00,  7.88it/s, est. speed input: 3788.05 toks/s, output: 174.04 toks/s]
[2025-01-08 20:34:10,203][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.32it/s, est. speed input: 2815.26 toks/s, output: 149.56 toks/s]
WARNING 01-08 20:34:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:10,429][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:12,670][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.24s/it, est. speed input: 310.18 toks/s, output: 14.73 toks/s]
[2025-01-08 20:34:12,670][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.80it/s, est. speed input: 4024.51 toks/s, output: 191.41 toks/s]
WARNING 01-08 20:34:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:12,892][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:13,860][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:00<00:01,  1.03it/s, est. speed input: 777.95 toks/s, output: 27.89 toks/s]
[2025-01-08 20:34:13,931][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.89it/s, est. speed input: 2077.23 toks/s, output: 83.74 toks/s]
WARNING 01-08 20:34:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:14,148][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:15,827][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.68s/it, est. speed input: 414.08 toks/s, output: 19.66 toks/s]
[2025-01-08 20:34:15,827][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.76it/s, est. speed input: 3493.14 toks/s, output: 157.24 toks/s]
WARNING 01-08 20:34:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:16,070][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:17,862][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.79s/it, est. speed input: 562.29 toks/s, output: 15.63 toks/s]
[2025-01-08 20:34:17,958][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.24it/s, est. speed input: 4273.00 toks/s, output: 125.04 toks/s]
WARNING 01-08 20:34:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:18,178][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:20,182][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.00s/it, est. speed input: 406.19 toks/s, output: 16.47 toks/s]
[2025-01-08 20:34:20,183][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.99it/s, est. speed input: 4004.31 toks/s, output: 164.62 toks/s]
WARNING 01-08 20:34:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:20,410][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:21,897][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.49s/it, est. speed input: 678.06 toks/s, output: 19.51 toks/s]
[2025-01-08 20:34:22,284][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.99it/s, est. speed input: 2884.99 toks/s, output: 106.18 toks/s]
[2025-01-08 20:34:22,285][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.20it/s, est. speed input: 2884.99 toks/s, output: 106.18 toks/s]
WARNING 01-08 20:34:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:22,513][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:25,146][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.63s/it, est. speed input: 333.90 toks/s, output: 12.54 toks/s]
[2025-01-08 20:34:25,146][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.32it/s, est. speed input: 4640.86 toks/s, output: 175.46 toks/s]
WARNING 01-08 20:34:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:25,357][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:26,249][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 987.10 toks/s, output: 30.29 toks/s]
[2025-01-08 20:34:26,283][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.16it/s, est. speed input: 2095.14 toks/s, output: 60.48 toks/s]
WARNING 01-08 20:34:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:26,500][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:27,931][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.43s/it, est. speed input: 652.04 toks/s, output: 23.06 toks/s]
[2025-01-08 20:34:27,932][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.49it/s, est. speed input: 3234.01 toks/s, output: 115.28 toks/s]
WARNING 01-08 20:34:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:28,168][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:30,726][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:25,  2.56s/it, est. speed input: 435.49 toks/s, output: 10.55 toks/s]
[2025-01-08 20:34:31,089][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:02<00:11,  1.27s/it, est. speed input: 832.31 toks/s, output: 22.60 toks/s]
[2025-01-08 20:34:31,205][root][ERROR] - Processed prompts:  27%|##7       | 3/11 [00:03<00:05,  1.35it/s, est. speed input: 1278.12 toks/s, output: 35.90 toks/s]
[2025-01-08 20:34:32,408][root][ERROR] - Processed prompts:  36%|###6      | 4/11 [00:04<00:06,  1.08it/s, est. speed input: 1226.08 toks/s, output: 46.23 toks/s]
[2025-01-08 20:34:32,808][root][ERROR] - Processed prompts:  45%|####5     | 5/11 [00:04<00:04,  1.36it/s, est. speed input: 1404.66 toks/s, output: 64.23 toks/s]
[2025-01-08 20:34:35,249][root][ERROR] - Processed prompts:  55%|#####4    | 6/11 [00:07<00:06,  1.31s/it, est. speed input: 1106.14 toks/s, output: 70.33 toks/s]
[2025-01-08 20:34:35,249][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:07<00:00,  1.55it/s, est. speed input: 2036.73 toks/s, output: 211.55 toks/s]
WARNING 01-08 20:34:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:35,503][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:36,499][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.00it/s, est. speed input: 943.02 toks/s, output: 33.14 toks/s]
[2025-01-08 20:34:36,500][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.01it/s, est. speed input: 1825.01 toks/s, output: 66.25 toks/s]
WARNING 01-08 20:34:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:36,737][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:39,389][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:26,  2.65s/it, est. speed input: 592.31 toks/s, output: 10.18 toks/s]
[2025-01-08 20:34:39,498][root][ERROR] - Processed prompts:  64%|######3   | 7/11 [00:02<00:01,  3.41it/s, est. speed input: 3484.69 toks/s, output: 73.16 toks/s]
[2025-01-08 20:34:42,695][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  1.90it/s, est. speed input: 2552.37 toks/s, output: 119.50 toks/s]
[2025-01-08 20:34:42,696][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:05<00:00,  1.85it/s, est. speed input: 2552.37 toks/s, output: 119.50 toks/s]
WARNING 01-08 20:34:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:43,004][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:44,412][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.41s/it, est. speed input: 1030.74 toks/s, output: 20.60 toks/s]
[2025-01-08 20:34:44,706][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.11it/s, est. speed input: 2359.32 toks/s, output: 60.53 toks/s]
[2025-01-08 20:34:47,323][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.22s/it, est. speed input: 1258.60 toks/s, output: 70.15 toks/s]
[2025-01-08 20:34:47,323][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.08s/it, est. speed input: 1258.60 toks/s, output: 70.15 toks/s]
WARNING 01-08 20:34:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:34:47,555][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:34:48,591][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.04s/it, est. speed input: 1618.43 toks/s, output: 28.00 toks/s]
[2025-01-08 20:34:51,479][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  2.13s/it, est. speed input: 747.53 toks/s, output: 58.36 toks/s]
[2025-01-08 20:34:51,479][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.96s/it, est. speed input: 747.53 toks/s, output: 58.36 toks/s]
[2025-01-08 20:34:59,156][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:34:59,210][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:35:00,872][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:04,  1.66s/it]
[2025-01-08 20:35:02,506][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:35:04,080][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 20:35:04,603][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:35:04,603][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:35:16,228][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:35:16,741][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:35:16,793][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:35:18,658][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 20:35:20,229][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 20:35:21,793][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.63s/it]
[2025-01-08 20:35:22,293][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:35:22,294][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 20:35:36,784][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:35:37,081][root][INFO] - Loading VLLM model.
WARNING 01-08 20:35:37 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:35:37 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:35:37 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:35:37 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:35:38,235][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:35:39,606][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:35:40,009][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:35:41,367][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:35:42,772][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:35:42,772][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:35:43 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:35:56 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:35:57 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:35:57 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:36:18 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:36:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:18,927][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:21,855][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.93s/it, est. speed input: 172.46 toks/s, output: 10.93 toks/s]
[2025-01-08 20:36:21,880][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.42it/s, est. speed input: 2735.79 toks/s, output: 175.39 toks/s]
WARNING 01-08 20:36:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:22,100][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:24,509][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.10 toks/s, output: 13.70 toks/s]
[2025-01-08 20:36:24,510][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.64it/s, est. speed input: 3827.01 toks/s, output: 219.11 toks/s]
WARNING 01-08 20:36:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:24,733][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:27,127][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.39s/it, est. speed input: 292.02 toks/s, output: 11.70 toks/s]
[2025-01-08 20:36:28,468][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.20it/s, est. speed input: 2943.35 toks/s, output: 145.09 toks/s]
[2025-01-08 20:36:28,469][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.28it/s, est. speed input: 2943.35 toks/s, output: 145.09 toks/s]
WARNING 01-08 20:36:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:28,709][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:31,086][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.38s/it, est. speed input: 292.41 toks/s, output: 13.88 toks/s]
[2025-01-08 20:36:31,087][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.89it/s, est. speed input: 4092.70 toks/s, output: 194.33 toks/s]
WARNING 01-08 20:36:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:31,296][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:32,185][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 935.35 toks/s, output: 31.48 toks/s]
[2025-01-08 20:36:32,337][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  2.20it/s, est. speed input: 1523.20 toks/s, output: 62.46 toks/s]
[2025-01-08 20:36:32,337][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.92it/s, est. speed input: 1523.20 toks/s, output: 62.46 toks/s]
WARNING 01-08 20:36:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:32,542][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:33,484][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 737.90 toks/s, output: 35.04 toks/s]
[2025-01-08 20:36:33,484][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 1468.87 toks/s, output: 70.05 toks/s]
WARNING 01-08 20:36:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:33,708][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:36,411][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 372.53 toks/s, output: 10.36 toks/s]
[2025-01-08 20:36:36,463][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.08it/s, est. speed input: 5051.01 toks/s, output: 147.35 toks/s]
WARNING 01-08 20:36:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:36,685][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:39,207][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:32,  2.52s/it, est. speed input: 322.73 toks/s, output: 12.69 toks/s]
[2025-01-08 20:36:39,242][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4456.92 toks/s, output: 180.29 toks/s]
WARNING 01-08 20:36:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:39,454][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:40,395][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 1210.79 toks/s, output: 29.74 toks/s]
[2025-01-08 20:36:40,548][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  2.10it/s, est. speed input: 2015.01 toks/s, output: 59.43 toks/s]
[2025-01-08 20:36:40,548][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.83it/s, est. speed input: 2015.01 toks/s, output: 59.43 toks/s]
WARNING 01-08 20:36:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:40,785][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:42,873][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.09s/it, est. speed input: 421.03 toks/s, output: 15.81 toks/s]
[2025-01-08 20:36:42,874][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.79it/s, est. speed input: 4179.34 toks/s, output: 158.02 toks/s]
WARNING 01-08 20:36:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:43,116][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:44,819][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:08,  1.70s/it, est. speed input: 658.86 toks/s, output: 17.03 toks/s]
[2025-01-08 20:36:44,959][root][ERROR] - Processed prompts:  33%|###3      | 2/6 [00:01<00:03,  1.28it/s, est. speed input: 1323.60 toks/s, output: 34.73 toks/s]
[2025-01-08 20:36:45,986][root][ERROR] - Processed prompts:  67%|######6   | 4/6 [00:02<00:01,  1.63it/s, est. speed input: 1711.16 toks/s, output: 64.81 toks/s]
[2025-01-08 20:36:48,094][root][ERROR] - Processed prompts:  83%|########3 | 5/6 [00:04<00:01,  1.08s/it, est. speed input: 1250.96 toks/s, output: 77.53 toks/s]
[2025-01-08 20:36:48,095][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:04<00:00,  1.21it/s, est. speed input: 1515.39 toks/s, output: 117.70 toks/s]
WARNING 01-08 20:36:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:48,333][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:49,174][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 953.18 toks/s, output: 39.22 toks/s]
[2025-01-08 20:36:49,175][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 953.18 toks/s, output: 39.22 toks/s]
WARNING 01-08 20:36:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:49,404][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:52,237][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:31,  2.83s/it, est. speed input: 555.09 toks/s, output: 9.53 toks/s]
[2025-01-08 20:36:52,964][root][ERROR] - Processed prompts:  25%|##5       | 3/12 [00:03<00:09,  1.00s/it, est. speed input: 1252.70 toks/s, output: 30.06 toks/s]
[2025-01-08 20:36:53,396][root][ERROR] - Processed prompts:  33%|###3      | 4/12 [00:03<00:06,  1.24it/s, est. speed input: 1447.18 toks/s, output: 43.35 toks/s]
[2025-01-08 20:36:53,836][root][ERROR] - Processed prompts:  42%|####1     | 5/12 [00:04<00:04,  1.46it/s, est. speed input: 1630.24 toks/s, output: 57.55 toks/s]
[2025-01-08 20:36:56,261][root][ERROR] - Processed prompts:  50%|#####     | 6/12 [00:06<00:07,  1.24s/it, est. speed input: 1245.68 toks/s, output: 62.42 toks/s]
[2025-01-08 20:36:56,934][root][ERROR] - Processed prompts:  58%|#####8    | 7/12 [00:07<00:05,  1.06s/it, est. speed input: 1309.60 toks/s, output: 83.41 toks/s]
[2025-01-08 20:36:56,934][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:07<00:00,  1.59it/s, est. speed input: 2184.12 toks/s, output: 216.22 toks/s]
WARNING 01-08 20:36:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:57,205][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:36:59,286][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:02<00:12,  2.08s/it, est. speed input: 755.54 toks/s, output: 12.98 toks/s]
[2025-01-08 20:36:59,397][root][ERROR] - Processed prompts:  86%|########5 | 6/7 [00:02<00:00,  3.64it/s, est. speed input: 4306.84 toks/s, output: 80.78 toks/s]
[2025-01-08 20:36:59,532][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:02<00:00,  3.01it/s, est. speed input: 4685.76 toks/s, output: 93.26 toks/s]
WARNING 01-08 20:36:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:36:59,781][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:37:01,377][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 978.03 toks/s, output: 45.77 toks/s]
[2025-01-08 20:37:01,377][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:01<00:00,  1.60s/it, est. speed input: 978.03 toks/s, output: 45.77 toks/s]
[2025-01-08 20:37:09,036][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:37:09,090][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:37:10,828][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 20:37:12,494][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 20:37:14,151][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:37:14,686][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:37:14,686][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 20:37:25,938][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:37:26,408][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:37:26,460][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:37:28,292][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 20:37:29,867][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 20:37:31,415][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:37:31,911][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:37:31,912][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:37:46,820][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:37:47,187][root][INFO] - Loading VLLM model.
WARNING 01-08 20:37:47 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:37:47 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:37:48 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:37:48 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:37:48,770][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:37:50,079][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 20:37:50,463][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.31it/s]
[2025-01-08 20:37:51,755][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 20:37:53,091][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 20:37:53,092][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 20:37:53 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:38:07 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:38:07 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:38:07 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:38:28 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:38:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:29,260][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:32,459][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.20s/it, est. speed input: 157.84 toks/s, output: 10.00 toks/s]
[2025-01-08 20:38:32,494][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.95it/s, est. speed input: 2498.64 toks/s, output: 162.35 toks/s]
WARNING 01-08 20:38:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:32,724][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:35,136][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.19 toks/s, output: 13.68 toks/s]
[2025-01-08 20:38:35,137][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3824.75 toks/s, output: 218.82 toks/s]
WARNING 01-08 20:38:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:35,370][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:37,792][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 288.63 toks/s, output: 11.56 toks/s]
[2025-01-08 20:38:39,085][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 3010.92 toks/s, output: 145.11 toks/s]
[2025-01-08 20:38:39,085][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.31it/s, est. speed input: 3010.92 toks/s, output: 145.11 toks/s]
WARNING 01-08 20:38:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:39,307][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:41,789][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 280.42 toks/s, output: 13.30 toks/s]
[2025-01-08 20:38:41,790][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.04it/s, est. speed input: 4204.11 toks/s, output: 199.39 toks/s]
WARNING 01-08 20:38:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:42,005][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:42,783][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 1065.05 toks/s, output: 36.02 toks/s]
[2025-01-08 20:38:42,783][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 1065.05 toks/s, output: 36.02 toks/s]
WARNING 01-08 20:38:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:42,999][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:43,822][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 838.10 toks/s, output: 40.08 toks/s]
[2025-01-08 20:38:43,822][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 838.10 toks/s, output: 40.08 toks/s]
WARNING 01-08 20:38:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:44,061][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:46,863][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.80s/it, est. speed input: 359.43 toks/s, output: 9.99 toks/s]
[2025-01-08 20:38:46,917][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.25it/s, est. speed input: 5295.06 toks/s, output: 152.34 toks/s]
WARNING 01-08 20:38:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:47,153][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:49,819][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.67s/it, est. speed input: 305.80 toks/s, output: 12.38 toks/s]
[2025-01-08 20:38:49,819][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.63it/s, est. speed input: 4584.76 toks/s, output: 185.69 toks/s]
WARNING 01-08 20:38:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:50,037][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:50,827][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1430.39 toks/s, output: 35.44 toks/s]
[2025-01-08 20:38:50,828][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1430.39 toks/s, output: 35.44 toks/s]
WARNING 01-08 20:38:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:51,061][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:53,150][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.09s/it, est. speed input: 420.72 toks/s, output: 15.79 toks/s]
[2025-01-08 20:38:53,151][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.78it/s, est. speed input: 4175.86 toks/s, output: 157.90 toks/s]
WARNING 01-08 20:38:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:53,389][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:38:56,969][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:03<00:17,  3.58s/it, est. speed input: 367.91 toks/s, output: 28.77 toks/s]
[2025-01-08 20:38:59,234][root][ERROR] - Processed prompts:  33%|###3      | 2/6 [00:05<00:11,  2.81s/it, est. speed input: 450.64 toks/s, output: 51.84 toks/s]
[2025-01-08 20:38:59,235][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:05<00:00,  1.03it/s, est. speed input: 1351.81 toks/s, output: 188.69 toks/s]
WARNING 01-08 20:38:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:38:59,537][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:39:02,840][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:42,  3.30s/it, est. speed input: 475.60 toks/s, output: 8.78 toks/s]
[2025-01-08 20:39:03,625][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:04<00:05,  1.52it/s, est. speed input: 1861.18 toks/s, output: 41.83 toks/s]
[2025-01-08 20:39:04,028][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:04,  1.67it/s, est. speed input: 1987.34 toks/s, output: 53.43 toks/s]
[2025-01-08 20:39:07,631][root][ERROR] - Processed prompts:  50%|#####     | 7/14 [00:08<00:09,  1.35s/it, est. speed input: 1265.58 toks/s, output: 54.36 toks/s]
[2025-01-08 20:39:07,631][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:08<00:00,  1.73it/s, est. speed input: 2419.21 toks/s, output: 227.33 toks/s]
WARNING 01-08 20:39:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:39:07,910][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:39:10,374][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:19,  2.46s/it, est. speed input: 638.23 toks/s, output: 10.96 toks/s]
[2025-01-08 20:39:13,322][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  1.86it/s, est. speed input: 2605.75 toks/s, output: 79.47 toks/s]
[2025-01-08 20:39:13,322][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:05<00:00,  1.66it/s, est. speed input: 2605.75 toks/s, output: 79.47 toks/s]
[2025-01-08 20:39:21,125][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:39:21,178][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:39:22,985][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 20:39:24,708][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 20:39:26,349][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 20:39:26,901][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.25s/it]
[2025-01-08 20:39:26,902][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 20:39:38,292][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:39:38,877][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:39:38,929][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:39:40,801][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 20:39:42,475][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 20:39:44,133][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 20:39:44,668][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.25s/it]
[2025-01-08 20:39:44,668][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 20:39:59,813][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:40:00,147][root][INFO] - Loading VLLM model.
WARNING 01-08 20:40:00 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:40:00 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:40:00 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:40:00 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:40:01,134][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:40:02,510][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 20:40:02,917][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 20:40:04,284][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:40:05,700][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:40:05,700][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:40:05 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:40:19 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:40:20 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:40:20 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:40:41 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:40:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:42,287][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:45,463][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.18s/it, est. speed input: 159.05 toks/s, output: 10.08 toks/s]
[2025-01-08 20:40:45,488][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.00it/s, est. speed input: 2524.71 toks/s, output: 161.86 toks/s]
WARNING 01-08 20:40:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:45,710][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:48,122][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 238.89 toks/s, output: 13.69 toks/s]
[2025-01-08 20:40:48,122][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3823.63 toks/s, output: 218.92 toks/s]
WARNING 01-08 20:40:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:48,344][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:50,737][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.39s/it, est. speed input: 292.19 toks/s, output: 11.70 toks/s]
[2025-01-08 20:40:52,082][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.20it/s, est. speed input: 2941.85 toks/s, output: 145.55 toks/s]
[2025-01-08 20:40:52,082][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.28it/s, est. speed input: 2941.85 toks/s, output: 145.55 toks/s]
WARNING 01-08 20:40:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:52,304][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:54,678][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 292.71 toks/s, output: 13.90 toks/s]
[2025-01-08 20:40:54,679][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.89it/s, est. speed input: 4096.91 toks/s, output: 194.53 toks/s]
WARNING 01-08 20:40:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:54,889][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:55,780][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.12it/s, est. speed input: 934.82 toks/s, output: 31.46 toks/s]
[2025-01-08 20:40:55,797][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.20it/s, est. speed input: 1746.65 toks/s, output: 62.81 toks/s]
WARNING 01-08 20:40:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:56,003][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:56,993][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 702.05 toks/s, output: 33.33 toks/s]
[2025-01-08 20:40:56,993][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.02it/s, est. speed input: 1403.42 toks/s, output: 66.64 toks/s]
WARNING 01-08 20:40:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:40:57,226][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:40:59,840][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.61s/it, est. speed input: 385.32 toks/s, output: 10.33 toks/s]
[2025-01-08 20:41:00,518][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  5.46it/s, est. speed input: 4228.23 toks/s, output: 133.66 toks/s]
[2025-01-08 20:41:00,518][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:03<00:00,  4.25it/s, est. speed input: 4228.23 toks/s, output: 133.66 toks/s]
WARNING 01-08 20:41:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:00,767][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:03,181][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.25 toks/s, output: 13.67 toks/s]
[2025-01-08 20:41:03,182][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.38it/s, est. speed input: 4384.92 toks/s, output: 177.68 toks/s]
WARNING 01-08 20:41:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:03,389][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:04,472][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.08s/it, est. speed input: 1052.43 toks/s, output: 25.85 toks/s]
[2025-01-08 20:41:04,490][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.73it/s, est. speed input: 2814.22 toks/s, output: 77.21 toks/s]
WARNING 01-08 20:41:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:04,712][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:06,090][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.38s/it, est. speed input: 590.82 toks/s, output: 23.95 toks/s]
[2025-01-08 20:41:06,090][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.63it/s, est. speed input: 3040.27 toks/s, output: 119.72 toks/s]
WARNING 01-08 20:41:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:06,316][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:09,139][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:28,  2.82s/it, est. speed input: 466.64 toks/s, output: 12.40 toks/s]
[2025-01-08 20:41:14,132][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:07<00:36,  4.10s/it, est. speed input: 336.65 toks/s, output: 30.07 toks/s]
[2025-01-08 20:41:14,132][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:07<00:00,  1.41it/s, est. speed input: 1858.19 toks/s, output: 260.37 toks/s]
WARNING 01-08 20:41:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:14,388][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:17,947][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:49,  3.56s/it, est. speed input: 442.28 toks/s, output: 7.59 toks/s]
[2025-01-08 20:41:18,049][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:03<00:02,  2.97it/s, est. speed input: 3444.60 toks/s, output: 63.11 toks/s]
[2025-01-08 20:41:22,038][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:07<00:01,  1.79it/s, est. speed input: 2575.99 toks/s, output: 116.86 toks/s]
[2025-01-08 20:41:22,039][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  1.96it/s, est. speed input: 2927.50 toks/s, output: 169.15 toks/s]
WARNING 01-08 20:41:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:41:22,338][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:41:23,860][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.52s/it, est. speed input: 1033.26 toks/s, output: 19.06 toks/s]
[2025-01-08 20:41:26,757][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.07s/it, est. speed input: 1466.02 toks/s, output: 65.19 toks/s]
[2025-01-08 20:41:26,757][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.10s/it, est. speed input: 1466.02 toks/s, output: 65.19 toks/s]
[2025-01-08 20:41:34,768][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:41:34,822][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:41:36,515][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 20:41:38,133][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:41:39,737][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:41:40,264][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:41:40,264][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:41:51,310][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:41:51,791][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:41:51,843][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:41:53,722][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 20:41:55,412][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 20:41:57,020][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:41:57,527][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:41:57,528][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 20:42:12,845][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:42:13,184][root][INFO] - Loading VLLM model.
WARNING 01-08 20:42:13 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:42:13 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:42:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:42:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:42:14,084][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:42:15,452][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:42:15,853][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:42:17,212][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 20:42:18,618][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 20:42:18,619][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 20:42:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:42:32 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:42:33 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:42:33 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:42:54 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:42:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:42:54,727][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:42:57,828][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.10s/it, est. speed input: 162.88 toks/s, output: 10.32 toks/s]
[2025-01-08 20:42:57,861][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.11it/s, est. speed input: 2578.35 toks/s, output: 167.21 toks/s]
WARNING 01-08 20:42:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:42:58,086][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:00,524][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.44s/it, est. speed input: 236.73 toks/s, output: 13.54 toks/s]
[2025-01-08 20:43:00,524][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.56it/s, est. speed input: 3784.97 toks/s, output: 216.56 toks/s]
WARNING 01-08 20:43:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:00,758][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:03,183][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.43s/it, est. speed input: 288.22 toks/s, output: 11.55 toks/s]
[2025-01-08 20:43:03,239][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.45it/s, est. speed input: 4507.14 toks/s, output: 187.39 toks/s]
WARNING 01-08 20:43:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:03,466][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:06,067][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.60s/it, est. speed input: 267.59 toks/s, output: 12.69 toks/s]
[2025-01-08 20:43:06,067][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.15it/s, est. speed input: 4278.93 toks/s, output: 202.95 toks/s]
WARNING 01-08 20:43:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:06,272][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:07,156][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 861.62 toks/s, output: 37.36 toks/s]
[2025-01-08 20:43:07,156][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.13it/s, est. speed input: 861.62 toks/s, output: 37.36 toks/s]
WARNING 01-08 20:43:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:07,384][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:10,200][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.82s/it, est. speed input: 357.60 toks/s, output: 9.94 toks/s]
[2025-01-08 20:43:10,258][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.22it/s, est. speed input: 5261.41 toks/s, output: 152.06 toks/s]
WARNING 01-08 20:43:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:10,484][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:13,035][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 319.49 toks/s, output: 12.94 toks/s]
[2025-01-08 20:43:13,036][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.49it/s, est. speed input: 4470.24 toks/s, output: 181.07 toks/s]
WARNING 01-08 20:43:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:13,242][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:14,191][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 1062.11 toks/s, output: 30.56 toks/s]
[2025-01-08 20:43:14,209][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.07it/s, est. speed input: 2143.70 toks/s, output: 61.04 toks/s]
WARNING 01-08 20:43:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:14,421][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:16,113][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:10,  1.69s/it, est. speed input: 520.44 toks/s, output: 19.52 toks/s]
[2025-01-08 20:43:16,113][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.14it/s, est. speed input: 3600.01 toks/s, output: 136.57 toks/s]
WARNING 01-08 20:43:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:16,334][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:23,518][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:07<00:57,  7.18s/it, est. speed input: 183.34 toks/s, output: 27.84 toks/s]
[2025-01-08 20:43:23,518][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:07<00:00,  1.25it/s, est. speed input: 1649.92 toks/s, output: 250.56 toks/s]
WARNING 01-08 20:43:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:23,795][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:26,691][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.90s/it, est. speed input: 454.82 toks/s, output: 2.07 toks/s]
[2025-01-08 20:43:27,479][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:23,  1.66s/it, est. speed input: 784.59 toks/s, output: 8.96 toks/s]
[2025-01-08 20:43:31,538][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:07<00:02,  1.86it/s, est. speed input: 2345.52 toks/s, output: 63.93 toks/s]
[2025-01-08 20:43:31,539][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.07it/s, est. speed input: 3025.86 toks/s, output: 167.24 toks/s]
WARNING 01-08 20:43:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:43:31,839][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:43:33,734][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:09,  1.90s/it, est. speed input: 829.00 toks/s, output: 15.30 toks/s]
[2025-01-08 20:43:33,734][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.17it/s, est. speed input: 4878.28 toks/s, output: 91.79 toks/s]
[2025-01-08 20:43:41,702][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:43:41,755][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:43:43,500][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 20:43:45,202][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:43:46,827][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:43:47,369][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:43:47,370][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 20:43:58,422][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:43:59,003][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:43:59,055][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:44:00,886][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 20:44:02,507][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:44:04,050][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:44:04,551][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:44:04,551][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:44:19,839][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:44:20,183][root][INFO] - Loading VLLM model.
WARNING 01-08 20:44:20 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:44:20 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:44:20 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:44:20 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:44:21,083][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:44:22,455][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:44:22,860][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.24it/s]
[2025-01-08 20:44:24,221][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:44:25,647][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:44:25,647][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:44:25 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:44:39 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:44:40 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:44:40 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:45:01 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:45:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:01,778][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:04,955][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.18s/it, est. speed input: 158.95 toks/s, output: 10.07 toks/s]
[2025-01-08 20:45:04,991][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.98it/s, est. speed input: 2514.76 toks/s, output: 163.71 toks/s]
WARNING 01-08 20:45:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:05,218][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:07,718][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 230.81 toks/s, output: 13.20 toks/s]
[2025-01-08 20:45:07,719][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.40it/s, est. speed input: 3691.12 toks/s, output: 211.15 toks/s]
WARNING 01-08 20:45:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:07,953][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:10,339][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.39s/it, est. speed input: 293.02 toks/s, output: 11.32 toks/s]
[2025-01-08 20:45:10,435][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.45it/s, est. speed input: 4507.30 toks/s, output: 187.80 toks/s]
WARNING 01-08 20:45:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:10,681][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:13,055][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 293.21 toks/s, output: 13.90 toks/s]
[2025-01-08 20:45:13,055][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.90it/s, est. speed input: 4103.39 toks/s, output: 194.58 toks/s]
WARNING 01-08 20:45:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:13,266][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:14,168][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 865.11 toks/s, output: 32.16 toks/s]
[2025-01-08 20:45:14,202][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.14it/s, est. speed input: 1637.91 toks/s, output: 64.11 toks/s]
WARNING 01-08 20:45:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:14,421][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:15,362][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 739.16 toks/s, output: 35.10 toks/s]
[2025-01-08 20:45:15,362][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1478.68 toks/s, output: 70.16 toks/s]
WARNING 01-08 20:45:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:15,592][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:18,295][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 372.99 toks/s, output: 10.73 toks/s]
[2025-01-08 20:45:18,355][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.07it/s, est. speed input: 5109.41 toks/s, output: 149.85 toks/s]
WARNING 01-08 20:45:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:18,581][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:21,131][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 319.66 toks/s, output: 12.94 toks/s]
[2025-01-08 20:45:21,132][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.49it/s, est. speed input: 4473.76 toks/s, output: 181.16 toks/s]
WARNING 01-08 20:45:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:21,341][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:22,309][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.03it/s, est. speed input: 1125.04 toks/s, output: 29.96 toks/s]
[2025-01-08 20:45:22,344][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.99it/s, est. speed input: 2147.65 toks/s, output: 59.85 toks/s]
WARNING 01-08 20:45:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:22,559][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:24,100][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.54s/it, est. speed input: 529.08 toks/s, output: 21.42 toks/s]
[2025-01-08 20:45:24,100][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.89it/s, est. speed input: 3341.56 toks/s, output: 128.50 toks/s]
WARNING 01-08 20:45:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:24,329][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:31,952][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:07<01:08,  7.62s/it, est. speed input: 173.05 toks/s, output: 26.24 toks/s]
[2025-01-08 20:45:31,952][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:07<00:00,  1.31it/s, est. speed input: 1729.02 toks/s, output: 262.37 toks/s]
WARNING 01-08 20:45:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:32,205][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:35,951][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:56,  3.75s/it, est. speed input: 419.95 toks/s, output: 7.21 toks/s]
[2025-01-08 20:45:36,060][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:04,  2.09it/s, est. speed input: 2448.19 toks/s, output: 44.89 toks/s]
[2025-01-08 20:45:36,835][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:04<00:02,  2.60it/s, est. speed input: 3014.68 toks/s, output: 63.29 toks/s]
[2025-01-08 20:45:40,478][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:08<00:04,  1.25it/s, est. speed input: 2036.58 toks/s, output: 71.80 toks/s]
[2025-01-08 20:45:40,479][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.93it/s, est. speed input: 2873.76 toks/s, output: 192.67 toks/s]
WARNING 01-08 20:45:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:45:40,805][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:45:42,507][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:06,  1.70s/it, est. speed input: 923.55 toks/s, output: 17.04 toks/s]
[2025-01-08 20:45:42,527][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  2.90it/s, est. speed input: 4547.74 toks/s, output: 85.39 toks/s]
[2025-01-08 20:45:50,452][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:45:50,505][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:45:52,215][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.71s/it]
[2025-01-08 20:45:53,851][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 20:45:55,427][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:45:55,951][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:45:55,952][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:46:07,131][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:46:07,689][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:46:07,741][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:46:09,620][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 20:46:11,263][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 20:46:12,886][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:46:13,391][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:46:13,392][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:46:28,857][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:46:29,165][root][INFO] - Loading VLLM model.
WARNING 01-08 20:46:29 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:46:29 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:46:29 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:46:30 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:46:30,330][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:46:31,652][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:46:32,042][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:46:33,357][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:46:34,708][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:46:34,708][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:46:35 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:46:48 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:46:49 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:46:49 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:47:10 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:47:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:10,845][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:13,942][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.10s/it, est. speed input: 163.08 toks/s, output: 10.33 toks/s]
[2025-01-08 20:47:13,969][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.12it/s, est. speed input: 2586.73 toks/s, output: 166.15 toks/s]
WARNING 01-08 20:47:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:14,205][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:16,616][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 238.92 toks/s, output: 13.69 toks/s]
[2025-01-08 20:47:16,617][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3824.61 toks/s, output: 218.95 toks/s]
WARNING 01-08 20:47:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:16,839][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:19,298][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 284.29 toks/s, output: 11.79 toks/s]
[2025-01-08 20:47:19,319][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.45it/s, est. speed input: 4509.92 toks/s, output: 188.32 toks/s]
WARNING 01-08 20:47:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:19,540][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:22,135][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.60s/it, est. speed input: 267.82 toks/s, output: 12.72 toks/s]
[2025-01-08 20:47:22,135][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.16it/s, est. speed input: 4286.86 toks/s, output: 203.42 toks/s]
WARNING 01-08 20:47:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:22,386][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:25,388][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.00s/it, est. speed input: 335.80 toks/s, output: 9.66 toks/s]
[2025-01-08 20:47:25,430][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.26it/s, est. speed input: 5300.86 toks/s, output: 154.45 toks/s]
WARNING 01-08 20:47:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:25,658][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:28,362][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.70s/it, est. speed input: 301.13 toks/s, output: 12.21 toks/s]
[2025-01-08 20:47:28,362][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.55it/s, est. speed input: 4518.53 toks/s, output: 183.08 toks/s]
WARNING 01-08 20:47:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:28,566][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:29,365][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1331.81 toks/s, output: 36.30 toks/s]
[2025-01-08 20:47:29,366][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1331.81 toks/s, output: 36.30 toks/s]
WARNING 01-08 20:47:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:29,583][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:30,564][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.02it/s, est. speed input: 896.81 toks/s, output: 33.63 toks/s]
[2025-01-08 20:47:30,565][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.04it/s, est. speed input: 1725.65 toks/s, output: 67.23 toks/s]
WARNING 01-08 20:47:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:30,797][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:32,993][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:28,  2.20s/it, est. speed input: 600.59 toks/s, output: 0.91 toks/s]
[2025-01-08 20:47:36,863][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:06<00:38,  3.18s/it, est. speed input: 434.60 toks/s, output: 19.12 toks/s]
[2025-01-08 20:47:39,109][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:08<00:18,  1.89s/it, est. speed input: 634.01 toks/s, output: 50.05 toks/s]
[2025-01-08 20:47:39,595][root][ERROR] - Processed prompts:  36%|###5      | 5/14 [00:08<00:13,  1.46s/it, est. speed input: 748.91 toks/s, output: 70.02 toks/s]
[2025-01-08 20:47:39,596][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:08<00:00,  1.59it/s, est. speed input: 2096.38 toks/s, output: 274.59 toks/s]
WARNING 01-08 20:47:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:39,898][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:43,392][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:48,  3.49s/it, est. speed input: 447.99 toks/s, output: 6.87 toks/s]
[2025-01-08 20:47:43,538][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:03<00:19,  1.52s/it, est. speed input: 862.37 toks/s, output: 14.29 toks/s]
[2025-01-08 20:47:44,150][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:04<00:00,  5.02it/s, est. speed input: 4666.08 toks/s, output: 94.31 toks/s]
[2025-01-08 20:47:46,643][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.51it/s, est. speed input: 3378.64 toks/s, output: 105.42 toks/s]
[2025-01-08 20:47:46,643][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:06<00:00,  2.22it/s, est. speed input: 3378.64 toks/s, output: 105.42 toks/s]
WARNING 01-08 20:47:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:47:46,944][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:47:47,744][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1758.50 toks/s, output: 33.77 toks/s]
[2025-01-08 20:47:47,744][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 1758.50 toks/s, output: 33.77 toks/s]
[2025-01-08 20:47:55,925][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:47:55,979][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:47:57,675][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 20:47:59,295][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:48:00,872][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:48:01,396][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:48:01,397][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:48:12,417][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:48:12,940][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:48:12,992][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:48:14,836][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 20:48:16,415][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 20:48:17,971][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:48:18,468][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:48:18,468][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:48:33,659][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:48:33,988][root][INFO] - Loading VLLM model.
WARNING 01-08 20:48:34 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:48:34 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:48:34 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:48:34 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:48:34,983][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:48:36,304][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:48:36,701][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:48:38,011][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:48:39,356][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:48:39,357][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:48:39 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:48:53 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:48:54 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:48:54 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:49:15 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:49:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:15,974][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:18,582][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 193.60 toks/s, output: 12.27 toks/s]
[2025-01-08 20:49:18,618][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.05it/s, est. speed input: 3055.47 toks/s, output: 198.91 toks/s]
WARNING 01-08 20:49:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:18,866][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:21,273][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.73 toks/s, output: 13.71 toks/s]
[2025-01-08 20:49:21,274][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.65it/s, est. speed input: 3833.70 toks/s, output: 219.31 toks/s]
WARNING 01-08 20:49:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:21,508][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:23,896][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.39s/it, est. speed input: 292.71 toks/s, output: 11.31 toks/s]
[2025-01-08 20:49:23,992][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.44it/s, est. speed input: 4502.99 toks/s, output: 187.62 toks/s]
WARNING 01-08 20:49:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:24,215][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:26,588][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.37s/it, est. speed input: 293.26 toks/s, output: 13.90 toks/s]
[2025-01-08 20:49:26,589][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.90it/s, est. speed input: 4104.33 toks/s, output: 194.62 toks/s]
WARNING 01-08 20:49:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:26,794][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:27,695][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.11it/s, est. speed input: 865.86 toks/s, output: 32.19 toks/s]
[2025-01-08 20:49:27,729][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.14it/s, est. speed input: 1639.25 toks/s, output: 64.16 toks/s]
WARNING 01-08 20:49:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:27,932][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:28,870][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.07it/s, est. speed input: 740.74 toks/s, output: 35.17 toks/s]
[2025-01-08 20:49:28,870][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.13it/s, est. speed input: 1481.95 toks/s, output: 70.31 toks/s]
WARNING 01-08 20:49:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:29,096][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:31,799][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.70s/it, est. speed input: 372.92 toks/s, output: 10.73 toks/s]
[2025-01-08 20:49:31,860][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.07it/s, est. speed input: 5108.10 toks/s, output: 149.81 toks/s]
WARNING 01-08 20:49:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:32,084][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:34,497][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.77 toks/s, output: 13.68 toks/s]
[2025-01-08 20:49:34,497][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.39it/s, est. speed input: 4389.54 toks/s, output: 177.75 toks/s]
WARNING 01-08 20:49:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:34,707][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:35,833][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.13s/it, est. speed input: 967.46 toks/s, output: 25.76 toks/s]
[2025-01-08 20:49:35,884][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.55it/s, est. speed input: 2731.77 toks/s, output: 76.47 toks/s]
WARNING 01-08 20:49:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:36,092][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:37,190][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 741.40 toks/s, output: 30.06 toks/s]
[2025-01-08 20:49:37,190][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.73it/s, est. speed input: 2225.19 toks/s, output: 90.14 toks/s]
WARNING 01-08 20:49:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:37,422][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:40,883][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:41,  3.46s/it, est. speed input: 381.67 toks/s, output: 12.42 toks/s]
[2025-01-08 20:49:42,223][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:04<00:24,  2.21s/it, est. speed input: 549.43 toks/s, output: 26.24 toks/s]
[2025-01-08 20:49:44,912][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:07<00:24,  2.43s/it, est. speed input: 528.30 toks/s, output: 39.12 toks/s]
[2025-01-08 20:49:45,913][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:08<00:16,  1.87s/it, est. speed input: 621.34 toks/s, output: 58.06 toks/s]
[2025-01-08 20:49:45,914][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:08<00:00,  1.53it/s, est. speed input: 2017.61 toks/s, output: 270.03 toks/s]
WARNING 01-08 20:49:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:46,214][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:49,690][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:45,  3.48s/it, est. speed input: 453.10 toks/s, output: 8.06 toks/s]
[2025-01-08 20:49:49,795][root][ERROR] - Processed prompts:  79%|#######8  | 11/14 [00:03<00:00,  4.22it/s, est. speed input: 4764.60 toks/s, output: 89.92 toks/s]
[2025-01-08 20:49:52,972][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.07it/s, est. speed input: 3168.25 toks/s, output: 118.23 toks/s]
WARNING 01-08 20:49:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:49:53,260][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:49:54,549][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.29s/it, est. speed input: 1282.44 toks/s, output: 22.50 toks/s]
[2025-01-08 20:49:54,550][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.33it/s, est. speed input: 3655.27 toks/s, output: 67.47 toks/s]
[2025-01-08 20:50:02,509][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:50:02,566][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:50:04,251][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 20:50:05,881][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:50:07,496][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 20:50:08,026][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 20:50:08,027][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:50:18,913][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:50:19,427][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:50:19,480][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:50:21,320][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 20:50:22,919][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 20:50:24,473][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:50:24,972][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 20:50:24,972][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 20:50:40,220][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:50:40,531][root][INFO] - Loading VLLM model.
WARNING 01-08 20:50:40 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:50:40 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:50:41 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:50:41 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:50:41,547][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:50:42,884][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.34s/it]
[2025-01-08 20:50:43,276][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.28it/s]
[2025-01-08 20:50:44,586][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:50:45,933][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:50:45,933][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 20:50:46 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:50:59 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:51:00 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:51:00 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:51:21 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 20:51:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:22,103][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:25,216][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:46,  3.11s/it, est. speed input: 162.26 toks/s, output: 10.28 toks/s]
[2025-01-08 20:51:25,246][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.09it/s, est. speed input: 2571.38 toks/s, output: 166.12 toks/s]
WARNING 01-08 20:51:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:25,467][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:27,908][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.44s/it, est. speed input: 236.44 toks/s, output: 13.52 toks/s]
[2025-01-08 20:51:27,908][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.55it/s, est. speed input: 3779.60 toks/s, output: 216.30 toks/s]
WARNING 01-08 20:51:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:28,132][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:30,515][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.38s/it, est. speed input: 293.32 toks/s, output: 11.33 toks/s]
[2025-01-08 20:51:30,622][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:02<00:05,  2.08it/s, est. speed input: 1123.03 toks/s, output: 45.79 toks/s]
[2025-01-08 20:51:33,478][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.56it/s, est. speed input: 2092.09 toks/s, output: 121.03 toks/s]
[2025-01-08 20:51:33,478][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.99it/s, est. speed input: 2092.09 toks/s, output: 121.03 toks/s]
WARNING 01-08 20:51:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:33,702][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:35,948][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:26,  2.25s/it, est. speed input: 309.50 toks/s, output: 14.70 toks/s]
[2025-01-08 20:51:35,949][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.79it/s, est. speed input: 4025.53 toks/s, output: 190.99 toks/s]
WARNING 01-08 20:51:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:36,172][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:37,181][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.01s/it, est. speed input: 773.44 toks/s, output: 26.77 toks/s]
[2025-01-08 20:51:40,085][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.34s/it, est. speed input: 643.38 toks/s, output: 65.44 toks/s]
[2025-01-08 20:51:40,085][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:03<00:00,  1.30s/it, est. speed input: 643.38 toks/s, output: 65.44 toks/s]
WARNING 01-08 20:51:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:40,306][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:41,365][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.06s/it, est. speed input: 651.53 toks/s, output: 31.16 toks/s]
[2025-01-08 20:51:41,366][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.83it/s, est. speed input: 1959.29 toks/s, output: 93.43 toks/s]
WARNING 01-08 20:51:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:41,619][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:44,174][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:30,  2.55s/it, est. speed input: 394.60 toks/s, output: 11.35 toks/s]
[2025-01-08 20:51:44,262][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  4.92it/s, est. speed input: 4964.44 toks/s, output: 149.09 toks/s]
WARNING 01-08 20:51:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:44,483][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:46,803][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.32s/it, est. speed input: 351.02 toks/s, output: 14.23 toks/s]
[2025-01-08 20:51:46,803][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.17it/s, est. speed input: 4214.12 toks/s, output: 170.72 toks/s]
WARNING 01-08 20:51:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:47,026][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:48,307][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.28s/it, est. speed input: 987.93 toks/s, output: 21.09 toks/s]
[2025-01-08 20:51:48,717][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  2.07it/s, est. speed input: 2017.20 toks/s, output: 62.70 toks/s]
[2025-01-08 20:51:51,264][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.20s/it, est. speed input: 1101.33 toks/s, output: 72.21 toks/s]
[2025-01-08 20:51:51,264][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.06s/it, est. speed input: 1101.33 toks/s, output: 72.21 toks/s]
WARNING 01-08 20:51:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:51,469][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:52,306][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 972.90 toks/s, output: 39.44 toks/s]
[2025-01-08 20:51:52,306][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 972.90 toks/s, output: 39.44 toks/s]
WARNING 01-08 20:51:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:51:52,538][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:51:55,788][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:45,  3.25s/it, est. speed input: 364.03 toks/s, output: 8.00 toks/s]
[2025-01-08 20:51:56,067][root][ERROR] - Processed prompts:  20%|##        | 3/15 [00:03<00:11,  1.06it/s, est. speed input: 1138.18 toks/s, output: 24.66 toks/s]
[2025-01-08 20:52:01,640][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:09<00:28,  2.55s/it, est. speed input: 586.13 toks/s, output: 31.53 toks/s]
[2025-01-08 20:52:01,641][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.65it/s, est. speed input: 2183.66 toks/s, output: 273.22 toks/s]
WARNING 01-08 20:52:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:52:01,852][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:52:02,949][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 732.11 toks/s, output: 30.09 toks/s]
[2025-01-08 20:52:02,950][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.73it/s, est. speed input: 2200.97 toks/s, output: 90.23 toks/s]
WARNING 01-08 20:52:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:52:03,192][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:52:06,541][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:03<00:40,  3.35s/it, est. speed input: 469.66 toks/s, output: 8.66 toks/s]
[2025-01-08 20:52:06,642][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:03<00:00,  3.97it/s, est. speed input: 4565.91 toks/s, output: 87.24 toks/s]
[2025-01-08 20:52:10,059][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:06<00:00,  1.89it/s, est. speed input: 2928.13 toks/s, output: 131.20 toks/s]
WARNING 01-08 20:52:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:52:10,402][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:52:15,749][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:05<00:16,  5.35s/it, est. speed input: 339.47 toks/s, output: 37.41 toks/s]
[2025-01-08 20:52:15,749][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:05<00:00,  1.34s/it, est. speed input: 1262.58 toks/s, output: 149.62 toks/s]
WARNING 01-08 20:52:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:52:15,989][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:52:17,106][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.12s/it, est. speed input: 1852.32 toks/s, output: 13.43 toks/s]
[2025-01-08 20:52:17,309][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:01<00:00,  1.73it/s, est. speed input: 2884.90 toks/s, output: 31.07 toks/s]
[2025-01-08 20:52:20,251][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.66s/it, est. speed input: 1380.86 toks/s, output: 56.55 toks/s]
[2025-01-08 20:52:20,252][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.42s/it, est. speed input: 1380.86 toks/s, output: 56.55 toks/s]
[2025-01-08 20:52:28,324][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:52:28,378][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:52:30,047][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 20:52:31,661][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 20:52:33,253][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 20:52:33,780][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:52:33,780][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 20:52:44,764][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:52:45,275][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:52:45,327][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:52:47,192][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 20:52:48,804][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:52:50,351][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 20:52:50,851][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 20:52:50,851][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 20:53:07,086][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:53:07,422][root][INFO] - Loading VLLM model.
WARNING 01-08 20:53:07 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:53:07 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:53:08 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:53:08 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:53:08,343][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:53:09,718][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 20:53:10,118][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 20:53:11,478][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 20:53:12,893][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 20:53:12,893][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 20:53:13 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:53:26 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:53:27 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:53:27 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:53:49 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:53:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:53:49,424][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:53:52,465][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.04s/it, est. speed input: 166.07 toks/s, output: 10.52 toks/s]
[2025-01-08 20:53:52,490][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.22it/s, est. speed input: 2635.13 toks/s, output: 168.93 toks/s]
WARNING 01-08 20:53:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:53:52,751][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:53:55,160][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.13 toks/s, output: 13.70 toks/s]
[2025-01-08 20:53:55,161][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.64it/s, est. speed input: 3827.62 toks/s, output: 219.15 toks/s]
WARNING 01-08 20:53:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:53:55,388][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:53:57,817][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.43s/it, est. speed input: 209.97 toks/s, output: 11.94 toks/s]
[2025-01-08 20:53:59,106][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 2957.01 toks/s, output: 149.26 toks/s]
[2025-01-08 20:53:59,107][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.30it/s, est. speed input: 2957.01 toks/s, output: 149.26 toks/s]
WARNING 01-08 20:53:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:53:59,331][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:01,818][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.49s/it, est. speed input: 279.48 toks/s, output: 13.27 toks/s]
[2025-01-08 20:54:01,819][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.03it/s, est. speed input: 4191.13 toks/s, output: 199.00 toks/s]
WARNING 01-08 20:54:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:02,025][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:02,783][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1096.22 toks/s, output: 34.34 toks/s]
[2025-01-08 20:54:02,783][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1096.22 toks/s, output: 34.34 toks/s]
WARNING 01-08 20:54:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:02,987][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:03,808][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 840.46 toks/s, output: 40.25 toks/s]
[2025-01-08 20:54:03,808][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 840.46 toks/s, output: 40.25 toks/s]
WARNING 01-08 20:54:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:04,041][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:06,820][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:38,  2.78s/it, est. speed input: 363.13 toks/s, output: 10.08 toks/s]
[2025-01-08 20:54:09,738][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  3.02it/s, est. speed input: 2622.48 toks/s, output: 108.48 toks/s]
[2025-01-08 20:54:09,738][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:05<00:00,  2.63it/s, est. speed input: 2622.48 toks/s, output: 108.48 toks/s]
WARNING 01-08 20:54:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:09,966][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:12,265][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.30s/it, est. speed input: 354.08 toks/s, output: 14.35 toks/s]
[2025-01-08 20:54:12,266][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.22it/s, est. speed input: 4249.89 toks/s, output: 172.20 toks/s]
WARNING 01-08 20:54:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:12,509][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:13,830][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.32s/it, est. speed input: 810.40 toks/s, output: 22.72 toks/s]
[2025-01-08 20:54:16,695][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.02s/it, est. speed input: 1040.30 toks/s, output: 69.29 toks/s]
[2025-01-08 20:54:16,695][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.05s/it, est. speed input: 1040.30 toks/s, output: 69.29 toks/s]
WARNING 01-08 20:54:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:16,922][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:18,025][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 733.93 toks/s, output: 29.94 toks/s]
[2025-01-08 20:54:18,025][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.72it/s, est. speed input: 2210.00 toks/s, output: 89.78 toks/s]
WARNING 01-08 20:54:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:18,259][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:21,222][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:35,  2.96s/it, est. speed input: 467.47 toks/s, output: 9.45 toks/s]
[2025-01-08 20:54:26,998][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:08<00:50,  4.62s/it, est. speed input: 309.41 toks/s, output: 26.09 toks/s]
[2025-01-08 20:54:26,999][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:08<00:00,  1.49it/s, est. speed input: 1969.74 toks/s, output: 277.81 toks/s]
WARNING 01-08 20:54:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:27,213][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:28,047][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 961.91 toks/s, output: 39.58 toks/s]
[2025-01-08 20:54:28,047][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 961.91 toks/s, output: 39.58 toks/s]
WARNING 01-08 20:54:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:28,299][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:32,005][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:51,  3.71s/it, est. speed input: 424.99 toks/s, output: 7.83 toks/s]
[2025-01-08 20:54:35,519][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:07<00:00,  2.08it/s, est. speed input: 2810.45 toks/s, output: 77.29 toks/s]
[2025-01-08 20:54:35,520][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  2.08it/s, est. speed input: 3194.43 toks/s, output: 132.68 toks/s]
WARNING 01-08 20:54:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:35,853][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:37,361][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:04,  1.51s/it, est. speed input: 1088.41 toks/s, output: 18.56 toks/s]
[2025-01-08 20:54:40,882][root][ERROR] - Processed prompts:  50%|#####     | 2/4 [00:05<00:05,  2.69s/it, est. speed input: 661.89 toks/s, output: 45.33 toks/s]
[2025-01-08 20:54:40,883][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:05<00:00,  1.26s/it, est. speed input: 1315.12 toks/s, output: 124.85 toks/s]
WARNING 01-08 20:54:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:54:41,126][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:54:44,907][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.78s/it, est. speed input: 513.67 toks/s, output: 52.90 toks/s]
[2025-01-08 20:54:44,907][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.78s/it, est. speed input: 513.67 toks/s, output: 52.90 toks/s]
[2025-01-08 20:54:52,982][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:54:53,036][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:54:54,732][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 20:54:56,356][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 20:54:57,966][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 20:54:58,491][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 20:54:58,491][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 20:55:09,580][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:55:10,103][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:55:10,155][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:55:12,025][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 20:55:13,697][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 20:55:15,306][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:55:15,815][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 20:55:15,815][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:55:31,732][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:55:32,041][root][INFO] - Loading VLLM model.
WARNING 01-08 20:55:32 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:55:32 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:55:32 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:55:32 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:55:32,983][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:55:34,300][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:55:34,691][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:55:35,999][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:55:37,349][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:55:37,349][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:55:37 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:55:51 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:55:51 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:55:51 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:56:13 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:56:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:13,917][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:17,068][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.15s/it, est. speed input: 160.29 toks/s, output: 10.16 toks/s]
[2025-01-08 20:56:17,101][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.03it/s, est. speed input: 2537.70 toks/s, output: 164.57 toks/s]
WARNING 01-08 20:56:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:17,328][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:19,735][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.77 toks/s, output: 13.71 toks/s]
[2025-01-08 20:56:19,736][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.65it/s, est. speed input: 3833.70 toks/s, output: 219.35 toks/s]
WARNING 01-08 20:56:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:19,962][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:22,458][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 280.09 toks/s, output: 12.02 toks/s]
[2025-01-08 20:56:22,510][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.28it/s, est. speed input: 4390.78 toks/s, output: 189.62 toks/s]
WARNING 01-08 20:56:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:22,737][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:25,216][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 280.82 toks/s, output: 13.31 toks/s]
[2025-01-08 20:56:25,216][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.05it/s, est. speed input: 4209.54 toks/s, output: 199.67 toks/s]
WARNING 01-08 20:56:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:25,428][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:26,219][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 957.94 toks/s, output: 37.96 toks/s]
[2025-01-08 20:56:26,219][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 957.94 toks/s, output: 37.96 toks/s]
WARNING 01-08 20:56:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:26,438][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:27,256][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 851.42 toks/s, output: 40.37 toks/s]
[2025-01-08 20:56:27,257][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 851.42 toks/s, output: 40.37 toks/s]
WARNING 01-08 20:56:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:27,504][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:30,377][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:40,  2.87s/it, est. speed input: 351.27 toks/s, output: 10.44 toks/s]
[2025-01-08 20:56:30,378][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.22it/s, est. speed input: 5266.82 toks/s, output: 156.59 toks/s]
WARNING 01-08 20:56:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:30,638][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:33,188][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 319.66 toks/s, output: 12.94 toks/s]
[2025-01-08 20:56:33,188][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.49it/s, est. speed input: 4472.14 toks/s, output: 181.14 toks/s]
WARNING 01-08 20:56:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:33,411][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:34,384][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.03it/s, est. speed input: 1096.86 toks/s, output: 30.84 toks/s]
[2025-01-08 20:56:34,435][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.95it/s, est. speed input: 2080.94 toks/s, output: 61.52 toks/s]
WARNING 01-08 20:56:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:34,647][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:35,750][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.10s/it, est. speed input: 798.26 toks/s, output: 29.93 toks/s]
[2025-01-08 20:56:35,750][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.72it/s, est. speed input: 2275.98 toks/s, output: 89.77 toks/s]
WARNING 01-08 20:56:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:35,984][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:40,513][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:04<00:54,  4.53s/it, est. speed input: 291.26 toks/s, output: 16.34 toks/s]
[2025-01-08 20:56:42,999][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:07<00:36,  3.33s/it, est. speed input: 376.05 toks/s, output: 31.65 toks/s]
[2025-01-08 20:56:44,666][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:08<00:25,  2.57s/it, est. speed input: 455.79 toks/s, output: 48.61 toks/s]
[2025-01-08 20:56:44,666][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:08<00:00,  1.50it/s, est. speed input: 1974.99 toks/s, output: 278.97 toks/s]
WARNING 01-08 20:56:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:44,968][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:48,583][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:50,  3.62s/it, est. speed input: 436.23 toks/s, output: 7.47 toks/s]
[2025-01-08 20:56:48,688][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:07,  1.40it/s, est. speed input: 1694.86 toks/s, output: 30.38 toks/s]
[2025-01-08 20:56:50,078][root][ERROR] - Processed prompts:  73%|#######3  | 11/15 [00:05<00:01,  2.96it/s, est. speed input: 3342.25 toks/s, output: 75.34 toks/s]
[2025-01-08 20:56:52,540][root][ERROR] - Processed prompts:  87%|########6 | 13/15 [00:07<00:01,  1.84it/s, est. speed input: 2637.66 toks/s, output: 103.67 toks/s]
[2025-01-08 20:56:52,541][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:07<00:00,  1.98it/s, est. speed input: 3026.18 toks/s, output: 156.49 toks/s]
WARNING 01-08 20:56:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:56:52,844][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:56:54,155][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.31s/it, est. speed input: 1202.08 toks/s, output: 22.90 toks/s]
[2025-01-08 20:56:57,033][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.41s/it, est. speed input: 1121.71 toks/s, output: 63.03 toks/s]
[2025-01-08 20:56:57,033][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.40s/it, est. speed input: 1121.71 toks/s, output: 63.03 toks/s]
[2025-01-08 20:57:04,981][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:57:05,035][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:57:06,760][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 20:57:08,467][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 20:57:10,115][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 20:57:10,649][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:57:10,649][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 20:57:21,893][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:57:22,418][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:57:22,470][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:57:24,388][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.92s/it]
[2025-01-08 20:57:26,046][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 20:57:27,669][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 20:57:28,182][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:57:28,182][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 20:57:43,692][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 20:57:44,048][root][INFO] - Loading VLLM model.
WARNING 01-08 20:57:44 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 20:57:44 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 20:57:44 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 20:57:44 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 20:57:45,056][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:57:46,379][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 20:57:46,770][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 20:57:48,078][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 20:57:49,420][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 20:57:49,420][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 20:57:49 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 20:58:03 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 20:58:04 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 20:58:04 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 20:58:25 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 20:58:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:25,916][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:29,097][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.18s/it, est. speed input: 158.76 toks/s, output: 10.06 toks/s]
[2025-01-08 20:58:29,124][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.99it/s, est. speed input: 2518.84 toks/s, output: 161.79 toks/s]
WARNING 01-08 20:58:29 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:29,343][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:31,751][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.22 toks/s, output: 13.71 toks/s]
[2025-01-08 20:58:31,752][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.64it/s, est. speed input: 3829.44 toks/s, output: 219.23 toks/s]
WARNING 01-08 20:58:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:31,974][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:34,474][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 279.62 toks/s, output: 12.00 toks/s]
[2025-01-08 20:58:35,713][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 2991.85 toks/s, output: 148.20 toks/s]
[2025-01-08 20:58:35,713][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.28it/s, est. speed input: 2991.85 toks/s, output: 148.20 toks/s]
WARNING 01-08 20:58:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:35,946][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:38,430][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 279.89 toks/s, output: 13.29 toks/s]
[2025-01-08 20:58:38,430][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.04it/s, est. speed input: 4199.66 toks/s, output: 199.29 toks/s]
WARNING 01-08 20:58:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:38,682][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:42,342][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.66s/it, est. speed input: 226.25 toks/s, output: 54.65 toks/s]
[2025-01-08 20:58:42,343][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.66s/it, est. speed input: 226.25 toks/s, output: 54.65 toks/s]
WARNING 01-08 20:58:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:42,548][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:43,498][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.05it/s, est. speed input: 726.47 toks/s, output: 34.74 toks/s]
[2025-01-08 20:58:43,498][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.10it/s, est. speed input: 1527.06 toks/s, output: 69.46 toks/s]
WARNING 01-08 20:58:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:43,724][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:46,471][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.75s/it, est. speed input: 367.45 toks/s, output: 10.92 toks/s]
[2025-01-08 20:58:49,341][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.86it/s, est. speed input: 2515.36 toks/s, output: 105.24 toks/s]
[2025-01-08 20:58:49,341][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:05<00:00,  2.49it/s, est. speed input: 2515.36 toks/s, output: 105.24 toks/s]
WARNING 01-08 20:58:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:49,602][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:52,017][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:28,  2.41s/it, est. speed input: 337.08 toks/s, output: 13.67 toks/s]
[2025-01-08 20:58:52,017][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.38it/s, est. speed input: 4382.93 toks/s, output: 177.60 toks/s]
WARNING 01-08 20:58:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:52,239][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:53,422][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.18s/it, est. speed input: 1101.89 toks/s, output: 25.37 toks/s]
[2025-01-08 20:58:53,458][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.46it/s, est. speed input: 2934.02 toks/s, output: 76.30 toks/s]
WARNING 01-08 20:58:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:53,669][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:58:54,945][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.28s/it, est. speed input: 637.79 toks/s, output: 25.86 toks/s]
[2025-01-08 20:58:54,946][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.13it/s, est. speed input: 2649.77 toks/s, output: 103.39 toks/s]
WARNING 01-08 20:58:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:58:55,177][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:59:03,738][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:08<01:34,  8.56s/it, est. speed input: 154.07 toks/s, output: 23.36 toks/s]
[2025-01-08 20:59:03,739][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:08<00:00,  1.40it/s, est. speed input: 1848.87 toks/s, output: 280.33 toks/s]
WARNING 01-08 20:59:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:59:03,992][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:59:07,957][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:59,  3.96s/it, est. speed input: 397.27 toks/s, output: 7.57 toks/s]
[2025-01-08 20:59:11,939][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:07<00:02,  1.73it/s, est. speed input: 2379.66 toks/s, output: 66.70 toks/s]
[2025-01-08 20:59:11,939][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.01it/s, est. speed input: 3113.16 toks/s, output: 167.37 toks/s]
WARNING 01-08 20:59:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 20:59:12,284][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 20:59:13,623][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.34s/it, est. speed input: 1176.79 toks/s, output: 22.41 toks/s]
[2025-01-08 20:59:13,641][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.21it/s, est. speed input: 3696.84 toks/s, output: 67.11 toks/s]
[2025-01-08 20:59:21,500][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:59:21,553][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:59:23,323][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 20:59:25,013][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.72s/it]
[2025-01-08 20:59:26,655][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:59:27,203][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 20:59:27,203][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 20:59:38,385][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 20:59:38,932][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 20:59:38,985][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 20:59:40,876][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.89s/it]
[2025-01-08 20:59:42,513][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.74s/it]
[2025-01-08 20:59:44,136][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 20:59:44,659][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 20:59:44,659][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 21:00:00,378][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:00:00,784][root][INFO] - Loading VLLM model.
WARNING 01-08 21:00:00 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:00:00 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:00:01 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:00:01 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:00:02,024][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:00:03,385][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.36s/it]
[2025-01-08 21:00:03,787][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.26it/s]
[2025-01-08 21:00:05,136][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.05s/it]
[2025-01-08 21:00:06,533][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 21:00:06,534][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 21:00:06 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:00:20 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:00:21 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:00:21 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:00:43 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:00:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:43,382][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:46,658][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:49,  3.28s/it, est. speed input: 154.19 toks/s, output: 9.77 toks/s]
[2025-01-08 21:00:46,685][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.84it/s, est. speed input: 2446.68 toks/s, output: 157.16 toks/s]
WARNING 01-08 21:00:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:46,912][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:49,327][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 238.56 toks/s, output: 13.67 toks/s]
[2025-01-08 21:00:49,328][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.62it/s, est. speed input: 3818.85 toks/s, output: 218.62 toks/s]
WARNING 01-08 21:00:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:49,559][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:51,659][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:31,  2.10s/it, est. speed input: 242.90 toks/s, output: 11.43 toks/s]
[2025-01-08 21:00:51,768][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:02<00:13,  1.08it/s, est. speed input: 461.79 toks/s, output: 23.09 toks/s]
[2025-01-08 21:00:51,871][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:02<00:02,  4.30it/s, est. speed input: 1324.17 toks/s, output: 72.70 toks/s]
[2025-01-08 21:00:53,125][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  6.49it/s, est. speed input: 2660.00 toks/s, output: 152.31 toks/s]
[2025-01-08 21:00:53,125][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.49it/s, est. speed input: 2660.00 toks/s, output: 152.31 toks/s]
WARNING 01-08 21:00:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:53,344][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:55,477][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:23,  2.13s/it, est. speed input: 325.85 toks/s, output: 15.47 toks/s]
[2025-01-08 21:00:55,477][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.62it/s, est. speed input: 3894.61 toks/s, output: 185.61 toks/s]
WARNING 01-08 21:00:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:55,684][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:56,671][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:00<00:02,  1.01it/s, est. speed input: 566.72 toks/s, output: 24.33 toks/s]
[2025-01-08 21:00:56,785][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:01<00:00,  3.35it/s, est. speed input: 1784.12 toks/s, output: 72.67 toks/s]
[2025-01-08 21:00:56,802][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.58it/s, est. speed input: 2261.97 toks/s, output: 99.28 toks/s]
WARNING 01-08 21:00:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:57,023][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:00:58,586][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:01<00:09,  1.56s/it, est. speed input: 440.89 toks/s, output: 21.12 toks/s]
[2025-01-08 21:00:58,620][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:01<00:00,  4.38it/s, est. speed input: 3148.39 toks/s, output: 145.90 toks/s]
WARNING 01-08 21:00:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:00:58,837][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:00,721][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.88s/it, est. speed input: 535.45 toks/s, output: 15.39 toks/s]
[2025-01-08 21:01:00,802][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.58it/s, est. speed input: 4223.30 toks/s, output: 138.93 toks/s]
WARNING 01-08 21:01:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:01,021][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:02,786][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.77s/it, est. speed input: 461.05 toks/s, output: 18.69 toks/s]
[2025-01-08 21:01:02,787][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.53it/s, est. speed input: 3641.57 toks/s, output: 149.49 toks/s]
WARNING 01-08 21:01:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:03,016][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:04,709][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:11,  1.69s/it, est. speed input: 517.56 toks/s, output: 16.54 toks/s]
[2025-01-08 21:01:07,872][root][ERROR] - Processed prompts:  88%|########7 | 7/8 [00:04<00:00,  1.54it/s, est. speed input: 1316.44 toks/s, output: 77.63 toks/s]
[2025-01-08 21:01:07,873][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:04<00:00,  1.65it/s, est. speed input: 1444.81 toks/s, output: 118.80 toks/s]
WARNING 01-08 21:01:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:08,107][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:09,882][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:12,  1.78s/it, est. speed input: 491.77 toks/s, output: 18.59 toks/s]
[2025-01-08 21:01:09,883][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:01<00:00,  4.50it/s, est. speed input: 3801.61 toks/s, output: 148.66 toks/s]
WARNING 01-08 21:01:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:10,132][root][ERROR] - Processed prompts:   0%|          | 0/8 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:11,364][root][ERROR] - Processed prompts:  12%|#2        | 1/8 [00:01<00:08,  1.23s/it, est. speed input: 1072.16 toks/s, output: 3.25 toks/s]
[2025-01-08 21:01:11,996][root][ERROR] - Processed prompts:  25%|##5       | 2/8 [00:01<00:05,  1.14it/s, est. speed input: 1222.21 toks/s, output: 17.17 toks/s]
[2025-01-08 21:01:13,684][root][ERROR] - Processed prompts:  50%|#####     | 4/8 [00:03<00:03,  1.17it/s, est. speed input: 1256.14 toks/s, output: 45.33 toks/s]
[2025-01-08 21:01:15,870][root][ERROR] - Processed prompts:  62%|######2   | 5/8 [00:05<00:03,  1.27s/it, est. speed input: 928.70 toks/s, output: 62.92 toks/s]
[2025-01-08 21:01:15,870][root][ERROR] - Processed prompts: 100%|##########| 8/8 [00:05<00:00,  1.39it/s, est. speed input: 1517.75 toks/s, output: 167.50 toks/s]
WARNING 01-08 21:01:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:16,125][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:17,521][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.40s/it, est. speed input: 625.42 toks/s, output: 23.64 toks/s]
[2025-01-08 21:01:17,556][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.50it/s, est. speed input: 2993.23 toks/s, output: 116.76 toks/s]
WARNING 01-08 21:01:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:17,784][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:20,185][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:21,  2.40s/it, est. speed input: 578.08 toks/s, output: 11.66 toks/s]
[2025-01-08 21:01:20,430][root][ERROR] - Processed prompts:  40%|####      | 4/10 [00:02<00:03,  1.92it/s, est. speed input: 2088.58 toks/s, output: 47.24 toks/s]
[2025-01-08 21:01:24,487][root][ERROR] - Processed prompts:  50%|#####     | 5/10 [00:06<00:07,  1.51s/it, est. speed input: 1021.17 toks/s, output: 48.48 toks/s]
[2025-01-08 21:01:24,488][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:06<00:00,  1.49it/s, est. speed input: 1940.03 toks/s, output: 197.66 toks/s]
WARNING 01-08 21:01:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:24,726][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:25,710][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.02it/s, est. speed input: 881.56 toks/s, output: 33.52 toks/s]
[2025-01-08 21:01:25,711][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.03it/s, est. speed input: 1768.54 toks/s, output: 67.00 toks/s]
WARNING 01-08 21:01:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:25,938][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:28,193][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:02<00:18,  2.26s/it, est. speed input: 698.35 toks/s, output: 11.97 toks/s]
[2025-01-08 21:01:31,595][root][ERROR] - Processed prompts:  67%|######6   | 6/9 [00:05<00:02,  1.14it/s, est. speed input: 1348.50 toks/s, output: 57.80 toks/s]
[2025-01-08 21:01:32,003][root][ERROR] - Processed prompts:  78%|#######7  | 7/9 [00:06<00:01,  1.28it/s, est. speed input: 1517.83 toks/s, output: 86.89 toks/s]
[2025-01-08 21:01:32,003][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:06<00:00,  1.48it/s, est. speed input: 1951.20 toks/s, output: 152.83 toks/s]
WARNING 01-08 21:01:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:32,303][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:33,513][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.21s/it, est. speed input: 1001.66 toks/s, output: 23.97 toks/s]
[2025-01-08 21:01:36,650][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:04<00:02,  2.34s/it, est. speed input: 525.26 toks/s, output: 52.69 toks/s]
[2025-01-08 21:01:36,650][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.45s/it, est. speed input: 915.36 toks/s, output: 98.69 toks/s]
WARNING 01-08 21:01:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:01:36,893][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:01:37,944][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.05s/it, est. speed input: 1833.72 toks/s, output: 26.63 toks/s]
[2025-01-08 21:01:37,962][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:01<00:00,  1.87it/s, est. speed input: 3032.73 toks/s, output: 53.32 toks/s]
[2025-01-08 21:01:45,976][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:01:46,030][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:01:47,724][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 21:01:49,317][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 21:01:50,917][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:01:51,468][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 21:01:51,468][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 21:02:02,799][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:02:03,276][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:02:03,328][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:02:05,179][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.85s/it]
[2025-01-08 21:02:06,741][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.68s/it]
[2025-01-08 21:02:08,280][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:02:08,781][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 21:02:08,781][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 21:02:23,671][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:02:24,010][root][INFO] - Loading VLLM model.
WARNING 01-08 21:02:24 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:02:24 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:02:24 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:02:24 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:02:24,898][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:02:26,218][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:02:26,611][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:02:27,922][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:02:29,266][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 21:02:29,266][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:02:29 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:02:43 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:02:43 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:02:43 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:03:05 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:03:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:05,852][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:08,488][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.64s/it, est. speed input: 191.62 toks/s, output: 12.14 toks/s]
[2025-01-08 21:03:08,535][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.96it/s, est. speed input: 3011.91 toks/s, output: 194.95 toks/s]
WARNING 01-08 21:03:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:08,758][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:11,177][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 238.59 toks/s, output: 13.65 toks/s]
[2025-01-08 21:03:11,177][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.61it/s, est. speed input: 3814.33 toks/s, output: 218.27 toks/s]
WARNING 01-08 21:03:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:11,411][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:13,913][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 279.36 toks/s, output: 11.99 toks/s]
[2025-01-08 21:03:13,914][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.39it/s, est. speed input: 4468.74 toks/s, output: 191.79 toks/s]
WARNING 01-08 21:03:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:14,137][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:16,737][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.60s/it, est. speed input: 267.67 toks/s, output: 12.69 toks/s]
[2025-01-08 21:03:16,738][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.15it/s, est. speed input: 4279.75 toks/s, output: 203.01 toks/s]
WARNING 01-08 21:03:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:16,941][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:17,766][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 923.03 toks/s, output: 40.03 toks/s]
[2025-01-08 21:03:17,766][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 923.03 toks/s, output: 40.03 toks/s]
WARNING 01-08 21:03:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:17,993][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:20,884][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:40,  2.89s/it, est. speed input: 349.11 toks/s, output: 10.38 toks/s]
[2025-01-08 21:03:20,884][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.19it/s, est. speed input: 5235.68 toks/s, output: 155.67 toks/s]
WARNING 01-08 21:03:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:21,110][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:23,664][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 319.05 toks/s, output: 12.92 toks/s]
[2025-01-08 21:03:23,665][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4464.11 toks/s, output: 180.82 toks/s]
WARNING 01-08 21:03:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:23,871][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:24,843][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.03it/s, est. speed input: 1094.78 toks/s, output: 30.87 toks/s]
[2025-01-08 21:03:24,860][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.02it/s, est. speed input: 2095.16 toks/s, output: 61.65 toks/s]
WARNING 01-08 21:03:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:25,067][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:26,194][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.13s/it, est. speed input: 722.52 toks/s, output: 29.29 toks/s]
[2025-01-08 21:03:26,195][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.66it/s, est. speed input: 2283.88 toks/s, output: 87.84 toks/s]
WARNING 01-08 21:03:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:26,428][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:28,442][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:24,  2.01s/it, est. speed input: 654.80 toks/s, output: 0.50 toks/s]
[2025-01-08 21:03:29,347][root][ERROR] - Processed prompts:  15%|#5        | 2/13 [00:02<00:14,  1.36s/it, est. speed input: 903.70 toks/s, output: 9.93 toks/s]
[2025-01-08 21:03:31,839][root][ERROR] - Processed prompts:  23%|##3       | 3/13 [00:05<00:18,  1.88s/it, est. speed input: 731.33 toks/s, output: 24.95 toks/s]
[2025-01-08 21:03:34,691][root][ERROR] - Processed prompts:  31%|###       | 4/13 [00:08<00:20,  2.26s/it, est. speed input: 638.52 toks/s, output: 40.54 toks/s]
[2025-01-08 21:03:34,691][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:08<00:00,  1.57it/s, est. speed input: 2075.04 toks/s, output: 258.37 toks/s]
WARNING 01-08 21:03:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:34,976][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:38,762][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:56,  3.79s/it, est. speed input: 416.34 toks/s, output: 7.13 toks/s]
[2025-01-08 21:03:38,875][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:22,  1.63s/it, est. speed input: 776.45 toks/s, output: 14.62 toks/s]
[2025-01-08 21:03:42,856][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:07<00:02,  1.89it/s, est. speed input: 2332.53 toks/s, output: 67.27 toks/s]
[2025-01-08 21:03:42,856][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.03it/s, est. speed input: 3045.11 toks/s, output: 168.79 toks/s]
WARNING 01-08 21:03:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:03:43,168][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:03:44,485][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.32s/it, est. speed input: 1195.96 toks/s, output: 22.78 toks/s]
[2025-01-08 21:03:47,363][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.41s/it, est. speed input: 1139.36 toks/s, output: 62.22 toks/s]
[2025-01-08 21:03:47,363][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.40s/it, est. speed input: 1139.36 toks/s, output: 62.22 toks/s]
[2025-01-08 21:03:55,525][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:03:55,579][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:03:57,266][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 21:03:58,890][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 21:04:00,480][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:04:01,019][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:04:01,020][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 21:04:12,031][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:04:12,576][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:04:12,629][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:04:14,463][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 21:04:16,053][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 21:04:17,605][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 21:04:18,123][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:04:18,123][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:04:33,650][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:04:33,968][root][INFO] - Loading VLLM model.
WARNING 01-08 21:04:34 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:04:34 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:04:34 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:04:34 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:04:34,935][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:04:36,316][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.38s/it]
[2025-01-08 21:04:36,726][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.23it/s]
[2025-01-08 21:04:38,093][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:04:39,505][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 21:04:39,505][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 21:04:39 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:04:53 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:04:54 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:04:54 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:05:15 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:05:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:15,670][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:18,449][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.78s/it, est. speed input: 181.71 toks/s, output: 11.51 toks/s]
[2025-01-08 21:05:18,502][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.65it/s, est. speed input: 2853.32 toks/s, output: 185.75 toks/s]
WARNING 01-08 21:05:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:18,726][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:21,149][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 238.20 toks/s, output: 13.62 toks/s]
[2025-01-08 21:05:21,149][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.60it/s, est. speed input: 3809.29 toks/s, output: 217.91 toks/s]
WARNING 01-08 21:05:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:21,382][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:23,878][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 280.11 toks/s, output: 12.02 toks/s]
[2025-01-08 21:05:23,878][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.41it/s, est. speed input: 4480.55 toks/s, output: 192.30 toks/s]
WARNING 01-08 21:05:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:24,148][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:26,741][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:38,  2.59s/it, est. speed input: 268.45 toks/s, output: 12.73 toks/s]
[2025-01-08 21:05:26,741][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.17it/s, est. speed input: 4293.35 toks/s, output: 203.60 toks/s]
WARNING 01-08 21:05:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:26,995][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:28,101][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 688.55 toks/s, output: 29.86 toks/s]
[2025-01-08 21:05:28,135][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.63it/s, est. speed input: 2003.47 toks/s, output: 88.63 toks/s]
WARNING 01-08 21:05:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:28,369][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:30,977][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:31,  2.61s/it, est. speed input: 386.93 toks/s, output: 11.50 toks/s]
[2025-01-08 21:05:30,977][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  4.98it/s, est. speed input: 5028.93 toks/s, output: 149.52 toks/s]
WARNING 01-08 21:05:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:31,201][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:33,493][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.29s/it, est. speed input: 355.23 toks/s, output: 14.40 toks/s]
[2025-01-08 21:05:33,494][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.24it/s, est. speed input: 4265.66 toks/s, output: 172.77 toks/s]
WARNING 01-08 21:05:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:33,708][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:34,983][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.27s/it, est. speed input: 791.94 toks/s, output: 23.55 toks/s]
[2025-01-08 21:05:34,983][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.14it/s, est. speed input: 3209.96 toks/s, output: 94.16 toks/s]
WARNING 01-08 21:05:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:35,212][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:37,293][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:18,  2.08s/it, est. speed input: 423.84 toks/s, output: 15.86 toks/s]
[2025-01-08 21:05:37,293][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:02<00:00,  4.80it/s, est. speed input: 4198.41 toks/s, output: 158.54 toks/s]
WARNING 01-08 21:05:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:37,513][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:43,501][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:05<00:29,  5.99s/it, est. speed input: 220.26 toks/s, output: 33.40 toks/s]
[2025-01-08 21:05:43,502][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:05<00:00,  1.00it/s, est. speed input: 1321.47 toks/s, output: 200.37 toks/s]
WARNING 01-08 21:05:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:43,710][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:44,560][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1112.51 toks/s, output: 38.85 toks/s]
[2025-01-08 21:05:44,560][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1112.51 toks/s, output: 38.85 toks/s]
WARNING 01-08 21:05:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:44,804][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:48,353][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:49,  3.55s/it, est. speed input: 445.25 toks/s, output: 8.45 toks/s]
[2025-01-08 21:05:48,612][root][ERROR] - Processed prompts:  47%|####6     | 7/15 [00:03<00:03,  2.44it/s, est. speed input: 2841.80 toks/s, output: 57.52 toks/s]
[2025-01-08 21:05:53,031][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:08<00:05,  1.06it/s, est. speed input: 1635.81 toks/s, output: 75.24 toks/s]
[2025-01-08 21:05:53,032][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:08<00:00,  1.82it/s, est. speed input: 2597.60 toks/s, output: 221.09 toks/s]
WARNING 01-08 21:05:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:53,349][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:05:56,041][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:02<00:24,  2.69s/it, est. speed input: 582.51 toks/s, output: 11.14 toks/s]
[2025-01-08 21:05:57,263][root][ERROR] - Processed prompts:  80%|########  | 8/10 [00:03<00:00,  2.48it/s, est. speed input: 3190.56 toks/s, output: 76.65 toks/s]
[2025-01-08 21:05:59,278][root][ERROR] - Processed prompts:  90%|######### | 9/10 [00:05<00:00,  1.53it/s, est. speed input: 2369.35 toks/s, output: 84.33 toks/s]
[2025-01-08 21:05:59,278][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:05<00:00,  1.69it/s, est. speed input: 2559.82 toks/s, output: 118.06 toks/s]
WARNING 01-08 21:05:59 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:05:59,550][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:06:03,271][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.72s/it, est. speed input: 368.42 toks/s, output: 53.75 toks/s]
[2025-01-08 21:06:03,272][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.72s/it, est. speed input: 368.42 toks/s, output: 53.75 toks/s]
[2025-01-08 21:06:11,380][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:06:11,436][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:06:13,110][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 21:06:14,734][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.64s/it]
[2025-01-08 21:06:16,299][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 21:06:16,822][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 21:06:16,823][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 21:06:28,155][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:06:28,661][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:06:28,713][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:06:30,558][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 21:06:32,142][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 21:06:33,728][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 21:06:34,222][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:06:34,223][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 21:06:49,628][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:06:50,006][root][INFO] - Loading VLLM model.
WARNING 01-08 21:06:50 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:06:50 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:06:50 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:06:51 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:06:51,186][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:06:52,508][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:06:52,896][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:06:54,206][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:06:55,551][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 21:06:55,551][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:06:55 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:07:09 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:07:10 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:07:10 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:07:31 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:07:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:31,821][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:34,578][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.76s/it, est. speed input: 183.17 toks/s, output: 11.61 toks/s]
[2025-01-08 21:07:34,627][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.70it/s, est. speed input: 2879.62 toks/s, output: 186.75 toks/s]
WARNING 01-08 21:07:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:34,847][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:37,232][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:35,  2.38s/it, est. speed input: 241.56 toks/s, output: 13.42 toks/s]
[2025-01-08 21:07:37,269][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.61it/s, est. speed input: 3810.79 toks/s, output: 217.63 toks/s]
WARNING 01-08 21:07:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:37,490][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:39,991][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 279.60 toks/s, output: 12.00 toks/s]
[2025-01-08 21:07:39,991][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.40it/s, est. speed input: 4472.27 toks/s, output: 191.94 toks/s]
WARNING 01-08 21:07:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:40,215][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:42,830][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 266.22 toks/s, output: 12.62 toks/s]
[2025-01-08 21:07:42,831][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.12it/s, est. speed input: 4256.55 toks/s, output: 201.91 toks/s]
WARNING 01-08 21:07:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:43,063][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:46,061][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  3.00s/it, est. speed input: 336.56 toks/s, output: 9.67 toks/s]
[2025-01-08 21:07:46,099][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.27it/s, est. speed input: 5318.14 toks/s, output: 157.79 toks/s]
WARNING 01-08 21:07:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:46,320][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:48,616][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.30s/it, est. speed input: 354.99 toks/s, output: 14.37 toks/s]
[2025-01-08 21:07:48,617][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.23it/s, est. speed input: 4258.45 toks/s, output: 172.45 toks/s]
WARNING 01-08 21:07:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:48,826][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:50,137][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.31s/it, est. speed input: 833.37 toks/s, output: 22.89 toks/s]
[2025-01-08 21:07:50,138][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.05it/s, est. speed input: 3268.17 toks/s, output: 91.54 toks/s]
WARNING 01-08 21:07:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:50,351][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:07:51,589][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.24s/it, est. speed input: 657.02 toks/s, output: 26.67 toks/s]
[2025-01-08 21:07:51,589][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.23it/s, est. speed input: 2630.45 toks/s, output: 106.64 toks/s]
WARNING 01-08 21:07:51 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:07:51,815][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:08:00,361][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:08<01:34,  8.55s/it, est. speed input: 154.34 toks/s, output: 23.40 toks/s]
[2025-01-08 21:08:00,362][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:08<00:00,  1.40it/s, est. speed input: 1851.90 toks/s, output: 280.80 toks/s]
WARNING 01-08 21:08:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:08:00,649][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:08:04,501][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:57,  3.85s/it, est. speed input: 411.29 toks/s, output: 7.27 toks/s]
[2025-01-08 21:08:04,607][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:04,  2.03it/s, est. speed input: 2390.72 toks/s, output: 44.73 toks/s]
[2025-01-08 21:08:09,346][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:08<00:06,  1.04it/s, est. speed input: 1608.40 toks/s, output: 54.97 toks/s]
[2025-01-08 21:08:09,346][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.84it/s, est. speed input: 2810.03 toks/s, output: 215.94 toks/s]
WARNING 01-08 21:08:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:08:09,647][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:08:10,954][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.31s/it, est. speed input: 1268.54 toks/s, output: 22.19 toks/s]
[2025-01-08 21:08:10,992][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.23it/s, est. speed input: 3666.35 toks/s, output: 66.96 toks/s]
[2025-01-08 21:08:19,100][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:08:19,154][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:08:20,883][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 21:08:22,498][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 21:08:24,090][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 21:08:24,615][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:08:24,616][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:08:35,608][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:08:36,122][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:08:36,174][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:08:37,965][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 21:08:39,546][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 21:08:41,090][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 21:08:41,588][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 21:08:41,588][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 21:08:57,628][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:08:57,958][root][INFO] - Loading VLLM model.
WARNING 01-08 21:08:58 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:08:58 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:08:58 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:08:58 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:08:58,903][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:09:00,215][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 21:09:00,605][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 21:09:01,899][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 21:09:03,235][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:09:03,235][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 21:09:03 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:09:17 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:09:17 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:09:17 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:09:38 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:09:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:39,298][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:42,348][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.05s/it, est. speed input: 165.60 toks/s, output: 10.49 toks/s]
[2025-01-08 21:09:42,438][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.10it/s, est. speed input: 2573.52 toks/s, output: 169.13 toks/s]
WARNING 01-08 21:09:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:42,657][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:45,071][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.07 toks/s, output: 13.67 toks/s]
[2025-01-08 21:09:45,072][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3825.35 toks/s, output: 218.71 toks/s]
WARNING 01-08 21:09:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:45,295][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:47,784][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.49s/it, est. speed input: 280.87 toks/s, output: 12.05 toks/s]
[2025-01-08 21:09:48,085][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  7.68it/s, est. speed input: 3941.15 toks/s, output: 178.51 toks/s]
[2025-01-08 21:09:48,085][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.73it/s, est. speed input: 3941.15 toks/s, output: 178.51 toks/s]
WARNING 01-08 21:09:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:48,303][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:50,682][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:30,  2.38s/it, est. speed input: 292.61 toks/s, output: 13.87 toks/s]
[2025-01-08 21:09:50,683][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.88it/s, est. speed input: 4097.09 toks/s, output: 194.18 toks/s]
WARNING 01-08 21:09:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:50,893][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:51,804][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.10it/s, est. speed input: 827.68 toks/s, output: 32.93 toks/s]
[2025-01-08 21:09:51,804][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.19it/s, est. speed input: 1466.96 toks/s, output: 65.83 toks/s]
WARNING 01-08 21:09:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:52,029][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:52,972][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 737.79 toks/s, output: 34.98 toks/s]
[2025-01-08 21:09:52,973][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.12it/s, est. speed input: 1467.54 toks/s, output: 69.93 toks/s]
WARNING 01-08 21:09:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:53,198][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:55,904][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:35,  2.71s/it, est. speed input: 372.94 toks/s, output: 10.72 toks/s]
[2025-01-08 21:09:55,938][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.11it/s, est. speed input: 5156.12 toks/s, output: 152.57 toks/s]
WARNING 01-08 21:09:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:56,163][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:58,325][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:02<00:21,  2.16s/it, est. speed input: 376.90 toks/s, output: 15.26 toks/s]
[2025-01-08 21:09:58,326][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:02<00:00,  5.09it/s, est. speed input: 4145.74 toks/s, output: 167.83 toks/s]
WARNING 01-08 21:09:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:09:58,549][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:09:59,982][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.43s/it, est. speed input: 761.89 toks/s, output: 20.93 toks/s]
[2025-01-08 21:10:01,081][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  2.24it/s, est. speed input: 2053.35 toks/s, output: 84.91 toks/s]
[2025-01-08 21:10:01,081][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:02<00:00,  1.97it/s, est. speed input: 2053.35 toks/s, output: 84.91 toks/s]
WARNING 01-08 21:10:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:10:01,302][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:10:02,805][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:07,  1.50s/it, est. speed input: 542.75 toks/s, output: 21.95 toks/s]
[2025-01-08 21:10:02,806][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:01<00:00,  3.99it/s, est. speed input: 3287.38 toks/s, output: 131.65 toks/s]
WARNING 01-08 21:10:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:10:03,031][root][ERROR] - Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:10:04,760][root][ERROR] - Processed prompts:  10%|#         | 1/10 [00:01<00:15,  1.73s/it, est. speed input: 762.92 toks/s, output: 2.89 toks/s]
[2025-01-08 21:10:10,359][root][ERROR] - Processed prompts:  20%|##        | 2/10 [00:07<00:32,  4.01s/it, est. speed input: 359.98 toks/s, output: 27.97 toks/s]
[2025-01-08 21:10:10,360][root][ERROR] - Processed prompts: 100%|##########| 10/10 [00:07<00:00,  1.36it/s, est. speed input: 1799.80 toks/s, output: 246.30 toks/s]
WARNING 01-08 21:10:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:10:10,609][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:10:13,838][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:48,  3.23s/it, est. speed input: 434.30 toks/s, output: 4.34 toks/s]
[2025-01-08 21:10:14,326][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:03<00:22,  1.62s/it, est. speed input: 801.28 toks/s, output: 11.03 toks/s]
[2025-01-08 21:10:14,433][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.57it/s, est. speed input: 1602.48 toks/s, output: 25.89 toks/s]
[2025-01-08 21:10:18,968][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:08<00:04,  1.38it/s, est. speed input: 1833.56 toks/s, output: 53.72 toks/s]
[2025-01-08 21:10:18,968][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.91it/s, est. speed input: 2834.19 toks/s, output: 197.28 toks/s]
WARNING 01-08 21:10:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:10:19,319][root][ERROR] - Processed prompts:   0%|          | 0/6 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:10:21,222][root][ERROR] - Processed prompts:  17%|#6        | 1/6 [00:01<00:09,  1.90s/it, est. speed input: 772.34 toks/s, output: 14.71 toks/s]
[2025-01-08 21:10:25,040][root][ERROR] - Processed prompts:  50%|#####     | 3/6 [00:05<00:05,  1.91s/it, est. speed input: 786.25 toks/s, output: 45.10 toks/s]
[2025-01-08 21:10:25,040][root][ERROR] - Processed prompts: 100%|##########| 6/6 [00:05<00:00,  1.05it/s, est. speed input: 1658.91 toks/s, output: 149.97 toks/s]
[2025-01-08 21:10:33,279][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:10:33,336][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:10:35,096][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 21:10:36,743][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 21:10:38,396][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.67s/it]
[2025-01-08 21:10:38,931][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.22s/it]
[2025-01-08 21:10:38,931][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 21:10:49,954][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:10:50,549][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:10:50,601][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:10:52,407][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.81s/it]
[2025-01-08 21:10:53,988][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 21:10:55,526][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 21:10:56,038][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 21:10:56,038][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 21:11:12,089][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:11:12,453][root][INFO] - Loading VLLM model.
WARNING 01-08 21:11:12 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:11:12 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:11:13 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:11:13 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:11:13,423][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:11:14,792][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 21:11:15,195][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 21:11:16,555][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:11:17,960][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 21:11:17,960][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 21:11:18 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:11:31 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:11:32 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:11:32 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:11:53 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:11:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:11:54,141][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:11:57,323][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:47,  3.18s/it, est. speed input: 158.72 toks/s, output: 10.69 toks/s]
[2025-01-08 21:11:57,441][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:03<00:01,  3.71it/s, est. speed input: 1377.04 toks/s, output: 96.35 toks/s]
[2025-01-08 21:11:57,555][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:03<00:00,  5.75it/s, est. speed input: 1923.15 toks/s, output: 140.61 toks/s]
[2025-01-08 21:11:57,842][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.32it/s, est. speed input: 2182.96 toks/s, output: 169.67 toks/s]
WARNING 01-08 21:11:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:11:58,064][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:00,488][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 242.18 toks/s, output: 13.61 toks/s]
[2025-01-08 21:12:00,488][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.60it/s, est. speed input: 3849.17 toks/s, output: 217.78 toks/s]
WARNING 01-08 21:12:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:00,716][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:03,190][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.47s/it, est. speed input: 282.52 toks/s, output: 12.13 toks/s]
[2025-01-08 21:12:06,300][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:05<00:00,  3.04it/s, est. speed input: 1843.90 toks/s, output: 111.03 toks/s]
[2025-01-08 21:12:06,300][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.87it/s, est. speed input: 1968.97 toks/s, output: 146.84 toks/s]
WARNING 01-08 21:12:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:06,525][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:09,025][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.50s/it, est. speed input: 282.54 toks/s, output: 13.21 toks/s]
[2025-01-08 21:12:09,025][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.00it/s, est. speed input: 4215.10 toks/s, output: 198.05 toks/s]
WARNING 01-08 21:12:09 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:09,231][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:10,065][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 898.84 toks/s, output: 38.35 toks/s]
[2025-01-08 21:12:10,066][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 898.84 toks/s, output: 38.35 toks/s]
WARNING 01-08 21:12:10 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:10,272][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:11,099][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 841.31 toks/s, output: 39.95 toks/s]
[2025-01-08 21:12:11,099][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 841.31 toks/s, output: 39.95 toks/s]
WARNING 01-08 21:12:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:11,328][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:14,185][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.86s/it, est. speed input: 353.24 toks/s, output: 10.15 toks/s]
[2025-01-08 21:12:14,221][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.19it/s, est. speed input: 5294.78 toks/s, output: 154.91 toks/s]
WARNING 01-08 21:12:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:14,475][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:16,785][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:25,  2.31s/it, est. speed input: 357.13 toks/s, output: 14.28 toks/s]
[2025-01-08 21:12:16,786][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:02<00:00,  5.19it/s, est. speed input: 4266.97 toks/s, output: 171.37 toks/s]
WARNING 01-08 21:12:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:17,010][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:18,324][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.31s/it, est. speed input: 831.01 toks/s, output: 22.83 toks/s]
[2025-01-08 21:12:20,562][root][ERROR] - Processed prompts:  75%|#######5  | 3/4 [00:03<00:01,  1.17s/it, est. speed input: 914.36 toks/s, output: 59.96 toks/s]
[2025-01-08 21:12:21,373][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.05s/it, est. speed input: 986.46 toks/s, output: 94.66 toks/s]
[2025-01-08 21:12:21,373][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:04<00:00,  1.09s/it, est. speed input: 986.46 toks/s, output: 94.66 toks/s]
WARNING 01-08 21:12:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:21,583][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:22,837][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:01<00:03,  1.25s/it, est. speed input: 645.79 toks/s, output: 26.31 toks/s]
[2025-01-08 21:12:22,838][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:01<00:00,  3.19it/s, est. speed input: 2658.78 toks/s, output: 105.20 toks/s]
WARNING 01-08 21:12:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:23,073][root][ERROR] - Processed prompts:   0%|          | 0/12 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:25,930][root][ERROR] - Processed prompts:   8%|8         | 1/12 [00:02<00:31,  2.86s/it, est. speed input: 459.85 toks/s, output: 10.50 toks/s]
[2025-01-08 21:12:31,362][root][ERROR] - Processed prompts:  17%|#6        | 2/12 [00:08<00:43,  4.37s/it, est. speed input: 317.63 toks/s, output: 27.75 toks/s]
[2025-01-08 21:12:31,363][root][ERROR] - Processed prompts: 100%|##########| 12/12 [00:08<00:00,  1.45it/s, est. speed input: 1908.68 toks/s, output: 269.00 toks/s]
WARNING 01-08 21:12:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:31,613][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:32,457][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 964.15 toks/s, output: 39.09 toks/s]
[2025-01-08 21:12:32,458][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 964.15 toks/s, output: 39.09 toks/s]
WARNING 01-08 21:12:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:32,707][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:36,347][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:50,  3.64s/it, est. speed input: 432.45 toks/s, output: 7.42 toks/s]
[2025-01-08 21:12:36,453][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:03<00:07,  1.39it/s, est. speed input: 1683.07 toks/s, output: 30.43 toks/s]
[2025-01-08 21:12:39,637][root][ERROR] - Processed prompts:  53%|#####3    | 8/15 [00:06<00:05,  1.31it/s, est. speed input: 1808.37 toks/s, output: 50.36 toks/s]
[2025-01-08 21:12:41,119][root][ERROR] - Processed prompts:  60%|######    | 9/15 [00:08<00:05,  1.12it/s, est. speed input: 1655.77 toks/s, output: 65.27 toks/s]
[2025-01-08 21:12:41,119][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:08<00:00,  1.78it/s, est. speed input: 2749.81 toks/s, output: 207.91 toks/s]
WARNING 01-08 21:12:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:41,456][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:43,253][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:07,  1.80s/it, est. speed input: 943.98 toks/s, output: 16.70 toks/s]
[2025-01-08 21:12:46,733][root][ERROR] - Processed prompts:  60%|######    | 3/5 [00:05<00:03,  1.75s/it, est. speed input: 967.07 toks/s, output: 49.27 toks/s]
[2025-01-08 21:12:46,734][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:05<00:00,  1.06s/it, est. speed input: 1589.13 toks/s, output: 125.07 toks/s]
WARNING 01-08 21:12:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:12:46,968][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:12:47,848][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 2136.86 toks/s, output: 31.81 toks/s]
[2025-01-08 21:12:47,849][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 2136.86 toks/s, output: 31.81 toks/s]
[2025-01-08 21:12:56,173][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:12:56,227][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:12:57,950][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 21:12:59,583][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 21:13:01,169][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 21:13:01,693][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:13:01,693][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:13:12,897][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:13:13,426][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:13:13,478][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:13:15,380][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 21:13:17,044][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.76s/it]
[2025-01-08 21:13:18,652][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 21:13:19,162][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 21:13:19,163][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 21:13:35,641][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:13:35,983][root][INFO] - Loading VLLM model.
WARNING 01-08 21:13:36 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:13:36 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:13:36 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:13:36 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:13:36,888][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:13:38,254][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 21:13:38,657][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 21:13:40,019][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:13:41,425][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 21:13:41,425][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 21:13:41 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:13:55 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:13:56 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:13:56 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:14:17 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:14:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:17,716][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:20,952][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:48,  3.24s/it, est. speed input: 156.09 toks/s, output: 10.20 toks/s]
[2025-01-08 21:14:21,057][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:05,  1.98it/s, est. speed input: 755.98 toks/s, output: 51.80 toks/s]
[2025-01-08 21:14:21,209][root][ERROR] - Processed prompts:  75%|#######5  | 12/16 [00:03<00:00,  5.68it/s, est. speed input: 1735.18 toks/s, output: 126.85 toks/s]
[2025-01-08 21:14:22,060][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  5.29it/s, est. speed input: 1860.15 toks/s, output: 161.15 toks/s]
[2025-01-08 21:14:22,061][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:04<00:00,  3.68it/s, est. speed input: 1860.15 toks/s, output: 161.15 toks/s]
WARNING 01-08 21:14:22 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:22,283][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:24,706][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 238.61 toks/s, output: 13.62 toks/s]
[2025-01-08 21:14:24,707][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.60it/s, est. speed input: 3881.05 toks/s, output: 217.91 toks/s]
WARNING 01-08 21:14:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:24,934][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:27,436][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.50s/it, est. speed input: 279.34 toks/s, output: 11.99 toks/s]
[2025-01-08 21:14:30,279][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.42it/s, est. speed input: 2092.52 toks/s, output: 121.61 toks/s]
[2025-01-08 21:14:30,279][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.99it/s, est. speed input: 2092.52 toks/s, output: 121.61 toks/s]
WARNING 01-08 21:14:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:30,506][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:33,004][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.50s/it, est. speed input: 279.10 toks/s, output: 13.21 toks/s]
[2025-01-08 21:14:33,005][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.00it/s, est. speed input: 4225.82 toks/s, output: 198.16 toks/s]
WARNING 01-08 21:14:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:33,223][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:34,046][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 1161.73 toks/s, output: 36.49 toks/s]
[2025-01-08 21:14:34,046][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 1161.73 toks/s, output: 36.49 toks/s]
WARNING 01-08 21:14:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:34,253][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:35,078][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 911.90 toks/s, output: 40.02 toks/s]
[2025-01-08 21:14:35,078][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 911.90 toks/s, output: 40.02 toks/s]
WARNING 01-08 21:14:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:35,335][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:38,207][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:40,  2.87s/it, est. speed input: 351.31 toks/s, output: 10.45 toks/s]
[2025-01-08 21:14:38,208][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.22it/s, est. speed input: 5268.41 toks/s, output: 156.64 toks/s]
WARNING 01-08 21:14:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:38,446][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:40,869][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:29,  2.42s/it, est. speed input: 336.88 toks/s, output: 13.62 toks/s]
[2025-01-08 21:14:40,869][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.37it/s, est. speed input: 4413.39 toks/s, output: 177.06 toks/s]
WARNING 01-08 21:14:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:41,083][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:42,216][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.13s/it, est. speed input: 938.82 toks/s, output: 25.59 toks/s]
[2025-01-08 21:14:45,103][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.36s/it, est. speed input: 843.93 toks/s, output: 64.42 toks/s]
[2025-01-08 21:14:45,104][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.34s/it, est. speed input: 843.93 toks/s, output: 64.42 toks/s]
WARNING 01-08 21:14:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:45,317][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:46,425][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.11s/it, est. speed input: 744.88 toks/s, output: 29.79 toks/s]
[2025-01-08 21:14:46,425][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.71it/s, est. speed input: 2268.14 toks/s, output: 89.35 toks/s]
WARNING 01-08 21:14:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:46,659][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:55,560][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:08<01:46,  8.90s/it, est. speed input: 148.18 toks/s, output: 22.47 toks/s]
[2025-01-08 21:14:55,561][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:08<00:00,  1.46it/s, est. speed input: 1926.27 toks/s, output: 292.08 toks/s]
WARNING 01-08 21:14:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:55,774][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:14:56,624][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1038.01 toks/s, output: 38.84 toks/s]
[2025-01-08 21:14:56,624][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1038.01 toks/s, output: 38.84 toks/s]
WARNING 01-08 21:14:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:14:56,907][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:15:00,602][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:51,  3.69s/it, est. speed input: 427.38 toks/s, output: 7.31 toks/s]
[2025-01-08 21:15:02,029][root][ERROR] - Processed prompts:  27%|##6       | 4/15 [00:05<00:11,  1.08s/it, est. speed input: 1231.75 toks/s, output: 29.87 toks/s]
[2025-01-08 21:15:06,269][root][ERROR] - Processed prompts:  33%|###3      | 5/15 [00:09<00:19,  1.96s/it, est. speed input: 842.29 toks/s, output: 37.71 toks/s]
[2025-01-08 21:15:06,269][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.60it/s, est. speed input: 2522.35 toks/s, output: 251.34 toks/s]
WARNING 01-08 21:15:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:15:06,647][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:15:11,465][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:04<00:09,  4.82s/it, est. speed input: 372.86 toks/s, output: 41.52 toks/s]
[2025-01-08 21:15:11,465][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.61s/it, est. speed input: 1037.93 toks/s, output: 124.55 toks/s]
WARNING 01-08 21:15:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:15:11,692][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:15:12,550][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1904.58 toks/s, output: 33.80 toks/s]
[2025-01-08 21:15:12,551][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 1904.58 toks/s, output: 33.80 toks/s]
[2025-01-08 21:15:20,851][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:15:20,905][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:15:22,638][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.73s/it]
[2025-01-08 21:15:24,363][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 21:15:25,994][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 21:15:26,544][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 21:15:26,545][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 21:15:37,676][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:15:38,190][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:15:38,243][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:15:40,103][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.86s/it]
[2025-01-08 21:15:41,703][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 21:15:43,273][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 21:15:43,769][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:15:43,769][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 21:16:00,509][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:16:00,851][root][INFO] - Loading VLLM model.
WARNING 01-08 21:16:01 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:16:01 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:16:01 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:16:01 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:16:01,792][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:16:03,104][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 21:16:03,490][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 21:16:04,787][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:01,  1.01s/it]
[2025-01-08 21:16:06,128][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:16:06,129][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 21:16:06 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:16:20 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:16:20 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:16:20 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:16:42 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:16:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:16:42,746][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:16:45,715][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.97s/it, est. speed input: 170.11 toks/s, output: 11.45 toks/s]
[2025-01-08 21:16:45,821][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.69it/s, est. speed input: 657.04 toks/s, output: 46.19 toks/s]
[2025-01-08 21:16:45,891][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.09it/s, est. speed input: 2569.96 toks/s, output: 191.47 toks/s]
WARNING 01-08 21:16:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:16:46,114][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:16:48,536][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 240.31 toks/s, output: 13.63 toks/s]
[2025-01-08 21:16:48,537][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.60it/s, est. speed input: 3841.52 toks/s, output: 217.96 toks/s]
WARNING 01-08 21:16:48 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:16:48,769][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:16:51,276][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:37,  2.51s/it, est. speed input: 278.77 toks/s, output: 11.96 toks/s]
[2025-01-08 21:16:51,401][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:02<00:01,  5.16it/s, est. speed input: 2655.73 toks/s, output: 121.20 toks/s]
[2025-01-08 21:16:52,284][root][ERROR] - Processed prompts:  94%|#########3| 15/16 [00:03<00:00,  5.36it/s, est. speed input: 2982.88 toks/s, output: 153.06 toks/s]
[2025-01-08 21:16:54,255][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.92it/s, est. speed input: 2038.70 toks/s, output: 134.53 toks/s]
WARNING 01-08 21:16:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:16:54,514][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:16:56,769][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:27,  2.26s/it, est. speed input: 310.81 toks/s, output: 14.63 toks/s]
[2025-01-08 21:16:56,770][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.76it/s, est. speed input: 4037.29 toks/s, output: 190.16 toks/s]
WARNING 01-08 21:16:56 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:16:56,999][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:16:58,174][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.17s/it, est. speed input: 670.79 toks/s, output: 29.79 toks/s]
[2025-01-08 21:17:01,199][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:04<00:02,  2.26s/it, est. speed input: 379.74 toks/s, output: 55.95 toks/s]
[2025-01-08 21:17:01,200][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.40s/it, est. speed input: 607.77 toks/s, output: 103.56 toks/s]
WARNING 01-08 21:17:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:01,412][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:02,476][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.06s/it, est. speed input: 659.04 toks/s, output: 31.02 toks/s]
[2025-01-08 21:17:02,476][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.82it/s, est. speed input: 1964.11 toks/s, output: 93.04 toks/s]
WARNING 01-08 21:17:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:02,706][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:05,303][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:31,  2.60s/it, est. speed input: 388.56 toks/s, output: 11.55 toks/s]
[2025-01-08 21:17:05,413][root][ERROR] - Processed prompts:  77%|#######6  | 10/13 [00:02<00:00,  5.03it/s, est. speed input: 3735.08 toks/s, output: 117.86 toks/s]
[2025-01-08 21:17:05,413][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  4.80it/s, est. speed input: 4857.40 toks/s, output: 155.53 toks/s]
WARNING 01-08 21:17:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:05,642][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:08,066][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:02<00:29,  2.42s/it, est. speed input: 338.22 toks/s, output: 13.61 toks/s]
[2025-01-08 21:17:08,151][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:02<00:00,  5.18it/s, est. speed input: 4246.39 toks/s, output: 172.96 toks/s]
WARNING 01-08 21:17:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:08,367][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:09,684][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.32s/it, est. speed input: 832.91 toks/s, output: 26.57 toks/s]
[2025-01-08 21:17:12,164][root][ERROR] - Processed prompts:  67%|######6   | 2/3 [00:03<00:02,  2.00s/it, est. speed input: 628.15 toks/s, output: 53.99 toks/s]
[2025-01-08 21:17:12,670][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.32s/it, est. speed input: 887.53 toks/s, output: 94.12 toks/s]
[2025-01-08 21:17:12,670][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.43s/it, est. speed input: 887.53 toks/s, output: 94.12 toks/s]
WARNING 01-08 21:17:12 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:12,890][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:13,880][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 823.08 toks/s, output: 33.33 toks/s]
[2025-01-08 21:17:13,881][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.02it/s, est. speed input: 1727.19 toks/s, output: 66.62 toks/s]
WARNING 01-08 21:17:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:14,122][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:16,357][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:29,  2.24s/it, est. speed input: 590.12 toks/s, output: 0.45 toks/s]
[2025-01-08 21:17:23,299][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:09<01:00,  5.00s/it, est. speed input: 287.89 toks/s, output: 21.90 toks/s]
[2025-01-08 21:17:23,300][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:09<00:00,  1.53it/s, est. speed input: 2076.66 toks/s, output: 283.40 toks/s]
WARNING 01-08 21:17:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:23,551][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:24,522][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.03it/s, est. speed input: 844.47 toks/s, output: 33.98 toks/s]
[2025-01-08 21:17:24,522][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.06it/s, est. speed input: 1673.83 toks/s, output: 67.94 toks/s]
WARNING 01-08 21:17:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:24,771][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:28,299][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:45,  3.53s/it, est. speed input: 448.78 toks/s, output: 8.22 toks/s]
[2025-01-08 21:17:28,399][root][ERROR] - Processed prompts:  29%|##8       | 4/14 [00:03<00:06,  1.44it/s, est. speed input: 1743.90 toks/s, output: 33.36 toks/s]
[2025-01-08 21:17:28,778][root][ERROR] - Processed prompts:  43%|####2     | 6/14 [00:04<00:03,  2.11it/s, est. speed input: 2370.38 toks/s, output: 49.92 toks/s]
[2025-01-08 21:17:33,082][root][ERROR] - Processed prompts:  57%|#####7    | 8/14 [00:08<00:06,  1.12s/it, est. speed input: 1523.04 toks/s, output: 72.20 toks/s]
[2025-01-08 21:17:33,082][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:08<00:00,  1.68it/s, est. speed input: 2588.81 toks/s, output: 216.59 toks/s]
WARNING 01-08 21:17:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:33,392][root][ERROR] - Processed prompts:   0%|          | 0/4 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:38,828][root][ERROR] - Processed prompts:  25%|##5       | 1/4 [00:05<00:16,  5.44s/it, est. speed input: 362.23 toks/s, output: 36.79 toks/s]
[2025-01-08 21:17:38,828][root][ERROR] - Processed prompts: 100%|##########| 4/4 [00:05<00:00,  1.36s/it, est. speed input: 1359.92 toks/s, output: 147.16 toks/s]
WARNING 01-08 21:17:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:17:39,075][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:17:42,189][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:03<00:03,  3.11s/it, est. speed input: 714.44 toks/s, output: 42.06 toks/s]
[2025-01-08 21:17:43,356][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:04<00:00,  1.97s/it, est. speed input: 1086.77 toks/s, output: 77.31 toks/s]
[2025-01-08 21:17:43,357][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:04<00:00,  2.14s/it, est. speed input: 1086.77 toks/s, output: 77.31 toks/s]
[2025-01-08 21:17:51,607][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:17:51,662][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:17:53,420][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.76s/it]
[2025-01-08 21:17:55,124][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 21:17:56,754][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 21:17:57,289][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 21:17:57,290][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 21:18:08,270][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:18:08,794][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:18:08,847][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:18:10,674][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.83s/it]
[2025-01-08 21:18:12,262][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 21:18:13,822][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 21:18:14,312][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 21:18:14,312][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:18:31,299][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:18:31,689][root][INFO] - Loading VLLM model.
WARNING 01-08 21:18:33 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:18:33 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:18:33 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:18:34 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:18:34,258][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:18:35,599][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.34s/it]
[2025-01-08 21:18:35,996][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.27it/s]
[2025-01-08 21:18:37,305][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:18:38,657][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 21:18:38,657][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.10s/it]
INFO 01-08 21:18:38 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:18:52 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:18:53 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:18:53 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:19:15 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:19:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:15,384][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:18,615][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:48,  3.23s/it, est. speed input: 156.35 toks/s, output: 10.84 toks/s]
[2025-01-08 21:19:18,710][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.81it/s, est. speed input: 2429.98 toks/s, output: 178.64 toks/s]
WARNING 01-08 21:19:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:18,946][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:21,373][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.43s/it, est. speed input: 238.58 toks/s, output: 13.60 toks/s]
[2025-01-08 21:19:21,373][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.59it/s, est. speed input: 3830.33 toks/s, output: 217.51 toks/s]
WARNING 01-08 21:19:21 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:21,609][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:24,074][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 283.60 toks/s, output: 11.77 toks/s]
[2025-01-08 21:19:24,111][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.40it/s, est. speed input: 4470.35 toks/s, output: 191.46 toks/s]
WARNING 01-08 21:19:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:24,349][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:26,967][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.62s/it, est. speed input: 266.61 toks/s, output: 12.60 toks/s]
[2025-01-08 21:19:26,968][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.11it/s, est. speed input: 4277.63 toks/s, output: 201.62 toks/s]
WARNING 01-08 21:19:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:27,241][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:30,249][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.01s/it, est. speed input: 335.10 toks/s, output: 9.64 toks/s]
[2025-01-08 21:19:30,287][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.25it/s, est. speed input: 5299.98 toks/s, output: 157.26 toks/s]
WARNING 01-08 21:19:30 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:30,537][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:33,213][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.68s/it, est. speed input: 305.34 toks/s, output: 12.33 toks/s]
[2025-01-08 21:19:33,213][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.60it/s, est. speed input: 4591.01 toks/s, output: 184.96 toks/s]
WARNING 01-08 21:19:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:33,440][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:34,280][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1267.55 toks/s, output: 35.74 toks/s]
[2025-01-08 21:19:34,280][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1267.55 toks/s, output: 35.74 toks/s]
WARNING 01-08 21:19:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:34,496][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:35,340][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 971.37 toks/s, output: 39.14 toks/s]
[2025-01-08 21:19:35,340][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 971.37 toks/s, output: 39.14 toks/s]
WARNING 01-08 21:19:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:35,591][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:45,312][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:09<02:16,  9.72s/it, est. speed input: 135.69 toks/s, output: 20.57 toks/s]
[2025-01-08 21:19:45,313][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.54it/s, est. speed input: 2034.95 toks/s, output: 308.59 toks/s]
WARNING 01-08 21:19:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:45,582][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:49,548][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:59,  3.97s/it, est. speed input: 397.65 toks/s, output: 7.31 toks/s]
[2025-01-08 21:19:53,062][root][ERROR] - Processed prompts:  88%|########7 | 14/16 [00:07<00:00,  2.18it/s, est. speed input: 2950.68 toks/s, output: 78.34 toks/s]
[2025-01-08 21:19:53,062][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:07<00:00,  2.14it/s, est. speed input: 3344.73 toks/s, output: 131.81 toks/s]
WARNING 01-08 21:19:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:19:53,414][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:19:54,260][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1929.45 toks/s, output: 33.12 toks/s]
[2025-01-08 21:19:54,260][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1929.45 toks/s, output: 33.12 toks/s]
[2025-01-08 21:20:02,486][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:20:02,540][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:20:04,329][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.79s/it]
[2025-01-08 21:20:06,051][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 21:20:07,715][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 21:20:08,273][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.26s/it]
[2025-01-08 21:20:08,273][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 21:20:19,339][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:20:19,909][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:20:19,962][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:20:21,852][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.89s/it]
[2025-01-08 21:20:23,542][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.77s/it]
[2025-01-08 21:20:25,185][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 21:20:25,720][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.25s/it]
[2025-01-08 21:20:25,721][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.44s/it]
[2025-01-08 21:20:41,235][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:20:41,645][root][INFO] - Loading VLLM model.
WARNING 01-08 21:20:42 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:20:42 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:20:42 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:20:42 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:20:44,105][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:20:45,477][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 21:20:45,882][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 21:20:47,242][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:20:48,650][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 21:20:48,650][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 21:20:48 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:21:02 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:21:03 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:21:03 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:21:24 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:21:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:25,192][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:28,099][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.91s/it, est. speed input: 173.71 toks/s, output: 11.35 toks/s]
[2025-01-08 21:21:28,203][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:03,  2.66it/s, est. speed input: 1006.26 toks/s, output: 69.41 toks/s]
[2025-01-08 21:21:28,276][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.19it/s, est. speed input: 2619.88 toks/s, output: 190.33 toks/s]
WARNING 01-08 21:21:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:28,498][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:30,916][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 239.45 toks/s, output: 13.65 toks/s]
[2025-01-08 21:21:30,917][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.61it/s, est. speed input: 3841.33 toks/s, output: 218.30 toks/s]
WARNING 01-08 21:21:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:31,155][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:33,621][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.47s/it, est. speed input: 283.48 toks/s, output: 11.76 toks/s]
[2025-01-08 21:21:33,639][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.44it/s, est. speed input: 4503.42 toks/s, output: 187.24 toks/s]
WARNING 01-08 21:21:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:33,866][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:36,487][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.62s/it, est. speed input: 266.36 toks/s, output: 12.59 toks/s]
[2025-01-08 21:21:36,487][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.10it/s, est. speed input: 4271.03 toks/s, output: 201.44 toks/s]
WARNING 01-08 21:21:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:36,719][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:39,720][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.00s/it, est. speed input: 335.86 toks/s, output: 9.66 toks/s]
[2025-01-08 21:21:39,738][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.30it/s, est. speed input: 5342.18 toks/s, output: 154.01 toks/s]
WARNING 01-08 21:21:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:39,966][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:42,783][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.82s/it, est. speed input: 290.07 toks/s, output: 11.72 toks/s]
[2025-01-08 21:21:42,801][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.64it/s, est. speed input: 4621.58 toks/s, output: 186.64 toks/s]
WARNING 01-08 21:21:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:43,008][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:43,886][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 1017.44 toks/s, output: 37.60 toks/s]
[2025-01-08 21:21:43,886][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.14it/s, est. speed input: 1017.44 toks/s, output: 37.60 toks/s]
WARNING 01-08 21:21:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:44,134][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:53,852][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:09<02:16,  9.72s/it, est. speed input: 135.54 toks/s, output: 20.58 toks/s]
[2025-01-08 21:21:53,852][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.54it/s, est. speed input: 2033.12 toks/s, output: 308.72 toks/s]
WARNING 01-08 21:21:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:21:54,153][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:21:57,924][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:56,  3.77s/it, est. speed input: 417.43 toks/s, output: 6.63 toks/s]
[2025-01-08 21:21:58,067][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:06,  1.69it/s, est. speed input: 2012.03 toks/s, output: 34.49 toks/s]
[2025-01-08 21:22:02,362][root][ERROR] - Processed prompts:  69%|######8   | 11/16 [00:08<00:03,  1.49it/s, est. speed input: 2056.18 toks/s, output: 58.59 toks/s]
[2025-01-08 21:22:02,363][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.95it/s, est. speed input: 3014.81 toks/s, output: 180.39 toks/s]
WARNING 01-08 21:22:02 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:22:02,673][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:22:06,399][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.73s/it, est. speed input: 367.14 toks/s, output: 53.67 toks/s]
[2025-01-08 21:22:06,399][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.73s/it, est. speed input: 367.14 toks/s, output: 53.67 toks/s]
[2025-01-08 21:22:14,620][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:22:14,673][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:22:16,423][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 21:22:18,131][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 21:22:19,788][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.69s/it]
[2025-01-08 21:22:20,328][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 21:22:20,329][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 21:22:31,284][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:22:31,784][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:22:31,836][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:22:33,718][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 21:22:35,340][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.73s/it]
[2025-01-08 21:22:36,898][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 21:22:37,399][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 21:22:37,400][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 21:22:53,327][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:22:53,674][root][INFO] - Loading VLLM model.
WARNING 01-08 21:22:53 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:22:53 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:22:54 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:22:54 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:22:54,632][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:22:55,954][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:22:56,343][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:22:57,648][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:22:58,991][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:22:58,991][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:22:59 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:23:13 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:23:13 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:23:13 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:23:35 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:23:35 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:35,541][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:38,571][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.03s/it, est. speed input: 166.63 toks/s, output: 10.89 toks/s]
[2025-01-08 21:23:38,677][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:03<00:07,  1.66it/s, est. speed input: 644.05 toks/s, output: 44.00 toks/s]
[2025-01-08 21:23:38,755][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.98it/s, est. speed input: 2513.62 toks/s, output: 183.85 toks/s]
WARNING 01-08 21:23:38 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:38,979][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:41,396][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 240.78 toks/s, output: 13.65 toks/s]
[2025-01-08 21:23:41,397][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.62it/s, est. speed input: 3844.39 toks/s, output: 218.38 toks/s]
WARNING 01-08 21:23:41 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:41,627][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:44,090][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 283.77 toks/s, output: 11.77 toks/s]
[2025-01-08 21:23:44,091][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.49it/s, est. speed input: 4539.18 toks/s, output: 188.32 toks/s]
WARNING 01-08 21:23:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:44,341][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:46,956][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 268.09 toks/s, output: 12.62 toks/s]
[2025-01-08 21:23:46,957][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.12it/s, est. speed input: 4281.58 toks/s, output: 201.86 toks/s]
WARNING 01-08 21:23:47 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:47,216][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:50,214][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  3.00s/it, est. speed input: 336.20 toks/s, output: 9.67 toks/s]
[2025-01-08 21:23:50,215][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.34it/s, est. speed input: 5378.05 toks/s, output: 154.73 toks/s]
WARNING 01-08 21:23:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:50,448][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:53,265][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.82s/it, est. speed input: 291.20 toks/s, output: 11.72 toks/s]
[2025-01-08 21:23:53,333][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.55it/s, est. speed input: 4543.36 toks/s, output: 184.47 toks/s]
WARNING 01-08 21:23:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:53,584][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:23:54,573][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.01it/s, est. speed input: 893.83 toks/s, output: 33.37 toks/s]
[2025-01-08 21:23:54,574][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.02it/s, est. speed input: 1799.09 toks/s, output: 66.71 toks/s]
WARNING 01-08 21:23:54 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:23:54,809][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:24:04,202][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:09<02:02,  9.39s/it, est. speed input: 140.23 toks/s, output: 21.30 toks/s]
[2025-01-08 21:24:04,202][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:09<00:00,  1.49it/s, est. speed input: 1963.07 toks/s, output: 298.11 toks/s]
WARNING 01-08 21:24:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:24:04,459][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:24:08,294][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:57,  3.83s/it, est. speed input: 410.44 toks/s, output: 7.04 toks/s]
[2025-01-08 21:24:11,697][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:07<00:04,  1.43it/s, est. speed input: 1957.69 toks/s, output: 52.09 toks/s]
[2025-01-08 21:24:13,074][root][ERROR] - Processed prompts:  62%|######2   | 10/16 [00:08<00:04,  1.26it/s, est. speed input: 1775.68 toks/s, output: 66.98 toks/s]
[2025-01-08 21:24:13,074][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:08<00:00,  1.86it/s, est. speed input: 2842.06 toks/s, output: 206.28 toks/s]
WARNING 01-08 21:24:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:24:13,424][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:24:14,481][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:01<00:01,  1.06s/it, est. speed input: 1294.26 toks/s, output: 28.38 toks/s]
[2025-01-08 21:24:17,353][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  2.12s/it, est. speed input: 748.76 toks/s, output: 58.54 toks/s]
[2025-01-08 21:24:17,353][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.96s/it, est. speed input: 748.76 toks/s, output: 58.54 toks/s]
[2025-01-08 21:24:25,504][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:24:25,558][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:24:27,241][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.68s/it]
[2025-01-08 21:24:28,834][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.63s/it]
[2025-01-08 21:24:30,436][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:24:30,961][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:24:30,961][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 21:24:42,181][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:24:42,675][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:24:42,727][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:24:44,612][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.88s/it]
[2025-01-08 21:24:46,207][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 21:24:47,784][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.65s/it]
[2025-01-08 21:24:48,285][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 21:24:48,285][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.39s/it]
[2025-01-08 21:25:04,372][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:25:04,676][root][INFO] - Loading VLLM model.
WARNING 01-08 21:25:04 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:25:04 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:25:05 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:25:05 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:25:05,661][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:25:06,984][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:25:07,376][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:25:08,685][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:25:10,030][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
[2025-01-08 21:25:10,030][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:25:10 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:25:24 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:25:24 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:25:24 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:25:46 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:25:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:25:46,634][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:25:49,843][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:48,  3.21s/it, est. speed input: 157.38 toks/s, output: 10.91 toks/s]
[2025-01-08 21:25:49,937][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.84it/s, est. speed input: 2446.22 toks/s, output: 179.53 toks/s]
WARNING 01-08 21:25:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:25:50,164][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:25:52,583][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.42s/it, est. speed input: 239.38 toks/s, output: 13.64 toks/s]
[2025-01-08 21:25:52,584][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.61it/s, est. speed input: 3842.67 toks/s, output: 218.23 toks/s]
WARNING 01-08 21:25:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:25:52,814][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:25:55,276][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 283.93 toks/s, output: 11.78 toks/s]
[2025-01-08 21:25:55,277][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.50it/s, est. speed input: 4541.70 toks/s, output: 188.42 toks/s]
WARNING 01-08 21:25:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:25:55,507][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:25:58,119][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 267.22 toks/s, output: 12.63 toks/s]
[2025-01-08 21:25:58,120][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.12it/s, est. speed input: 4287.13 toks/s, output: 202.09 toks/s]
WARNING 01-08 21:25:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:25:58,357][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:01,346][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.99s/it, est. speed input: 337.27 toks/s, output: 9.70 toks/s]
[2025-01-08 21:26:01,346][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.35it/s, est. speed input: 5395.14 toks/s, output: 155.22 toks/s]
WARNING 01-08 21:26:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:26:01,590][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:04,422][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.83s/it, est. speed input: 288.46 toks/s, output: 11.65 toks/s]
[2025-01-08 21:26:04,423][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.65it/s, est. speed input: 4625.91 toks/s, output: 186.38 toks/s]
WARNING 01-08 21:26:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:26:04,652][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:05,497][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1055.37 toks/s, output: 39.04 toks/s]
[2025-01-08 21:26:05,498][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1055.37 toks/s, output: 39.04 toks/s]
WARNING 01-08 21:26:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:26:05,736][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:08,789][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:42,  3.05s/it, est. speed input: 431.39 toks/s, output: 6.88 toks/s]
[2025-01-08 21:26:15,284][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:09<01:06,  5.08s/it, est. speed input: 275.88 toks/s, output: 23.15 toks/s]
[2025-01-08 21:26:15,285][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.57it/s, est. speed input: 2068.98 toks/s, output: 295.45 toks/s]
WARNING 01-08 21:26:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:26:15,564][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:19,502][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:59,  3.94s/it, est. speed input: 400.27 toks/s, output: 7.37 toks/s]
[2025-01-08 21:26:25,939][root][ERROR] - Processed prompts:  12%|#2        | 2/16 [00:10<01:15,  5.41s/it, est. speed input: 303.63 toks/s, output: 22.07 toks/s]
[2025-01-08 21:26:25,940][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:10<00:00,  1.54it/s, est. speed input: 2386.31 toks/s, output: 291.95 toks/s]
WARNING 01-08 21:26:26 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:26:26,259][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:26:30,013][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.75s/it, est. speed input: 418.81 toks/s, output: 53.28 toks/s]
[2025-01-08 21:26:30,013][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.75s/it, est. speed input: 418.81 toks/s, output: 53.28 toks/s]
[2025-01-08 21:26:38,283][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:26:38,337][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:26:40,010][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.67s/it]
[2025-01-08 21:26:41,642][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 21:26:43,233][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:26:43,757][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:26:43,757][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 21:26:54,919][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:26:55,402][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:26:55,454][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:26:57,324][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.87s/it]
[2025-01-08 21:26:58,905][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.70s/it]
[2025-01-08 21:27:00,466][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 21:27:00,971][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:27:00,971][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 21:27:17,819][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:27:18,157][root][INFO] - Loading VLLM model.
WARNING 01-08 21:27:18 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:27:18 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:27:18 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:27:18 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:27:19,211][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:27:20,530][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:27:20,919][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:27:22,227][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.02s/it]
[2025-01-08 21:27:23,566][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:27:23,567][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:27:23 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:27:37 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:27:38 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:27:38 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:27:59 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:28:00 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:00,145][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:03,212][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:03<00:45,  3.07s/it, est. speed input: 164.72 toks/s, output: 11.09 toks/s]
[2025-01-08 21:28:03,312][root][ERROR] - Processed prompts:  38%|###7      | 6/16 [00:03<00:03,  2.54it/s, est. speed input: 956.88 toks/s, output: 66.95 toks/s]
[2025-01-08 21:28:03,340][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.01it/s, est. speed input: 2529.74 toks/s, output: 184.72 toks/s]
WARNING 01-08 21:28:03 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:03,564][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:06,001][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.44s/it, est. speed input: 237.63 toks/s, output: 13.54 toks/s]
[2025-01-08 21:28:06,002][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.56it/s, est. speed input: 3813.43 toks/s, output: 216.64 toks/s]
WARNING 01-08 21:28:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:06,237][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:08,702][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 283.59 toks/s, output: 11.77 toks/s]
[2025-01-08 21:28:08,703][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.49it/s, est. speed input: 4536.35 toks/s, output: 188.20 toks/s]
WARNING 01-08 21:28:08 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:08,927][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:11,541][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 267.05 toks/s, output: 12.63 toks/s]
[2025-01-08 21:28:11,542][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.12it/s, est. speed input: 4283.22 toks/s, output: 201.96 toks/s]
WARNING 01-08 21:28:11 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:11,775][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:14,770][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.99s/it, est. speed input: 336.63 toks/s, output: 9.68 toks/s]
[2025-01-08 21:28:14,770][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.34it/s, est. speed input: 5384.96 toks/s, output: 154.92 toks/s]
WARNING 01-08 21:28:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:14,998][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:17,819][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.82s/it, est. speed input: 289.70 toks/s, output: 11.70 toks/s]
[2025-01-08 21:28:17,819][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.67it/s, est. speed input: 4644.76 toks/s, output: 187.18 toks/s]
WARNING 01-08 21:28:18 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:18,023][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:18,871][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1052.41 toks/s, output: 38.93 toks/s]
[2025-01-08 21:28:18,871][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1052.41 toks/s, output: 38.93 toks/s]
WARNING 01-08 21:28:19 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:19,103][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:22,149][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:03<00:42,  3.05s/it, est. speed input: 432.42 toks/s, output: 6.90 toks/s]
[2025-01-08 21:28:28,643][root][ERROR] - Processed prompts:  13%|#3        | 2/15 [00:09<01:05,  5.07s/it, est. speed input: 276.10 toks/s, output: 23.17 toks/s]
[2025-01-08 21:28:28,644][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.57it/s, est. speed input: 2070.59 toks/s, output: 295.68 toks/s]
WARNING 01-08 21:28:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:28,942][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:39,594][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:10<02:39, 10.65s/it, est. speed input: 147.58 toks/s, output: 18.78 toks/s]
[2025-01-08 21:28:39,594][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:10<00:00,  1.50it/s, est. speed input: 2324.13 toks/s, output: 300.41 toks/s]
WARNING 01-08 21:28:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:28:39,905][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:28:43,654][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.75s/it, est. speed input: 419.60 toks/s, output: 53.35 toks/s]
[2025-01-08 21:28:43,654][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.75s/it, est. speed input: 419.60 toks/s, output: 53.35 toks/s]
[2025-01-08 21:28:51,998][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:28:52,052][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:28:53,752][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.70s/it]
[2025-01-08 21:28:55,379][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 21:28:57,088][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 21:28:57,647][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 21:28:57,648][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.40s/it]
[2025-01-08 21:29:08,787][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:29:09,375][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:29:09,427][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:29:11,337][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.91s/it]
[2025-01-08 21:29:12,976][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.75s/it]
[2025-01-08 21:29:14,612][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.70s/it]
[2025-01-08 21:29:15,120][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 21:29:15,120][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.42s/it]
[2025-01-08 21:29:32,135][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:29:32,470][root][INFO] - Loading VLLM model.
WARNING 01-08 21:29:32 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:29:32 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:29:33 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:29:33 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:29:33,504][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:29:34,875][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 21:29:35,277][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 21:29:36,651][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:29:38,058][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.20s/it]
[2025-01-08 21:29:38,058][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
INFO 01-08 21:29:38 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:29:52 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:29:52 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:29:52 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:30:14 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:30:14 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:14,351][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:17,191][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.84s/it, est. speed input: 177.80 toks/s, output: 11.97 toks/s]
[2025-01-08 21:30:17,295][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:02<00:06,  1.77it/s, est. speed input: 686.15 toks/s, output: 47.89 toks/s]
[2025-01-08 21:30:17,374][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.29it/s, est. speed input: 2672.73 toks/s, output: 197.48 toks/s]
WARNING 01-08 21:30:17 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:17,597][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:20,008][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 240.15 toks/s, output: 13.69 toks/s]
[2025-01-08 21:30:20,009][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3856.71 toks/s, output: 218.94 toks/s]
WARNING 01-08 21:30:20 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:20,238][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:22,692][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.45s/it, est. speed input: 284.85 toks/s, output: 11.82 toks/s]
[2025-01-08 21:30:25,547][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.43it/s, est. speed input: 2071.03 toks/s, output: 119.80 toks/s]
[2025-01-08 21:30:25,548][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.01it/s, est. speed input: 2071.03 toks/s, output: 119.80 toks/s]
WARNING 01-08 21:30:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:25,774][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:28,264][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.49s/it, est. speed input: 280.31 toks/s, output: 13.25 toks/s]
[2025-01-08 21:30:28,265][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.02it/s, est. speed input: 4217.34 toks/s, output: 198.74 toks/s]
WARNING 01-08 21:30:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:28,477][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:32,118][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.64s/it, est. speed input: 205.99 toks/s, output: 54.93 toks/s]
[2025-01-08 21:30:32,119][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.64s/it, est. speed input: 205.99 toks/s, output: 54.93 toks/s]
WARNING 01-08 21:30:32 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:32,330][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:33,157][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 840.18 toks/s, output: 39.89 toks/s]
[2025-01-08 21:30:33,158][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.21it/s, est. speed input: 840.18 toks/s, output: 39.89 toks/s]
WARNING 01-08 21:30:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:33,411][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:36,244][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.83s/it, est. speed input: 355.85 toks/s, output: 10.24 toks/s]
[2025-01-08 21:30:36,262][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.26it/s, est. speed input: 5304.06 toks/s, output: 152.94 toks/s]
WARNING 01-08 21:30:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:36,497][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:39,052][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:33,  2.55s/it, est. speed input: 319.77 toks/s, output: 12.92 toks/s]
[2025-01-08 21:30:39,053][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:02<00:00,  5.48it/s, est. speed input: 4487.80 toks/s, output: 180.78 toks/s]
WARNING 01-08 21:30:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:39,276][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:40,239][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 1278.34 toks/s, output: 30.11 toks/s]
[2025-01-08 21:30:43,125][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  2.09s/it, est. speed input: 595.76 toks/s, output: 59.50 toks/s]
[2025-01-08 21:30:43,125][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:03<00:00,  1.92s/it, est. speed input: 595.76 toks/s, output: 59.50 toks/s]
WARNING 01-08 21:30:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:43,338][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:44,300][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.04it/s, est. speed input: 846.87 toks/s, output: 34.33 toks/s]
[2025-01-08 21:30:44,300][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.08it/s, est. speed input: 1693.16 toks/s, output: 68.64 toks/s]
WARNING 01-08 21:30:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:44,538][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:30:48,047][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:03<00:45,  3.51s/it, est. speed input: 375.32 toks/s, output: 10.83 toks/s]
[2025-01-08 21:30:53,656][root][ERROR] - Processed prompts:  14%|#4        | 2/14 [00:09<00:56,  4.74s/it, est. speed input: 288.89 toks/s, output: 26.10 toks/s]
[2025-01-08 21:30:53,656][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:09<00:00,  1.54it/s, est. speed input: 2022.31 toks/s, output: 289.31 toks/s]
WARNING 01-08 21:30:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:30:53,921][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:31:04,591][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:10<02:40, 10.67s/it, est. speed input: 147.70 toks/s, output: 18.74 toks/s]
[2025-01-08 21:31:04,592][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:10<00:00,  1.50it/s, est. speed input: 2340.09 toks/s, output: 299.88 toks/s]
WARNING 01-08 21:31:04 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:31:04,953][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:31:09,213][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:04<00:04,  4.26s/it, est. speed input: 423.80 toks/s, output: 46.96 toks/s]
[2025-01-08 21:31:09,213][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:04<00:00,  2.13s/it, est. speed input: 845.89 toks/s, output: 93.91 toks/s]
[2025-01-08 21:31:17,668][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:31:17,722][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:31:19,411][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.69s/it]
[2025-01-08 21:31:21,031][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 21:31:22,622][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:31:23,144][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:31:23,145][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.36s/it]
[2025-01-08 21:31:34,139][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:31:34,675][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:31:34,727][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:31:36,572][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.84s/it]
[2025-01-08 21:31:38,195][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 21:31:39,738][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.64s/it]
[2025-01-08 21:31:40,236][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.19s/it]
[2025-01-08 21:31:40,237][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.38s/it]
[2025-01-08 21:31:57,448][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:31:57,743][root][INFO] - Loading VLLM model.
WARNING 01-08 21:31:57 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:31:57 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:31:58 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:31:58 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:31:58,776][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:32:00,091][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
[2025-01-08 21:32:00,484][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]
[2025-01-08 21:32:01,782][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 21:32:03,127][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:32:03,127][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
INFO 01-08 21:32:03 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:32:17 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:32:17 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:32:17 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:32:39 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:32:39 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:39,465][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:42,251][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:41,  2.79s/it, est. speed input: 181.29 toks/s, output: 12.21 toks/s]
[2025-01-08 21:32:42,355][root][ERROR] - Processed prompts:  25%|##5       | 4/16 [00:02<00:06,  1.80it/s, est. speed input: 699.06 toks/s, output: 48.80 toks/s]
[2025-01-08 21:32:42,406][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  5.44it/s, est. speed input: 2747.81 toks/s, output: 199.96 toks/s]
WARNING 01-08 21:32:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:42,627][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:45,079][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.45s/it, est. speed input: 236.17 toks/s, output: 13.46 toks/s]
[2025-01-08 21:32:45,080][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.52it/s, est. speed input: 3789.19 toks/s, output: 215.31 toks/s]
WARNING 01-08 21:32:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:45,307][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:47,763][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 284.64 toks/s, output: 11.81 toks/s]
[2025-01-08 21:32:50,636][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.42it/s, est. speed input: 2098.67 toks/s, output: 120.66 toks/s]
[2025-01-08 21:32:50,637][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.00it/s, est. speed input: 2098.67 toks/s, output: 120.66 toks/s]
WARNING 01-08 21:32:50 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:50,859][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:53,342][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:34,  2.48s/it, est. speed input: 281.14 toks/s, output: 13.29 toks/s]
[2025-01-08 21:32:53,342][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  6.04it/s, est. speed input: 4226.47 toks/s, output: 199.32 toks/s]
WARNING 01-08 21:32:53 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:53,552][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:57,233][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.68s/it, est. speed input: 259.53 toks/s, output: 54.35 toks/s]
[2025-01-08 21:32:57,233][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.68s/it, est. speed input: 259.53 toks/s, output: 54.35 toks/s]
WARNING 01-08 21:32:57 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:57,467][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:32:58,415][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.06it/s, est. speed input: 807.11 toks/s, output: 34.82 toks/s]
[2025-01-08 21:32:58,416][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.11it/s, est. speed input: 1538.74 toks/s, output: 69.61 toks/s]
WARNING 01-08 21:32:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:32:58,643][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:01,274][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:02<00:34,  2.63s/it, est. speed input: 383.24 toks/s, output: 10.27 toks/s]
[2025-01-08 21:33:04,803][root][ERROR] - Processed prompts:  86%|########5 | 12/14 [00:06<00:00,  2.18it/s, est. speed input: 1965.05 toks/s, output: 84.75 toks/s]
[2025-01-08 21:33:04,803][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:06<00:00,  2.27it/s, est. speed input: 2292.40 toks/s, output: 149.69 toks/s]
WARNING 01-08 21:33:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:05,034][root][ERROR] - Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:06,921][root][ERROR] - Processed prompts:  11%|#1        | 1/9 [00:01<00:15,  1.89s/it, est. speed input: 432.33 toks/s, output: 17.48 toks/s]
[2025-01-08 21:33:06,922][root][ERROR] - Processed prompts: 100%|##########| 9/9 [00:01<00:00,  4.77it/s, est. speed input: 3901.61 toks/s, output: 157.31 toks/s]
WARNING 01-08 21:33:07 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:07,145][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:13,563][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:06<00:38,  6.42s/it, est. speed input: 169.69 toks/s, output: 31.16 toks/s]
[2025-01-08 21:33:13,563][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:06<00:00,  1.09it/s, est. speed input: 1312.38 toks/s, output: 218.13 toks/s]
WARNING 01-08 21:33:13 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:13,781][root][ERROR] - Processed prompts:   0%|          | 0/5 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:15,140][root][ERROR] - Processed prompts:  20%|##        | 1/5 [00:01<00:05,  1.36s/it, est. speed input: 598.73 toks/s, output: 24.30 toks/s]
[2025-01-08 21:33:15,140][root][ERROR] - Processed prompts: 100%|##########| 5/5 [00:01<00:00,  3.68it/s, est. speed input: 2993.39 toks/s, output: 121.47 toks/s]
WARNING 01-08 21:33:15 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:15,372][root][ERROR] - Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:20,695][root][ERROR] - Processed prompts:   9%|9         | 1/11 [00:05<00:53,  5.32s/it, est. speed input: 247.81 toks/s, output: 20.85 toks/s]
[2025-01-08 21:33:23,420][root][ERROR] - Processed prompts:  18%|#8        | 2/11 [00:08<00:34,  3.79s/it, est. speed input: 327.77 toks/s, output: 38.64 toks/s]
[2025-01-08 21:33:23,421][root][ERROR] - Processed prompts: 100%|##########| 11/11 [00:08<00:00,  1.37it/s, est. speed input: 1841.77 toks/s, output: 262.28 toks/s]
WARNING 01-08 21:33:23 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:23,663][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:24,786][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:01<00:02,  1.12s/it, est. speed input: 782.19 toks/s, output: 29.40 toks/s]
[2025-01-08 21:33:24,786][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:01<00:00,  2.67it/s, est. speed input: 2282.37 toks/s, output: 88.16 toks/s]
WARNING 01-08 21:33:25 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:25,059][root][ERROR] - Processed prompts:   0%|          | 0/13 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:34,497][root][ERROR] - Processed prompts:   8%|7         | 1/13 [00:09<01:53,  9.44s/it, est. speed input: 165.82 toks/s, output: 21.19 toks/s]
[2025-01-08 21:33:34,497][root][ERROR] - Processed prompts: 100%|##########| 13/13 [00:09<00:00,  1.38it/s, est. speed input: 2214.80 toks/s, output: 275.47 toks/s]
WARNING 01-08 21:33:34 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:34,798][root][ERROR] - Processed prompts:   0%|          | 0/7 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:41,944][root][ERROR] - Processed prompts:  14%|#4        | 1/7 [00:07<00:42,  7.15s/it, est. speed input: 255.11 toks/s, output: 27.99 toks/s]
[2025-01-08 21:33:41,944][root][ERROR] - Processed prompts: 100%|##########| 7/7 [00:07<00:00,  1.02s/it, est. speed input: 1863.47 toks/s, output: 195.90 toks/s]
WARNING 01-08 21:33:42 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:33:42,198][root][ERROR] - Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:33:47,168][root][ERROR] - Processed prompts:  33%|###3      | 1/3 [00:04<00:09,  4.97s/it, est. speed input: 402.82 toks/s, output: 40.24 toks/s]
[2025-01-08 21:33:47,168][root][ERROR] - Processed prompts: 100%|##########| 3/3 [00:04<00:00,  1.66s/it, est. speed input: 1258.44 toks/s, output: 120.71 toks/s]
[2025-01-08 21:33:55,712][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:33:55,766][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:33:57,483][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.72s/it]
[2025-01-08 21:33:59,086][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.65s/it]
[2025-01-08 21:34:00,697][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.63s/it]
[2025-01-08 21:34:01,233][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 21:34:01,233][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:34:12,442][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:34:12,947][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:34:12,999][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:34:14,904][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.90s/it]
[2025-01-08 21:34:16,594][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.78s/it]
[2025-01-08 21:34:18,224][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.71s/it]
[2025-01-08 21:34:18,734][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.24s/it]
[2025-01-08 21:34:18,734][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.43s/it]
[2025-01-08 21:34:37,056][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:34:37,435][root][INFO] - Loading VLLM model.
WARNING 01-08 21:34:43 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:34:43 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:34:43 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:34:43 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:34:44,154][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:34:45,470][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.32s/it]
[2025-01-08 21:34:45,860][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.30it/s]
[2025-01-08 21:34:47,160][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.01s/it]
[2025-01-08 21:34:48,487][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.14s/it]
[2025-01-08 21:34:48,487][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
INFO 01-08 21:34:48 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:35:02 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:35:03 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:35:03 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:35:24 model_runner.py:1335] Graph capturing finished in 22 secs.
WARNING 01-08 21:35:24 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:24,900][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:27,830][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:43,  2.93s/it, est. speed input: 172.38 toks/s, output: 11.61 toks/s]
[2025-01-08 21:35:27,930][root][ERROR] - Processed prompts:  31%|###1      | 5/16 [00:03<00:05,  2.19it/s, est. speed input: 833.38 toks/s, output: 57.76 toks/s]
[2025-01-08 21:35:28,220][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  7.96it/s, est. speed input: 2433.72 toks/s, output: 181.32 toks/s]
[2025-01-08 21:35:28,220][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  4.82it/s, est. speed input: 2433.72 toks/s, output: 181.32 toks/s]
WARNING 01-08 21:35:28 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:28,449][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:30,862][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.41s/it, est. speed input: 239.59 toks/s, output: 13.68 toks/s]
[2025-01-08 21:35:30,862][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.63it/s, est. speed input: 3856.53 toks/s, output: 218.81 toks/s]
WARNING 01-08 21:35:31 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:31,085][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:33,547][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.46s/it, est. speed input: 284.03 toks/s, output: 11.78 toks/s]
[2025-01-08 21:35:33,564][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.46it/s, est. speed input: 4512.20 toks/s, output: 187.60 toks/s]
WARNING 01-08 21:35:33 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:33,789][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:36,400][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 267.01 toks/s, output: 12.64 toks/s]
[2025-01-08 21:35:36,401][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.13it/s, est. speed input: 4293.39 toks/s, output: 202.22 toks/s]
WARNING 01-08 21:35:36 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:36,605][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:37,464][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 893.30 toks/s, output: 40.76 toks/s]
[2025-01-08 21:35:37,464][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 893.30 toks/s, output: 40.76 toks/s]
WARNING 01-08 21:35:37 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:37,692][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:40,541][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:39,  2.85s/it, est. speed input: 353.83 toks/s, output: 10.18 toks/s]
[2025-01-08 21:35:40,559][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.23it/s, est. speed input: 5274.77 toks/s, output: 152.09 toks/s]
WARNING 01-08 21:35:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:40,788][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:43,464][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.68s/it, est. speed input: 304.89 toks/s, output: 12.33 toks/s]
[2025-01-08 21:35:43,465][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.60it/s, est. speed input: 4591.99 toks/s, output: 184.90 toks/s]
WARNING 01-08 21:35:43 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:43,669][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:44,461][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1272.95 toks/s, output: 36.62 toks/s]
[2025-01-08 21:35:44,461][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 1272.95 toks/s, output: 36.62 toks/s]
WARNING 01-08 21:35:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:44,663][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:45,507][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1052.60 toks/s, output: 39.12 toks/s]
[2025-01-08 21:35:45,508][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1052.60 toks/s, output: 39.12 toks/s]
WARNING 01-08 21:35:45 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:45,748][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:35:55,459][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:09<02:15,  9.71s/it, est. speed input: 135.62 toks/s, output: 20.60 toks/s]
[2025-01-08 21:35:55,460][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:09<00:00,  1.54it/s, est. speed input: 2034.35 toks/s, output: 308.91 toks/s]
WARNING 01-08 21:35:55 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:35:55,751][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:36:06,409][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:10<02:39, 10.66s/it, est. speed input: 147.58 toks/s, output: 18.76 toks/s]
[2025-01-08 21:36:06,410][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:10<00:00,  1.50it/s, est. speed input: 2341.24 toks/s, output: 300.22 toks/s]
WARNING 01-08 21:36:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:36:06,725][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:36:10,469][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.74s/it, est. speed input: 420.51 toks/s, output: 53.43 toks/s]
[2025-01-08 21:36:10,469][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.74s/it, est. speed input: 420.51 toks/s, output: 53.43 toks/s]
[2025-01-08 21:36:18,954][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:36:19,009][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:36:20,752][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.74s/it]
[2025-01-08 21:36:22,370][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.67s/it]
[2025-01-08 21:36:23,966][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.64s/it]
[2025-01-08 21:36:24,494][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.20s/it]
[2025-01-08 21:36:24,494][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:36:35,533][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:36:36,152][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:36:36,203][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:36:37,976][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.77s/it]
[2025-01-08 21:36:39,555][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.66s/it]
[2025-01-08 21:36:41,116][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.61s/it]
[2025-01-08 21:36:41,609][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.17s/it]
[2025-01-08 21:36:41,609][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.35s/it]
[2025-01-08 21:36:58,789][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
[2025-01-08 21:36:59,112][root][INFO] - Loading VLLM model.
WARNING 01-08 21:36:59 arg_utils.py:872] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.
INFO 01-08 21:36:59 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)
INFO 01-08 21:36:59 model_runner.py:915] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...
INFO 01-08 21:36:59 weight_utils.py:236] Using model weights format ['*.safetensors']
[2025-01-08 21:37:00,130][root][ERROR] - Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:37:01,498][root][ERROR] - Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.37s/it]
[2025-01-08 21:37:01,897][root][ERROR] - Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.25it/s]
[2025-01-08 21:37:03,261][root][ERROR] - Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.06s/it]
[2025-01-08 21:37:04,663][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
[2025-01-08 21:37:04,663][root][ERROR] - Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.13s/it]
INFO 01-08 21:37:04 model_runner.py:926] Loading model weights took 14.9614 GB
INFO 01-08 21:37:18 gpu_executor.py:122] # GPU blocks: 19941, # CPU blocks: 2048
INFO 01-08 21:37:19 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 21:37:19 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-08 21:37:40 model_runner.py:1335] Graph capturing finished in 21 secs.
WARNING 01-08 21:37:40 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:40,979][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:37:43,827][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:42,  2.85s/it, est. speed input: 177.35 toks/s, output: 11.59 toks/s]
[2025-01-08 21:37:43,948][root][ERROR] - Processed prompts:  56%|#####6    | 9/16 [00:02<00:01,  4.12it/s, est. speed input: 1531.17 toks/s, output: 104.44 toks/s]
[2025-01-08 21:37:44,060][root][ERROR] - Processed prompts:  81%|########1 | 13/16 [00:03<00:00,  6.34it/s, est. speed input: 2131.13 toks/s, output: 151.60 toks/s]
[2025-01-08 21:37:44,077][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:03<00:00,  5.16it/s, est. speed input: 2608.22 toks/s, output: 191.74 toks/s]
WARNING 01-08 21:37:44 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:44,318][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:37:46,757][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.44s/it, est. speed input: 237.08 toks/s, output: 13.54 toks/s]
[2025-01-08 21:37:46,757][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.56it/s, est. speed input: 3812.49 toks/s, output: 216.50 toks/s]
WARNING 01-08 21:37:46 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:46,983][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:37:49,450][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:36,  2.47s/it, est. speed input: 283.44 toks/s, output: 11.76 toks/s]
[2025-01-08 21:37:49,450][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.49it/s, est. speed input: 4533.97 toks/s, output: 188.10 toks/s]
WARNING 01-08 21:37:49 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:49,683][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:37:52,297][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:39,  2.61s/it, est. speed input: 266.68 toks/s, output: 12.63 toks/s]
[2025-01-08 21:37:52,298][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:02<00:00,  6.12it/s, est. speed input: 4285.10 toks/s, output: 201.98 toks/s]
WARNING 01-08 21:37:52 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:52,529][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:37:55,524][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:02<00:44,  2.99s/it, est. speed input: 336.60 toks/s, output: 9.68 toks/s]
[2025-01-08 21:37:58,411][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  3.15it/s, est. speed input: 2741.88 toks/s, output: 107.95 toks/s]
[2025-01-08 21:37:58,411][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:05<00:00,  2.72it/s, est. speed input: 2741.88 toks/s, output: 107.95 toks/s]
WARNING 01-08 21:37:58 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:37:58,643][root][ERROR] - Processed prompts:   0%|          | 0/15 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:01,321][root][ERROR] - Processed prompts:   7%|6         | 1/15 [00:02<00:37,  2.68s/it, est. speed input: 304.74 toks/s, output: 12.32 toks/s]
[2025-01-08 21:38:01,321][root][ERROR] - Processed prompts: 100%|##########| 15/15 [00:02<00:00,  5.60it/s, est. speed input: 4588.54 toks/s, output: 184.81 toks/s]
WARNING 01-08 21:38:01 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:38:01,529][root][ERROR] - Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:05,238][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.71s/it, est. speed input: 341.86 toks/s, output: 53.92 toks/s]
[2025-01-08 21:38:05,238][root][ERROR] - Processed prompts: 100%|##########| 1/1 [00:03<00:00,  3.71s/it, est. speed input: 341.86 toks/s, output: 53.92 toks/s]
WARNING 01-08 21:38:05 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:38:05,444][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:06,427][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:00<00:00,  1.02it/s, est. speed input: 897.09 toks/s, output: 33.56 toks/s]
[2025-01-08 21:38:06,428][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:00<00:00,  2.03it/s, est. speed input: 1720.26 toks/s, output: 67.10 toks/s]
WARNING 01-08 21:38:06 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:38:06,665][root][ERROR] - Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:16,049][root][ERROR] - Processed prompts:   7%|7         | 1/14 [00:09<02:01,  9.38s/it, est. speed input: 140.36 toks/s, output: 21.32 toks/s]
[2025-01-08 21:38:16,049][root][ERROR] - Processed prompts: 100%|##########| 14/14 [00:09<00:00,  1.49it/s, est. speed input: 1964.88 toks/s, output: 298.39 toks/s]
WARNING 01-08 21:38:16 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:38:16,340][root][ERROR] - Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:27,043][root][ERROR] - Processed prompts:   6%|6         | 1/16 [00:10<02:40, 10.70s/it, est. speed input: 147.07 toks/s, output: 18.69 toks/s]
[2025-01-08 21:38:27,044][root][ERROR] - Processed prompts: 100%|##########| 16/16 [00:10<00:00,  1.49it/s, est. speed input: 2347.16 toks/s, output: 298.98 toks/s]
WARNING 01-08 21:38:27 tokenizer.py:174] No tokenizer found in /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob, using base model tokenizer instead. (Exception: Can't load tokenizer for '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob' is the correct path to a directory containing all relevant files for a GPT2TokenizerFast tokenizer.)
[2025-01-08 21:38:27,355][root][ERROR] - Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
[2025-01-08 21:38:31,625][root][ERROR] - Processed prompts:  50%|#####     | 1/2 [00:04<00:04,  4.27s/it, est. speed input: 368.68 toks/s, output: 46.85 toks/s]
[2025-01-08 21:38:31,625][root][ERROR] - Processed prompts: 100%|##########| 2/2 [00:04<00:00,  2.13s/it, est. speed input: 837.52 toks/s, output: 93.68 toks/s]
[2025-01-08 21:38:40,016][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:38:40,070][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:38:41,824][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.75s/it]
[2025-01-08 21:38:43,497][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.71s/it]
[2025-01-08 21:38:45,157][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:05<00:01,  1.68s/it]
[2025-01-08 21:38:45,696][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.23s/it]
[2025-01-08 21:38:45,696][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.41s/it]
[2025-01-08 21:38:56,724][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_alice
[2025-01-08 21:38:57,263][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-01-08 21:38:57,317][root][ERROR] - Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[2025-01-08 21:38:59,141][root][ERROR] - Loading checkpoint shards:  25%|##5       | 1/4 [00:01<00:05,  1.82s/it]
[2025-01-08 21:39:00,738][root][ERROR] - Loading checkpoint shards:  50%|#####     | 2/4 [00:03<00:03,  1.69s/it]
[2025-01-08 21:39:02,284][root][ERROR] - Loading checkpoint shards:  75%|#######5  | 3/4 [00:04<00:01,  1.62s/it]
[2025-01-08 21:39:02,793][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.18s/it]
[2025-01-08 21:39:02,793][root][ERROR] - Loading checkpoint shards: 100%|##########| 4/4 [00:05<00:00,  1.37s/it]
[2025-01-08 21:39:20,188][root][INFO] - LoRA weights saved to /home/mila/d/dereck.piche/llm_negotiation/outputs/2025-01-08/17-08-38/ad_bob
