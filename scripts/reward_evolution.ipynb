{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from mllm.markov_games.rollout_tree import *\n",
    "from mllm.markov_games.export import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scripts.fetch_trees import *\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b88eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_trees = get_rollout_trees(\"(...)/seed_1000/\")\n",
    "print(f\"Rollout trees from {len(rollout_trees)} iterations loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0728cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_agent_rewards(rollout_trees_by_iteration):\n",
    "    \"\"\"\n",
    "    Analyze agent rewards across iterations, calculating mean rewards per time step.\n",
    "    \n",
    "    Args:\n",
    "        rollout_trees_by_iteration: List of lists, where each inner list contains \n",
    "                                  RolloutTreeRootNode objects for one iteration\n",
    "    \"\"\"\n",
    "    iteration_numbers = []\n",
    "    agent_rewards_by_iteration = defaultdict(list)\n",
    "    \n",
    "    for iteration_idx, rollout_trees in enumerate(rollout_trees_by_iteration):\n",
    "        if not rollout_trees:\n",
    "            continue\n",
    "            \n",
    "        # Collect rewards from all rollout trees in this iteration\n",
    "        iteration_agent_rewards = defaultdict(list)\n",
    "        \n",
    "        for tree in rollout_trees:\n",
    "            # Get main path for this tree\n",
    "            main_path, _ = get_rollout_tree_paths(tree)\n",
    "            \n",
    "            # Get all agents\n",
    "            agents = get_all_agents(tree)\n",
    "            \n",
    "            # Gather rewards for each agent in the main path\n",
    "            all_rewards = gather_all_rewards(main_path)\n",
    "            \n",
    "            if all_rewards:\n",
    "                # Calculate mean reward per time step for each agent\n",
    "                for agent in agents:\n",
    "                    agent_step_rewards = [step_rewards.get(agent, 0) for step_rewards in all_rewards]\n",
    "                    # Mean across time steps for this agent in this tree\n",
    "                    agent_mean_per_step = np.mean(agent_step_rewards)\n",
    "                    iteration_agent_rewards[agent].append(agent_mean_per_step)\n",
    "        \n",
    "        # Calculate mean across all trees for this iteration\n",
    "        if iteration_agent_rewards:\n",
    "            iteration_numbers.append(iteration_idx)\n",
    "            \n",
    "            for agent, rewards in iteration_agent_rewards.items():\n",
    "                # Mean across all trees for this agent in this iteration\n",
    "                agent_iteration_mean = np.mean(rewards)\n",
    "                agent_rewards_by_iteration[agent].append(agent_iteration_mean)\n",
    "    \n",
    "    return iteration_numbers, agent_rewards_by_iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cd6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agent_reward_evolution(iteration_numbers, agent_rewards_by_iteration, output_path=None):\n",
    "    \"\"\"\n",
    "    Create a single plot showing individual agent reward evolution.\n",
    "    \"\"\"\n",
    "    # Create a smaller, focused plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(agent_rewards_by_iteration)))\n",
    "    \n",
    "    for i, (agent, rewards) in enumerate(agent_rewards_by_iteration.items()):\n",
    "        plt.plot(iteration_numbers[:len(rewards)], rewards, \n",
    "                marker='o', linewidth=2, markersize=5, \n",
    "                color=colors[i], label=f'Agent {agent}')\n",
    "    \n",
    "    plt.title('Individual Agent Reward Evolution\\n(Mean per Time Step)', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Mean Reward per Time Step')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if agent_rewards_by_iteration:\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"Number of iterations: {len(iteration_numbers)}\")\n",
    "        for agent, rewards in agent_rewards_by_iteration.items():\n",
    "            if rewards:\n",
    "                print(f\"Agent {agent}: {rewards[0]:.3f} â†’ {rewards[-1]:.3f} (change: {rewards[-1] - rewards[0]:.3f})\")\n",
    "    else:\n",
    "        print(\"No reward data found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8afbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze agent reward evolution (mean across time steps and iterations)\n",
    "iteration_numbers, agent_rewards_by_iteration = analyze_agent_rewards(rollout_trees)\n",
    "\n",
    "# Create the plot\n",
    "plot_agent_reward_evolution(iteration_numbers, agent_rewards_by_iteration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
