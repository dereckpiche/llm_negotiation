defaults:
  - dereck_base_config.yaml

experiment:
  name: "SUM_REWARDS/2_big_adapters"
  description: "Sum rewards with 2 big adapters"

matches:
  agents:
    alice:
      kwargs:
        agent_name: "alice"
        policy_id: "llama/adapter_alice"
    bob:
      kwargs:
        agent_name: "bob"
        policy_id: "llama/adapter_bob"

temperature: 0.7



models:
  llama:
    class: local_llm_v2
    init_args:
      vllm_params:
        max_lora_rank: 512
      name: 'llama'
      adapter_configs:
        adapter_alice:
          type: "lora"
          optimizer_method: "Adam"
          optimizer_kwargs:
            lr: 1e-6
            weight_decay: 0.0
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 512
            lora_alpha: 1024
            lora_dropout: 0.0
            target_modules: "all-linear"
        adapter_bob:
          type: "lora"
          optimizer_method: "Adam"
          optimizer_kwargs:
            lr: 1e-6
            weight_decay: 0.0
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 512
            lora_alpha: 1024
            lora_dropout: 0.0
            target_modules: "all-linear"


####################################################################################################
# TRAINING
####################################################################################################
default_kwargs: &default_kwargs
  train_func_args:
    gradient_checkpointing: true
    use_accelerate_gradaccum: true
    temperature: ${temperature}
    entropy_coef: 0.0
    kl_loss_coef: 0.0
    debug_enabled: True
    debug_log_path: "${oc.env:SCRATCH}/${experiment.name}/trainer_debugger"
  train_data_args:
    average_score_over_message: False

training:
  agents:
    alice:
      training_data_func_args:
        score_method: sum_rloo_scores
        score_method_kwargs:
          discount_factor: 1.0
    bob:
      training_data_func_args:
        score_method: sum_rloo_scores
        score_method_kwargs:
          discount_factor: 1.0
  llama:
    adapters:
      adapter_alice:
        train_func: train_reinforce_main
        <<: *default_kwargs
      adapter_bob:
        train_func: train_reinforce_main
        <<: *default_kwargs
