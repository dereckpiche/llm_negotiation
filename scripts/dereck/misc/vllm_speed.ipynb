{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vllm import *\n",
    " \n",
    "device0 = torch.device(\"cuda:0\")\n",
    "llm_agent1 = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", dtype=torch.bfloat16, enable_lora=True, max_model_len=13000, gpu_memory_utilization=0.45, device=device0)\n",
    "\n",
    "llm_agent2 = LLM(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", dtype=torch.bfloat16, enable_lora=True, max_model_len=13000, gpu_memory_utilization=0.45, device=device0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_games = 5\n",
    "parallel_games = 1\n",
    "initial_prompts = [ str(n) + \" Hi, \" for n in range(total_games) ]\n",
    "for i in range(0, int(total_games/parallel_games)):\n",
    "    prompts = initial_prompts[i*parallel_games: (i+1)*parallel_games]\n",
    "    print(prompts)\n",
    "    output1 = llm_agent1.generate(prompts, sampling_params=SamplingParams(skip_special_tokens=True, max_tokens=10))\n",
    "    print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
