defaults:
    - config.yaml

experiment:
    name: "trust_and_split"
    method: generate_and_train
    description: "Trust-and-Split negotiation game"
    nb_epochs: 10
    nb_matches_per_iteration: 32
    reinit_matches_each_it: true
    checkpoint_every_n_iterations: 25
    start_epoch: 0
    resume_experiment: true
    base_seed: 1001

# Top-level agent ids for convenience
agent_0_id: Alice
agent_1_id: Bob
agent_ids: ["Alice", "Bob"]

####################################################################################################
#                                           GENERATION
####################################################################################################

common_agent_kwargs: &common_agent_kwargs
    nb_messages_per_round: 1
    goal: "Maximize your total points over the whole game."

markov_games:
    runner_method_name: LinearRunner
    runner_kwargs: {}

    simulation_class_name: TrustAndSplitSimulation
    simulation_init_args:
        agent_ids: ${agent_ids}
        rounds_per_game: 3
        nb_messages_per_agent: 1
        max_coins: 10

    agents:
        0:
            agent_id: ${agent_0_id}
            agent_class_name: TrustAndSplitAgent
            policy_id: base_llm/agent_adapter
            init_kwargs:
                <<: *common_agent_kwargs

        1:
            agent_id: ${agent_1_id}
            agent_class_name: TrustAndSplitAgent
            policy_id: base_llm/agent_adapter
            init_kwargs:
                <<: *common_agent_kwargs

    # Optional: a log function name if you add one later
    # log_func: log_tas_match

    run_batched_matches_args:
        nb_parallel_matches: -1

temperature: 1.0

