defaults:
  - negotiation_game.yaml

experiment:
  name: "negotiation_game_faceoff_${now:%Y-%m-%d___%H-%M-%S}"
  # name: "${now:%Y-%m-%d___%H-%M-%S}_no_name" (having timestamp is good for debugging, but it is difficult to restart with preemption)
  description: "Agents facing off."
  nb_epochs: 1
  nb_matches_per_iteration: 256
  checkpoint_every_n_iterations: -1 # don't save checkpoint
  base_seed: 344

####################################################################################################
#                                           GENERATION
####################################################################################################

matches:
  max_length: 10
  continuation_prob: 1.0
  same_length_batch: True
  nb_matches_with_same_roundwise_utilities: 0
  log_func: dond_log_match
  stop_condition: game_over_condition
  stop_condition_kwargs: {}

  run_batched_matches_args:
    nb_parallel_matches: -1


  agents:
    Alice:
      kwargs:
        agent_name: "Alice"
        policy_id: "qwen/adapter_alice"
    Bob:
      kwargs:
        agent_name: "Bob"
        policy_id: "qwen/adapter_bob"

temperature: 0.7



models:
  qwen:
    init_args:
      vllm_params:
        gpu_memory_utilization: 0.9
      adapter_configs:
        adapter_alice:
          type: "lora"
          hf_server_import_kwargs:
            repo_id: LLMnegotiation/sum_of_rewards
            repo_type: model
            allow_patterns: ["seed_344/sp_adapter/model/*"]
          optimizer_method: "SGD"
          optimizer_kwargs: {}
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 64
            lora_alpha: 128
            lora_dropout: 0.0
            target_modules: "all-linear"

        adapter_bob:
          type: "lora"
          hf_server_import_kwargs:
            repo_id: LLMnegotiation/greedy_rl
            repo_type: model
            allow_patterns: ["seed_645/sp_adapter/model/*"]
          optimizer_method: "SGD"
          optimizer_kwargs: {}
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 64
            lora_alpha: 128
            lora_dropout: 0.0
            target_modules: "all-linear"
  # 4o:
  #   class: server_llm
  #   init_args:
  #     model_name: "gpt-4o"
  #     api_key: None
