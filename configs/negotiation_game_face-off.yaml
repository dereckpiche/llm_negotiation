defaults:
  - negotiation_game_fixed_manual.yaml

experiment:
  name: "negotiation_game_fixed_manual_faceoff_adv_align_rerun_temp1.0_nodiscountingaa_timedecay_usecurrstep_greedy"
  # name: "${now:%Y-%m-%d___%H-%M-%S}_no_name" (having timestamp is good for debugging, but it is difficult to restart with preemption)
  description: "Agents facing off."
  nb_epochs: 1
  nb_matches_per_iteration: 64
  checkpoint_every_n_iterations: -1 # don't save checkpoint
  base_seed: 344

####################################################################################################
#                                           GENERATION
####################################################################################################

matches:
  max_length: 20
  continuation_prob: 1.0
  same_length_batch: True
  nb_matches_with_same_roundwise_utilities: 64
  log_func: dond_log_match
  stop_condition: game_over_condition
  stop_condition_kwargs: {}

  run_batched_matches_args:
    nb_parallel_matches: -1


  agents:
    Alice:
      kwargs:
        agent_name: "Alice"
        policy_id: "qwen/adapter_alice"
    Bob:
      kwargs:
        agent_name: "Bob"
        policy_id: "qwen/adapter_bob"

temperature: 1.0



models:
  qwen:
    init_args:
      vllm_params:
        gpu_memory_utilization: 0.9
      adapter_configs:
        adapter_alice:
          type: "lora"
          # local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_adv_align_temp1.0_beta0.1_usecurrstep/seed_344/sp_adapter/model/
          # local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_greedyrl/seed_344/sp_adapter/model/
          local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_adv_align_rerun_temp1.0_nodiscountingaa_timedecay_usecurrstep/seed_344/sp_adapter/model/
          # hf_server_import_kwargs:
          #   repo_id: LLMnegotiation/sum_of_rewards
          #   repo_type: model
          #   allow_patterns: ["seed_344/sp_adapter/model/*"]
          optimizer_method: "SGD"
          optimizer_kwargs: {}
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 64
            lora_alpha: 128
            lora_dropout: 0.0
            target_modules: "all-linear"

        adapter_bob:
          type: "lora"
          local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_greedyrl/seed_344/sp_adapter/model/
          # local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_adv_align_temp1.0_beta0.1_usecurrstep/seed_344/sp_adapter/model/
          # local_import_adapter_path: /home/mila/m/mohammed.muqeeth/scratch/llm_negotiation/negotiation_game_fixed_manual_adv_align_temp1.0_nodiscountingaa_timedecay_usecurrstep/seed_344/sp_adapter/model/
          # hf_server_import_kwargs:
          #   repo_id: LLMnegotiation/greedy_rl
          #   repo_type: model
          #   allow_patterns: ["seed_645/sp_adapter/model/*"]
          optimizer_method: "SGD"
          optimizer_kwargs: {}
          lora_kwargs:
            task_type: "CAUSAL_LM"
            r: 64
            lora_alpha: 128
            lora_dropout: 0.0
            target_modules: "all-linear"
  # 4o:
  #   class: server_llm
  #   init_args:
  #     model_name: "gpt-4o"
  #     api_key: None
