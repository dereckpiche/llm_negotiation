# To quickly check if code still runs

defaults:
    - ipd.yaml

experiment:
    name: "ipd_${now:%Y-%m-%d___%H-%M-%S}_value_debug"
    nb_epochs: 10
    nb_matches_per_iteration: 16
    reinit_matches_each_it: true
    checkpoint_every_n_iterations: 1e5
    start_epoch: 0
    resume_experiment: true
    base_seed: 1000
    train: true

agent_0_id: Alice
agent_1_id: Bob
agent_ids: ["Alice", "Bob"]

markov_games:
    simulation_init_args:
        rounds_per_game: 10


temperature: 1.0

models:
    base_llm:
        class: LeanLocalLLM
        init_args:
            llm_id: base_llm
            model_name: "Qwen/Qwen2-0.5B" # Qwen/Qwen3-4B-Instruct-2507
            inference_backend: dummy
optimizers:
    agent_optimizer:
        module_pointer: ["base_llm", "agent_adapter"]
        optimizer_class_name: torch.optim.Adam
        init_args:
            lr: 1e-6
            weight_decay: 0.0

    critic_optimizer:
        module_pointer: agent_critic
        optimizer_class_name: torch.optim.Adam
        init_args:
            lr: 1e-4
            weight_decay: 0.0

trainers:
    agent_trainer:
        kwargs:
            use_gae: True
            entropy_coeff: 0.1
            entropy_topk: 20
            use_gae_lambda_annealing: True
            whiten_advantages: True
            whiten_advantages_time_step_wise: True
            gae_lambda_annealing_limit: 0.92
            gae_lambda_annealing_method: "sigmoid_annealing"
            gae_lambda_annealing_method_params: {temperature: 15}
            kl_coeff: 0.0
            gradient_clipping: 1.0
            mini_batch_size: 4
            use_gradient_checkpointing: True
            temperature: ${temperature}
            device: "cuda:0"
            enable_tokenwise_logging: True
